{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28093953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, 'C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4')\n",
    "# sys.path.insert(1, 'C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\crawler\\\\api\\crawler_config')\n",
    "warnings.filterwarnings('ignore')\n",
    "from crawler.api.crawler_config import CrawlerConfig\n",
    "from crawler.api.github_crawler import GithubCrawler\n",
    "import pycg\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import label_ranking_average_precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "every-zoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/results_csv.csv\n",
      "                                            full_name  star_count language  \\\n",
      "0                           Snawoot_workua-cv-updater           3   python   \n",
      "1                                krax1337_bts-resumes           3   python   \n",
      "2                 wangwenhaoxiaotie_Document_classify           3   python   \n",
      "3           AimoreRRD_Reinforcement-Learning-Research           3   python   \n",
      "4                seolhokim_BipedalWalker-BranchingDQN           3   python   \n",
      "5                                     benibienz_TAMER           3   python   \n",
      "6                                      codebasic_pyko           3   python   \n",
      "7                 carrliitos_NLPInformationExtraction           3   python   \n",
      "8                               pemagrg1_Japanese-NLP           3   python   \n",
      "9                               LehiChiang_CV_toolkit           3   python   \n",
      "10                      gaoyuanliang_cheque_detection           3   python   \n",
      "11                                  hackcha_deepcolor           2   python   \n",
      "12                              gitmirgut_bb_stitcher           2   python   \n",
      "13          hklchung_GAN-GenerativeAdversarialNetwork           2   python   \n",
      "14                        Snawoot_rabotaua-cv-updater           2   python   \n",
      "15                                    gomahajan_rllib           3   python   \n",
      "16                         Adamantios_Atari-Skiing-RL           3   python   \n",
      "17                                nicehiro_puck-world           3   python   \n",
      "18                             CUN-bjy_gym-ddpg-keras           3   python   \n",
      "19                              FixedThink_RocketCogs           2   python   \n",
      "20                       FLHonker_Self-Driving-Car-RL           2   python   \n",
      "21                                       naetherm_NLP           3   python   \n",
      "22             dhk3136_summarization-bert-vs-baseline           3   python   \n",
      "23                              KBNLresearch_multiNER           3   python   \n",
      "24                          phamdinhha_end-to-end-qna           3   python   \n",
      "25                                  iafisher_montague           3   python   \n",
      "26  pritomsaha_Context-sensitive-Bangla-spell-checker           3   python   \n",
      "\n",
      "                                               topics  \\\n",
      "0   ['cv', 'workflow-automation', 'web-automation'...   \n",
      "1               ['python', 'django', 'parsing', 'cv']   \n",
      "2                           ['cv', 'medical-receipt']   \n",
      "3   ['game', 'learning', 'research', 'reinforcemen...   \n",
      "4   ['reinforcement-learning', 'q-learning', 'pyto...   \n",
      "5                    ['reinforcement-learning', 'rl']   \n",
      "6   ['python', 'nlp', 'machine-learning', 'natural...   \n",
      "7   ['nlp', 'text-extraction', 'information-extrac...   \n",
      "8   ['python', 'nlp', 'japanese', 'japanese-nlp', ...   \n",
      "9                                   ['toolkit', 'cv']   \n",
      "10  ['deep-learning', 'cv', 'xception-model', 'che...   \n",
      "11                                      ['cv', 'gan']   \n",
      "12      ['computer-vision', 'cv', 'stitching', 'cv2']   \n",
      "13  ['tensorflow', 'fake-images', 'cv', 'pytorch',...   \n",
      "14  ['cv', 'workflow-automation', 'web-automation'...   \n",
      "15              ['openai-gym', 'rl', 'mujoco', 'a2c']   \n",
      "16  ['agent', 'reinforcement-learning', 'openai-gy...   \n",
      "17                  ['gym', 'rl', 'env', 'puckworld']   \n",
      "18  ['reinforcement-learning', 'keras', 'openai-gy...   \n",
      "19  ['red-discordbot', 'rl', 'discord-py', 'rocket...   \n",
      "20                           ['car', 'driving', 'rl']   \n",
      "21  ['python', 'nlp', 'machine-learning', 'natural...   \n",
      "22  ['python', 'nlp', 'metrics', 'glue', 'jupyter-...   \n",
      "23  ['nlp', 'natural-language-processing', 'patter...   \n",
      "24  ['nlp', 'question-answering', 'nlp-machine-lea...   \n",
      "25                        ['nlp', 'formal-semantics']   \n",
      "26        ['nlp', 'spellcheck', 'word2vec', 'bangla']   \n",
      "\n",
      "                                      featured_topics  \\\n",
      "0                                  ['Computervision']   \n",
      "1   ['Python', 'Django', 'Parsing', 'Computervision']   \n",
      "2                                  ['Computervision']   \n",
      "3   ['Reinforcementlearning', 'Reinforcementlearni...   \n",
      "4   ['Reinforcementlearning', 'Reinforcementlearni...   \n",
      "5   ['Reinforcementlearning', 'Reinforcementlearni...   \n",
      "6   ['Python', 'Naturallanguageprocessing', 'Machi...   \n",
      "7                       ['Naturallanguageprocessing']   \n",
      "8             ['Python', 'Naturallanguageprocessing']   \n",
      "9                                  ['Computervision']   \n",
      "10                 ['Deeplearning', 'Computervision']   \n",
      "11                                 ['Computervision']   \n",
      "12               ['Computervision', 'Computervision']   \n",
      "13                   ['Tensorflow', 'Computervision']   \n",
      "14                                 ['Computervision']   \n",
      "15                          ['Reinforcementlearning']   \n",
      "16  ['Reinforcementlearning', 'Reinforcementlearni...   \n",
      "17                          ['Reinforcementlearning']   \n",
      "18  ['Reinforcementlearning', 'Reinforcementlearni...   \n",
      "19                          ['Reinforcementlearning']   \n",
      "20                          ['Reinforcementlearning']   \n",
      "21  ['Python', 'Naturallanguageprocessing', 'Machi...   \n",
      "22  ['Python', 'Naturallanguageprocessing', 'Jupyt...   \n",
      "23  ['Naturallanguageprocessing', 'Naturallanguage...   \n",
      "24                      ['Naturallanguageprocessing']   \n",
      "25                      ['Naturallanguageprocessing']   \n",
      "26                      ['Naturallanguageprocessing']   \n",
      "\n",
      "                      added_on  \\\n",
      "0   2021-09-27 16:19:56.499875   \n",
      "1   2021-09-27 16:20:04.804268   \n",
      "2   2021-09-27 16:20:26.836244   \n",
      "3   2021-09-27 16:20:49.836386   \n",
      "4   2021-09-27 16:20:58.412228   \n",
      "5   2021-09-27 16:21:04.561668   \n",
      "6   2021-09-27 16:21:25.477992   \n",
      "7   2021-09-27 16:21:36.040567   \n",
      "8   2021-09-27 16:21:55.110155   \n",
      "9   2021-09-27 17:46:22.347674   \n",
      "10  2021-09-27 17:46:40.433763   \n",
      "11  2021-09-27 17:46:46.940723   \n",
      "12  2021-09-27 17:47:02.377327   \n",
      "13  2021-09-27 17:47:24.159883   \n",
      "14  2021-09-27 17:47:33.963575   \n",
      "15  2021-09-27 17:47:47.922837   \n",
      "16  2021-09-27 17:47:59.109784   \n",
      "17  2021-09-27 17:48:18.776332   \n",
      "18  2021-09-27 17:48:31.709437   \n",
      "19  2021-09-27 17:48:45.658768   \n",
      "20  2021-09-27 17:48:58.573931   \n",
      "21  2021-09-27 17:49:16.334574   \n",
      "22  2021-09-27 17:50:05.519045   \n",
      "23  2021-09-27 17:50:13.387287   \n",
      "24  2021-09-27 17:50:22.572888   \n",
      "25  2021-09-27 17:50:35.901950   \n",
      "26  2021-09-27 17:50:53.386911   \n",
      "\n",
      "                                            clone_url  \\\n",
      "0    https://github.com/Snawoot/workua-cv-updater.git   \n",
      "1         https://github.com/krax1337/bts-resumes.git   \n",
      "2   https://github.com/wangwenhaoxiaotie/Document_...   \n",
      "3   https://github.com/AimoreRRD/Reinforcement-Lea...   \n",
      "4   https://github.com/seolhokim/BipedalWalker-Bra...   \n",
      "5              https://github.com/benibienz/TAMER.git   \n",
      "6               https://github.com/codebasic/pyko.git   \n",
      "7   https://github.com/carrliitos/NLPInformationEx...   \n",
      "8        https://github.com/pemagrg1/Japanese-NLP.git   \n",
      "9        https://github.com/LehiChiang/CV_toolkit.git   \n",
      "10  https://github.com/gaoyuanliang/cheque_detecti...   \n",
      "11           https://github.com/hackcha/deepcolor.git   \n",
      "12       https://github.com/gitmirgut/bb_stitcher.git   \n",
      "13  https://github.com/hklchung/GAN-GenerativeAdve...   \n",
      "14  https://github.com/Snawoot/rabotaua-cv-updater...   \n",
      "15             https://github.com/gomahajan/rllib.git   \n",
      "16  https://github.com/Adamantios/Atari-Skiing-RL.git   \n",
      "17         https://github.com/nicehiro/puck-world.git   \n",
      "18      https://github.com/CUN-bjy/gym-ddpg-keras.git   \n",
      "19       https://github.com/FixedThink/RocketCogs.git   \n",
      "20  https://github.com/FLHonker/Self-Driving-Car-R...   \n",
      "21                https://github.com/naetherm/NLP.git   \n",
      "22  https://github.com/dhk3136/summarization-bert-...   \n",
      "23       https://github.com/KBNLresearch/multiNER.git   \n",
      "24   https://github.com/phamdinhha/end-to-end-qna.git   \n",
      "25           https://github.com/iafisher/montague.git   \n",
      "26  https://github.com/pritomsaha/Context-sensitiv...   \n",
      "\n",
      "                 last_modified  \n",
      "0   2021-09-27 16:19:56.499881  \n",
      "1   2021-09-27 16:20:04.804274  \n",
      "2   2021-09-27 16:20:26.836249  \n",
      "3   2021-09-27 16:20:49.836391  \n",
      "4   2021-09-27 16:20:58.412232  \n",
      "5   2021-09-27 16:21:04.561673  \n",
      "6   2021-09-27 16:21:25.477997  \n",
      "7   2021-09-27 16:21:36.040571  \n",
      "8   2021-09-27 16:21:55.110160  \n",
      "9   2021-09-27 17:46:22.347679  \n",
      "10  2021-09-27 17:46:40.433768  \n",
      "11  2021-09-27 17:46:46.940727  \n",
      "12  2021-09-27 17:47:02.377332  \n",
      "13  2021-09-27 17:47:24.159887  \n",
      "14  2021-09-27 17:47:33.963580  \n",
      "15  2021-09-27 17:47:47.922841  \n",
      "16  2021-09-27 17:47:59.109788  \n",
      "17  2021-09-27 17:48:18.776337  \n",
      "18  2021-09-27 17:48:31.709441  \n",
      "19  2021-09-27 17:48:45.658772  \n",
      "20  2021-09-27 17:48:58.573935  \n",
      "21  2021-09-27 17:49:16.334578  \n",
      "22  2021-09-27 17:50:05.519050  \n",
      "23  2021-09-27 17:50:13.387291  \n",
      "24  2021-09-27 17:50:22.572893  \n",
      "25  2021-09-27 17:50:35.901954  \n",
      "26  2021-09-27 17:50:53.386915  \n",
      "    Unnamed: 0                                          full_name  star_count  \\\n",
      "0            0                          Snawoot_workua-cv-updater           3   \n",
      "1            1                               krax1337_bts-resumes           3   \n",
      "2            2                wangwenhaoxiaotie_Document_classify           3   \n",
      "3            3          AimoreRRD_Reinforcement-Learning-Research           3   \n",
      "4            4               seolhokim_BipedalWalker-BranchingDQN           3   \n",
      "5            5                                    benibienz_TAMER           3   \n",
      "6            6                                     codebasic_pyko           3   \n",
      "7            7                carrliitos_NLPInformationExtraction           3   \n",
      "8            8                              pemagrg1_Japanese-NLP           3   \n",
      "9            9                              LehiChiang_CV_toolkit           3   \n",
      "10          10                      gaoyuanliang_cheque_detection           3   \n",
      "11          11                                  hackcha_deepcolor           2   \n",
      "12          12                              gitmirgut_bb_stitcher           2   \n",
      "13          13          hklchung_GAN-GenerativeAdversarialNetwork           2   \n",
      "14          14                        Snawoot_rabotaua-cv-updater           2   \n",
      "15          15                                    gomahajan_rllib           3   \n",
      "16          16                         Adamantios_Atari-Skiing-RL           3   \n",
      "17          17                                nicehiro_puck-world           3   \n",
      "18          18                             CUN-bjy_gym-ddpg-keras           3   \n",
      "19          19                              FixedThink_RocketCogs           2   \n",
      "20          20                       FLHonker_Self-Driving-Car-RL           2   \n",
      "21          21                                       naetherm_NLP           3   \n",
      "22          22             dhk3136_summarization-bert-vs-baseline           3   \n",
      "23          23                              KBNLresearch_multiNER           3   \n",
      "24          24                          phamdinhha_end-to-end-qna           3   \n",
      "25          25                                  iafisher_montague           3   \n",
      "26          26  pritomsaha_Context-sensitive-Bangla-spell-checker           3   \n",
      "\n",
      "   language                                             topics  \\\n",
      "0    python  ['cv', 'workflow-automation', 'web-automation'...   \n",
      "1    python              ['python', 'django', 'parsing', 'cv']   \n",
      "2    python                          ['cv', 'medical-receipt']   \n",
      "3    python  ['game', 'learning', 'research', 'reinforcemen...   \n",
      "4    python  ['reinforcement-learning', 'q-learning', 'pyto...   \n",
      "5    python                   ['reinforcement-learning', 'rl']   \n",
      "6    python  ['python', 'nlp', 'machine-learning', 'natural...   \n",
      "7    python  ['nlp', 'text-extraction', 'information-extrac...   \n",
      "8    python  ['python', 'nlp', 'japanese', 'japanese-nlp', ...   \n",
      "9    python                                  ['toolkit', 'cv']   \n",
      "10   python  ['deep-learning', 'cv', 'xception-model', 'che...   \n",
      "11   python                                      ['cv', 'gan']   \n",
      "12   python      ['computer-vision', 'cv', 'stitching', 'cv2']   \n",
      "13   python  ['tensorflow', 'fake-images', 'cv', 'pytorch',...   \n",
      "14   python  ['cv', 'workflow-automation', 'web-automation'...   \n",
      "15   python              ['openai-gym', 'rl', 'mujoco', 'a2c']   \n",
      "16   python  ['agent', 'reinforcement-learning', 'openai-gy...   \n",
      "17   python                  ['gym', 'rl', 'env', 'puckworld']   \n",
      "18   python  ['reinforcement-learning', 'keras', 'openai-gy...   \n",
      "19   python  ['red-discordbot', 'rl', 'discord-py', 'rocket...   \n",
      "20   python                           ['car', 'driving', 'rl']   \n",
      "21   python  ['python', 'nlp', 'machine-learning', 'natural...   \n",
      "22   python  ['python', 'nlp', 'metrics', 'glue', 'jupyter-...   \n",
      "23   python  ['nlp', 'natural-language-processing', 'patter...   \n",
      "24   python  ['nlp', 'question-answering', 'nlp-machine-lea...   \n",
      "25   python                        ['nlp', 'formal-semantics']   \n",
      "26   python        ['nlp', 'spellcheck', 'word2vec', 'bangla']   \n",
      "\n",
      "                                      featured_topics  \\\n",
      "0                                  ['Computervision']   \n",
      "1   ['Python', 'Django', 'Parsing', 'Computervision']   \n",
      "2                                  ['Computervision']   \n",
      "3   ['Reinforcementlearning', 'Reinforcementlearni...   \n",
      "4   ['Reinforcementlearning', 'Reinforcementlearni...   \n",
      "5   ['Reinforcementlearning', 'Reinforcementlearni...   \n",
      "6   ['Python', 'Naturallanguageprocessing', 'Machi...   \n",
      "7                       ['Naturallanguageprocessing']   \n",
      "8             ['Python', 'Naturallanguageprocessing']   \n",
      "9                                  ['Computervision']   \n",
      "10                 ['Deeplearning', 'Computervision']   \n",
      "11                                 ['Computervision']   \n",
      "12               ['Computervision', 'Computervision']   \n",
      "13                   ['Tensorflow', 'Computervision']   \n",
      "14                                 ['Computervision']   \n",
      "15                          ['Reinforcementlearning']   \n",
      "16  ['Reinforcementlearning', 'Reinforcementlearni...   \n",
      "17                          ['Reinforcementlearning']   \n",
      "18  ['Reinforcementlearning', 'Reinforcementlearni...   \n",
      "19                          ['Reinforcementlearning']   \n",
      "20                          ['Reinforcementlearning']   \n",
      "21  ['Python', 'Naturallanguageprocessing', 'Machi...   \n",
      "22  ['Python', 'Naturallanguageprocessing', 'Jupyt...   \n",
      "23  ['Naturallanguageprocessing', 'Naturallanguage...   \n",
      "24                      ['Naturallanguageprocessing']   \n",
      "25                      ['Naturallanguageprocessing']   \n",
      "26                      ['Naturallanguageprocessing']   \n",
      "\n",
      "                      added_on  \\\n",
      "0   2021-09-27 16:19:56.499875   \n",
      "1   2021-09-27 16:20:04.804268   \n",
      "2   2021-09-27 16:20:26.836244   \n",
      "3   2021-09-27 16:20:49.836386   \n",
      "4   2021-09-27 16:20:58.412228   \n",
      "5   2021-09-27 16:21:04.561668   \n",
      "6   2021-09-27 16:21:25.477992   \n",
      "7   2021-09-27 16:21:36.040567   \n",
      "8   2021-09-27 16:21:55.110155   \n",
      "9   2021-09-27 17:46:22.347674   \n",
      "10  2021-09-27 17:46:40.433763   \n",
      "11  2021-09-27 17:46:46.940723   \n",
      "12  2021-09-27 17:47:02.377327   \n",
      "13  2021-09-27 17:47:24.159883   \n",
      "14  2021-09-27 17:47:33.963575   \n",
      "15  2021-09-27 17:47:47.922837   \n",
      "16  2021-09-27 17:47:59.109784   \n",
      "17  2021-09-27 17:48:18.776332   \n",
      "18  2021-09-27 17:48:31.709437   \n",
      "19  2021-09-27 17:48:45.658768   \n",
      "20  2021-09-27 17:48:58.573931   \n",
      "21  2021-09-27 17:49:16.334574   \n",
      "22  2021-09-27 17:50:05.519045   \n",
      "23  2021-09-27 17:50:13.387287   \n",
      "24  2021-09-27 17:50:22.572888   \n",
      "25  2021-09-27 17:50:35.901950   \n",
      "26  2021-09-27 17:50:53.386911   \n",
      "\n",
      "                                            clone_url  \\\n",
      "0    https://github.com/Snawoot/workua-cv-updater.git   \n",
      "1         https://github.com/krax1337/bts-resumes.git   \n",
      "2   https://github.com/wangwenhaoxiaotie/Document_...   \n",
      "3   https://github.com/AimoreRRD/Reinforcement-Lea...   \n",
      "4   https://github.com/seolhokim/BipedalWalker-Bra...   \n",
      "5              https://github.com/benibienz/TAMER.git   \n",
      "6               https://github.com/codebasic/pyko.git   \n",
      "7   https://github.com/carrliitos/NLPInformationEx...   \n",
      "8        https://github.com/pemagrg1/Japanese-NLP.git   \n",
      "9        https://github.com/LehiChiang/CV_toolkit.git   \n",
      "10  https://github.com/gaoyuanliang/cheque_detecti...   \n",
      "11           https://github.com/hackcha/deepcolor.git   \n",
      "12       https://github.com/gitmirgut/bb_stitcher.git   \n",
      "13  https://github.com/hklchung/GAN-GenerativeAdve...   \n",
      "14  https://github.com/Snawoot/rabotaua-cv-updater...   \n",
      "15             https://github.com/gomahajan/rllib.git   \n",
      "16  https://github.com/Adamantios/Atari-Skiing-RL.git   \n",
      "17         https://github.com/nicehiro/puck-world.git   \n",
      "18      https://github.com/CUN-bjy/gym-ddpg-keras.git   \n",
      "19       https://github.com/FixedThink/RocketCogs.git   \n",
      "20  https://github.com/FLHonker/Self-Driving-Car-R...   \n",
      "21                https://github.com/naetherm/NLP.git   \n",
      "22  https://github.com/dhk3136/summarization-bert-...   \n",
      "23       https://github.com/KBNLresearch/multiNER.git   \n",
      "24   https://github.com/phamdinhha/end-to-end-qna.git   \n",
      "25           https://github.com/iafisher/montague.git   \n",
      "26  https://github.com/pritomsaha/Context-sensitiv...   \n",
      "\n",
      "                 last_modified  \n",
      "0   2021-09-27 16:19:56.499881  \n",
      "1   2021-09-27 16:20:04.804274  \n",
      "2   2021-09-27 16:20:26.836249  \n",
      "3   2021-09-27 16:20:49.836391  \n",
      "4   2021-09-27 16:20:58.412232  \n",
      "5   2021-09-27 16:21:04.561673  \n",
      "6   2021-09-27 16:21:25.477997  \n",
      "7   2021-09-27 16:21:36.040571  \n",
      "8   2021-09-27 16:21:55.110160  \n",
      "9   2021-09-27 17:46:22.347679  \n",
      "10  2021-09-27 17:46:40.433768  \n",
      "11  2021-09-27 17:46:46.940727  \n",
      "12  2021-09-27 17:47:02.377332  \n",
      "13  2021-09-27 17:47:24.159887  \n",
      "14  2021-09-27 17:47:33.963580  \n",
      "15  2021-09-27 17:47:47.922841  \n",
      "16  2021-09-27 17:47:59.109788  \n",
      "17  2021-09-27 17:48:18.776337  \n",
      "18  2021-09-27 17:48:31.709441  \n",
      "19  2021-09-27 17:48:45.658772  \n",
      "20  2021-09-27 17:48:58.573935  \n",
      "21  2021-09-27 17:49:16.334578  \n",
      "22  2021-09-27 17:50:05.519050  \n",
      "23  2021-09-27 17:50:13.387291  \n",
      "24  2021-09-27 17:50:22.572893  \n",
      "25  2021-09-27 17:50:35.901954  \n",
      "26  2021-09-27 17:50:53.386915  \n"
     ]
    }
   ],
   "source": [
    "topics = ['CV','RL','NLP']\n",
    "proxies = {'http': 'http://proxy.jpmchase.net:10443','https':'http://proxy.jpmchase.net:10443'}\n",
    "crawler_config = CrawlerConfig('dataset/', 3, 0, False,proxies=proxies)\n",
    "crawler = GithubCrawler(crawler_config)\n",
    "crawler.scrap(topics, limit=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bound-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics=crawler.match_topics_to_featured(['CV','RL','NLP'],0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dependent-details",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\Topical\\distilbert-base-uncased"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\Topical\\graphcodebert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\Topical\\graphcodebert-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\Topical\\distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\n",
      "0it [00:00, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "\n",
      "1it [00:04,  4.63s/it]\n",
      "2it [00:29, 10.61s/it]\n",
      "3it [00:35,  9.45s/it]\n",
      "4it [00:45,  9.38s/it]\n",
      "5it [00:52,  8.88s/it]\n",
      "6it [00:59,  8.07s/it]\n",
      "7it [01:03,  6.96s/it]\n",
      "8it [01:28, 12.45s/it]\n",
      "9it [01:38, 11.58s/it]\n",
      "10it [01:54, 13.00s/it]\n",
      "11it [02:00, 10.77s/it]\n",
      "12it [02:23, 14.59s/it]\n",
      "13it [02:51, 18.70s/it]\n",
      "14it [03:06, 17.53s/it]\n",
      "15it [03:10, 13.43s/it]\n",
      "17it [03:30, 12.42s/it]\n",
      "18it [03:41, 12.01s/it]\n",
      "19it [03:59, 13.59s/it]\n",
      "20it [04:19, 15.53s/it]\n",
      "21it [04:26, 13.02s/it]\n",
      "22it [04:55, 18.00s/it]\n",
      "23it [05:04, 15.11s/it]\n",
      "24it [05:06, 11.19s/it]\n",
      "25it [05:25, 13.68s/it]\n",
      "26it [05:51, 17.44s/it]\n",
      "27it [06:18, 20.22s/it]\n",
      "27it [06:18, 14.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Taking dataset from:  C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\n",
      "27\n",
      "27\n",
      "embed index dataset: 0\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Snawoot_workua-cv-updater\\\\setup.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Snawoot_workua-cv-updater\\\\workua_cv_updater\\\\__main__.py']\n",
      "from os import path\n",
      "\n",
      "from setuptools import setup\n",
      "\n",
      "this_directory = path.abspath(path.dirname(__file__))\n",
      "with open(path.join(this_directory, 'README.md'), encoding='utf-8') as f:\n",
      "    long_description = f.read()\n",
      "\n",
      "setup(name='workua_cv_updater',\n",
      "      version='0.1.1',\n",
      "      description='Tool which updates your CV on work.ua',\n",
      "      url='https://github.com/danilasokolov0103/CV_updater',\n",
      "      author='Danila Sokolov',\n",
      "      author_email='danilasokolov0103@gmail.com',\n",
      "      packages=['workua_cv_updater'],\n",
      "      python_requires='>=3.5.3',\n",
      "      setup_requires=[\n",
      "          'wheel',\n",
      "      ],\n",
      "      install_requires=[\n",
      "          'selenium>=3.141.0',\n",
      "          'webdriver-manager>=2.5.1',\n",
      "      ],\n",
      "      entry_points={\n",
      "          'console_scripts': [\n",
      "              'workua-cv-updater=workua_cv_updater.__main__:main',\n",
      "          ],\n",
      "      },\n",
      "      classifiers=[\n",
      "          \"Programming Language :: Python :: 3\",\n",
      "          \"License :: Public Domain\",\n",
      "          \"Operating System :: OS Independent\",\n",
      "          \"Development Status :: 4 - Beta\",\n",
      "          \"Environment :: Console\",\n",
      "          \"Intended Audience :: End Users/Desktop\",\n",
      "          \"Natural Language :: English\",\n",
      "          \"Topic :: Office/Business\",\n",
      "          \"Topic :: Other/Nonlisted Topic\",\n",
      "      ],\n",
      "      long_description=long_description,\n",
      "      long_description_content_type='text/markdown',\n",
      "      zip_safe=True)\n",
      "\n",
      "Output: {'setup': ['setuptools.setup', '<builtin>.open', 'os.path.join', 'os.path.abspath', 'os.path.dirname'], 'os.path.dirname': [], 'os.path.abspath': [], 'os.path.join': [], '<builtin>.open': [], 'setuptools.setup': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Snawoot_workua-cv-updater\\setup.py\n",
      "[('setup', 'setuptools setup'), ('setup', 'os path join'), ('setup', 'os path abspath'), ('setup', 'os path dirname')]\n",
      "0\n",
      "found files: []\n",
      "#!/usr/bin/env python3\n",
      "\n",
      "import logging\n",
      "import argparse\n",
      "import enum\n",
      "import os\n",
      "import os.path\n",
      "import sqlite3\n",
      "import signal\n",
      "from time import sleep, time, ctime, localtime, strftime\n",
      "from random import randrange, random\n",
      "import collections\n",
      "from heapq import merge\n",
      "from contextlib import contextmanager\n",
      "import json\n",
      "\n",
      "from selenium import webdriver\n",
      "from selenium.webdriver.chrome.options import Options\n",
      "from selenium.webdriver.common.by import By\n",
      "from selenium.webdriver.common.action_chains import ActionChains\n",
      "from selenium.webdriver.support.ui import WebDriverWait\n",
      "from selenium.webdriver.support import expected_conditions as EC\n",
      "from selenium.common.exceptions import (TimeoutException,\n",
      "                                        StaleElementReferenceException,\n",
      "                                        NoSuchElementException,\n",
      "                                        ElementClickInterceptedException,\n",
      "                                        WebDriverException)\n",
      "from webdriver_manager.chrome import ChromeDriverManager\n",
      "from webdriver_manager.utils import ChromeType\n",
      "\n",
      "RESUME_LIST_URL = \"https://www.work.ua/ru/jobseeker/my/resumes/\"\n",
      "RESUME_LIST_URL_PATTERN = r\"^https://www\\.work\\.ua/(ru/)?jobseeker/my/resumes/?$\"\n",
      "LOGIN_URL = \"https://www.work.ua/jobseeker/login/\"\n",
      "POST_LOGIN_URL_PATTERN = r\"^https://www\\.work\\.ua/(ru/)?jobseeker/my/?$\"\n",
      "CREATE_URL_PATTERN = r\"^https://www.work.ua/(ru/)?jobseeker/my/resumes/create/?(\\?.*)?$\"\n",
      "UPDATE_BUTTON_XPATH = \"//a[contains(@href, '/update/expire_date')]\"\n",
      "CREATE_BUTTON_XPATH = \"//a[contains(@href, '/jobseeker/my/resumes/create')]\"\n",
      "UPDATE_INTERVAL = 7 * 24 * 3600\n",
      "UPDATE_INTERVAL_MIN_DRIFT = 10\n",
      "UPDATE_INTERVAL_MAX_DRIFT = 60\n",
      "SESSION_REFRESH_INTERVAL = 1 * 3600\n",
      "SESSION_REFRESH_INTERVAL_MIN_DRIFT = 10\n",
      "SESSION_REFRESH_INTERVAL_MAX_DRIFT = 60\n",
      "MANUAL_LOGIN_TIMEOUT = 3600\n",
      "REFRESH_WAIT = 10\n",
      "\n",
      "DB_INIT = [\n",
      "    \"CREATE TABLE IF NOT EXISTS update_ts (\\n\"\n",
      "    \"name TEXT PRIMARY KEY,\\n\"\n",
      "    \"value REAL NOT NULL DEFAULT 0)\\n\"\n",
      "]\n",
      "\n",
      "def wall_clock_wait(when, precision=1.):\n",
      "    \"\"\" Sleep variation which is doesn't increases\n",
      "    sleep duration when computer enters suspend/hybernation\n",
      "    \"\"\"\n",
      "    while time() < when:\n",
      "        sleep(precision)\n",
      "\n",
      "def setup_logger(name, verbosity):\n",
      "    logger = logging.getLogger(name)\n",
      "    logger.setLevel(verbosity)\n",
      "    handler = logging.StreamHandler()\n",
      "    handler.setLevel(verbosity)\n",
      "    handler.setFormatter(logging.Formatter(\"%(asctime)s \"\n",
      "                                           \"%(levelname)-8s \"\n",
      "                                           \"%(name)s: %(message)s\",\n",
      "                                           \"%Y-%m-%d %H:%M:%S\"))\n",
      "    logger.addHandler(handler)\n",
      "    return logger\n",
      "\n",
      "class LogLevel(enum.IntEnum):\n",
      "    debug = logging.DEBUG\n",
      "    info = logging.INFO\n",
      "    warn = logging.WARN\n",
      "    error = logging.ERROR\n",
      "    fatal = logging.FATAL\n",
      "    crit = logging.CRITICAL\n",
      "\n",
      "    def __str__(self):\n",
      "        return self.name\n",
      "\n",
      "class Command(enum.Enum):\n",
      "    login = 1\n",
      "    update = 2\n",
      "\n",
      "    def __str__(self):\n",
      "        return self.name\n",
      "\n",
      "class BrowserType(enum.Enum):\n",
      "    chrome = ChromeType.GOOGLE\n",
      "    chromium = ChromeType.CHROMIUM\n",
      "\n",
      "    def __str__(self):\n",
      "        return self.name\n",
      "\n",
      "class ScheduledEvent(enum.Enum):\n",
      "    REFRESH = 1\n",
      "    UPDATE = 2\n",
      "\n",
      "ScheduleEntry = collections.namedtuple('ScheduleEntry', ('when', 'what'))\n",
      "\n",
      "def update(browser, timeout):\n",
      "    logger = logging.getLogger(\"UPDATE\")\n",
      "    browser.get(RESUME_LIST_URL)\n",
      "    visited_urls = set()\n",
      "    while True:\n",
      "        for elem in browser.find_elements_by_xpath(UPDATE_BUTTON_XPATH):\n",
      "            href = elem.get_attribute(\"href\")\n",
      "            logger.debug(\"Update link href = %s\", repr(href))\n",
      "            if href in visited_urls:\n",
      "                continue\n",
      "            sleep(1 + 2 * random())\n",
      "            elem.click()\n",
      "            visited_urls.add(href)\n",
      "            logger.debug(\"Clicked!\")\n",
      "            WebDriverWait(browser, timeout).until(\n",
      "                EC.staleness_of(elem)\n",
      "            )\n",
      "            WebDriverWait(browser, timeout).until(\n",
      "                EC.url_matches(RESUME_LIST_URL_PATTERN)\n",
      "            )\n",
      "            break\n",
      "        else:\n",
      "            break\n",
      "    logger.info('Updated!')\n",
      "\n",
      "def login(browser, timeout):\n",
      "    logger = logging.getLogger(\"LOGIN\")\n",
      "    browser.get(LOGIN_URL)\n",
      "    WebDriverWait(browser, timeout).until(\n",
      "        EC.url_matches(POST_LOGIN_URL_PATTERN)\n",
      "    )\n",
      "    sleep(REFRESH_WAIT)\n",
      "    logger.info('Successfully logged in!')\n",
      "\n",
      "def refresh(browser, timeout):\n",
      "    logger = logging.getLogger(\"REFRESH\")\n",
      "    browser.get(RESUME_LIST_URL)\n",
      "    elem = WebDriverWait(browser, timeout).until(\n",
      "        EC.visibility_of_element_located((By.XPATH, CREATE_BUTTON_XPATH))\n",
      "    )\n",
      "    elem.click()\n",
      "    WebDriverWait(browser, timeout).until(\n",
      "        EC.url_matches(CREATE_URL_PATTERN)\n",
      "    )\n",
      "    sleep(REFRESH_WAIT)\n",
      "    logger.info('Session refreshed')\n",
      "\n",
      "def parse_args():\n",
      "    def check_loglevel(arg):\n",
      "        try:\n",
      "            return LogLevel[arg]\n",
      "        except (IndexError, KeyError):\n",
      "            raise argparse.ArgumentTypeError(\"%s is not valid loglevel\" % (repr(arg),))\n",
      "\n",
      "    def check_command(arg):\n",
      "        try:\n",
      "            return Command[arg]\n",
      "        except (IndexError, KeyError):\n",
      "            raise argparse.ArgumentTypeError(\"%s is not valid command\" % (repr(arg),))\n",
      "\n",
      "    def check_browser_type(arg):\n",
      "        try:\n",
      "            return BrowserType[arg]\n",
      "        except (IndexError, KeyError):\n",
      "            raise argparse.ArgumentTypeError(\"%s is not valid browser type\" % (repr(arg),))\n",
      "\n",
      "    def check_positive_float(arg):\n",
      "        def fail():\n",
      "            raise argparse.ArgumentTypeError(\"%s is not valid positive float\" % (repr(arg),))\n",
      "        try:\n",
      "            fvalue = float(arg)\n",
      "        except ValueError:\n",
      "            fail()\n",
      "        if fvalue <= 0:\n",
      "            fail()\n",
      "        return fvalue\n",
      "\n",
      "    parser = argparse.ArgumentParser(\n",
      "        description=\"Python script to update your CV\",\n",
      "        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
      "    parser.add_argument(\"-t\", \"--timeout\",\n",
      "                        help=\"webdriver wait timeout\",\n",
      "                        type=check_positive_float,\n",
      "                        default=10.)\n",
      "    parser.add_argument(\"-b\", \"--browser\",\n",
      "                        help=\"browser type\",\n",
      "                        type=check_browser_type,\n",
      "                        choices=BrowserType,\n",
      "                        default=BrowserType.chromium)\n",
      "    parser.add_argument(\"-v\", \"--verbosity\",\n",
      "                        help=\"logging verbosity\",\n",
      "                        type=check_loglevel,\n",
      "                        choices=LogLevel,\n",
      "                        default=LogLevel.info)\n",
      "    parser.add_argument(\"cmd\", help=\"command\",\n",
      "                        type=check_command,\n",
      "                        choices=Command)\n",
      "    parser.add_argument(\"-d\", \"--data-dir\",\n",
      "                        default=os.path.join(os.path.expanduser(\"~\"),\n",
      "                                             '.config',\n",
      "                                             'workua-cv-updater'),\n",
      "                        help=\"application datadir location\",\n",
      "                        metavar=\"FILE\")\n",
      "    return parser.parse_args()\n",
      "\n",
      "class BrowserFactory:\n",
      "    def __init__(self, profile_dir, screenshot_dir, browser_type, headless=True):\n",
      "        chrome_options = Options()\n",
      "        # option below causes webdriver process remaining in memory\n",
      "        # chrome_options.add_argument('--no-sandbox')\n",
      "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
      "        chrome_options.add_argument('--disable-gpu')\n",
      "        chrome_options.add_argument('user-data-dir=' + profile_dir)\n",
      "        chrome_options.add_argument('window-size=1920,1055')\n",
      "        if headless:\n",
      "            chrome_options.add_argument('--headless')\n",
      "        self._options = chrome_options\n",
      "        self._driver = ChromeDriverManager(chrome_type=browser_type).install()\n",
      "        self._screenshot_dir = screenshot_dir\n",
      "\n",
      "    def new(self):\n",
      "        return webdriver.Chrome(\n",
      "            self._driver,\n",
      "            options=self._options)\n",
      "\n",
      "    @property\n",
      "    def screenshot_dir(self):\n",
      "        return self._screenshot_dir\n",
      "\n",
      "class UpdateTracker:\n",
      "    def __init__(self, dbpath):\n",
      "        conn = sqlite3.connect(dbpath)\n",
      "        cur = conn.cursor()\n",
      "        try:\n",
      "            for q in DB_INIT:\n",
      "                cur.execute(q)\n",
      "            conn.commit()\n",
      "            cur.execute(\"SELECT 1 FROM update_ts WHERE name = ?\", (\"last\",))\n",
      "            if cur.fetchone() is None:\n",
      "                cur.execute(\"INSERT INTO update_ts (name, value) VALUES (?,?)\",\n",
      "                            (\"last\", 0.))\n",
      "                conn.commit()\n",
      "            cur.execute(\"SELECT 1 FROM update_ts WHERE name = ?\", (\"login\",))\n",
      "            if cur.fetchone() is None:\n",
      "                cur.execute(\"INSERT INTO update_ts (name, value) VALUES (?,?)\",\n",
      "                            (\"login\", 0.))\n",
      "                conn.commit()\n",
      "        finally:\n",
      "            cur.close()\n",
      "        self._conn = conn\n",
      "\n",
      "    def last_update(self):\n",
      "        cur = self._conn.cursor()\n",
      "        try:\n",
      "            cur.execute(\"SELECT value FROM update_ts WHERE name = ?\",\n",
      "                        (\"last\",))\n",
      "            return cur.fetchone()[0]\n",
      "        finally:\n",
      "            cur.close()\n",
      "\n",
      "    def last_login(self):\n",
      "        cur = self._conn.cursor()\n",
      "        try:\n",
      "            cur.execute(\"SELECT value FROM update_ts WHERE name = ?\",\n",
      "                        (\"login\",))\n",
      "            return cur.fetchone()[0]\n",
      "        finally:\n",
      "            cur.close()\n",
      "\n",
      "    def update(self, ts):\n",
      "        c = self._conn\n",
      "        with c:\n",
      "            c.execute(\"UPDATE update_ts SET value = ? WHERE name = ? AND value < ?\",\n",
      "                      (float(ts), \"last\", float(ts)))\n",
      "\n",
      "    def login(self, ts):\n",
      "        c = self._conn\n",
      "        with c:\n",
      "            c.execute(\"UPDATE update_ts SET value = ? WHERE name = ? AND value < ?\",\n",
      "                      (float(ts), \"login\", float(ts)))\n",
      "\n",
      "    def close(self):\n",
      "        self._conn.close()\n",
      "        self._conn = None\n",
      "\n",
      "def random_interval(base, min_drift, max_drift):\n",
      "    return base + min_drift + random() * (max_drift - min_drift)\n",
      "\n",
      "class Scheduler:\n",
      "    def __init__(self, last_login, last_update):\n",
      "        self._it = self._iter_events(last_login, last_update)\n",
      "\n",
      "    def __iter__(self):\n",
      "        return self\n",
      "\n",
      "    def __next__(self):\n",
      "        return next(self._it)\n",
      "\n",
      "    @staticmethod\n",
      "    def _event_stream(token, last_occured, base, min_drift, max_drift):\n",
      "        t = max(last_occured + random_interval(base, min_drift, max_drift), time())\n",
      "        yield ScheduleEntry(when=t, what=token)\n",
      "        while True:\n",
      "            t += random_interval(base, min_drift, max_drift)\n",
      "            yield ScheduleEntry(when=t, what=token)\n",
      "\n",
      "    @staticmethod\n",
      "    def _iter_events(last_login, last_update):\n",
      "        return merge(\n",
      "            Scheduler._event_stream(ScheduledEvent.REFRESH,\n",
      "                                    last_login,\n",
      "                                    SESSION_REFRESH_INTERVAL,\n",
      "                                    SESSION_REFRESH_INTERVAL_MIN_DRIFT,\n",
      "                                    SESSION_REFRESH_INTERVAL_MAX_DRIFT),\n",
      "            Scheduler._event_stream(ScheduledEvent.UPDATE,\n",
      "                                    last_update,\n",
      "                                    UPDATE_INTERVAL,\n",
      "                                    UPDATE_INTERVAL_MIN_DRIFT,\n",
      "                                    UPDATE_INTERVAL_MAX_DRIFT),\n",
      "            key=lambda ev: ev.when\n",
      "        )\n",
      "\n",
      "@contextmanager\n",
      "def managed_browser(browser_factory):\n",
      "    logger = logging.getLogger(\"GUARD\")\n",
      "    browser = browser_factory.new()\n",
      "    try:\n",
      "        yield browser\n",
      "    except WebDriverException as exc:\n",
      "        logger.warning(\"WebDriver exception occured: %s. Saving essential data...\", str(exc))\n",
      "        logger.warning(\"Current URL: %s\", browser.current_url)\n",
      "        logger.warning(\"Cookies: \\n%s\", json.dumps(browser.get_cookies(), indent=4))\n",
      "        ss_filename = strftime(\"err-%Y-%m-%d-%H-%M-%S.png\", localtime())\n",
      "        ss_path = os.path.join(browser_factory.screenshot_dir, ss_filename)\n",
      "        browser.save_screenshot(ss_path)\n",
      "        logger.warning(\"Screenshot saved to %s\", ss_path)\n",
      "        raise\n",
      "    else:\n",
      "        logger.debug(\"Current URL: %s\", browser.current_url)\n",
      "        logger.debug(\"Cookies: \\n%s\", json.dumps(browser.get_cookies(), indent=4))\n",
      "    finally:\n",
      "        browser.quit()\n",
      "\n",
      "def update_loop(browser_factory, tracker, timeout):\n",
      "    logger = logging.getLogger(\"EVLOOP\")\n",
      "    last_update = tracker.last_update()\n",
      "    last_login = tracker.last_login()\n",
      "    logger.info(\"Starting scheduler. \"\n",
      "                \"Last update @ %.3f (%s); last refresh @ %.3f (%s).\",\n",
      "                last_update, ctime(last_update),\n",
      "                last_login, ctime(last_login))\n",
      "    for ev in Scheduler(last_login, last_update):\n",
      "        logger.info(\"Next event is %s @ %.3f (%s)\",\n",
      "                    ev.what.name, ev.when, ctime(ev.when))\n",
      "        wall_clock_wait(ev.when)\n",
      "        try:\n",
      "            if ev.what is ScheduledEvent.REFRESH:\n",
      "                logger.info(\"Refreshing session now!\")\n",
      "                with managed_browser(browser_factory) as browser:\n",
      "                    refresh(browser, timeout)\n",
      "                tracker.login(time())\n",
      "            elif ev.what is ScheduledEvent.UPDATE:\n",
      "                logger.info(\"Updating CVs now!\")\n",
      "                with managed_browser(browser_factory) as browser:\n",
      "                    try:\n",
      "                        update(browser, timeout)\n",
      "                    except WebDriverException as exc:\n",
      "                        raise\n",
      "                tracker.update(time())\n",
      "        except KeyboardInterrupt:\n",
      "            raise\n",
      "        except Exception as exc:\n",
      "            logger.exception(\"Event %s handling failed: %s\", ev.what.name, str(exc))\n",
      "\n",
      "def sig_handler(signum, frame):\n",
      "    raise KeyboardInterrupt\n",
      "\n",
      "def main():\n",
      "    args = parse_args()\n",
      "    mainlogger = setup_logger(\"MAIN\", args.verbosity)\n",
      "    setup_logger(\"UPDATE\", args.verbosity)\n",
      "    setup_logger(\"LOGIN\", args.verbosity)\n",
      "    setup_logger(\"REFRESH\", args.verbosity)\n",
      "    setup_logger(\"EVLOOP\", args.verbosity)\n",
      "    setup_logger(\"GUARD\", args.verbosity)\n",
      "\n",
      "    screenshot_dir = os.path.join(args.data_dir, \"screenshots\")\n",
      "    os.makedirs(screenshot_dir, mode=0o700, exist_ok=True)\n",
      "    profile_dir = os.path.join(args.data_dir, \"profile\")\n",
      "    browser_factory = BrowserFactory(profile_dir,\n",
      "                                     screenshot_dir,\n",
      "                                     args.browser.value,\n",
      "                                     args.cmd is Command.update)\n",
      "    db_path = os.path.join(args.data_dir, 'updater.db')\n",
      "    tracker = UpdateTracker(db_path)\n",
      "    signal.signal(signal.SIGTERM, sig_handler)\n",
      "\n",
      "    try:\n",
      "        if args.cmd is Command.login:\n",
      "            mainlogger.info(\"Login mode. Please enter your credentials in opened \"\n",
      "                            \"browser window.\")\n",
      "            try:\n",
      "                with managed_browser(browser_factory) as browser:\n",
      "                    login(browser, MANUAL_LOGIN_TIMEOUT)\n",
      "                tracker.login(time())\n",
      "            except KeyboardInterrupt:\n",
      "                mainlogger.warning(\"Interrupted!\")\n",
      "        elif args.cmd is Command.update:\n",
      "            mainlogger.info(\"Update mode. Running headless browser.\")\n",
      "            try:\n",
      "                update_loop(browser_factory, tracker, args.timeout)\n",
      "            except KeyboardInterrupt:\n",
      "                pass\n",
      "            finally:\n",
      "                mainlogger.info(\"Shutting down...\")\n",
      "    finally:\n",
      "        tracker.close()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n",
      "Output: {'__main__': ['__main__.main', 'contextlib.contextmanager', 'collections.namedtuple'], '__main__.wall_clock_wait': ['time.sleep', 'time.time'], 'time.time': [], 'time.sleep': [], '__main__.setup_logger': ['logging.getLogger', 'logging.Formatter', 'logging.StreamHandler'], 'logging.getLogger': [], 'logging.StreamHandler': [], 'logging.Formatter': [], '__main__.LogLevel.__str__': [], '__main__.Command.__str__': [], '__main__.BrowserType.__str__': [], 'collections.namedtuple': [], '__main__.update': ['<builtin>.set', 'logging.getLogger', 'selenium.webdriver.support.ui.WebDriverWait', 'random.random', 'selenium.webdriver.support.expected_conditions.url_matches', 'time.sleep', '<builtin>.repr', 'selenium.webdriver.support.expected_conditions.staleness_of'], '<builtin>.set': [], '<builtin>.repr': [], 'random.random': [], 'selenium.webdriver.support.expected_conditions.staleness_of': [], 'selenium.webdriver.support.ui.WebDriverWait': [], 'selenium.webdriver.support.expected_conditions.url_matches': [], '__main__.login': ['logging.getLogger', 'selenium.webdriver.support.expected_conditions.url_matches', 'selenium.webdriver.support.ui.WebDriverWait', 'time.sleep'], '__main__.refresh': ['logging.getLogger', 'selenium.webdriver.support.ui.WebDriverWait', 'selenium.webdriver.support.expected_conditions.visibility_of_element_located', 'selenium.webdriver.support.expected_conditions.url_matches', 'time.sleep'], 'selenium.webdriver.support.expected_conditions.visibility_of_element_located': [], '__main__.parse_args': ['os.path.expanduser', 'argparse.ArgumentParser', 'os.path.join'], '__main__.parse_args.check_loglevel': ['argparse.ArgumentTypeError', '<builtin>.repr'], 'argparse.ArgumentTypeError': [], '__main__.parse_args.check_command': ['argparse.ArgumentTypeError', '<builtin>.repr'], '__main__.parse_args.check_browser_type': ['argparse.ArgumentTypeError', '<builtin>.repr'], '__main__.parse_args.check_positive_float': ['<builtin>.float', '__main__.parse_args.check_positive_float.fail'], '__main__.parse_args.check_positive_float.fail': ['argparse.ArgumentTypeError', '<builtin>.repr'], '<builtin>.float': [], 'argparse.ArgumentParser': [], 'os.path.expanduser': [], 'os.path.join': [], '__main__.BrowserFactory.__init__': ['webdriver_manager.chrome.ChromeDriverManager', 'selenium.webdriver.chrome.options.Options'], 'selenium.webdriver.chrome.options.Options': [], 'webdriver_manager.chrome.ChromeDriverManager': [], '__main__.BrowserFactory.new': ['selenium.webdriver.Chrome'], 'selenium.webdriver.Chrome': [], '__main__.BrowserFactory.screenshot_dir': [], '__main__.UpdateTracker.__init__': ['sqlite3.connect'], 'sqlite3.connect': [], '__main__.UpdateTracker.last_update': [], '__main__.UpdateTracker.last_login': [], '__main__.UpdateTracker.update': ['<builtin>.float'], '__main__.UpdateTracker.login': ['<builtin>.float'], '__main__.UpdateTracker.close': [], '__main__.random_interval': ['random.random'], '__main__.Scheduler.__init__': ['__main__.Scheduler._iter_events'], '__main__.Scheduler._iter_events': ['__main__.Scheduler._event_stream', 'heapq.merge'], '__main__.Scheduler.__iter__': [], '__main__.Scheduler.__next__': ['<builtin>.next'], '<builtin>.next': [], '__main__.Scheduler._event_stream': ['__main__.random_interval', '<builtin>.max', 'time.time'], '<builtin>.max': [], '__main__.Scheduler._iter_events.<lambda1>': [], 'heapq.merge': [], 'contextlib.contextmanager': [], '__main__.managed_browser': ['time.strftime', '__main__.BrowserFactory.new', 'os.path.join', 'logging.getLogger', '<builtin>.str', 'time.localtime', 'json.dumps'], '<builtin>.str': [], 'json.dumps': [], 'time.localtime': [], 'time.strftime': [], '__main__.update_loop': ['__main__.Scheduler.__iter__', 'time.ctime', '__main__.refresh', '__main__.update', 'logging.getLogger', '__main__.managed_browser', '<builtin>.str', '__main__.Scheduler.__init__', '__main__.UpdateTracker.last_login', '__main__.Scheduler.__next__', 'time.time', '__main__.UpdateTracker.login', '__main__.UpdateTracker.last_update', '__main__.wall_clock_wait', '__main__.UpdateTracker.update'], 'time.ctime': [], '__main__.sig_handler': [], '__main__.main': ['__main__.UpdateTracker.close', '__main__.login', 'os.path.join', '__main__.managed_browser', 'os.makedirs', '__main__.update_loop', '__main__.BrowserFactory.__init__', '__main__.parse_args', 'time.time', '__main__.UpdateTracker.__init__', 'signal.signal', '__main__.UpdateTracker.login', '__main__.setup_logger'], 'os.makedirs': [], 'signal.signal': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Snawoot_workua-cv-updater\\workua_cv_updater\\__main__.py\n",
      "[('__main__', '__main__ main'), ('__main__', 'contextlib contextmanager'), ('__main__', 'collections namedtuple'), ('__main__ wall_clock_wait', 'time sleep'), ('__main__ wall_clock_wait', 'time time'), ('__main__ setup_logger', 'logging getLogger'), ('__main__ setup_logger', 'logging Formatter'), ('__main__ setup_logger', 'logging StreamHandler'), ('__main__ update', 'logging getLogger'), ('__main__ update', 'selenium webdriver support ui WebDriverWait'), ('__main__ update', 'random random'), ('__main__ update', 'selenium webdriver support expected_conditions url_matches'), ('__main__ update', 'time sleep'), ('__main__ update', 'selenium webdriver support expected_conditions staleness_of'), ('__main__ login', 'logging getLogger'), ('__main__ login', 'selenium webdriver support expected_conditions url_matches'), ('__main__ login', 'selenium webdriver support ui WebDriverWait'), ('__main__ login', 'time sleep'), ('__main__ refresh', 'logging getLogger'), ('__main__ refresh', 'selenium webdriver support ui WebDriverWait'), ('__main__ refresh', 'selenium webdriver support expected_conditions visibility_of_element_located'), ('__main__ refresh', 'selenium webdriver support expected_conditions url_matches'), ('__main__ refresh', 'time sleep'), ('__main__ parse_args', 'os path expanduser'), ('__main__ parse_args', 'argparse ArgumentParser'), ('__main__ parse_args', 'os path join'), ('__main__ parse_args check_loglevel', 'argparse ArgumentTypeError'), ('__main__ parse_args check_command', 'argparse ArgumentTypeError'), ('__main__ parse_args check_browser_type', 'argparse ArgumentTypeError'), ('__main__ parse_args check_positive_float', '__main__ parse_args check_positive_float fail')]\n",
      "98\n",
      "********************pycgContent*************************\n",
      "[[('setup', 'setuptools setup'), ('setup', 'os path join'), ('setup', 'os path abspath'), ('setup', 'os path dirname')], [('__main__', '__main__ main'), ('__main__', 'contextlib contextmanager'), ('__main__', 'collections namedtuple'), ('__main__ wall_clock_wait', 'time sleep'), ('__main__ wall_clock_wait', 'time time'), ('__main__ setup_logger', 'logging getLogger'), ('__main__ setup_logger', 'logging Formatter'), ('__main__ setup_logger', 'logging StreamHandler'), ('__main__ update', 'logging getLogger'), ('__main__ update', 'selenium webdriver support ui WebDriverWait'), ('__main__ update', 'random random'), ('__main__ update', 'selenium webdriver support expected_conditions url_matches'), ('__main__ update', 'time sleep'), ('__main__ update', 'selenium webdriver support expected_conditions staleness_of'), ('__main__ login', 'logging getLogger'), ('__main__ login', 'selenium webdriver support expected_conditions url_matches'), ('__main__ login', 'selenium webdriver support ui WebDriverWait'), ('__main__ login', 'time sleep'), ('__main__ refresh', 'logging getLogger'), ('__main__ refresh', 'selenium webdriver support ui WebDriverWait'), ('__main__ refresh', 'selenium webdriver support expected_conditions visibility_of_element_located'), ('__main__ refresh', 'selenium webdriver support expected_conditions url_matches'), ('__main__ refresh', 'time sleep'), ('__main__ parse_args', 'os path expanduser'), ('__main__ parse_args', 'argparse ArgumentParser'), ('__main__ parse_args', 'os path join'), ('__main__ parse_args check_loglevel', 'argparse ArgumentTypeError'), ('__main__ parse_args check_command', 'argparse ArgumentTypeError'), ('__main__ parse_args check_browser_type', 'argparse ArgumentTypeError'), ('__main__ parse_args check_positive_float', '__main__ parse_args check_positive_float fail')]]\n",
      "********************doctrings*************************\n",
      "['', \"wall clock wait setup logger update login refresh parse args random interval managed browser update loop sig handler main [SEP] Sleep variation which is doesn't increases sleep duration when computer enters suspend/hybernation\"]\n",
      "embed index dataset: 1\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\apps.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\myproject\\\\settings.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\rtf_utils.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\models.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\io_utils.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\jobs.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\tests.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\docx_utils.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\doc_utils.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\vacants_ru.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\manage.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\myproject\\\\wsgi.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\views.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\urls.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\vacants_en.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\pdf_utils.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\vacants.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\formuploads\\\\admin.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\krax1337_bts-resumes\\\\myproject\\\\urls.py']\n",
      "from django.apps import AppConfig\n",
      "\n",
      "\n",
      "class FormuploadsConfig(AppConfig):\n",
      "    name = 'formuploads'\n",
      "\n",
      "Output: {'apps': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\apps.py\n",
      "[]\n",
      "found files: []\n",
      "\"\"\"\n",
      "Django settings for myproject project.\n",
      "\n",
      "Generated by 'django-admin startproject' using Django 2.0.7.\n",
      "\n",
      "For more information on this file, see\n",
      "https://docs.djangoproject.com/en/2.0/topics/settings/\n",
      "\n",
      "For the full list of settings and their values, see\n",
      "https://docs.djangoproject.com/en/2.0/ref/settings/\n",
      "\"\"\"\n",
      "\n",
      "import os\n",
      "import django_heroku\n",
      "\n",
      "# Build paths inside the project like this: os.path.join(BASE_DIR, ...)\n",
      "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
      "\n",
      "\n",
      "# Quick-start development settings - unsuitable for production\n",
      "# See https://docs.djangoproject.com/en/2.0/howto/deployment/checklist/\n",
      "\n",
      "# SECURITY WARNING: keep the secret key used in production secret!\n",
      "SECRET_KEY = '&a1f3a^hd+z$nuq!)k27h75jj)v2q(yj=@!8ri#1ba7u41o(03'\n",
      "\n",
      "# SECURITY WARNING: don't run with debug turned on in production!\n",
      "DEBUG = True\n",
      "\n",
      "ALLOWED_HOSTS = []\n",
      "\n",
      "\n",
      "# Application definition\n",
      "\n",
      "INSTALLED_APPS = [\n",
      "    'formuploads.apps.FormuploadsConfig',\n",
      "    'django.contrib.admin',\n",
      "    'django.contrib.auth',\n",
      "    'django.contrib.contenttypes',\n",
      "    'django.contrib.sessions',\n",
      "    'django.contrib.messages',\n",
      "    'django.contrib.staticfiles',\n",
      "    'bootstrap4',\n",
      "]\n",
      "\n",
      "MIDDLEWARE = [\n",
      "    'django.middleware.security.SecurityMiddleware',\n",
      "    'django.contrib.sessions.middleware.SessionMiddleware',\n",
      "    'django.middleware.common.CommonMiddleware',\n",
      "    'django.middleware.csrf.CsrfViewMiddleware',\n",
      "    'django.contrib.auth.middleware.AuthenticationMiddleware',\n",
      "    'django.contrib.messages.middleware.MessageMiddleware',\n",
      "    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n",
      "]\n",
      "\n",
      "ROOT_URLCONF = 'myproject.urls'\n",
      "\n",
      "TEMPLATES = [\n",
      "    {\n",
      "        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n",
      "        'DIRS': [],\n",
      "        'APP_DIRS': True,\n",
      "        'OPTIONS': {\n",
      "            'context_processors': [\n",
      "                'django.template.context_processors.debug',\n",
      "                'django.template.context_processors.request',\n",
      "                'django.contrib.auth.context_processors.auth',\n",
      "                'django.contrib.messages.context_processors.messages',\n",
      "            ],\n",
      "        },\n",
      "    },\n",
      "]\n",
      "\n",
      "WSGI_APPLICATION = 'myproject.wsgi.application'\n",
      "\n",
      "\n",
      "# Database\n",
      "# https://docs.djangoproject.com/en/2.0/ref/settings/#databases\n",
      "\n",
      "DATABASES = {\n",
      "    'default': {\n",
      "        'ENGINE': 'django.db.backends.sqlite3',\n",
      "        'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "# Password validation\n",
      "# https://docs.djangoproject.com/en/2.0/ref/settings/#auth-password-validators\n",
      "\n",
      "AUTH_PASSWORD_VALIDATORS = [\n",
      "    {\n",
      "        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',\n",
      "    },\n",
      "    {\n",
      "        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',\n",
      "    },\n",
      "    {\n",
      "        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',\n",
      "    },\n",
      "    {\n",
      "        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',\n",
      "    },\n",
      "]\n",
      "\n",
      "\n",
      "# Internationalization\n",
      "# https://docs.djangoproject.com/en/2.0/topics/i18n/\n",
      "\n",
      "LANGUAGE_CODE = 'en-us'\n",
      "\n",
      "TIME_ZONE = 'UTC'\n",
      "\n",
      "USE_I18N = True\n",
      "\n",
      "USE_L10N = True\n",
      "\n",
      "USE_TZ = True\n",
      "\n",
      "\n",
      "# Static files (CSS, JavaScript, Images)\n",
      "# https://docs.djangoproject.com/en/2.0/howto/static-files/\n",
      "\n",
      "STATIC_URL = '/static/'\n",
      "\n",
      "STATICFILES_DIRS = (\n",
      "    os.path.join(BASE_DIR, 'static'),\n",
      ")\n",
      "\n",
      "django_heroku.settings(locals())\n",
      "\n",
      "# BOOTSTRAP3 = {\n",
      "#     'include_jquery': True,\n",
      "# }\n",
      "\n",
      "Output: {'settings': ['<builtin>.locals', 'os.path.dirname', 'os.path.abspath', 'os.path.join', 'django_heroku.settings'], 'os.path.abspath': [], 'os.path.dirname': [], 'os.path.join': [], '<builtin>.locals': [], 'django_heroku.settings': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\myproject\\settings.py\n",
      "[('settings', 'os path dirname'), ('settings', 'os path abspath'), ('settings', 'os path join'), ('settings', 'django_heroku settings')]\n",
      "0\n",
      "found files: []\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "\"\"\"\n",
      "Extract text in RTF Files. Refactored to use with Python 3.x\n",
      "Source:\n",
      "\thttp://stackoverflow.com/a/188877\n",
      "Code created by Markus Jarderot: http://mizardx.blogspot.com\n",
      "\"\"\"\n",
      "\n",
      "import re\n",
      "\n",
      "\n",
      "def rtf_to_text(text):\n",
      "\ttext = open(text).read()\n",
      "\tpattern = re.compile(\n",
      "\t\tr\"\\\\([a-z]{1,32})(-?\\d{1,10})?[ ]?|\\\\'([0-9a-f]{2})|\\\\([^a-z])|([{}])|[\\r\\n]+|(.)\", re.I)\n",
      "\t# control words which specify a \"destionation\".\n",
      "\tdestinations = frozenset((\n",
      "\t\t'aftncn', 'aftnsep', 'aftnsepc', 'annotation', 'atnauthor', 'atndate', 'atnicn', 'atnid',\n",
      "\t\t'atnparent', 'atnref', 'atntime', 'atrfend', 'atrfstart', 'author', 'background',\n",
      "\t\t'bkmkend', 'bkmkstart', 'blipuid', 'buptim', 'category', 'colorschememapping',\n",
      "\t\t'colortbl', 'comment', 'company', 'creatim', 'datafield', 'datastore', 'defchp', 'defpap',\n",
      "\t\t'do', 'doccomm', 'docvar', 'dptxbxtext', 'ebcend', 'ebcstart', 'factoidname', 'falt',\n",
      "\t\t'fchars', 'ffdeftext', 'ffentrymcr', 'ffexitmcr', 'ffformat', 'ffhelptext', 'ffl',\n",
      "\t\t'ffname', 'ffstattext', 'field', 'file', 'filetbl', 'fldinst', 'fldrslt', 'fldtype',\n",
      "\t\t'fname', 'fontemb', 'fontfile', 'fonttbl', 'footer', 'footerf', 'footerl', 'footerr',\n",
      "\t\t'footnote', 'formfield', 'ftncn', 'ftnsep', 'ftnsepc', 'g', 'generator', 'gridtbl',\n",
      "\t\t'header', 'headerf', 'headerl', 'headerr', 'hl', 'hlfr', 'hlinkbase', 'hlloc', 'hlsrc',\n",
      "\t\t'hsv', 'htmltag', 'info', 'keycode', 'keywords', 'latentstyles', 'lchars', 'levelnumbers',\n",
      "\t\t'leveltext', 'lfolevel', 'linkval', 'list', 'listlevel', 'listname', 'listoverride',\n",
      "\t\t'listoverridetable', 'listpicture', 'liststylename', 'listtable', 'listtext',\n",
      "\t\t'lsdlockedexcept', 'macc', 'maccPr', 'mailmerge', 'maln', 'malnScr', 'manager', 'margPr',\n",
      "\t\t'mbar', 'mbarPr', 'mbaseJc', 'mbegChr', 'mborderBox', 'mborderBoxPr', 'mbox', 'mboxPr',\n",
      "\t\t'mchr', 'mcount', 'mctrlPr', 'md', 'mdeg', 'mdegHide', 'mden', 'mdiff', 'mdPr', 'me',\n",
      "\t\t'mendChr', 'meqArr', 'meqArrPr', 'mf', 'mfName', 'mfPr', 'mfunc', 'mfuncPr', 'mgroupChr',\n",
      "\t\t'mgroupChrPr', 'mgrow', 'mhideBot', 'mhideLeft', 'mhideRight', 'mhideTop', 'mhtmltag',\n",
      "\t\t'mlim', 'mlimloc', 'mlimlow', 'mlimlowPr', 'mlimupp', 'mlimuppPr', 'mm', 'mmaddfieldname',\n",
      "\t\t'mmath', 'mmathPict', 'mmathPr', 'mmaxdist', 'mmc', 'mmcJc', 'mmconnectstr',\n",
      "\t\t'mmconnectstrdata', 'mmcPr', 'mmcs', 'mmdatasource', 'mmheadersource', 'mmmailsubject',\n",
      "\t\t'mmodso', 'mmodsofilter', 'mmodsofldmpdata', 'mmodsomappedname', 'mmodsoname',\n",
      "\t\t'mmodsorecipdata', 'mmodsosort', 'mmodsosrc', 'mmodsotable', 'mmodsoudl',\n",
      "\t\t'mmodsoudldata', 'mmodsouniquetag', 'mmPr', 'mmquery', 'mmr', 'mnary', 'mnaryPr',\n",
      "\t\t'mnoBreak', 'mnum', 'mobjDist', 'moMath', 'moMathPara', 'moMathParaPr', 'mopEmu',\n",
      "\t\t'mphant', 'mphantPr', 'mplcHide', 'mpos', 'mr', 'mrad', 'mradPr', 'mrPr', 'msepChr',\n",
      "\t\t'mshow', 'mshp', 'msPre', 'msPrePr', 'msSub', 'msSubPr', 'msSubSup', 'msSubSupPr', 'msSup',\n",
      "\t\t'msSupPr', 'mstrikeBLTR', 'mstrikeH', 'mstrikeTLBR', 'mstrikeV', 'msub', 'msubHide',\n",
      "\t\t'msup', 'msupHide', 'mtransp', 'mtype', 'mvertJc', 'mvfmf', 'mvfml', 'mvtof', 'mvtol',\n",
      "\t\t'mzeroAsc', 'mzeroDesc', 'mzeroWid', 'nesttableprops', 'nextfile', 'nonesttables',\n",
      "\t\t'objalias', 'objclass', 'objdata', 'object', 'objname', 'objsect', 'objtime', 'oldcprops',\n",
      "\t\t'oldpprops', 'oldsprops', 'oldtprops', 'oleclsid', 'operator', 'panose', 'password',\n",
      "\t\t'passwordhash', 'pgp', 'pgptbl', 'picprop', 'pict', 'pn', 'pnseclvl', 'pntext', 'pntxta',\n",
      "\t\t'pntxtb', 'printim', 'private', 'propname', 'protend', 'protstart', 'protusertbl', 'pxe',\n",
      "\t\t'result', 'revtbl', 'revtim', 'rsidtbl', 'rxe', 'shp', 'shpgrp', 'shpinst',\n",
      "\t\t'shppict', 'shprslt', 'shptxt', 'sn', 'sp', 'staticval', 'stylesheet', 'subject', 'sv',\n",
      "\t\t'svb', 'tc', 'template', 'themedata', 'title', 'txe', 'ud', 'upr', 'userprops',\n",
      "\t\t'wgrffmtfilter', 'windowcaption', 'writereservation', 'writereservhash', 'xe', 'xform',\n",
      "\t\t'xmlattrname', 'xmlattrvalue', 'xmlclose', 'xmlname', 'xmlnstbl',\n",
      "\t\t'xmlopen',\n",
      "\t))\n",
      "\t# Translation of some special characters.\n",
      "\tspecialchars = {\n",
      "\t\t'par': '\\n',\n",
      "\t\t'cell': '\\n',\n",
      "\t\t'sect': '\\n\\n',\n",
      "\t\t'page': '\\n\\n',\n",
      "\t\t'line': '\\n',\n",
      "\t\t'tab': '\\t',\n",
      "\t\t'emdash': '\\u2014',\n",
      "\t\t'endash': '\\u2013',\n",
      "\t\t'emspace': '\\u2003',\n",
      "\t\t'enspace': '\\u2002',\n",
      "\t\t'qmspace': '\\u2005',\n",
      "\t\t'bullet': '\\u2022',\n",
      "\t\t'lquote': '\\u2018',\n",
      "\t\t'rquote': '\\u2019',\n",
      "\t\t'ldblquote': '\\201C',\n",
      "\t\t'rdblquote': '\\u201D',\n",
      "\t}\n",
      "\tstack = []\n",
      "\t# Whether this group (and all inside it) are \"ignorable\".\n",
      "\tignorable = False\n",
      "\t# Number of ASCII characters to skip after a unicode character.\n",
      "\tucskip = 1\n",
      "\tcurskip = 0             # Number of ASCII characters left to skip\n",
      "\tout = []                # Output buffer.\n",
      "\tfor match in pattern.finditer(text):\n",
      "\t\tword, arg, hex, char, brace, tchar = match.groups()\n",
      "\t\tif brace:\n",
      "\t\t\tcurskip = 0\n",
      "\t\t\tif brace == '{':\n",
      "\t\t\t\t# Push state\n",
      "\t\t\t\tstack.append((ucskip, ignorable))\n",
      "\t\t\telif brace == '}':\n",
      "\t\t\t\t# Pop state\n",
      "\t\t\t\tucskip, ignorable = stack.pop()\n",
      "\t\telif char:  # \\x (not a letter)\n",
      "\t\t\tcurskip = 0\n",
      "\t\t\tif char == '~':\n",
      "\t\t\t\tif not ignorable:\n",
      "\t\t\t\t\tout.append('\\xA0')\n",
      "\t\t\telif char in '{}\\\\':\n",
      "\t\t\t\tif not ignorable:\n",
      "\t\t\t\t\tout.append(char)\n",
      "\t\t\telif char == '*':\n",
      "\t\t\t\tignorable = True\n",
      "\t\telif word:  # \\foo\n",
      "\t\t\tcurskip = 0\n",
      "\t\t\tif word in destinations:\n",
      "\t\t\t\tignorable = True\n",
      "\t\t\telif ignorable:\n",
      "\t\t\t\tpass\n",
      "\t\t\telif word in specialchars:\n",
      "\t\t\t\tout.append(specialchars[word])\n",
      "\t\t\telif word == 'uc':\n",
      "\t\t\t\tucskip = int(arg)\n",
      "\t\t\telif word == 'u':\n",
      "\t\t\t\tc = int(arg)\n",
      "\t\t\t\tif c < 0:\n",
      "\t\t\t\t\tc += 0x10000\n",
      "\t\t\t\tif c > 127:\n",
      "\t\t\t\t\tout.append(chr(c))  # NOQA\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tout.append(chr(c))\n",
      "\t\t\t\tcurskip = ucskip\n",
      "\t\telif hex:  # \\'xx\n",
      "\t\t\tif curskip > 0:\n",
      "\t\t\t\tcurskip -= 1\n",
      "\t\t\telif not ignorable:\n",
      "\t\t\t\tc = int(hex, 16)\n",
      "\t\t\t\tif c > 127:\n",
      "\t\t\t\t\tout.append(chr(c))  # NOQA\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tout.append(chr(c))\n",
      "\t\telif tchar:\n",
      "\t\t\tif curskip > 0:\n",
      "\t\t\t\tcurskip -= 1\n",
      "\t\t\telif not ignorable:\n",
      "\t\t\t\tout.append(tchar)\n",
      "\n",
      "\ttext_1 = ''.join(out)\n",
      "\ttry:\n",
      "\t\ttext_1 = text_1.encode(\"cp1252\").decode(\"cp1251\")\n",
      "\texcept:\n",
      "\t\tpass\n",
      "\n",
      "\tresult = []\n",
      "\tfor line in text_1.split('\\n'):\n",
      "\t\tline2 = line.strip()\n",
      "\t\tif line2 != '':\n",
      "\t\t\tresult.append(line2)\n",
      "\n",
      "\treturn result\n",
      "\n",
      "\n",
      "Output: {'rtf_utils': [], 'rtf_utils.rtf_to_text': ['re.compile', '<builtin>.chr', '<builtin>.frozenset', '<builtin>.open', '<builtin>.int'], '<builtin>.open': [], 're.compile': [], '<builtin>.frozenset': [], '<builtin>.int': [], '<builtin>.chr': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\rtf_utils.py\n",
      "[('rtf_utils rtf_to_text', 're compile')]\n",
      "0\n",
      "found files: []\n",
      "from django.db import models\n",
      "\n",
      "# Create your models here.\n",
      "\n",
      "Output: {'models': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\models.py\n",
      "[]\n",
      "found files: []\n",
      "import os\n",
      "\n",
      "from .doc_utils import doc_to_text\n",
      "from .docx_utils import docx_to_text\n",
      "from .pdf_utils import pdf_to_text\n",
      "from .rtf_utils import rtf_to_text\n",
      "\n",
      "\n",
      "def read_pdf_and_docx(dir_path):\n",
      "    txt = None\n",
      "    f = dir_path\n",
      "    if f.lower().endswith('.docx'):\n",
      "        txt = docx_to_text(f)\n",
      "    elif f.lower().endswith('.pdf'):\n",
      "        txt = pdf_to_text(f)\n",
      "    elif f.lower().endswith('.doc'):\n",
      "        txt = doc_to_text(f)\n",
      "    elif f.lower().endswith('.rtf'):\n",
      "        txt = rtf_to_text(f)\n",
      "    if len(txt) <= 1:\n",
      "        f1 = f[:-4]\n",
      "        os.rename(f , f1 + \".rtf\")\n",
      "        txt = rtf_to_text(f1 + \".rtf\")\n",
      "    return txt\n",
      "\n",
      "Output: {'io_utils': [], 'io_utils.read_pdf_and_docx': ['<builtin>.len', 'rtf_utils.rtf_to_text', 'docx_utils.docx_to_text', 'pdf_utils.pdf_to_text', 'doc_utils.doc_to_text', 'os.rename'], 'docx_utils.docx_to_text': [], 'pdf_utils.pdf_to_text': [], 'doc_utils.doc_to_text': [], 'rtf_utils.rtf_to_text': [], '<builtin>.len': [], 'os.rename': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\io_utils.py\n",
      "[('io_utils read_pdf_and_docx', 'rtf_utils rtf_to_text'), ('io_utils read_pdf_and_docx', 'docx_utils docx_to_text'), ('io_utils read_pdf_and_docx', 'pdf_utils pdf_to_text'), ('io_utils read_pdf_and_docx', 'doc_utils doc_to_text'), ('io_utils read_pdf_and_docx', 'os rename')]\n",
      "0\n",
      "found files: []\n",
      "import urllib.request\n",
      "from xml.etree import ElementTree as ET\n",
      "\n",
      "def analyse_file(all_vacants_info, vacants_ids):\n",
      "    requestURL = \"https://www.enbek.kz/ru/xml/jooble\"\n",
      "    root = ET.parse(urllib.request.urlopen(requestURL)).getroot()\n",
      "    for key in vacants_ids:\n",
      "        for job in root.iter('job'):\n",
      "            if(job.attrib.get('id') == key):\n",
      "                all_vacants_info.append({\n",
      "\n",
      "                    'job_name': str(job.find('name').text).replace(\", \", \"\", 1),\n",
      "                    'job_region': str(job.find('region').text),\n",
      "                    \"job_salary\": str(job.find('salary').text),\n",
      "                    \"job_description\": str(job.find('description').text).replace(\"p&gt;\", \" \")\n",
      "                                .replace(\"li\", \" \").replace(\"ul\", \" \")\n",
      "                                .replace(\"/\", \" \").replace(\"&gt;\", \" \")\n",
      "                                .replace(\"&lt;\", \" \").replace(\"ul&gt;\", \" \")\n",
      "                                .replace(\"/li&gt;\", \" \").replace(\"li&gt;\", \" \")\n",
      "                                .replace(\"-&amp;\", \" \").replace(\"nbsp;\", \" \")\n",
      "                                .replace(\"&amp;\", \" \").replace(\"quot;\", \" \")\n",
      "                                .replace(\"br\", \" \").replace(\"strong\", \" \")\n",
      "                                .replace(\"strong\", \" \").replace(\"ol\", \" \"),\n",
      "                    \"job_email\": str(job.find('email').text),\n",
      "                    \"job_phone\": str(job.find('phone').text),\n",
      "                    \"job_link\": str(job.find('link').text),\n",
      "\n",
      "                })\n",
      "    return all_vacants_info\n",
      "\n",
      "def all_jobs():\n",
      "    all_jobs=[{}]\n",
      "    requestURL = \"https://www.enbek.kz/ru/xml/jooble\"\n",
      "    root = ET.parse(urllib.request.urlopen(requestURL)).getroot()\n",
      "    for job in root.iter('job'):\n",
      "        all_jobs.append({\n",
      "\n",
      "                        'job_name': str(job.find('name').text).replace(\", \", \"\", 1),\n",
      "                        'job_region': str(job.find('region').text),\n",
      "                        \"job_salary\": str(job.find('salary').text),\n",
      "                        \"job_description\": str(job.find('description').text).replace(\"p&gt;\", \" \")\n",
      "                                    .replace(\"li\", \" \").replace(\"ul\", \" \")\n",
      "                                    .replace(\"/\", \" \").replace(\"&gt;\", \" \")\n",
      "                                    .replace(\"&lt;\", \" \").replace(\"ul&gt;\", \" \")\n",
      "                                    .replace(\"/li&gt;\", \" \").replace(\"li&gt;\", \" \")\n",
      "                                    .replace(\"-&amp;\", \" \").replace(\"nbsp;\", \" \")\n",
      "                                    .replace(\"&amp;\", \" \").replace(\"quot;\", \" \")\n",
      "                                    .replace(\"br\", \" \").replace(\"strong\", \" \")\n",
      "                                    .replace(\"strong\", \" \").replace(\"ol\", \" \"),\n",
      "                        \"job_email\": str(job.find('email').text),\n",
      "                        \"job_phone\": str(job.find('phone').text),\n",
      "                        \"job_link\": str(job.find('link').text),\n",
      "\n",
      "                    })\n",
      "    return all_jobs   \n",
      "Output: {'jobs': [], 'jobs.analyse_file': ['xml.etree.ElementTree.parse'], 'xml.etree.ElementTree.parse': [], 'jobs.all_jobs': ['xml.etree.ElementTree.parse']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\jobs.py\n",
      "[('jobs analyse_file', 'xml etree ElementTree parse'), ('jobs all_jobs', 'xml etree ElementTree parse')]\n",
      "0\n",
      "found files: []\n",
      "from django.test import TestCase\n",
      "\n",
      "# Create your tests here.\n",
      "\n",
      "Output: {'tests': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\tests.py\n",
      "[]\n",
      "found files: []\n",
      "import docx\n",
      "\n",
      "\n",
      "def docx_to_text(file_path):\n",
      "\n",
      "    doc = docx.Document(file_path)\n",
      "    result = []\n",
      "    for p in doc.paragraphs:\n",
      "        txt = p.text.strip()\n",
      "        if txt != '':\n",
      "            txt = preprocess_text(txt)\n",
      "            result.append(txt)\n",
      "    tables = doc.tables\n",
      "    for table in tables:\n",
      "        for row in table.rows:\n",
      "            for cell in row.cells:\n",
      "                for paragraph in cell.paragraphs:\n",
      "                    result.append(paragraph.text)\n",
      "    return result\n",
      "\n",
      "\n",
      "def preprocess_text(text):\n",
      "    text = ' '.join(text.split())\n",
      "    text = join_name_tag(text)\n",
      "    return text\n",
      "\n",
      "\n",
      "def join_name_tag(text):\n",
      "    text = text.replace('\\u2003', '')\n",
      "    return text\n",
      "\n",
      "Output: {'docx_utils': [], 'docx_utils.docx_to_text': ['docx.Document', 'docx_utils.preprocess_text'], 'docx.Document': [], 'docx_utils.preprocess_text': ['docx_utils.join_name_tag'], 'docx_utils.join_name_tag': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\docx_utils.py\n",
      "[('docx_utils docx_to_text', 'docx Document'), ('docx_utils docx_to_text', 'docx_utils preprocess_text'), ('docx_utils preprocess_text', 'docx_utils join_name_tag')]\n",
      "0\n",
      "found files: []\n",
      "from subprocess import Popen, PIPE\n",
      "import os\n",
      "import shutil\n",
      "from .docx_utils import docx_to_text\n",
      "\n",
      "\n",
      "def doc_to_text(file_path):\n",
      "    file_path = file_path[:-4]\n",
      "    coding = \"-mcp1251\"\n",
      "    cmd = 'antiword' + \" \" + coding + \" \" ' \"./' + file_path + \\\n",
      "        \".doc\" + '\"' + \" \" + \">\" + \" ./upload/\" + \"new.txt\"\n",
      "    os.system(str(cmd))\n",
      "    f = open('./upload/new.txt', 'r', encoding='windows-1251')\n",
      "    result = []\n",
      "    for line in f:\n",
      "        if line != '\\n':\n",
      "            line = line.replace('\\n', '')\n",
      "            line = line.replace('|', '')\n",
      "            line = \" \".join(line.split())\n",
      "            result.append(line)\n",
      "    return result\n",
      "\n",
      "Output: {'doc_utils': [], 'doc_utils.doc_to_text': ['<builtin>.open', 'os.system', '<builtin>.str'], '<builtin>.str': [], 'os.system': [], '<builtin>.open': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\doc_utils.py\n",
      "[('doc_utils doc_to_text', 'os system')]\n",
      "0\n",
      "found files: []\n",
      "from nltk.corpus import stopwords\n",
      "import string\n",
      "\n",
      "\n",
      "def stop_words_kk():\n",
      "    stop_words_kk = []\n",
      "    with open('./stop.txt', 'rb') as f:\n",
      "        lines = f.readlines()\n",
      "        stop_words_kk.append(lines[0])\n",
      "    return stop_words_kk\n",
      "\n",
      "\n",
      "stop_words = stopwords.words('russian')\n",
      "stop_words += stop_words_kk()\n",
      "for word in stopwords.words('russian'):\n",
      "    stop_words.append(word.upper())\n",
      "stop_words += stopwords.words('english')\n",
      "for word in stopwords.words('english'):\n",
      "    stop_words.append(word.upper())\n",
      "\n",
      "\n",
      "numbers = ['(', ')', '', ';', ':', '[', ']', ',', '', '', '', '',\n",
      "           '', '', '', '', '',\n",
      "           '', '', '', '', '', '1', '2', '3', '4', '5', '6', '7', '8', '9', '', '', 'of', 'p', '', '', '', '', '',\n",
      "           '/p', 'lt', 'li', '/li', 'gt', '/ul', 'amp', 'nbsp', 'ul', '/strong', 'mdash;','b l;', 'bl;']\n",
      "\n",
      "for i in range(1950, 2040):\n",
      "    numbers.append(str(i))\n",
      "\n",
      "for i in range(10, 100):\n",
      "    numbers.append(str(i))\n",
      "    \n",
      "def get_vacants_ru(l):\n",
      "    head_hunter = False\n",
      "    for line in l:\n",
      "        if \" \" in line:\n",
      "            head_hunter = True\n",
      "            break\n",
      "\n",
      "    key_words = [\"   \",\" \",\"\",\" \",\" \",\"\",\" \",\" \", \" \",\"\" ]\n",
      "\n",
      "    if (head_hunter):\n",
      "        cv_summary = {\"education\": \"\", \"position\": \"\",\n",
      "                      \"skills\": \"\", \"experience\": \"\", \"language\": \"\", \"about\": \"\", \"reference\": \"\", \"other\": \"\"}\n",
      "        counter = -1\n",
      "        while counter < len(l) - 1:\n",
      "            counter += 1\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \"   \" in l[counter]:\n",
      "                counter += 1\n",
      "                while('' not in l[counter]):\n",
      "                    cv_summary[\"position\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "                while (\"\" in l[counter]):\n",
      "                    cv_summary[\"position\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \" \" in l[counter]:\n",
      "                cv_summary[\"experience\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l):\n",
      "                    if (\" \" not in l[counter]):\n",
      "                        ok = False\n",
      "                        for k in key_words:\n",
      "                            if (k in l[counter]):\n",
      "                                ok = True\n",
      "                                break\n",
      "                        if ok:\n",
      "                            break\n",
      "                        cv_summary[\"experience\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \"\" in l[counter]:\n",
      "                cv_summary[\"education\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l):\n",
      "                    if (\" \" not in l[counter]):\n",
      "                        ok = False\n",
      "                        for k in key_words:\n",
      "                            if (k in l[counter]):\n",
      "                                ok = True\n",
      "                                break\n",
      "                        if ok:\n",
      "                            break\n",
      "                        cv_summary[\"education\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \" \" in l[counter]:\n",
      "                cv_summary[\"language\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l):\n",
      "                    if (\" \" not in l[counter]):\n",
      "                        ok = False\n",
      "                        for k in key_words:\n",
      "                            if (k in l[counter]):\n",
      "                                ok = True\n",
      "                                break\n",
      "                        if ok:\n",
      "                            break\n",
      "                        cv_summary[\"language\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \"\" in l[counter]:\n",
      "                cv_summary[\"skills\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l) - 1:\n",
      "                    if (\" \" not in l[counter]):\n",
      "                        ok = False\n",
      "                        for k in key_words:\n",
      "                            if (k in l[counter]):\n",
      "                                ok = True\n",
      "                                break\n",
      "                        if ok:\n",
      "                            break\n",
      "                        cv_summary[\"skills\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "                    \n",
      "\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \" \" in l[counter]:\n",
      "                cv_summary[\"other\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l):\n",
      "                    if (\" \" not in l[counter]):    \n",
      "                        ok = False\n",
      "                        for k in key_words:\n",
      "                            if (k in l[counter]):\n",
      "                                ok = True\n",
      "                                break\n",
      "                        if ok:\n",
      "                            break\n",
      "                        cv_summary[\"other\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \"\" in l[counter]:\n",
      "                cv_summary[\"reference\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l):\n",
      "                    if (\" \" not in l[counter]):\n",
      "                        ok = False\n",
      "                        for k in key_words:\n",
      "                            if (k in l[counter]):\n",
      "                                ok = True\n",
      "                                break\n",
      "                        if ok:\n",
      "                            break\n",
      "                        cv_summary[\"reference\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "                                    \n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \" \" in l[counter]:\n",
      "                cv_summary[\"about\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l):\n",
      "                    if (\" \" not in l[counter]):\n",
      "                        cv_summary[\"about\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "        for key in cv_summary:\n",
      "            cv_summary[key] = cv_summary[key].replace(',', ' ').replace(')', '').replace('(', '').split()\n",
      "\n",
      "            cv_summary[key] = [a for a in cv_summary[key]\n",
      "                               if not a in stop_words and not a in string.punctuation]\n",
      "            cv_summary[key] = [ab for ab in cv_summary[key]\n",
      "                               if not ab in stop_words and not ab in numbers]\n",
      "\n",
      "        if 'position' in cv_summary:\n",
      "            key_pos = [x for x in cv_summary[\"position\"] if x != \"\"]\n",
      "            cv_summary['position'] = key_pos\n",
      "\n",
      "    else:\n",
      "\n",
      "        key_words = {\n",
      "            \"education\": [\"\", \"\",\n",
      "                          \"\"],\n",
      "\n",
      "            \"position\": [\"\", \" \",\"   \", \" \"],\n",
      "\n",
      "            \"skills\": [\"\",\n",
      "                       \" \"],\n",
      "\n",
      "            \"experience\": [\" \", \" \",\" \", \" \"],\n",
      "\n",
      "            \"language\": [\"\", \" \", \" \", \" \"],\n",
      "\n",
      "            \"about\": [\" \", \" \", \" \", \"\", \"\", \"  \"],\n",
      "            \"reference\": [\"\"],\n",
      "            \"other\": [\"\", \" \", \"\", \" \"],\n",
      "        }\n",
      "\n",
      "        cv_summary = {\"education\": \"\", \"position\": \"\",\n",
      "                      \"skills\": \"\", \"experience\": \"\", \"language\": \"\", \"about\": \"\", \"reference\": \"\", \"other\": \"\"}\n",
      "\n",
      "        counter_l = -1\n",
      "        while (counter_l < len(l) - 1):\n",
      "            counter_l += 1\n",
      "            for key in key_words:\n",
      "                for word in key_words[key]:\n",
      "                    if counter_l < len(l) and word.lower() in l[counter_l].lower():\n",
      "    \n",
      "                        check = True\n",
      "                        cv_summary[key] += \" \" + l[counter_l].lower().replace(word.lower(), '')\n",
      "\n",
      "                        counter_l += 1\n",
      "                        while (check):\n",
      "                            if (counter_l > len(l) - 1):\n",
      "                                check = False\n",
      "                                break\n",
      "                            for key_1 in key_words:\n",
      "                                if key_1 != key:\n",
      "                                    for word_1 in key_words[key_1]:\n",
      "                                        if word_1.lower() in l[counter_l].lower():\n",
      "                                            check = False\n",
      "                                            counter_l -= 1\n",
      "                                            break\n",
      "                                    if check == False:\n",
      "                                        break\n",
      "                            if not check:\n",
      "                                break\n",
      "                            else:\n",
      "                                cv_summary[key] += \" \" + l[counter_l]\n",
      "                                counter_l += 1\n",
      "\n",
      "        for key in cv_summary:\n",
      "            cv_summary[key] = cv_summary[key].replace(',', ' ').replace(')', '').replace('(', '').split()\n",
      "            cv_summary[key] = [a for a in cv_summary[key]\n",
      "                               if not a in stop_words and not a in string.punctuation]\n",
      "            cv_summary[key] = [ab for ab in cv_summary[key]\n",
      "                               if not ab in stop_words and not ab in numbers]\n",
      "\n",
      "        if 'position' in cv_summary:\n",
      "            key_pos = [x for x in cv_summary[\"position\"] if x != \"\"]\n",
      "            cv_summary['position'] = key_pos\n",
      "\n",
      "    return cv_summary\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\vacants_ru.py\n",
      "[]\n",
      "found files: []\n",
      "#!/usr/bin/env python\n",
      "import os\n",
      "import sys\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"myproject.settings\")\n",
      "    try:\n",
      "        from django.core.management import execute_from_command_line\n",
      "    except ImportError as exc:\n",
      "        raise ImportError(\n",
      "            \"Couldn't import Django. Are you sure it's installed and \"\n",
      "            \"available on your PYTHONPATH environment variable? Did you \"\n",
      "            \"forget to activate a virtual environment?\"\n",
      "        ) from exc\n",
      "    execute_from_command_line(sys.argv)\n",
      "\n",
      "Output: {'manage': ['<builtin>.ImportError', 'os.environ.setdefault', 'django.core.management.execute_from_command_line'], 'os.environ.setdefault': [], '<builtin>.ImportError': [], 'django.core.management.execute_from_command_line': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\manage.py\n",
      "[('manage', 'os environ setdefault'), ('manage', 'django core management execute_from_command_line')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"\n",
      "WSGI config for myproject project.\n",
      "\n",
      "It exposes the WSGI callable as a module-level variable named ``application``.\n",
      "\n",
      "For more information on this file, see\n",
      "https://docs.djangoproject.com/en/2.0/howto/deployment/wsgi/\n",
      "\"\"\"\n",
      "\n",
      "import os\n",
      "\n",
      "from django.core.wsgi import get_wsgi_application\n",
      "\n",
      "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"myproject.settings\")\n",
      "\n",
      "application = get_wsgi_application()\n",
      "\n",
      "Output: {'wsgi': ['os.environ.setdefault', 'django.core.wsgi.get_wsgi_application'], 'os.environ.setdefault': [], 'django.core.wsgi.get_wsgi_application': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\myproject\\wsgi.py\n",
      "[('wsgi', 'os environ setdefault'), ('wsgi', 'django core wsgi get_wsgi_application')]\n",
      "0\n",
      "found files: []\n",
      "import json\n",
      "import pdfkit\n",
      "import os\n",
      "import shutil\n",
      "import urllib.request\n",
      "import ast\n",
      "from django.conf import settings\n",
      "from xml.etree import ElementTree as ET\n",
      "from wsgiref.util import FileWrapper\n",
      "\n",
      "from dicttoxml import dicttoxml\n",
      "from django.http import HttpResponse\n",
      "from django.http import Http404\n",
      "from django.http import JsonResponse\n",
      "from django.shortcuts import render\n",
      "from django.views.decorators.csrf import csrf_exempt\n",
      "\n",
      "from .vacants import get_vacants\n",
      "from .jobs import all_jobs, analyse_file\n",
      "from random import randrange, uniform\n",
      "cv_summary = {}\n",
      "\n",
      "\n",
      "def home(request):\n",
      "\treturn render(request, 'formuploads/index.html')\n",
      "\n",
      "\n",
      "def show_json(request):\n",
      "\tif 'cv_summary' in request.session:\n",
      "\t\tcv = request.session['cv_summary']\n",
      "\treturn HttpResponse(json.dumps(cv, ensure_ascii=False), content_type=\"application/json\")\n",
      "\n",
      "\n",
      "def show_xml(request):\n",
      "\tif 'cv_summary' in request.session:\n",
      "\t\tcv = request.session['cv_summary']\n",
      "\treturn HttpResponse(dicttoxml(cv, custom_root='cv_summary', attr_type=False), content_type=\"application/xml\")\n",
      "\n",
      "\n",
      "@csrf_exempt\n",
      "def upload(request):\n",
      "\n",
      "\tall_vacants_info = [{}]\n",
      "\tvacants_ids = []\n",
      "\ttry:\n",
      "\t\tvacants_ids, cv_summary = handle_uploaded_file(\n",
      "\t\t\trequest.FILES['file'], str(request.FILES['file']))\n",
      "\texcept:\n",
      "\t\treturn render(request, 'formuploads/failed.html', {'error': ' : pdf, doc, docx, rtf'})\n",
      "\trequest.session['cv_summary'] = cv_summary\n",
      "\tall_vacants_info = analyse_file(all_vacants_info, vacants_ids)\n",
      "\n",
      "\tif request.method == 'POST':\n",
      "\t\trecommend = [str()]\n",
      "\t\trecommend.pop(0)\n",
      "\t\tfor key in cv_summary:\n",
      "\t\t\tif (len(cv_summary[key]) < 5 and key != 'other'):\n",
      "\t\t\t\trecommend.append(\"      : \" +\n",
      "\t\t\t\t\t\t\t\t str(key) + \"   \")\n",
      "\t\trecommend_len = len(recommend)\n",
      "\t   \n",
      "\t\treturn render(request, 'formuploads/success.html', {'vacants': all_vacants_info,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'cv_summary': cv_summary, 'recommend': recommend, 'recommend_len': recommend_len})\n",
      "\treturn render(request, 'formuploads/failed.html', {'error': '  '})\n",
      "\n",
      "\n",
      "def test(request):\n",
      "\tif 'cv_summary' in request.session:\n",
      "\t\tcv = request.session['cv_summary']\n",
      "\tfor k in cv:\n",
      "\t\tfor v in cv[k]:\n",
      "\t\t\tif \"C++\" in v or \"c++\" in v or \"++\" in v or \"++\" in v:\n",
      "\t\t\t\treturn render(request, 'formuploads/test.html')\n",
      "\treturn render(request, 'formuploads/failed.html', {'error': '    '})\n",
      "\n",
      "\n",
      "def handle_uploaded_file(file, filename):\n",
      "\tif not os.path.exists('upload/'):\n",
      "\t\tos.mkdir('upload/')\n",
      "\twith open('upload/' + filename, 'wb+') as destination:\n",
      "\t\tfor chunk in file.chunks():\n",
      "\t\t\tdestination.write(chunk)\n",
      "\tdir_path = 'upload/' + filename\n",
      "\tresults = []\n",
      "\tresults, cv_summary = get_vacants(dir_path)\n",
      "\tif os.path.exists('upload/'):\n",
      "\t\tshutil.rmtree('upload/')\n",
      "\treturn results, cv_summary\n",
      "\n",
      "def search(search_type=\"job_name\",search_text=\" 1\"):\n",
      "\tall_jobs_array=all_jobs()\n",
      "\t\n",
      "\tfound_job=[{}]\n",
      "\t\n",
      "\tfor value in all_jobs_array:\n",
      "\t\tfor key in value:\n",
      "\t\t\tif key == search_type and search_text.lower() in value[key].lower():\n",
      "\t\t\t\tfound_job.append(value)\n",
      "\t\t\t\t\t\n",
      "\n",
      "\n",
      "\treturn found_job                 \n",
      "\t\t\t\t\t\n",
      "def search_v(request):\n",
      "\tjob_name, job_region, job_description = False, False, False\n",
      "\tname=\"job_name\"\n",
      "\tjob_name=request.GET.get('job_name')\n",
      "\tjob_region  =request.GET.get('job_region')\n",
      "\tjob_description=request.GET.get('job_description')\n",
      "\n",
      "\tsearch_txt = request.GET['search_text']\n",
      "\tif job_name=='True':\n",
      "\t\tname=\"job_name\"\n",
      "\tif job_region=='True':\n",
      "\t\tname=\"job_region\"\n",
      "\tif job_description=='True':\n",
      "\t\tname=\"job_description\"\n",
      "\n",
      "\tfound_job=search(name,search_txt)\n",
      "\t\n",
      "\t\n",
      "\treturn render(request,'formuploads/search.html', {'found_job':found_job, 'check':[job_name,job_region,job_description] , 'name':name})\n",
      "\n",
      "def generate_pdf(request):\n",
      "\t\n",
      "\treturn render(request,'formuploads/generate_pdf.html')\n",
      "\n",
      "def resume_create(request):\n",
      "\t\n",
      "\tresume = {}\n",
      "\tresume['firstname'] = request.GET.get('firstname')\n",
      "\tresume['lastname'] = request.GET.get('lastname')\n",
      "\tresume['phone'] = request.GET.get('phone')\n",
      "\tresume['email'] = request.GET.get('email')\n",
      "\tresume['address'] = request.GET.get('address')\n",
      "\tresume['positions'] = request.GET.get('positions')\n",
      "\tresume['skills'] = request.GET.get('skills')\n",
      "\tresume['about'] = request.GET.get('about')\n",
      "\tresume['educations'] = [{}]\n",
      "\tresume['experiences'] = [{}]\n",
      "\tresume['languages'] = [{}]\n",
      "\n",
      "\tcounter_1 = 0\n",
      "\ttry:\n",
      "\t\tcounter_1_stp = int(request.GET.get('counter_1'))\n",
      "\texcept:\n",
      "\t\tcounter_1_stp = 0\n",
      "\n",
      "\tif(counter_1_stp == '0' or None):\n",
      "\t\tcounter_1_stp = 0\n",
      "\n",
      "\twhile True:\n",
      "\t\tcounter_1 += 1\n",
      "\t\tif(counter_1 > counter_1_stp):\n",
      "\t\t\tbreak\n",
      "\t\tresume['educations'].append({\n",
      "\t\t\t'name': request.GET.get('education_name' + str(counter_1)),\n",
      "\t\t\t'degree': request.GET.get('education_degree' + str(counter_1)),\n",
      "\t\t\t'start_date': request.GET.get('education_start_date' + str(counter_1)),\n",
      "\t\t\t'end_date': request.GET.get('education_end_date' + str(counter_1)),\n",
      "\t\t\t'description': request.GET.get('education_description' + str(counter_1)),\n",
      "\t\t})\n",
      "\tresume['educations'].pop(0)\n",
      "\n",
      "\n",
      "\n",
      "\tcounter_2 = 0\n",
      "\ttry:\n",
      "\t\tcounter_2_stp = int(request.GET.get('counter_2'))\n",
      "\texcept:\n",
      "\t\tcounter_2_stp = 0\n",
      "\n",
      "\tif(counter_2_stp == '0' or None):\n",
      "\t\tcounter_2_stp = 0\n",
      "\n",
      "\twhile True:\n",
      "\t\tcounter_2 += 1\n",
      "\t\tif(counter_2 > counter_2_stp):\n",
      "\t\t\tbreak\n",
      "\t\tresume['experiences'].append({\n",
      "\t\t\t'name': request.GET.get('experience_name' + str(counter_2)),\n",
      "\t\t\t'designation': request.GET.get('experience_designation' + str(counter_2)),\n",
      "\t\t\t'start_date': request.GET.get('experience_start_date' + str(counter_2)),\n",
      "\t\t\t'end_date': request.GET.get('experience_end_date' + str(counter_2)),\n",
      "\t\t\t'description': request.GET.get('experience_description' + str(counter_2)),\n",
      "\t\t})\n",
      "\tresume['experiences'].pop(0)\n",
      "\n",
      "\tcounter_3 = 0\n",
      "\ttry:\n",
      "\t\tcounter_3_stp = int(request.GET.get('counter_3'))\n",
      "\texcept:\n",
      "\t\tcounter_3_stp = 0\n",
      "\n",
      "\tif(counter_3_stp == '0' or None):\n",
      "\t\tcounter_3_stp = 0\n",
      "\n",
      "\twhile True:\n",
      "\t\tcounter_3 += 1\n",
      "\t\tif(counter_3 > counter_3_stp):\n",
      "\t\t\tbreak\n",
      "\t\tresume['languages'].append({\n",
      "\t\t\t'name': request.GET.get('language_name' + str(counter_3)),\n",
      "\t\t\t'level': request.GET.get('language_level' + str(counter_3)),\n",
      "\t\t})\n",
      "\tresume['languages'].pop(0)\n",
      "\n",
      "\treturn render(request, 'formuploads/resume_create.html',{'resume': resume})\n",
      "\n",
      "def extract_pdf(request):\n",
      "\turlParams = request.get_full_path()\n",
      "\turlParams = urlParams[40:]\n",
      "\n",
      "\tpath_wkthmltopdf_krax = r'/app/bin/wkhtmltopdf'\n",
      "\tconfig = pdfkit.configuration(wkhtmltopdf=path_wkthmltopdf_krax)\n",
      "\tresumeUrl = 'https://' + request.get_host() +'/generate_pdf/resume_create/' + \"resume\" + urlParams\n",
      "\n",
      "\tif not os.path.exists('download/'):\n",
      "\t\tos.mkdir('download/')\n",
      "\t\n",
      "\tpdfkit.from_url(resumeUrl, 'download/resume.pdf',configuration=config)\n",
      "\t\n",
      "\tresponse = HttpResponse(open(\"download/resume.pdf\", 'rb').read())\n",
      "\tresponse['Content-Type'] = 'application/pdf'\n",
      "\tresponse['Content-Disposition'] = 'attachment; filename=resume.pdf'\n",
      "\tif os.path.exists('upload/'):\n",
      "\t\tshutil.rmtree('upload/')\n",
      "\treturn response\n",
      "\n",
      "\n",
      "\n",
      "def download_pdf(request, path):\n",
      "\t\n",
      "\tfile_path = os.path.join(settings.MEDIA_ROOT, path)\n",
      "\tif os.path.exists(file_path):\n",
      "\t\twith open(file_path, 'rb') as fh:\n",
      "\t\t\tresponse = HttpResponse(fh.read(), content_type=\"application/pdf\")\n",
      "\t\t\tresponse['Content-Disposition'] = 'inline; filename=' + os.path.basename(file_path)\n",
      "\t\t\treturn response\n",
      "\traise Http404\n",
      "def rate(request):\n",
      "\tif 'cv_summary' in request.session:\n",
      "\t\tcv = request.session['cv_summary']\n",
      "\t\tcv.pop(\"other\")\n",
      "\tcnt = 0\n",
      "\trecommendations = []\n",
      "\tif len(cv['skills']) >= 5:\n",
      "\t\tcnt += randrange(18,20)\n",
      "\telif len(cv['skills']) > 0:\n",
      "\t\tcnt += 10\n",
      "\t\trecommendations.append('skills')\n",
      "\telse:\n",
      "\t\trecommendations.append('skills')\n",
      "\tif len(cv['education']) >= 5:\n",
      "\t\tcnt += randrange(18,20)\n",
      "\telif len(cv['education']) > 0:\n",
      "\t\tcnt += 10\n",
      "\t\trecommendations.append('education')\n",
      "\telse:\n",
      "\t\trecommendations.append('education')\n",
      "\tif len(cv['experience']) >= 5:\n",
      "\t\tcnt += randrange(18,20)\n",
      "\telif len(cv['experience']) > 0:\n",
      "\t\tcnt += 10    \n",
      "\t\trecommendations.append('experience')\n",
      "\telse:\n",
      "\t\trecommendations.append('experience')\n",
      "\tif len(cv['language']) >= 2:\n",
      "\t\tcnt += randrange(8,10)\n",
      "\telif len(cv['language']) > 0:\n",
      "\t\tcnt += 5\n",
      "\t\trecommendations.append('language')\n",
      "\telse:\n",
      "\t\trecommendations.append('language')\n",
      "\tif len(cv['position']) >= 5:\n",
      "\t\tcnt += randrange(8,10)\n",
      "\telif len(cv['position']) > 0:\n",
      "\t\tcnt += 5\n",
      "\t\trecommendations.append('position')\n",
      "\telse:\n",
      "\t\trecommendations.append('position')\n",
      "\tif len(cv['about']) > 0:\n",
      "\t\tcnt += 7\n",
      "\telse:\n",
      "\t\trecommendations.append('about')\n",
      "\tif len(cv['reference']) > 0:\n",
      "\t\tcnt += 8\n",
      "\telse:\n",
      "\t\trecommendations.append('reference')    \n",
      "\tcnt += randrange(-1,1)\n",
      "\tif cnt > 100:\n",
      "\t\tcnt = 100\n",
      "\tif cnt < 0:\n",
      "\t\tcnt = 0\n",
      "\treturn render(request, 'formuploads/rate.html',{\"percentage\": int(cnt), \"reccomendations\": recommendations})\n",
      "\n",
      "\n",
      "def resume(request):\n",
      "\tresume = request.GET.get('resume')\n",
      "\tresume_dict = ast.literal_eval(resume)\n",
      "\treturn render(request, 'formuploads/resume.html',{'resume': resume_dict})\n",
      "\n",
      "\n",
      "def resume_download(request,resume_dict):\n",
      "\treturn render(request,'formuploads/resume.html',{'resume': resume_dict})\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\views.py\n",
      "[]\n",
      "found files: []\n",
      "from django.contrib import admin\n",
      "from django.urls import include, path\n",
      "\n",
      "from . import views\n",
      "\n",
      "app_name = \"formuploads\"\n",
      "urlpatterns = [\n",
      "    path('', views.home, name=\"home\"),\n",
      "    path('upload/', views.upload, name=\"upload\"),\n",
      "    \n",
      "    path('search/', views.search_v, name=\"search\"),\n",
      "    path('generate_pdf/', views.generate_pdf, name=\"generate_pdf\"),\n",
      "    path('upload/show_json/', views.show_json, name=\"show_json\"),\n",
      "    path('upload/show_xml/', views.show_xml, name=\"show_xml\"),\n",
      "    path('upload/rate/', views.rate, name = 'rate'),\n",
      "    path('upload/rate/test', views.test, name=\"test\"),\n",
      "    path('generate_pdf/resume_create/', views.resume_create, name=\"resume_create\"),#     \n",
      "\n",
      "    path('generate_pdf/resume_create/resume/', views.resume, name=\"resume\"), #    html\n",
      "    path('generate_pdf/resume_create/extract_pdf/', views.extract_pdf, name=\"extract_pdf\"), #     \n",
      "    #path('generate_pdf/resume_create/download_my_pdf', views.download_pdf, name=\"download_my_pdf\"),\n",
      "    \n",
      "]\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\urls.py\n",
      "[]\n",
      "found files: []\n",
      "from nltk.corpus import stopwords\n",
      "import string\n",
      "\n",
      "\n",
      "stop_words = stopwords.words('english')\n",
      "for word in stopwords.words('english'):\n",
      "    stop_words.append(word.upper())\n",
      "\n",
      "\n",
      "numbers = ['(', ')','', '', ';', ':', '[', ']', ',', '', '', 'January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
      "           'August', 'September', 'October', 'November', 'December', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'year', 'month', 'months', 'of', 'p',\n",
      "           '/p', 'lt', 'li', '/li', 'gt', '/ul', 'amp', 'nbsp', 'ul', '/strong']\n",
      "for i in range(1950, 2040):\n",
      "    numbers.append(str(i))\n",
      "\n",
      "\n",
      "for i in range(10, 100):\n",
      "    numbers.append(str(i))\n",
      "    \n",
      "def get_vacants_en(l):\n",
      "    head_hunter = False\n",
      "    for line in l:\n",
      "        if \"Resume updated\" in line:\n",
      "            head_hunter = True\n",
      "            break\n",
      "    if (head_hunter):\n",
      "        key_words = [\"Desired position and salary\",\"Work experience\",\"Education\",\"Key skills\",\"Languages\", \"Skills\", \"Further information\",\" \", \"About me\",\"Recommendations\"]\n",
      "        cv_summary = {\"education\": \"\", \"position\": \"\",\n",
      "                      \"skills\": \"\", \"experience\": \"\", \"language\": \"\", \"about\": \"\", \"other\": \"\"}\n",
      "        counter = -1\n",
      "        while counter < len(l) - 1:\n",
      "            counter += 1\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \"Desired position and salary\" in l[counter]:\n",
      "                counter += 1\n",
      "                while('' not in l[counter]):\n",
      "                    cv_summary[\"position\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "                while (\"\" in l[counter]):\n",
      "                    cv_summary[\"position\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \"Work experience\" in l[counter]:\n",
      "                cv_summary[\"experience\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l):\n",
      "                    if (\"Resume updated\" not in l[counter]):\n",
      "                        ok = False\n",
      "                        for k in key_words:\n",
      "                            if (k in l[counter]):\n",
      "                                ok = True\n",
      "                                break\n",
      "                        if ok:\n",
      "                            break\n",
      "                        cv_summary[\"experience\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \"Education\" in l[counter]:\n",
      "                cv_summary[\"education\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l):\n",
      "                    if (\"Resume updated\" not in l[counter]):\n",
      "                        ok = False\n",
      "                        for k in key_words:\n",
      "                            if (k in l[counter]):\n",
      "                                ok = True\n",
      "                                break\n",
      "                        if ok:\n",
      "                            break\n",
      "                        cv_summary[\"education\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \"Languages\" in l[counter]:\n",
      "                cv_summary[\"language\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l):\n",
      "                    if (\"Resume updated\" not in l[counter]):\n",
      "                        ok = False\n",
      "                        for k in key_words:\n",
      "                            if (k in l[counter]):\n",
      "                                ok = True\n",
      "                                break\n",
      "                        if ok:\n",
      "                            break\n",
      "                        cv_summary[\"language\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \"Skills\" in l[counter]:\n",
      "                cv_summary[\"skills\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l):\n",
      "                    if (\"Resume updated\" not in l[counter]):\n",
      "                        ok = False\n",
      "                        for k in key_words:\n",
      "                            if (k in l[counter]):\n",
      "                                ok = True\n",
      "                                break\n",
      "                        if ok:\n",
      "                            break\n",
      "                        cv_summary[\"skills\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "            \n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \" \" in l[counter]:\n",
      "                cv_summary[\"other\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l):\n",
      "                    if (\" \" not in l[counter]):    \n",
      "                        ok = False\n",
      "                        for k in key_words:\n",
      "                            if (k in l[counter]):\n",
      "                                ok = True\n",
      "                                break\n",
      "                        if ok:\n",
      "                            break\n",
      "                        cv_summary[\"other\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \"Recommendations\" in l[counter]:\n",
      "                cv_summary[\"reference\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l):\n",
      "                    if (\"Resume updated\" not in l[counter]):\n",
      "                        ok = False\n",
      "                        for k in key_words:\n",
      "                            if (k in l[counter]):\n",
      "                                ok = True\n",
      "                                break\n",
      "                        if ok:\n",
      "                            break\n",
      "                        cv_summary[\"reference\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "            if counter == len(l):\n",
      "                break\n",
      "            if \"About me\" in l[counter]:\n",
      "                cv_summary[\"about\"] = \"\"\n",
      "                counter += 1\n",
      "                while counter < len(l):\n",
      "                    if (\"Resume updated\" not in l[counter]):\n",
      "                        cv_summary[\"about\"] += \" \" + l[counter]\n",
      "                    counter += 1\n",
      "\n",
      "        for key in cv_summary:\n",
      "            cv_summary[key] = cv_summary[key].replace(',', ' ').replace(')', '').replace('(', '').split()\n",
      "\n",
      "            cv_summary[key] = [a for a in cv_summary[key]\n",
      "                               if not a in stop_words and not a in string.punctuation]\n",
      "            cv_summary[key] = [\n",
      "                ab for ab in cv_summary[key] if not ab in numbers]\n",
      "\n",
      "        if 'position' in cv_summary:\n",
      "            key_pos = [x for x in cv_summary[\"position\"] if x != \"\"]\n",
      "            cv_summary['position'] = key_pos\n",
      "\n",
      "    else:\n",
      "\n",
      "        key_words = {\n",
      "            \"education\": [\"Education\", \"Qualification\",\n",
      "                          \"Specialty\"],\n",
      "\n",
      "            \"position\": [\"Goal\", \"Desired Position\"],\n",
      "\n",
      "            \"skills\": [\"Skills\", \"Additional information\",\n",
      "                       \"Computer literacy\", \"Qualities\"],\n",
      "\n",
      "            \"experience\": [\"Work Experience\", \"Activities\", \"Work History\", \"Affiliations\", \"Experience\"],\n",
      "\n",
      "            \"language\": [\"Languages\", \"Knowledge of Languages\", \"Language\"],\n",
      "\n",
      "            \"about\": [\"About me\", \"Additional information\", \"Additional information\", \"Awards\",\"Achievements\", \"Accomplishment\"],\n",
      "            \"reference\": [\"Recommendations\", \"References\",\"Reference\", \"Referees\"],\n",
      "            \"other\": [\"interests\", \"hobby\"]\n",
      "        }\n",
      "\n",
      "        cv_summary = {\"education\": \"\", \"position\": \"\",\n",
      "                      \"skills\": \"\", \"experience\": \"\", \"language\": \"\", \"about\": \"\", \"reference\": \"\", \"other\":\"\"}\n",
      "\n",
      "        counter_l = -1\n",
      "        while (counter_l < len(l) - 1):\n",
      "            counter_l += 1\n",
      "            for key in key_words:\n",
      "                for word in key_words[key]:\n",
      "                    if counter_l < len(l) and word.lower() in l[counter_l].lower():\n",
      "                        check = True\n",
      "                        cv_summary[key] += \" \" + l[counter_l].lower().replace(word.lower(), '')\n",
      "                        counter_l += 1\n",
      "                        while (check):\n",
      "                            if (counter_l > len(l) - 1):\n",
      "                                check = False\n",
      "                                break\n",
      "                            for key_1 in key_words:\n",
      "                                if key_1 != key:\n",
      "                                    for word_1 in key_words[key_1]:\n",
      "                                        if word_1.lower() in l[counter_l].lower():\n",
      "                                            check = False\n",
      "                                            counter_l -= 1\n",
      "                                            break\n",
      "                                    if check == False:\n",
      "                                        break\n",
      "                            if not check:\n",
      "                                break\n",
      "                            else:\n",
      "                                cv_summary[key] += \" \" + l[counter_l]\n",
      "                                counter_l += 1\n",
      "\n",
      "        for key in cv_summary:\n",
      "            cv_summary[key] = cv_summary[key].replace(',', ' ').replace(')', '').replace('(', '').split()\n",
      "            cv_summary[key] = [a for a in cv_summary[key]\n",
      "                               if not a in stop_words and not a in string.punctuation]\n",
      "            \n",
      "            cv_summary[key] = [\n",
      "                ab for ab in cv_summary[key] if not ab in numbers]\n",
      "\n",
      "    return cv_summary\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\vacants_en.py\n",
      "[]\n",
      "found files: []\n",
      "from io import StringIO\n",
      "\n",
      "from pdfminer.converter import TextConverter\n",
      "from pdfminer.layout import LAParams\n",
      "from pdfminer.pdfinterp import PDFPageInterpreter, PDFResourceManager\n",
      "from pdfminer.pdfpage import PDFPage\n",
      "\n",
      "\n",
      "def pdf_to_text(fname, pages=None):\n",
      "    if not pages:\n",
      "        pagenums = set()\n",
      "    else:\n",
      "        pagenums = set(pages)\n",
      "\n",
      "    output = StringIO()\n",
      "    manager = PDFResourceManager()\n",
      "    converter = TextConverter(manager, output, laparams=LAParams())\n",
      "    interpreter = PDFPageInterpreter(manager, converter)\n",
      "\n",
      "    infile = open(fname, 'rb')\n",
      "    for page in PDFPage.get_pages(infile, pagenums):\n",
      "        interpreter.process_page(page)\n",
      "    infile.close()\n",
      "    converter.close()\n",
      "    text = output.getvalue()\n",
      "    output.close()\n",
      "    result = []\n",
      "    for line in text.split('\\n'):\n",
      "        line2 = line.strip()\n",
      "        if line2 != '':\n",
      "            result.append(line2)\n",
      "    return result\n",
      "\n",
      "Output: {'pdf_utils': [], 'pdf_utils.pdf_to_text': ['pdfminer.pdfinterp.PDFResourceManager', '<builtin>.set', '<builtin>.open', 'pdfminer.pdfpage.PDFPage.get_pages', 'pdfminer.converter.TextConverter', 'pdfminer.pdfinterp.PDFPageInterpreter', 'pdfminer.layout.LAParams', 'io.StringIO'], '<builtin>.set': [], 'io.StringIO': [], 'pdfminer.pdfinterp.PDFResourceManager': [], 'pdfminer.layout.LAParams': [], 'pdfminer.converter.TextConverter': [], 'pdfminer.pdfinterp.PDFPageInterpreter': [], '<builtin>.open': [], 'pdfminer.pdfpage.PDFPage.get_pages': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\pdf_utils.py\n",
      "[('pdf_utils pdf_to_text', 'pdfminer pdfinterp PDFResourceManager'), ('pdf_utils pdf_to_text', 'pdfminer pdfpage PDFPage get_pages'), ('pdf_utils pdf_to_text', 'pdfminer converter TextConverter'), ('pdf_utils pdf_to_text', 'pdfminer pdfinterp PDFPageInterpreter'), ('pdf_utils pdf_to_text', 'pdfminer layout LAParams'), ('pdf_utils pdf_to_text', 'io StringIO')]\n",
      "0\n",
      "found files: []\n",
      "import html\n",
      "import json\n",
      "import operator\n",
      "import os\n",
      "import string\n",
      "import unicodedata\n",
      "import urllib\n",
      "import urllib.request\n",
      "from xml.etree import ElementTree as ET\n",
      "\n",
      "import requests\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.tokenize import word_tokenize\n",
      "\n",
      "from langdetect import detect\n",
      "\n",
      "from .io_utils import read_pdf_and_docx\n",
      "from .vacants_en import get_vacants_en\n",
      "from .vacants_ru import get_vacants_ru\n",
      "\n",
      "requestURL = \"https://www.enbek.kz/ru/xml/jooble\"\n",
      "\n",
      "name = \"\"\n",
      "root = ET.parse(urllib.request.urlopen(requestURL)).getroot()\n",
      "\n",
      "\n",
      "def stop_words_kk():\n",
      "    stop_words_kk = []\n",
      "    with open('./stop.txt', 'rb') as f:\n",
      "        lines = f.readlines()\n",
      "        stop_words_kk.append(lines[0])\n",
      "    return stop_words_kk\n",
      "\n",
      "\n",
      "stop_words = stopwords.words('russian')\n",
      "stop_words_k = stop_words_kk()\n",
      "for word in stopwords.words('russian'):\n",
      "    stop_words.append(word.upper())\n",
      "\n",
      "\n",
      "numbers = ['(', ')', '', ';', ':', '[', ']', ',', '', '', '', '',\n",
      "           '', '', '', '', '',\n",
      "           '', '', '', '', '', '1', '2', '3', '4', '5', '6', '7', '8', '9', '', '', '', 'of', 'p',\n",
      "           '/p', 'lt', 'li', '/li', 'gt', '/ul', 'amp', 'nbsp', 'ul', '/strong']\n",
      "\n",
      "jobs = dict()\n",
      "\n",
      "\n",
      "for job in root.iter('job'):\n",
      "    job_id = job.attrib.get('id')\n",
      "\n",
      "    name = job.find('name').text\n",
      "    names = word_tokenize(name)\n",
      "    names = [\n",
      "        wor for wor in names if not wor in stop_words and not wor in string.punctuation]\n",
      "    names = [\n",
      "        word for word in names if not word in stop_words_k and not word in numbers]\n",
      "    jobs[job_id] = names\n",
      "\n",
      "    description = job.find('description').text\n",
      "    if(description != None):\n",
      "        descriptions = word_tokenize(description)\n",
      "        descriptions = [\n",
      "            wor for wor in descriptions if not wor in stop_words and not wor in string.punctuation]\n",
      "        descriptions = [\n",
      "            word for word in descriptions if not word in stop_words_k and not word in numbers]\n",
      "        jobs[job_id].extend(descriptions)\n",
      "\n",
      "\n",
      "def get_vacants(fname, pages=None):\n",
      "    l = read_pdf_and_docx(fname)\n",
      "    cnt_en = 0\n",
      "    cnt_ru = 0\n",
      "    for line in l:\n",
      "        try:\n",
      "            if detect(line.lower()) == 'en':\n",
      "                cnt_en += 1\n",
      "            if detect(line.lower()) == 'ru':\n",
      "                cnt_ru += 1\n",
      "        except:\n",
      "            continue\n",
      "    if cnt_ru > cnt_en:\n",
      "        cv_summary = get_vacants_ru(l)\n",
      "    else:\n",
      "        cv_summary = get_vacants_en(l)\n",
      "    recomend = {}\n",
      "    for key in jobs:\n",
      "        for word in jobs[key]:\n",
      "            for key_1 in cv_summary:\n",
      "                if(key_1 == \"position\" or key_1 == \"skills\"):\n",
      "                    for word_1 in cv_summary[key_1]:\n",
      "                        if(word == word_1):\n",
      "                            if key not in recomend.keys():\n",
      "                                recomend[key] = 1\n",
      "                            else:\n",
      "                                recomend[key] += 1\n",
      "\n",
      "    recomend_sorted_list = sorted(\n",
      "        recomend.items(), key=lambda x: x[1], reverse=True)\n",
      "\n",
      "    recomend_sorted_dict = dict(recomend_sorted_list)\n",
      "\n",
      "    res_dict = {}\n",
      "\n",
      "    counter = -1\n",
      "    for key in recomend_sorted_dict:\n",
      "        counter += 1\n",
      "        if(counter > 20):\n",
      "            break\n",
      "        else:\n",
      "            res_dict[key] = recomend_sorted_dict[key]\n",
      "\n",
      "    return res_dict.keys(), cv_summary\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\vacants.py\n",
      "[]\n",
      "found files: []\n",
      "from django.contrib import admin\n",
      "\n",
      "# Register your models here.\n",
      "\n",
      "Output: {'admin': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\formuploads\\admin.py\n",
      "[]\n",
      "found files: []\n",
      "\"\"\"myproject URL Configuration\n",
      "\n",
      "The `urlpatterns` list routes URLs to views. For more information please see:\n",
      "    https://docs.djangoproject.com/en/2.0/topics/http/urls/\n",
      "Examples:\n",
      "Function views\n",
      "    1. Add an import:  from my_app import views\n",
      "    2. Add a URL to urlpatterns:  path('', views.home, name='home')\n",
      "Class-based views\n",
      "    1. Add an import:  from other_app.views import Home\n",
      "    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')\n",
      "Including another URLconf\n",
      "    1. Import the include() function: from django.urls import include, path\n",
      "    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))\n",
      "\"\"\"\n",
      "from django.contrib import admin\n",
      "from django.urls import path, include\n",
      "from django.conf import settings\n",
      "from django.views.generic.base import RedirectView\n",
      "\n",
      "urlpatterns = [\n",
      "    \n",
      "    path('favicon.ico', RedirectView.as_view(url=settings.STATIC_URL + 'favicon.ico')),\n",
      "    path('', include('formuploads.urls')),\n",
      "\n",
      "]\n",
      "\n",
      "Output: {'urls': ['django.urls.include', 'django.urls.path', 'django.views.generic.base.RedirectView.as_view'], 'django.views.generic.base.RedirectView.as_view': [], 'django.urls.path': [], 'django.urls.include': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\krax1337_bts-resumes\\myproject\\urls.py\n",
      "[('urls', 'django urls include'), ('urls', 'django urls path'), ('urls', 'django views generic base RedirectView as_view')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('settings', 'os path dirname'), ('settings', 'os path abspath'), ('settings', 'os path join'), ('settings', 'django_heroku settings')], [('rtf_utils rtf_to_text', 're compile')], [('io_utils read_pdf_and_docx', 'rtf_utils rtf_to_text'), ('io_utils read_pdf_and_docx', 'docx_utils docx_to_text'), ('io_utils read_pdf_and_docx', 'pdf_utils pdf_to_text'), ('io_utils read_pdf_and_docx', 'doc_utils doc_to_text'), ('io_utils read_pdf_and_docx', 'os rename')], [('jobs analyse_file', 'xml etree ElementTree parse'), ('jobs all_jobs', 'xml etree ElementTree parse')], [('docx_utils docx_to_text', 'docx Document'), ('docx_utils docx_to_text', 'docx_utils preprocess_text'), ('docx_utils preprocess_text', 'docx_utils join_name_tag')], [('doc_utils doc_to_text', 'os system')], [('manage', 'os environ setdefault'), ('manage', 'django core management execute_from_command_line')], [('wsgi', 'os environ setdefault'), ('wsgi', 'django core wsgi get_wsgi_application')], [('pdf_utils pdf_to_text', 'pdfminer pdfinterp PDFResourceManager'), ('pdf_utils pdf_to_text', 'pdfminer pdfpage PDFPage get_pages'), ('pdf_utils pdf_to_text', 'pdfminer converter TextConverter'), ('pdf_utils pdf_to_text', 'pdfminer pdfinterp PDFPageInterpreter'), ('pdf_utils pdf_to_text', 'pdfminer layout LAParams'), ('pdf_utils pdf_to_text', 'io StringIO')], [('urls', 'django urls include'), ('urls', 'django urls path'), ('urls', 'django views generic base RedirectView as_view')]]\n",
      "********************doctrings*************************\n",
      "['', 'rtf to text', 'read pdf and docx', 'analyse file all jobs', 'docx to text preprocess text join name tag', 'doc to text', '', '', 'pdf to text', '']\n",
      "embed index dataset: 2\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\wangwenhaoxiaotie_Document_classify\\\\models\\\\layoutlm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\wangwenhaoxiaotie_Document_classify\\\\doc_cls\\\\test.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\wangwenhaoxiaotie_Document_classify\\\\doc_cls\\\\train.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\wangwenhaoxiaotie_Document_classify\\\\models\\\\doc_cls.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\wangwenhaoxiaotie_Document_classify\\\\doc_cls\\\\ocr_dataset.py']\n",
      "import logging\n",
      "\n",
      "import torch\n",
      "from torch import nn\n",
      "from torch.nn import CrossEntropyLoss, MSELoss\n",
      "from transformers import BertConfig, BertModel, BertPreTrainedModel\n",
      "from transformers.modeling_bert import BertLayerNorm\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "LAYOUTLM_PRETRAINED_MODEL_ARCHIVE_MAP = {}\n",
      "\n",
      "LAYOUTLM_PRETRAINED_CONFIG_ARCHIVE_MAP = {}\n",
      "\n",
      "\n",
      "class LayoutlmConfig(BertConfig):\n",
      "    pretrained_config_archive_map = LAYOUTLM_PRETRAINED_CONFIG_ARCHIVE_MAP\n",
      "    model_type = \"bert\"\n",
      "\n",
      "    def __init__(self, max_2d_position_embeddings=1024, **kwargs):\n",
      "        super().__init__(**kwargs)\n",
      "        self.max_2d_position_embeddings = max_2d_position_embeddings\n",
      "\n",
      "\n",
      "class LayoutlmEmbeddings(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(LayoutlmEmbeddings, self).__init__()\n",
      "        self.word_embeddings = nn.Embedding(\n",
      "            config.vocab_size, config.hidden_size, padding_idx=0\n",
      "        )\n",
      "        self.position_embeddings = nn.Embedding(\n",
      "            config.max_position_embeddings, config.hidden_size\n",
      "        )\n",
      "        self.x_position_embeddings = nn.Embedding(\n",
      "            config.max_2d_position_embeddings, config.hidden_size\n",
      "        )\n",
      "        self.y_position_embeddings = nn.Embedding(\n",
      "            config.max_2d_position_embeddings, config.hidden_size\n",
      "        )\n",
      "        self.h_position_embeddings = nn.Embedding(\n",
      "            config.max_2d_position_embeddings, config.hidden_size\n",
      "        )\n",
      "        self.w_position_embeddings = nn.Embedding(\n",
      "            config.max_2d_position_embeddings, config.hidden_size\n",
      "        )\n",
      "        self.token_type_embeddings = nn.Embedding(\n",
      "            config.type_vocab_size, config.hidden_size\n",
      "        )\n",
      "\n",
      "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
      "        # any TensorFlow checkpoint file\n",
      "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
      "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
      "\n",
      "    def forward(\n",
      "        self,\n",
      "        input_ids,\n",
      "        bbox,\n",
      "        token_type_ids=None,\n",
      "        position_ids=None,\n",
      "        inputs_embeds=None,\n",
      "    ):\n",
      "        seq_length = input_ids.size(1)\n",
      "        if position_ids is None:\n",
      "            position_ids = torch.arange(\n",
      "                seq_length, dtype=torch.long, device=input_ids.device\n",
      "            )\n",
      "            position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
      "        if token_type_ids is None:\n",
      "            token_type_ids = torch.zeros_like(input_ids)\n",
      "\n",
      "        words_embeddings = self.word_embeddings(input_ids)\n",
      "        position_embeddings = self.position_embeddings(position_ids)\n",
      "        left_position_embeddings = self.x_position_embeddings(bbox[:, :, 0])\n",
      "        upper_position_embeddings = self.y_position_embeddings(bbox[:, :, 1])\n",
      "        right_position_embeddings = self.x_position_embeddings(bbox[:, :, 2])\n",
      "        lower_position_embeddings = self.y_position_embeddings(bbox[:, :, 3])\n",
      "        h_position_embeddings = self.h_position_embeddings(\n",
      "            bbox[:, :, 3] - bbox[:, :, 1]\n",
      "        )\n",
      "        w_position_embeddings = self.w_position_embeddings(\n",
      "            bbox[:, :, 2] - bbox[:, :, 0]\n",
      "        )\n",
      "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
      "\n",
      "        embeddings = (\n",
      "            words_embeddings\n",
      "            + position_embeddings\n",
      "            + left_position_embeddings\n",
      "            + upper_position_embeddings\n",
      "            + right_position_embeddings\n",
      "            + lower_position_embeddings\n",
      "            + h_position_embeddings\n",
      "            + w_position_embeddings\n",
      "            + token_type_embeddings\n",
      "        )\n",
      "        embeddings = self.LayerNorm(embeddings)\n",
      "        embeddings = self.dropout(embeddings)\n",
      "        return embeddings\n",
      "\n",
      "\n",
      "class LayoutlmModel(BertModel):\n",
      "\n",
      "    config_class = LayoutlmConfig\n",
      "    pretrained_model_archive_map = LAYOUTLM_PRETRAINED_MODEL_ARCHIVE_MAP\n",
      "    base_model_prefix = \"bert\"\n",
      "\n",
      "    def __init__(self, config):\n",
      "        super(LayoutlmModel, self).__init__(config)\n",
      "        self.embeddings = LayoutlmEmbeddings(config)\n",
      "        self.init_weights()\n",
      "\n",
      "    def forward(\n",
      "        self,\n",
      "        input_ids,\n",
      "        bbox,\n",
      "        attention_mask=None,\n",
      "        token_type_ids=None,\n",
      "        position_ids=None,\n",
      "        head_mask=None,\n",
      "        inputs_embeds=None,\n",
      "        encoder_hidden_states=None,\n",
      "        encoder_attention_mask=None,\n",
      "    ):\n",
      "        if attention_mask is None:\n",
      "            attention_mask = torch.ones_like(input_ids)\n",
      "        if token_type_ids is None:\n",
      "            token_type_ids = torch.zeros_like(input_ids)\n",
      "\n",
      "        # We create a 3D attention mask from a 2D tensor mask.\n",
      "        # Sizes are [batch_size, 1, 1, to_seq_length]\n",
      "        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n",
      "        # this attention mask is more simple than the triangular masking of causal attention\n",
      "        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n",
      "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
      "\n",
      "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
      "        # masked positions, this operation will create a tensor which is 0.0 for\n",
      "        # positions we want to attend and -10000.0 for masked positions.\n",
      "        # Since we are adding it to the raw scores before the softmax, this is\n",
      "        # effectively the same as removing these entirely.\n",
      "        extended_attention_mask = extended_attention_mask.to(\n",
      "            dtype=next(self.parameters()).dtype\n",
      "        )  # fp16 compatibility\n",
      "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
      "\n",
      "        # Prepare head mask if needed\n",
      "        # 1.0 in head_mask indicate we keep the head\n",
      "        # attention_probs has shape bsz x n_heads x N x N\n",
      "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
      "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
      "        if head_mask is not None:\n",
      "            if head_mask.dim() == 1:\n",
      "                head_mask = (\n",
      "                    head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
      "                )\n",
      "                head_mask = head_mask.expand(\n",
      "                    self.config.num_hidden_layers, -1, -1, -1, -1\n",
      "                )\n",
      "            elif head_mask.dim() == 2:\n",
      "                head_mask = (\n",
      "                    head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)\n",
      "                )  # We can specify head_mask for each layer\n",
      "            head_mask = head_mask.to(\n",
      "                dtype=next(self.parameters()).dtype\n",
      "            )  # switch to fload if need + fp16 compatibility\n",
      "        else:\n",
      "            head_mask = [None] * self.config.num_hidden_layers\n",
      "\n",
      "        embedding_output = self.embeddings(\n",
      "            input_ids, bbox, position_ids=position_ids, token_type_ids=token_type_ids\n",
      "        )\n",
      "        encoder_outputs = self.encoder(\n",
      "            embedding_output, extended_attention_mask, head_mask=head_mask\n",
      "        )\n",
      "        sequence_output = encoder_outputs[0]\n",
      "        pooled_output = self.pooler(sequence_output)\n",
      "\n",
      "        outputs = (sequence_output, pooled_output) + encoder_outputs[\n",
      "            1:\n",
      "        ]  # add hidden_states and attentions if they are here\n",
      "        return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
      "\n",
      "\n",
      "class LayoutlmForTokenClassification(BertPreTrainedModel):\n",
      "    config_class = LayoutlmConfig\n",
      "    pretrained_model_archive_map = LAYOUTLM_PRETRAINED_MODEL_ARCHIVE_MAP\n",
      "    base_model_prefix = \"bert\"\n",
      "\n",
      "    def __init__(self, config):\n",
      "        super().__init__(config)\n",
      "        self.num_labels = config.num_labels\n",
      "        self.bert = LayoutlmModel(config)\n",
      "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
      "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
      "\n",
      "        self.init_weights()\n",
      "\n",
      "    def forward(\n",
      "        self,\n",
      "        input_ids,\n",
      "        bbox,\n",
      "        attention_mask=None,\n",
      "        token_type_ids=None,\n",
      "        position_ids=None,\n",
      "        head_mask=None,\n",
      "        inputs_embeds=None,\n",
      "        labels=None,\n",
      "    ):\n",
      "\n",
      "        outputs = self.bert(\n",
      "            input_ids=input_ids,\n",
      "            bbox=bbox,\n",
      "            attention_mask=attention_mask,\n",
      "            token_type_ids=token_type_ids,\n",
      "            position_ids=position_ids,\n",
      "            head_mask=head_mask,\n",
      "        )\n",
      "\n",
      "        sequence_output = outputs[0]\n",
      "\n",
      "        sequence_output = self.dropout(sequence_output)\n",
      "        logits = self.classifier(sequence_output)\n",
      "\n",
      "        outputs = (logits,) + outputs[\n",
      "            2:\n",
      "        ]  # add hidden states and attention if they are here\n",
      "        if labels is not None:\n",
      "            loss_fct = CrossEntropyLoss()\n",
      "            # Only keep active parts of the loss\n",
      "            if attention_mask is not None:\n",
      "                active_loss = attention_mask.view(-1) == 1\n",
      "                active_logits = logits.view(-1, self.num_labels)[active_loss]\n",
      "                active_labels = labels.view(-1)[active_loss]\n",
      "                loss = loss_fct(active_logits, active_labels)\n",
      "            else:\n",
      "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
      "            outputs = (loss,) + outputs\n",
      "\n",
      "        return outputs  # (loss), scores, (hidden_states), (attentions)\n",
      "\n",
      "\n",
      "class LayoutlmForSequenceClassification(BertPreTrainedModel):\n",
      "    config_class = LayoutlmConfig\n",
      "    pretrained_model_archive_map = LAYOUTLM_PRETRAINED_MODEL_ARCHIVE_MAP\n",
      "    base_model_prefix = \"bert\"\n",
      "\n",
      "    def __init__(self, config):\n",
      "        super(LayoutlmForSequenceClassification, self).__init__(config)\n",
      "        self.num_labels = config.num_labels\n",
      "\n",
      "        self.bert = LayoutlmModel(config)\n",
      "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
      "        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
      "\n",
      "        self.init_weights()\n",
      "\n",
      "    def forward(\n",
      "        self,\n",
      "        input_ids,\n",
      "        bbox,\n",
      "        attention_mask=None,\n",
      "        token_type_ids=None,\n",
      "        position_ids=None,\n",
      "        head_mask=None,\n",
      "        inputs_embeds=None,\n",
      "        labels=None,\n",
      "    ):\n",
      "\n",
      "        outputs = self.bert(\n",
      "            input_ids=input_ids,\n",
      "            bbox=bbox,\n",
      "            attention_mask=attention_mask,\n",
      "            token_type_ids=token_type_ids,\n",
      "            position_ids=position_ids,\n",
      "            head_mask=head_mask,\n",
      "        )\n",
      "\n",
      "        pooled_output = outputs[1]\n",
      "\n",
      "        pooled_output = self.dropout(pooled_output)\n",
      "        logits = self.classifier(pooled_output)\n",
      "\n",
      "        outputs = (logits,) + outputs[\n",
      "            2:\n",
      "        ]  # add hidden states and attention if they are here\n",
      "\n",
      "        if labels is not None:\n",
      "            if self.num_labels == 1:\n",
      "                #  We are doing regression\n",
      "                loss_fct = MSELoss()\n",
      "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
      "            else:\n",
      "                loss_fct = CrossEntropyLoss()\n",
      "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
      "            outputs = (loss,) + outputs\n",
      "\n",
      "        return outputs  # (loss), logits, (hidden_states), (attentions)\n",
      "\n",
      "\n",
      "class LayoutlmForFeatureExtraction(BertPreTrainedModel):\n",
      "    config_class = LayoutlmConfig\n",
      "    pretrained_model_archive_map = LAYOUTLM_PRETRAINED_MODEL_ARCHIVE_MAP\n",
      "    base_model_prefix = \"bert\"\n",
      "\n",
      "    def __init__(self, config):\n",
      "        super(LayoutlmForFeatureExtraction, self).__init__(config)\n",
      "        self.bert = LayoutlmModel(config)\n",
      "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
      "        self.init_weights()\n",
      "\n",
      "    def forward(\n",
      "        self,\n",
      "        input_ids,\n",
      "        bbox,\n",
      "        attention_mask=None,\n",
      "        token_type_ids=None,\n",
      "        position_ids=None,\n",
      "        head_mask=None,\n",
      "        inputs_embeds=None,\n",
      "        labels=None,\n",
      "    ):\n",
      "\n",
      "        outputs = self.bert(\n",
      "            input_ids=input_ids,\n",
      "            bbox=bbox,\n",
      "            attention_mask=attention_mask,\n",
      "            token_type_ids=token_type_ids,\n",
      "            position_ids=position_ids,\n",
      "            head_mask=head_mask,\n",
      "        )\n",
      "\n",
      "        pooled_output = outputs[1]\n",
      "        return pooled_output\n",
      "\n",
      "Output: {'layoutlm': ['logging.getLogger'], 'logging.getLogger': [], 'layoutlm.LayoutlmConfig.__init__': ['<builtin>.super'], '<builtin>.super': [], 'layoutlm.LayoutlmEmbeddings.__init__': ['torch.nn.Dropout', '<builtin>.super', 'torch.nn.Embedding', 'transformers.modeling_bert.BertLayerNorm'], 'torch.nn.Embedding': [], 'transformers.modeling_bert.BertLayerNorm': [], 'torch.nn.Dropout': [], 'layoutlm.LayoutlmEmbeddings.forward': ['torch.zeros_like', 'torch.arange'], 'torch.arange': [], 'torch.zeros_like': [], 'layoutlm.LayoutlmModel.__init__': ['<builtin>.super', 'layoutlm.LayoutlmEmbeddings.__init__', 'transformers.BertModel.init_weights'], 'transformers.BertModel.init_weights': [], 'layoutlm.LayoutlmModel.forward': ['<builtin>.next', 'layoutlm.LayoutlmEmbeddings.__init__', 'transformers.BertModel.parameters', 'transformers.BertModel.encoder', 'torch.zeros_like', 'transformers.BertModel.pooler', 'torch.ones_like'], 'torch.ones_like': [], 'transformers.BertModel.parameters': [], '<builtin>.next': [], 'transformers.BertModel.encoder': [], 'transformers.BertModel.pooler': [], 'layoutlm.LayoutlmForTokenClassification.__init__': ['torch.nn.Linear', 'layoutlm.LayoutlmModel.__init__', 'torch.nn.Dropout', '<builtin>.super', 'transformers.BertPreTrainedModel.init_weights'], 'torch.nn.Linear': [], 'transformers.BertPreTrainedModel.init_weights': [], 'layoutlm.LayoutlmForTokenClassification.forward': ['torch.nn.CrossEntropyLoss', 'layoutlm.LayoutlmModel.__init__'], 'torch.nn.CrossEntropyLoss': [], 'layoutlm.LayoutlmForSequenceClassification.__init__': ['torch.nn.Linear', 'layoutlm.LayoutlmModel.__init__', 'torch.nn.Dropout', '<builtin>.super', 'transformers.BertPreTrainedModel.init_weights'], 'layoutlm.LayoutlmForSequenceClassification.forward': ['torch.nn.MSELoss', 'torch.nn.CrossEntropyLoss', 'layoutlm.LayoutlmModel.__init__'], 'torch.nn.MSELoss': [], 'layoutlm.LayoutlmForFeatureExtraction.__init__': ['torch.nn.Dropout', '<builtin>.super', 'transformers.BertPreTrainedModel.init_weights', 'layoutlm.LayoutlmModel.__init__'], 'layoutlm.LayoutlmForFeatureExtraction.forward': ['layoutlm.LayoutlmModel.__init__']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\wangwenhaoxiaotie_Document_classify\\models\\layoutlm.py\n",
      "[('layoutlm', 'logging getLogger'), ('layoutlm LayoutlmEmbeddings __init__', 'torch nn Dropout'), ('layoutlm LayoutlmEmbeddings __init__', 'torch nn Embedding'), ('layoutlm LayoutlmEmbeddings __init__', 'transformers modeling_bert BertLayerNorm'), ('layoutlm LayoutlmEmbeddings forward', 'torch zeros_like'), ('layoutlm LayoutlmEmbeddings forward', 'torch arange'), ('layoutlm LayoutlmModel __init__', 'layoutlm LayoutlmEmbeddings __init__'), ('layoutlm LayoutlmModel __init__', 'transformers BertModel init_weights'), ('layoutlm LayoutlmModel forward', 'layoutlm LayoutlmEmbeddings __init__'), ('layoutlm LayoutlmModel forward', 'transformers BertModel parameters'), ('layoutlm LayoutlmModel forward', 'transformers BertModel encoder'), ('layoutlm LayoutlmModel forward', 'torch zeros_like'), ('layoutlm LayoutlmModel forward', 'transformers BertModel pooler'), ('layoutlm LayoutlmModel forward', 'torch ones_like'), ('layoutlm LayoutlmForTokenClassification __init__', 'torch nn Linear'), ('layoutlm LayoutlmForTokenClassification __init__', 'layoutlm LayoutlmModel __init__'), ('layoutlm LayoutlmForTokenClassification __init__', 'torch nn Dropout'), ('layoutlm LayoutlmForTokenClassification __init__', 'transformers BertPreTrainedModel init_weights'), ('layoutlm LayoutlmForTokenClassification forward', 'torch nn CrossEntropyLoss'), ('layoutlm LayoutlmForTokenClassification forward', 'layoutlm LayoutlmModel __init__'), ('layoutlm LayoutlmForSequenceClassification __init__', 'torch nn Linear'), ('layoutlm LayoutlmForSequenceClassification __init__', 'layoutlm LayoutlmModel __init__'), ('layoutlm LayoutlmForSequenceClassification __init__', 'torch nn Dropout'), ('layoutlm LayoutlmForSequenceClassification __init__', 'transformers BertPreTrainedModel init_weights'), ('layoutlm LayoutlmForSequenceClassification forward', 'torch nn MSELoss'), ('layoutlm LayoutlmForSequenceClassification forward', 'torch nn CrossEntropyLoss'), ('layoutlm LayoutlmForSequenceClassification forward', 'layoutlm LayoutlmModel __init__'), ('layoutlm LayoutlmForFeatureExtraction __init__', 'torch nn Dropout'), ('layoutlm LayoutlmForFeatureExtraction __init__', 'transformers BertPreTrainedModel init_weights'), ('layoutlm LayoutlmForFeatureExtraction __init__', 'layoutlm LayoutlmModel __init__')]\n",
      "0\n",
      "found files: []\n",
      "from __future__ import absolute_import, division, print_function\n",
      "import argparse\n",
      "import glob\n",
      "import logging\n",
      "import os\n",
      "import random\n",
      "import shutil\n",
      "import math\n",
      "from collections import OrderedDict\n",
      "\n",
      "import json\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn\n",
      "from tensorboardX import SummaryWriter\n",
      "import torch.nn.functional as F\n",
      "from torch.nn import CrossEntropyLoss, MSELoss, BCELoss, BCEWithLogitsLoss\n",
      "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
      "from torch.utils.data.distributed import DistributedSampler\n",
      "from torchsummary import summary\n",
      "from tqdm import tqdm, trange\n",
      "from transformers import (\n",
      "    WEIGHTS_NAME,\n",
      "    AdamW,\n",
      "    BertConfig,\n",
      "    BertTokenizer,\n",
      "    BertForTokenClassification,\n",
      "    RobertaConfig,\n",
      "    RobertaForTokenClassification,\n",
      "    RobertaTokenizer,\n",
      "    get_linear_schedule_with_warmup,\n",
      ")\n",
      "\n",
      "from ocr_dataset import OcrDataset\n",
      "from models import LayoutlmConfig, LayoutlmForTokenClassification, DocumentClassifier\n",
      "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "\n",
      "ALL_MODELS = sum(\n",
      "    (\n",
      "        tuple(conf.pretrained_config_archive_map.keys())\n",
      "        for conf in (BertConfig, RobertaConfig, LayoutlmConfig)\n",
      "    ),\n",
      "    (),\n",
      ")\n",
      "    \n",
      "    \n",
      "MODEL_CLASSES = {\n",
      "    \"bert\": (BertConfig, BertForTokenClassification, BertTokenizer),\n",
      "    \"roberta\": (RobertaConfig, RobertaForTokenClassification, RobertaTokenizer),\n",
      "    \"layoutlm\": (LayoutlmConfig, LayoutlmForTokenClassification, BertTokenizer),\n",
      "}\n",
      "\n",
      "\n",
      "def evaluate(args, model, tokenizer, labels, mode, prefix=\"\"):\n",
      "    eval_dataset = OcrDataset(args.data_dir, tokenizer, labels, \"test_v2\")\n",
      "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
      "    eval_sampler = SequentialSampler(eval_dataset)\n",
      "    eval_dataloader = DataLoader(\n",
      "        eval_dataset,\n",
      "        sampler=eval_sampler,\n",
      "        batch_size=args.eval_batch_size,\n",
      "        collate_fn=None,\n",
      "    )\n",
      "    model.eval()\n",
      "\n",
      "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
      "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
      "    \n",
      "    if mode == \"test_v2\":\n",
      "        dev_loss = 0\n",
      "        dev_steps = 0\n",
      "        logit_all, label_all, file_names_all = [], [], []\n",
      "        logit_soft_all = []\n",
      "        correct_files, error_files = [], []\n",
      "        files = []\n",
      "        entropy_all = []\n",
      "        for batch in tqdm(eval_dataloader):\n",
      "            with torch.no_grad():\n",
      "                inputs = {\n",
      "                    \"input_ids\": batch['input_ids'].to(args.device),\n",
      "                    \"attention_mask\": batch['attention_mask'].to(args.device),\n",
      "                    \"image\": batch['image'].to(args.device),\n",
      "                    \"label\": batch['label'].to(args.device),\n",
      "                }\n",
      "                \n",
      "                if args.model_type in [\"layoutlm\"]:\n",
      "                    inputs[\"bbox\"] = batch['bbox'].to(args.device)\n",
      "                inputs[\"token_type_ids\"] = (\n",
      "                    batch['token_type_ids'].to(args.device)\n",
      "                    if args.model_type in [\"bert\", \"layoutlm\"]\n",
      "                    else None\n",
      "                )  # RoBERTa don\"t use segment_ids\n",
      "\n",
      "                logit, loss = model(**inputs)\n",
      "\n",
      "                if args.n_gpu > 1:\n",
      "                    loss = loss.mean()  # mean() to average on multi-gpu parallel training   \n",
      "\n",
      "                file_names = batch['file_names']                    \n",
      "                \n",
      "                logit_soft = F.softmax(logit, dim=-1)         \n",
      "                entropy = (-torch.sum(logit_soft * torch.log(logit_soft), -1)).detach().cpu().numpy().tolist()\n",
      "                logit_soft = logit_soft.detach().cpu().numpy().tolist()\n",
      "                #import ipdb;ipdb.set_trace()\n",
      "                dev_loss += loss.item()\n",
      "                \n",
      "                logit = logit.argmax(-1).detach().cpu().numpy().tolist()\n",
      "                label = inputs['label'].detach().cpu().numpy().tolist()\n",
      "\n",
      "                logit_all.extend(logit)\n",
      "                logit_soft_all.extend(logit_soft)\n",
      "                label_all.extend(label)\n",
      "                file_names_all.extend(file_names)\n",
      "                entropy_all.extend(entropy)\n",
      "                \n",
      "                \n",
      "             \n",
      "            dev_steps += 1\n",
      "            \n",
      "        acc = accuracy_score(logit_all, label_all)\n",
      "        f1 = f1_score(logit_all, label_all, average=None)   # 'micro'/'macro'/'weighted'\n",
      "        macro_f1 = f1_score(logit_all, label_all, average='macro') \n",
      "        micro_f1 = f1_score(logit_all, label_all, average='micro') \n",
      "        \n",
      "        cm = confusion_matrix(logit_all, label_all)\n",
      "        \n",
      "        labels = open(args.labels).read().split('\\n')\n",
      "        label_map = {i: label for i, label in enumerate(labels)}\n",
      "        \n",
      "        for i, (logit, label) in enumerate(zip(logit_all, label_all)):\n",
      " \n",
      "            files.append((file_names_all[i], label_map[logit], label_map[label], entropy_all[i]))\n",
      "            #if logit != label:\n",
      "            #import ipdb;ipdb.set_trace()\n",
      "            if logit != label:\n",
      "#                 print(logit_soft_all[i], max(logit_soft_all[i]))\n",
      "#                 print('====='*20)\n",
      "                error_files.append((file_names_all[i], label_map[logit], label_map[label]))\n",
      "                \n",
      "#             if (label == 10 and np.argmax(logit_soft_all[i]) != 10 and max(logit_soft_all[i]) > 0.5) or \\\n",
      "#             (label != 10 and np.argmax(logit_soft_all[i]) == 10 and max(logit_soft_all[i]) <= 0.3):\n",
      "#                 error_files.append((file_names_all[i], label_map[logit], label_map[label]))\n",
      "            else:\n",
      "                correct_files.append((file_names_all[i], label_map[logit], label_map[label]))\n",
      "        #print(\"Test: acc {:.5f}, f1 {}, cm {}\".format(acc, f1, cm))  \n",
      "        print(\"Test: acc {:.5f}, macro_f1 {}, micro_f1 {}\".format(acc, macro_f1, micro_f1))  \n",
      "        print(\"Test: f1 {}\".format(f1))\n",
      "        print(\"Test: cm {}\".format(cm)) \n",
      "        return dev_loss / dev_steps, error_files, correct_files, files\n",
      "        \n",
      "\n",
      "\n",
      "def main():  \n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    ## Required parameters\n",
      "    parser.add_argument(\n",
      "        \"--data_dir\",\n",
      "        default=None,\n",
      "        type=str,\n",
      "        required=True,\n",
      "        help=\"The input data dir. Should contain the training files for the CoNLL-2003 NER task.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--model_type\",\n",
      "        default=None,\n",
      "        type=str,\n",
      "        required=True,\n",
      "        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--img_model_type\",\n",
      "        default=None,\n",
      "        type=str,\n",
      "        required=True,\n",
      "        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n",
      "    )    \n",
      "    parser.add_argument(\n",
      "        \"--model_name_or_path\",\n",
      "        default=None,\n",
      "        type=str,\n",
      "        required=True,\n",
      "        help=\"Path to pre-trained model or shortcut name selected in the list: \"\n",
      "        + \", \".join(ALL_MODELS),\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--output_dir\",\n",
      "        default=None,\n",
      "        type=str,\n",
      "        required=True,\n",
      "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
      "    )\n",
      "\n",
      "    ## Other parameters\n",
      "    parser.add_argument(\n",
      "        \"--labels\",\n",
      "        default=\"./CORD/labels.txt\",\n",
      "        type=str,\n",
      "        help=\"Path to a file containing all labels. If not specified, CoNLL-2003 labels are used.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--config_name\",\n",
      "        default=\"\",\n",
      "        type=str,\n",
      "        help=\"Pretrained config name or path if not the same as model_name\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--tokenizer_name\",\n",
      "        default=\"\",\n",
      "        type=str,\n",
      "        help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--cache_dir\",\n",
      "        default=\"\",\n",
      "        type=str,\n",
      "        help=\"Where do you want to store the pre-trained models downloaded from s3\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--max_seq_length\",\n",
      "        default=512,\n",
      "        type=int,\n",
      "        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
      "        \"than this will be truncated, sequences shorter will be padded.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--do_train\", action=\"store_true\", help=\"Whether to run training.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the dev set.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--do_predict\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Whether to run predictions on the test set.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--evaluate_during_training\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Whether to run evaluation during training at each logging step.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--do_lower_case\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Set this flag if you are using an uncased model.\",\n",
      "    )\n",
      "\n",
      "    parser.add_argument(\n",
      "        \"--per_gpu_train_batch_size\",\n",
      "        default=8,\n",
      "        type=int,\n",
      "        help=\"Batch size per GPU/CPU for training.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--per_gpu_eval_batch_size\",\n",
      "        default=16,\n",
      "        type=int,\n",
      "        help=\"Batch size per GPU/CPU for evaluation.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--gradient_accumulation_steps\",\n",
      "        type=int,\n",
      "        default=1,\n",
      "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--learning_rate\",\n",
      "        default=5e-5,   # 5e-5\n",
      "        type=float,\n",
      "        help=\"The initial learning rate for Adam.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--num_train_epochs\",\n",
      "        default=3.0,\n",
      "        type=float,\n",
      "        help=\"Total number of training epochs to perform.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--max_steps\",\n",
      "        default=-1,\n",
      "        type=int,\n",
      "        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\"\n",
      "    )\n",
      "\n",
      "    parser.add_argument(\n",
      "        \"--logging_steps\", type=int, default=500, help=\"Log every X updates steps.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--save_steps\",\n",
      "        type=int,\n",
      "        default=50,\n",
      "        help=\"Save checkpoint every X updates steps.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--eval_all_checkpoints\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--overwrite_output_dir\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Overwrite the content of the output directory\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--overwrite_cache\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Overwrite the cached training and evaluation sets\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--seed\", type=int, default=42, help=\"random seed for initialization\"\n",
      "    )\n",
      "\n",
      "    parser.add_argument(\n",
      "        \"--fp16\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--fp16_opt_level\",\n",
      "        type=str,\n",
      "        default=\"O1\",\n",
      "        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
      "        \"See details at https://nvidia.github.io/apex/amp.html\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--local_rank\",\n",
      "        type=int,\n",
      "        default=-1,\n",
      "        help=\"For distributed training: local_rank\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--server_port\", type=str, default=\"\", help=\"For distant debugging.\"\n",
      "    )\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    if (\n",
      "        os.path.exists(args.output_dir)\n",
      "        and os.listdir(args.output_dir)\n",
      "        and args.do_train\n",
      "    ):\n",
      "        if not args.overwrite_output_dir:\n",
      "            raise ValueError(\n",
      "                \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
      "                    args.output_dir\n",
      "                )\n",
      "            )\n",
      "        else:\n",
      "            if args.local_rank in [-1, 0]:\n",
      "                shutil.rmtree(args.output_dir)\n",
      "\n",
      "    if not os.path.exists(args.output_dir) and (args.do_eval or args.do_predict):\n",
      "        raise ValueError(\n",
      "            \"Output directory ({}) does not exist. Please train and save the model before inference stage.\".format(\n",
      "                args.output_dir\n",
      "            )\n",
      "        )\n",
      "\n",
      "    if (\n",
      "        not os.path.exists(args.output_dir)\n",
      "        and args.do_train\n",
      "        and args.local_rank in [-1, 0]\n",
      "    ):\n",
      "        os.makedirs(args.output_dir)\n",
      "\n",
      "    # Setup distant debugging if needed\n",
      "    if args.server_ip and args.server_port:\n",
      "        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
      "        import ptvsd\n",
      "\n",
      "        print(\"Waiting for debugger attach\")\n",
      "        ptvsd.enable_attach(\n",
      "            address=(args.server_ip, args.server_port), redirect_output=True\n",
      "        )\n",
      "        ptvsd.wait_for_attach()\n",
      "\n",
      "    # Setup CUDA, GPU & distributed training\n",
      "        \n",
      "    if args.local_rank == -1 or args.no_cuda:\n",
      "        device = torch.device(\n",
      "            \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
      "        )\n",
      "        args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()\n",
      "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
      "        torch.cuda.set_device(args.local_rank)\n",
      "        device = torch.device(\"cuda\", args.local_rank)\n",
      "        torch.distributed.init_process_group(backend=\"nccl\")\n",
      "        args.n_gpu = 1\n",
      "    args.device = device\n",
      "\n",
      "    # Setup logging\n",
      "    logging.basicConfig(\n",
      "        filename=os.path.join(args.output_dir, \"train.log\")\n",
      "        if args.local_rank in [-1, 0]\n",
      "        else None,\n",
      "        format=\"%(asctime)s - %(levelname)s - %(name)s -  %(message)s\",\n",
      "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
      "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
      "    )\n",
      "    logger.warning(\n",
      "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
      "        args.local_rank,\n",
      "        device,\n",
      "        args.n_gpu,\n",
      "        bool(args.local_rank != -1),\n",
      "        args.fp16,\n",
      "    )\n",
      "\n",
      "    labels = open(args.labels).read().split('\\n')\n",
      "    num_labels = len(labels)\n",
      "    \n",
      "\n",
      "    # Load pretrained model and tokenizer\n",
      "    if args.local_rank not in [-1, 0]:\n",
      "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
      "\n",
      "    args.model_type = args.model_type.lower()\n",
      "    config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
      "    \n",
      "    config = config_class.from_pretrained(\n",
      "        args.config_name if args.config_name else args.model_name_or_path,\n",
      "        num_labels=num_labels,\n",
      "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
      "    )\n",
      "    \n",
      "    tokenizer = tokenizer_class.from_pretrained(\n",
      "        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
      "        do_lower_case=args.do_lower_case,\n",
      "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
      "    )\n",
      "\n",
      "                \n",
      "    if args.do_predict and args.local_rank in [-1, 0]:\n",
      "        \n",
      "        model = DocumentClassifier(config, args.img_model_type, args.device, 2816, num_labels)   # 1280/3072\n",
      "\n",
      "        pretrained_weights = (torch.load(os.path.join(args.model_name_or_path, 'pytorch_model.bin')))\n",
      "        model.load_state_dict(pretrained_weights)\n",
      "     \n",
      "        model.to(args.device)\n",
      "        dev_loss, error_files, correct_files, files = evaluate(\n",
      "            args, model, tokenizer, labels, mode=\"test_v2\"\n",
      "        )\n",
      "#         files.sort(key=lambda x: x[-1], reverse=True)        \n",
      "#         json.dump(files, open('outputs/test_entropy_base.json', 'w'), indent=2, ensure_ascii=False)\n",
      "        \n",
      "        #print(\"dev loss: %f\" % dev_loss)\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\wangwenhaoxiaotie_Document_classify\\doc_cls\\test.py\n",
      "[]\n",
      "found files: []\n",
      "# coding=utf-8\n",
      "# Copyright 2018 The Google AI Language Team Authors and The HuggingFace Inc. team.\n",
      "# Copyright (c) 2018, NVIDIA CORPORATION.  All rights reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\"\"\" Fine-tuning the library models for named entity recognition on CoNLL-2003 (Bert or Roberta). \"\"\"\n",
      "\n",
      "from __future__ import absolute_import, division, print_function\n",
      "import argparse\n",
      "import glob\n",
      "import logging\n",
      "import os\n",
      "import random\n",
      "import shutil\n",
      "import math\n",
      "from collections import OrderedDict\n",
      "\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import nn\n",
      "from tensorboardX import SummaryWriter\n",
      "from torch.nn import CrossEntropyLoss, MSELoss, BCELoss, BCEWithLogitsLoss\n",
      "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
      "from torch.utils.data.distributed import DistributedSampler\n",
      "from torchsummary import summary\n",
      "from tqdm import tqdm, trange\n",
      "from transformers import (\n",
      "    WEIGHTS_NAME,\n",
      "    AdamW,\n",
      "    BertConfig,\n",
      "    BertTokenizer,\n",
      "    BertForTokenClassification,\n",
      "    RobertaConfig,\n",
      "    RobertaForTokenClassification,\n",
      "    RobertaTokenizer,\n",
      "    get_linear_schedule_with_warmup,\n",
      ")\n",
      "\n",
      "from ocr_dataset import OcrDataset\n",
      "from models import LayoutlmConfig, LayoutlmForTokenClassification, DocumentClassifier\n",
      "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "\n",
      "ALL_MODELS = sum(\n",
      "    (\n",
      "        tuple(conf.pretrained_config_archive_map.keys())\n",
      "        for conf in (BertConfig, RobertaConfig, LayoutlmConfig)\n",
      "    ),\n",
      "    (),\n",
      ")\n",
      "    \n",
      "    \n",
      "MODEL_CLASSES = {\n",
      "    \"bert\": (BertConfig, BertForTokenClassification, BertTokenizer),\n",
      "    \"roberta\": (RobertaConfig, RobertaForTokenClassification, RobertaTokenizer),\n",
      "    \"layoutlm\": (LayoutlmConfig, LayoutlmForTokenClassification, BertTokenizer),\n",
      "}\n",
      "\n",
      "\n",
      "def set_seed(args):\n",
      "    random.seed(args.seed)\n",
      "    np.random.seed(args.seed)\n",
      "    torch.manual_seed(args.seed)\n",
      "    if args.n_gpu > 0:\n",
      "        torch.cuda.manual_seed_all(args.seed)   \n",
      "\n",
      "\n",
      "\n",
      "def train(args, train_dataset, model, tokenizer, labels):\n",
      "    \n",
      "    \"\"\" Train the model \"\"\"\n",
      "    if args.local_rank in [-1, 0]:\n",
      "        tb_writer = SummaryWriter(logdir=\"runs/\" + os.path.basename(args.output_dir))\n",
      "\n",
      "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
      "    train_sampler = (\n",
      "        RandomSampler(train_dataset)\n",
      "        if args.local_rank == -1\n",
      "        else DistributedSampler(train_dataset)\n",
      "    )\n",
      "\n",
      "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, drop_last=True)\n",
      "    \n",
      "    if args.max_steps > 0:\n",
      "        t_total = args.max_steps\n",
      "        args.num_train_epochs = (\n",
      "            args.max_steps\n",
      "            // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
      "            + 1\n",
      "        )\n",
      "    else:\n",
      "        t_total = (\n",
      "            len(train_dataloader)\n",
      "            // args.gradient_accumulation_steps\n",
      "            * args.num_train_epochs\n",
      "        )\n",
      "\n",
      "    # Prepare optimizer and schedule (linear warmup and decay)\n",
      "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
      "    optimizer_grouped_parameters = [\n",
      "        {\n",
      "            \"params\": [\n",
      "                p\n",
      "                for n, p in model.named_parameters()\n",
      "                if not any(nd in n for nd in no_decay)\n",
      "            ],\n",
      "            \"weight_decay\": args.weight_decay,\n",
      "        },\n",
      "        {\n",
      "            \"params\": [\n",
      "                p\n",
      "                for n, p in model.named_parameters()\n",
      "                if any(nd in n for nd in no_decay)\n",
      "            ],\n",
      "            \"weight_decay\": 0.0,\n",
      "        },\n",
      "    ]\n",
      "    optimizer = AdamW(\n",
      "        optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon\n",
      "    )\n",
      "    scheduler = get_linear_schedule_with_warmup(\n",
      "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
      "    )\n",
      "    if args.fp16:\n",
      "        try:\n",
      "            from apex import amp\n",
      "        except ImportError:\n",
      "            raise ImportError(\n",
      "                \"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"\n",
      "            )\n",
      "        model, optimizer = amp.initialize(\n",
      "            model, optimizer, opt_level=args.fp16_opt_level\n",
      "        )\n",
      "\n",
      "    # multi-gpu training (should be after apex fp16 initialization)\n",
      "    \n",
      "    if args.n_gpu > 1:\n",
      "        model = torch.nn.DataParallel(model)\n",
      "    # Distributed training (should be after apex fp16 initialization)\n",
      "    if args.local_rank != -1:\n",
      "        model = torch.nn.parallel.DistributedDataParallel(\n",
      "            model,\n",
      "            device_ids=[args.local_rank],\n",
      "            output_device=args.local_rank,\n",
      "            find_unused_parameters=True,\n",
      "        )\n",
      "\n",
      "    # Train!\n",
      "    logger.info(\"***** Running training *****\")\n",
      "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
      "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
      "    logger.info(\n",
      "        \"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size\n",
      "    )\n",
      "    logger.info(\n",
      "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
      "        args.train_batch_size\n",
      "        * args.gradient_accumulation_steps\n",
      "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
      "    )\n",
      "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
      "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
      "\n",
      "    global_step = 0\n",
      "    tr_loss, logging_loss = 0.0, 0.0\n",
      "    model.zero_grad()\n",
      "    train_iterator = trange(\n",
      "        int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n",
      "    )\n",
      "    \n",
      "    set_seed(args)  # Added here for reproductibility (even between python 2 and 3)\n",
      "    for _ in train_iterator:\n",
      "        epoch_iterator = tqdm(\n",
      "            train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0]\n",
      "        )\n",
      "        for step, batch in enumerate(epoch_iterator):\n",
      "            model.train()\n",
      "            \n",
      "            inputs = {\n",
      "                \"input_ids\": batch['input_ids'].to(args.device),\n",
      "                \"attention_mask\": batch['attention_mask'].to(args.device),\n",
      "                \"image\": batch['image'].to(args.device),\n",
      "                \"label\": batch['label'].to(args.device)\n",
      "            }\n",
      "\n",
      "            if args.model_type in [\"layoutlm\"]:\n",
      "                inputs[\"bbox\"] = batch['bbox'].to(args.device)\n",
      "            inputs[\"token_type_ids\"] = (\n",
      "                batch['token_type_ids'].to(args.device) if args.model_type in [\"bert\", \"layoutlm\"] else None\n",
      "            )  # RoBERTa don\"t use segment_ids\n",
      "            \n",
      "            _, loss = model(**inputs)\n",
      "            #import ipdb;ipdb.set_trace()\n",
      "            if args.n_gpu > 1:\n",
      "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
      "            if args.gradient_accumulation_steps > 1:\n",
      "                loss = loss / args.gradient_accumulation_steps\n",
      "\n",
      "            if args.fp16:\n",
      "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
      "                    scaled_loss.backward()\n",
      "            else:\n",
      "                loss.backward()\n",
      "\n",
      "            tr_loss += loss.item()\n",
      "\n",
      "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
      "                if args.fp16:\n",
      "                    torch.nn.utils.clip_grad_norm_(\n",
      "                        amp.master_params(optimizer), args.max_grad_norm\n",
      "                    )\n",
      "                else:\n",
      "                    torch.nn.utils.clip_grad_norm_(\n",
      "                        model.parameters(), args.max_grad_norm\n",
      "                    )\n",
      "                optimizer.step()\n",
      "                scheduler.step()  # Update learning rate schedule\n",
      "                model.zero_grad()\n",
      "                global_step += 1\n",
      "\n",
      "                if (\n",
      "                    args.local_rank in [-1, 0]\n",
      "                    and args.logging_steps > 0\n",
      "                    and global_step % args.logging_steps == 0\n",
      "                    and global_step > 299\n",
      "                ):\n",
      "                    # Log metrics\n",
      "                    if (\n",
      "                        args.local_rank in [-1, 0] and args.evaluate_during_training\n",
      "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
      "                        dev_loss = evaluate(\n",
      "                                args,\n",
      "                                model,\n",
      "                                tokenizer,\n",
      "                                labels,\n",
      "                                mode=\"dev_v2\"\n",
      "                        )\n",
      "                        \n",
      "                        logger.info(\"dev loss: %f\" % dev_loss)\n",
      "                        print(\"dev loss: %f\" % dev_loss)\n",
      "                        model.train()\n",
      "                        \n",
      "                if (\n",
      "                    args.local_rank in [-1, 0]\n",
      "                    and args.save_steps > 0\n",
      "                    and global_step % args.save_steps == 0\n",
      "                    and global_step > 299\n",
      "                ):\n",
      "                    # Save model checkpoint\n",
      "                    output_dir = os.path.join(\n",
      "                        args.output_dir, \"checkpoint-{}\".format(global_step)\n",
      "                    )\n",
      "                    \n",
      "                    if not os.path.exists(output_dir):\n",
      "                        os.makedirs(output_dir)\n",
      "                    model_to_save = (\n",
      "                        model.module if hasattr(model, \"module\") else model\n",
      "                    )  # Take care of distributed/parallel training\n",
      "                    \n",
      "                    model_to_save.save_pretrained(output_dir)\n",
      "                    tokenizer.save_pretrained(output_dir)\n",
      "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
      "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
      "\n",
      "            if args.max_steps > 0 and global_step > args.max_steps:\n",
      "                epoch_iterator.close()\n",
      "                break\n",
      "                \n",
      "        if args.max_steps > 0 and global_step > args.max_steps:\n",
      "            train_iterator.close()\n",
      "            break\n",
      "        \n",
      "        logger.info(\"step: %d\" %(global_step))\n",
      "        logger.info(\"loss: %f\" % (tr_loss / global_step))\n",
      "        \n",
      "        print(\"loss: %f\" % (tr_loss / global_step))\n",
      "        \n",
      "        \n",
      "    if args.local_rank in [-1, 0]:\n",
      "        tb_writer.close()\n",
      "    \n",
      "    return global_step, tr_loss / global_step\n",
      "\n",
      "\n",
      "def evaluate(args, model, tokenizer, labels, mode, prefix=\"\"):\n",
      "    eval_dataset = OcrDataset(args.data_dir, tokenizer, labels, \"dev_v2\")\n",
      "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
      "    eval_sampler = SequentialSampler(eval_dataset)\n",
      "    eval_dataloader = DataLoader(\n",
      "        eval_dataset,\n",
      "        sampler=eval_sampler,\n",
      "        batch_size=args.eval_batch_size,\n",
      "        collate_fn=None,\n",
      "    )\n",
      "    model.eval()\n",
      "\n",
      "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
      "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
      "    \n",
      "    if mode == \"dev_v2\":\n",
      "        dev_loss = 0\n",
      "        dev_steps = 0\n",
      "        logit_all, label_all = [], []\n",
      "        for batch in tqdm(eval_dataloader):\n",
      "            with torch.no_grad():\n",
      "                inputs = {\n",
      "                    \"input_ids\": batch['input_ids'].to(args.device),\n",
      "                    \"attention_mask\": batch['attention_mask'].to(args.device),\n",
      "                    \"image\": batch['image'].to(args.device),\n",
      "                    \"label\": batch['label'].to(args.device)\n",
      "                }\n",
      "                if args.model_type in [\"layoutlm\"]:\n",
      "                    inputs[\"bbox\"] = batch['bbox'].to(args.device)\n",
      "                inputs[\"token_type_ids\"] = (\n",
      "                    batch['token_type_ids'].to(args.device)\n",
      "                    if args.model_type in [\"bert\", \"layoutlm\"]\n",
      "                    else None\n",
      "                )  # RoBERTa don\"t use segment_ids\n",
      "\n",
      "                logit, loss = model(**inputs)\n",
      "\n",
      "                if args.n_gpu > 1:\n",
      "                    loss = loss.mean()  # mean() to average on multi-gpu parallel training   \n",
      "                    \n",
      "                #import ipdb;ipdb.set_trace()\n",
      "                dev_loss += loss.item()\n",
      "                \n",
      "                logit = logit.argmax(-1).detach().cpu().numpy().tolist()\n",
      "                label = inputs['label'].detach().cpu().numpy().tolist()\n",
      "\n",
      "                logit_all.extend(logit)\n",
      "                label_all.extend(label)\n",
      "                \n",
      "                \n",
      "             \n",
      "            dev_steps += 1\n",
      "            \n",
      "        acc = accuracy_score(logit_all, label_all)\n",
      "        f1 = f1_score(logit_all, label_all, average=None)   # 'micro'/'macro'/'weighted'\n",
      "        macro_f1 = f1_score(logit_all, label_all, average='macro') \n",
      "        micro_f1 = f1_score(logit_all, label_all, average='micro') \n",
      "        \n",
      "        cm = confusion_matrix(logit_all, label_all)\n",
      "        #print(\"Test: acc {:.5f}, f1 {}, cm {}\".format(acc, f1, cm))  \n",
      "        print(\"Test: acc {:.5f}, macro_f1 {}, micro_f1 {}\".format(acc, macro_f1, micro_f1))  \n",
      "        print(\"Test: f1 {}\".format(f1))\n",
      "        return dev_loss / dev_steps\n",
      "        \n",
      "\n",
      "\n",
      "def main():  \n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    ## Required parameters\n",
      "    parser.add_argument(\n",
      "        \"--data_dir\",\n",
      "        default=None,\n",
      "        type=str,\n",
      "        required=True,\n",
      "        help=\"The input data dir. Should contain the training files for the CoNLL-2003 NER task.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--model_type\",\n",
      "        default=None,\n",
      "        type=str,\n",
      "        required=True,\n",
      "        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--img_model_type\",\n",
      "        default=None,\n",
      "        type=str,\n",
      "        required=True,\n",
      "        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n",
      "    )    \n",
      "    parser.add_argument(\n",
      "        \"--model_name_or_path\",\n",
      "        default=None,\n",
      "        type=str,\n",
      "        required=True,\n",
      "        help=\"Path to pre-trained model or shortcut name selected in the list: \"\n",
      "        + \", \".join(ALL_MODELS),\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--output_dir\",\n",
      "        default=None,\n",
      "        type=str,\n",
      "        required=True,\n",
      "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
      "    )\n",
      "\n",
      "    ## Other parameters\n",
      "    parser.add_argument(\n",
      "        \"--labels\",\n",
      "        default=\"./CORD/labels.txt\",\n",
      "        type=str,\n",
      "        help=\"Path to a file containing all labels. If not specified, CoNLL-2003 labels are used.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--config_name\",\n",
      "        default=\"\",\n",
      "        type=str,\n",
      "        help=\"Pretrained config name or path if not the same as model_name\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--tokenizer_name\",\n",
      "        default=\"\",\n",
      "        type=str,\n",
      "        help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--cache_dir\",\n",
      "        default=\"\",\n",
      "        type=str,\n",
      "        help=\"Where do you want to store the pre-trained models downloaded from s3\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--max_seq_length\",\n",
      "        default=512,\n",
      "        type=int,\n",
      "        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
      "        \"than this will be truncated, sequences shorter will be padded.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--do_train\", action=\"store_true\", help=\"Whether to run training.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the dev set.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--do_predict\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Whether to run predictions on the test set.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--evaluate_during_training\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Whether to run evaluation during training at each logging step.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--do_lower_case\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Set this flag if you are using an uncased model.\",\n",
      "    )\n",
      "\n",
      "    parser.add_argument(\n",
      "        \"--per_gpu_train_batch_size\",\n",
      "        default=8,\n",
      "        type=int,\n",
      "        help=\"Batch size per GPU/CPU for training.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--per_gpu_eval_batch_size\",\n",
      "        default=16,\n",
      "        type=int,\n",
      "        help=\"Batch size per GPU/CPU for evaluation.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--gradient_accumulation_steps\",\n",
      "        type=int,\n",
      "        default=1,\n",
      "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--learning_rate\",\n",
      "        default=5e-5,   # 5e-5\n",
      "        type=float,\n",
      "        help=\"The initial learning rate for Adam.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--num_train_epochs\",\n",
      "        default=3.0,\n",
      "        type=float,\n",
      "        help=\"Total number of training epochs to perform.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--max_steps\",\n",
      "        default=-1,\n",
      "        type=int,\n",
      "        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\"\n",
      "    )\n",
      "\n",
      "    parser.add_argument(\n",
      "        \"--logging_steps\", type=int, default=500, help=\"Log every X updates steps.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--save_steps\",\n",
      "        type=int,\n",
      "        default=50,\n",
      "        help=\"Save checkpoint every X updates steps.\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--eval_all_checkpoints\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--overwrite_output_dir\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Overwrite the content of the output directory\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--overwrite_cache\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Overwrite the cached training and evaluation sets\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--seed\", type=int, default=42, help=\"random seed for initialization\"\n",
      "    )\n",
      "\n",
      "    parser.add_argument(\n",
      "        \"--fp16\",\n",
      "        action=\"store_true\",\n",
      "        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--fp16_opt_level\",\n",
      "        type=str,\n",
      "        default=\"O1\",\n",
      "        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
      "        \"See details at https://nvidia.github.io/apex/amp.html\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--local_rank\",\n",
      "        type=int,\n",
      "        default=-1,\n",
      "        help=\"For distributed training: local_rank\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--server_port\", type=str, default=\"\", help=\"For distant debugging.\"\n",
      "    )\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    if (\n",
      "        os.path.exists(args.output_dir)\n",
      "        and os.listdir(args.output_dir)\n",
      "        and args.do_train\n",
      "    ):\n",
      "        if not args.overwrite_output_dir:\n",
      "            raise ValueError(\n",
      "                \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
      "                    args.output_dir\n",
      "                )\n",
      "            )\n",
      "        else:\n",
      "            if args.local_rank in [-1, 0]:\n",
      "                shutil.rmtree(args.output_dir)\n",
      "\n",
      "    if not os.path.exists(args.output_dir) and (args.do_eval or args.do_predict):\n",
      "        raise ValueError(\n",
      "            \"Output directory ({}) does not exist. Please train and save the model before inference stage.\".format(\n",
      "                args.output_dir\n",
      "            )\n",
      "        )\n",
      "\n",
      "    if (\n",
      "        not os.path.exists(args.output_dir)\n",
      "        and args.do_train\n",
      "        and args.local_rank in [-1, 0]\n",
      "    ):\n",
      "        os.makedirs(args.output_dir)\n",
      "\n",
      "    # Setup distant debugging if needed\n",
      "    if args.server_ip and args.server_port:\n",
      "        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
      "        import ptvsd\n",
      "\n",
      "        print(\"Waiting for debugger attach\")\n",
      "        ptvsd.enable_attach(\n",
      "            address=(args.server_ip, args.server_port), redirect_output=True\n",
      "        )\n",
      "        ptvsd.wait_for_attach()\n",
      "\n",
      "    # Setup CUDA, GPU & distributed training\n",
      "        \n",
      "    if args.local_rank == -1 or args.no_cuda:\n",
      "        device = torch.device(\n",
      "            \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
      "        )\n",
      "        args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()\n",
      "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
      "        torch.cuda.set_device(args.local_rank)\n",
      "        device = torch.device(\"cuda\", args.local_rank)\n",
      "        torch.distributed.init_process_group(backend=\"nccl\")\n",
      "        args.n_gpu = 1\n",
      "    args.device = device\n",
      "\n",
      "    # Setup logging\n",
      "    logging.basicConfig(\n",
      "        filename=os.path.join(args.output_dir, \"train.log\")\n",
      "        if args.local_rank in [-1, 0]\n",
      "        else None,\n",
      "        format=\"%(asctime)s - %(levelname)s - %(name)s -  %(message)s\",\n",
      "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
      "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
      "    )\n",
      "    logger.warning(\n",
      "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
      "        args.local_rank,\n",
      "        device,\n",
      "        args.n_gpu,\n",
      "        bool(args.local_rank != -1),\n",
      "        args.fp16,\n",
      "    )\n",
      "\n",
      "    # Set seed\n",
      "    set_seed(args)\n",
      "\n",
      "    labels = open(args.labels).read().split('\\n')\n",
      "    num_labels = len(labels)\n",
      "    \n",
      "\n",
      "    # Load pretrained model and tokenizer\n",
      "    if args.local_rank not in [-1, 0]:\n",
      "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
      "\n",
      "    args.model_type = args.model_type.lower()\n",
      "    config_class, model_class, tokenizer_class = MODEL_CLASSES[args.model_type]\n",
      "    \n",
      "    config = config_class.from_pretrained(\n",
      "        args.config_name if args.config_name else args.model_name_or_path,\n",
      "        num_labels=num_labels,\n",
      "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
      "    )\n",
      "    \n",
      "    tokenizer = tokenizer_class.from_pretrained(\n",
      "        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
      "        do_lower_case=args.do_lower_case,\n",
      "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
      "    )\n",
      "    \n",
      "    model = DocumentClassifier(config, args.img_model_type, args.device, 2816, num_labels)   # 1280/1536/3072\n",
      "    \n",
      "    pretrained_weights = torch.load(os.path.join(args.model_name_or_path, 'pytorch_model.bin'), map_location=torch.device('cpu'))\n",
      "    \n",
      "    pretrained_weights_new = OrderedDict()\n",
      "    for key, value in pretrained_weights.items():\n",
      "        #print(key)\n",
      "        pretrained_weights_new['layoutlm.'+key] = value    \n",
      "        \n",
      "    model.load_state_dict(pretrained_weights_new, strict=False)\n",
      "    \n",
      "    if args.local_rank == 0:\n",
      "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
      "\n",
      "    model.to(args.device)\n",
      "    logger.info(\"Training/evaluation parameters %s\", args)\n",
      "    \n",
      "    # Training\n",
      "    if args.do_train:\n",
      "       \n",
      "        train_dataset = OcrDataset(args.data_dir, tokenizer, labels, \"train_v2\")\n",
      "\n",
      "        \n",
      "        global_step, tr_loss = train(\n",
      "            args, train_dataset, model, tokenizer, labels\n",
      "        )\n",
      "    \n",
      "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
      "\n",
      "    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
      "    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
      "        # Create output directory if needed\n",
      "        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
      "            os.makedirs(args.output_dir)\n",
      "\n",
      "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
      "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
      "        # They can then be reloaded using `from_pretrained()`\n",
      "        model_to_save = (\n",
      "            model.module if hasattr(model, \"module\") else model\n",
      "        )  # Take care of distributed/parallel training\n",
      "        \n",
      "        model_to_save.save_pretrained(args.output_dir)\n",
      "        tokenizer.save_pretrained(args.output_dir)\n",
      "\n",
      "        # Good practice: save your training arguments together with the trained model\n",
      "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
      "\n",
      "    # Evaluation\n",
      "    results = {}\n",
      "    if args.do_eval and args.local_rank in [-1, 0]:\n",
      "        tokenizer = tokenizer_class.from_pretrained(\n",
      "            args.output_dir, do_lower_case=args.do_lower_case\n",
      "        )\n",
      "        checkpoints = [args.output_dir]\n",
      "        if args.eval_all_checkpoints:\n",
      "            checkpoints = list(\n",
      "                os.path.dirname(c)\n",
      "                for c in sorted(\n",
      "                    glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True)\n",
      "                )\n",
      "            )\n",
      "            logging.getLogger(\"pytorch_transformers.modeling_utils\").setLevel(\n",
      "                logging.WARN\n",
      "            )  # Reduce logging\n",
      "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
      "        for checkpoint in checkpoints:\n",
      "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
      "            model = model_class.from_pretrained(checkpoint)\n",
      "            model.to(args.device)\n",
      "            result, _ = evaluate(\n",
      "                args,\n",
      "                model,\n",
      "                tokenizer,\n",
      "                labels,\n",
      "                mode=\"dev_v2\",\n",
      "                prefix=global_step,\n",
      "            )\n",
      "            if global_step:\n",
      "                result = {\"{}_{}\".format(global_step, k): v for k, v in result.items()}\n",
      "            results.update(result)\n",
      "        output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\n",
      "        with open(output_eval_file, \"w\") as writer:\n",
      "            for key in sorted(results.keys()):\n",
      "                writer.write(\"{} = {}\\n\".format(key, str(results[key])))\n",
      "\n",
      "                \n",
      "    if args.do_predict and args.local_rank in [-1, 0]:\n",
      "        tokenizer = tokenizer_class.from_pretrained(\n",
      "            args.model_name_or_path, do_lower_case=args.do_lower_case\n",
      "        )\n",
      "        \n",
      "        model = DocumentClassifier(config, args.img_model_type, args.device, 1536, num_labels)   # 1280\n",
      "\n",
      "        pretrained_weights = (torch.load(os.path.join(args.model_name_or_path, 'pytorch_model.bin')))\n",
      "        model.load_state_dict(pretrained_weights)\n",
      "        \n",
      "        model.to(args.device)\n",
      "        evaluate(\n",
      "            args, model, tokenizer, labels, mode=\"dev_v2\"\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\wangwenhaoxiaotie_Document_classify\\doc_cls\\train.py\n",
      "[]\n",
      "found files: []\n",
      "import logging\n",
      "import torch\n",
      "from torch import nn\n",
      "from torch.nn import CrossEntropyLoss\n",
      "import torchvision.models as torch_models\n",
      "from .layoutlm import LayoutlmForFeatureExtraction\n",
      "\n",
      "\n",
      "class DocumentClassifier(nn.Module):\n",
      "    def __init__(self, layoutlm_config, img_model, feat_channels, num_classes):\n",
      "        super().__init__()\n",
      "        self.layoutlm = LayoutlmForFeatureExtraction(layoutlm_config)\n",
      "        if img_model == \"resnet18\":\n",
      "            self.img_model = nn.Sequential(*list(torch_models.resnet18().children())[:-2])\n",
      "        elif img_model == \"resnet34\":\n",
      "            self.img_model = nn.Sequential(*list(torch_models.resnet34().children())[:-2])\n",
      "        elif img_model == \"resnet50\":\n",
      "            self.img_model = nn.Sequential(*list(torch_models.resnet50().children())[:-2])\n",
      "        elif img_model == \"mobilenet_v2\":\n",
      "            self.img_model = torch_models.mobilenet_v2().features\n",
      "        elif img_model == \"mnasnet\":\n",
      "            self.img_model = torch_models.mnasnet1_0().layers\n",
      "        elif img_model == \"shufflenet_v2\":\n",
      "            self.img_model = nn.Sequential(*list(torch_models.shufflenet_v2_x1_0().children())[:-1])\n",
      "        self.classifier = nn.Sequential(\n",
      "            nn.Linear(feat_channels, feat_channels),\n",
      "            nn.BatchNorm1d(feat_channels),\n",
      "            nn.ReLU(inplace=True),\n",
      "            nn.Dropout(p=0.3, inplace=True),\n",
      "            nn.Linear(feat_channels, num_classes)\n",
      "        )\n",
      "\n",
      "    def forward(self, input_ids, bbox, attention_mask, image, label=None):\n",
      "        lm_feat = self.layoutlm(input_ids, bbox, attention_mask)\n",
      "        im_feat = self.img_model(image).mean([2, 3])\n",
      "        feat = torch.cat([lm_feat, im_feat], 1)\n",
      "        logits = self.classifier(feat)\n",
      "        \n",
      "        if label is not None:\n",
      "            loss_fct = CrossEntropyLoss()\n",
      "            loss = loss_fct(logits, label)\n",
      "            return logits, loss\n",
      "        return logits\n",
      "\n",
      "Output: {'doc_cls': [], 'doc_cls.DocumentClassifier.__init__': ['<builtin>.list', 'torchvision.models.mobilenet_v2', 'torchvision.models.resnet50', 'torch.nn.Sequential', 'torch.nn.Linear', 'torch.nn.ReLU', '<builtin>.super', 'torch.nn.Dropout', 'torchvision.models.shufflenet_v2_x1_0', 'layoutlm.LayoutlmForFeatureExtraction', 'torchvision.models.resnet34', 'torch.nn.BatchNorm1d', 'torchvision.models.resnet18', 'torchvision.models.mnasnet1_0'], '<builtin>.super': [], 'layoutlm.LayoutlmForFeatureExtraction': [], 'torchvision.models.resnet18': [], '<builtin>.list': [], 'torch.nn.Sequential': [], 'torchvision.models.resnet34': [], 'torchvision.models.resnet50': [], 'torchvision.models.mobilenet_v2': [], 'torchvision.models.mnasnet1_0': [], 'torchvision.models.shufflenet_v2_x1_0': [], 'torch.nn.Linear': [], 'torch.nn.BatchNorm1d': [], 'torch.nn.ReLU': [], 'torch.nn.Dropout': [], 'doc_cls.DocumentClassifier.forward': ['torch.cat', 'torch.nn.CrossEntropyLoss'], 'torch.cat': [], 'torch.nn.CrossEntropyLoss': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\wangwenhaoxiaotie_Document_classify\\models\\doc_cls.py\n",
      "[('doc_cls DocumentClassifier __init__', 'torchvision models mobilenet_v2'), ('doc_cls DocumentClassifier __init__', 'torchvision models resnet50'), ('doc_cls DocumentClassifier __init__', 'torch nn Sequential'), ('doc_cls DocumentClassifier __init__', 'torch nn Linear'), ('doc_cls DocumentClassifier __init__', 'torch nn ReLU'), ('doc_cls DocumentClassifier __init__', 'torch nn Dropout'), ('doc_cls DocumentClassifier __init__', 'torchvision models shufflenet_v2_x1_0'), ('doc_cls DocumentClassifier __init__', 'layoutlm LayoutlmForFeatureExtraction'), ('doc_cls DocumentClassifier __init__', 'torchvision models resnet34'), ('doc_cls DocumentClassifier __init__', 'torch nn BatchNorm1d'), ('doc_cls DocumentClassifier __init__', 'torchvision models resnet18'), ('doc_cls DocumentClassifier __init__', 'torchvision models mnasnet1_0'), ('doc_cls DocumentClassifier forward', 'torch cat'), ('doc_cls DocumentClassifier forward', 'torch nn CrossEntropyLoss')]\n",
      "0\n",
      "found files: []\n",
      "import logging\n",
      "import os\n",
      "import csv\n",
      "import json\n",
      "from PIL import Image, ImageFile\n",
      "from tqdm import tqdm\n",
      "\n",
      "import torch\n",
      "from torch.utils.data import Dataset\n",
      "import torchvision.transforms as T\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "\n",
      "class OcrDataset(Dataset):\n",
      "    def __init__(self, data_dir, tokenizer, labels, mode, max_seq_length=512):\n",
      "        # Load data features from cache or dataset file\n",
      "        cached_features_file = os.path.join(\n",
      "            data_dir,\n",
      "            \"cached_{}_{}_v2\".format(\n",
      "                mode,\n",
      "                str(max_seq_length),\n",
      "            ),\n",
      "        )\n",
      "        if os.path.exists(cached_features_file):\n",
      "            logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
      "            features = torch.load(cached_features_file)\n",
      "        else:\n",
      "            logger.info(\"Creating features from dataset file at %s\", data_dir)\n",
      "            examples = read_examples_from_file(data_dir, mode)\n",
      "            features = convert_examples_to_features(\n",
      "                examples,\n",
      "                labels,\n",
      "                max_seq_length,\n",
      "                tokenizer,\n",
      "                cls_token=tokenizer.cls_token,\n",
      "                sep_token=tokenizer.sep_token,\n",
      "                pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0]\n",
      "            )\n",
      "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
      "            torch.save(features, cached_features_file)\n",
      "\n",
      "        self.features = features\n",
      "        #import ipdb;ipdb.set_trace()\n",
      "        # Convert to Tensors and build dataset\n",
      "        self.all_input_ids = torch.tensor(\n",
      "            [f.input_ids for f in features], dtype=torch.long\n",
      "        )\n",
      "        self.all_bboxes = torch.tensor(\n",
      "            [f.boxes for f in features], dtype=torch.long\n",
      "        )\n",
      "        self.all_input_mask = torch.tensor(\n",
      "            [f.input_mask for f in features], dtype=torch.long\n",
      "        )\n",
      "        self.all_segment_ids = torch.tensor(\n",
      "            [f.segment_ids for f in features], dtype=torch.long\n",
      "        )        \n",
      "        self.all_label_id = torch.tensor(\n",
      "            [f.label_id for f in features], dtype=torch.long\n",
      "        )\n",
      "        self.image_transform = T.Compose([\n",
      "            T.Resize((256, 256)),\n",
      "            T.ToTensor(),\n",
      "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "        ])\n",
      "        self.all_file_names = [f.file_name for f in features]       \n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self.features) \n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        #print(self.features[index].file_name)\n",
      "        ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
      "        image = Image.open(self.features[index].file_name).convert('RGB')\n",
      "        image = self.image_transform(image)\n",
      "\n",
      "        return dict(\n",
      "            input_ids=self.all_input_ids[index],\n",
      "            token_type_ids=self.all_segment_ids[index],\n",
      "            bbox=self.all_bboxes[index],\n",
      "            attention_mask=self.all_input_mask[index],\n",
      "            image=image,\n",
      "            label=self.all_label_id[index],\n",
      "            file_names=self.all_file_names[index]\n",
      "        )\n",
      "\n",
      "class InputExample(object):\n",
      "    \"\"\"A single training/test example for token classification.\"\"\"\n",
      "\n",
      "    def __init__(self, guid, words, label, boxes, actual_bboxes, file_name, page_size):\n",
      "        \"\"\"Constructs a InputExample.\n",
      "\n",
      "        Args:\n",
      "            guid: Unique id for the example.\n",
      "            words: list. The words of the sequence.\n",
      "            labels: (Optional) list. The labels for each word of the sequence. This should be\n",
      "            specified for train and dev examples, but not for test examples.\n",
      "        \"\"\"\n",
      "        self.guid = guid\n",
      "        self.words = words\n",
      "        self.label = label\n",
      "        self.boxes = boxes\n",
      "        self.actual_bboxes = actual_bboxes\n",
      "        self.file_name = file_name\n",
      "        self.page_size = page_size\n",
      "\n",
      "    def __repr__(self):\n",
      "        s = \"\"\n",
      "        for k in [\"guid\", \"words\", \"label\", \"boxes\", \"actual_bboxes\", \"file_name\", \"page_size\"]:\n",
      "            s += f\"{k}: {self.__dict__[k]}\\n\"\n",
      "        return s\n",
      "\n",
      "\n",
      "class InputFeatures(object):\n",
      "    \"\"\"A single set of features of data.\"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        input_ids,\n",
      "        input_mask,\n",
      "        segment_ids,\n",
      "        label_id,\n",
      "        boxes,\n",
      "        actual_bboxes,\n",
      "        file_name,\n",
      "        page_size,\n",
      "    ):\n",
      "        assert (\n",
      "            0 <= all(boxes) <= 1000\n",
      "        ), \"Error with input bbox ({}): the coordinate value is not between 0 and 1000\".format(\n",
      "            boxes\n",
      "        )\n",
      "        self.input_ids = input_ids\n",
      "        self.input_mask = input_mask\n",
      "        self.segment_ids = segment_ids\n",
      "        self.label_id = label_id\n",
      "        self.boxes = boxes\n",
      "        self.actual_bboxes=actual_bboxes\n",
      "        self.file_name = file_name\n",
      "        self.page_size = page_size\n",
      "\n",
      "    def __repr__(self):\n",
      "        s = \"\"\n",
      "        for k in [\"input_ids\", \"input_mask\", \"label_id\", \"boxes\", \"file_name\", \"page_size\"]:\n",
      "            s += f\"{k}: {self.__dict__[k]}\\n\"\n",
      "        return s\n",
      "\n",
      "\n",
      "def read_examples_from_file(data_dir, mode, threshold=0.5):\n",
      "    csv_file = os.path.join(data_dir, \"{}.csv\".format(mode))\n",
      "    guid_index = 1\n",
      "    examples = []\n",
      "    with open(csv_file, \"r\", encoding=\"utf-8\") as fc:\n",
      "        csv_reader = csv.reader(fc)\n",
      "        for img_path, json_path, label in tqdm(csv_reader):\n",
      "            img_path = os.path.join(data_dir, img_path)\n",
      "            json_path = os.path.join(data_dir, json_path)\n",
      "           \n",
      "            #json_data = json.load(open(json_path, \"r\", encoding=\"utf-8\"))[\"result\"]\n",
      "            json_data = json.load(open(json_path, \"r\", encoding=\"utf-8\"))['ret_data']['details'][0]\n",
      "            width, height = json_data[\"width\"], json_data[\"height\"]\n",
      "            words = []\n",
      "            boxes = []\n",
      "            actual_bboxes = []\n",
      "            file_name = img_path\n",
      "            page_size = (width, height)\n",
      "\n",
      "            for item in json_data[\"ocr_contents\"]:\n",
      "                if item.get(\"type\") == \"textbox\" and item.get(\"ocr_confidence\", 0) > threshold:\n",
      "                    words.append(item.get(\"text\", \"\"))\n",
      "                    x1, y1, w, h = item.get(\"rect\")\n",
      "                    x2, y2 = x1 + w, y1 + h\n",
      "                    boxes.append([int(round(1000 * x1 / width)), int(round(1000 * y1 / height)),\n",
      "                        int(round(1000 * x2 / width)), int(round(1000 * y2 / height))])\n",
      "                    actual_bboxes.append([x1, y1, x2, y2])\n",
      "\n",
      "            examples.append(\n",
      "                InputExample(\n",
      "                    guid=\"{}-{}\".format(mode, guid_index),\n",
      "                    words=words,\n",
      "                    label=label,\n",
      "                    boxes=boxes,\n",
      "                    actual_bboxes=actual_bboxes,\n",
      "                    file_name=file_name,\n",
      "                    page_size=page_size,\n",
      "                )\n",
      "            )\n",
      "            guid_index += 1\n",
      "    return examples\n",
      "\n",
      "\n",
      "def convert_examples_to_features(\n",
      "    examples,\n",
      "    label_list,\n",
      "    max_seq_length,\n",
      "    tokenizer,\n",
      "    cls_token_at_end=False,\n",
      "    cls_token=\"[CLS]\",\n",
      "    sep_token=\"[SEP]\",\n",
      "    sep_token_extra=False,\n",
      "    pad_on_left=False,\n",
      "    pad_token=0,\n",
      "    cls_token_box=[0, 0, 0, 0],\n",
      "    sep_token_box=[1000, 1000, 1000, 1000],\n",
      "    pad_token_box=[0, 0, 0, 0],\n",
      "    mask_padding_with_zero=True,\n",
      "):\n",
      "    label_map = {label: i for i, label in enumerate(label_list)}\n",
      "\n",
      "    features = []\n",
      "    for (ex_index, example) in tqdm(enumerate(examples)):\n",
      "        file_name = example.file_name\n",
      "        page_size = example.page_size\n",
      "        width, height = page_size\n",
      "        if ex_index % 10000 == 0:\n",
      "            logger.info(\"Writing example %d of %d\", ex_index, len(examples))\n",
      "\n",
      "        tokens = []\n",
      "        token_boxes = []\n",
      "        actual_bboxes = []\n",
      "        label_id = label_map[example.label]\n",
      "        for word, box, actual_bbox in zip(\n",
      "            example.words, example.boxes, example.actual_bboxes\n",
      "        ):\n",
      "            word_tokens = tokenizer.tokenize(word)\n",
      "            tokens.extend(word_tokens)\n",
      "            token_boxes.extend([box] * len(word_tokens))\n",
      "            actual_bboxes.extend([actual_bbox] * len(word_tokens))\n",
      "\n",
      "        # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
      "        special_tokens_count = 3 if sep_token_extra else 2\n",
      "        if len(tokens) > max_seq_length - special_tokens_count:\n",
      "            tokens = tokens[: (max_seq_length - special_tokens_count)]\n",
      "            token_boxes = token_boxes[: (max_seq_length - special_tokens_count)]\n",
      "            actual_bboxes = actual_bboxes[: (max_seq_length - special_tokens_count)]\n",
      "\n",
      "        # The convention in BERT is:\n",
      "        # (a) For sequence pairs:\n",
      "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
      "        #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
      "        # (b) For single sequences:\n",
      "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
      "        #  type_ids:   0   0   0   0  0     0   0\n",
      "        #\n",
      "        # Where \"type_ids\" are used to indicate whether this is the first\n",
      "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
      "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
      "        # embedding vector (and position vector). This is not *strictly* necessary\n",
      "        # since the [SEP] token unambiguously separates the sequences, but it makes\n",
      "        # it easier for the model to learn the concept of sequences.\n",
      "        #\n",
      "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
      "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
      "        # the entire model is fine-tuned.\n",
      "        tokens += [sep_token]\n",
      "        token_boxes += [sep_token_box]\n",
      "        actual_bboxes += [[0, 0, width, height]]\n",
      "        if sep_token_extra:\n",
      "            # roberta uses an extra separator b/w pairs of sentences\n",
      "            tokens += [sep_token]\n",
      "            token_boxes += [sep_token_box]\n",
      "            actual_bboxes += [[0, 0, width, height]]\n",
      "\n",
      "        \n",
      "        segment_ids = [0] * len(tokens) \n",
      "        \n",
      "        if cls_token_at_end:\n",
      "            tokens += [cls_token]\n",
      "            token_boxes += [cls_token_box]\n",
      "            actual_bboxes += [[0, 0, width, height]]\n",
      "            segment_ids += [0]\n",
      "        else:\n",
      "            tokens = [cls_token] + tokens\n",
      "            token_boxes = [cls_token_box] + token_boxes\n",
      "            actual_bboxes = [[0, 0, width, height]] + actual_bboxes\n",
      "            segment_ids = [0] + segment_ids\n",
      "\n",
      "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
      "\n",
      "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
      "        # tokens are attended to.\n",
      "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
      "\n",
      "        # Zero-pad up to the sequence length.\n",
      "        padding_length = max_seq_length - len(input_ids)\n",
      "        if pad_on_left:\n",
      "            input_ids = ([pad_token] * padding_length) + input_ids\n",
      "            input_mask = (\n",
      "                [0 if mask_padding_with_zero else 1] * padding_length\n",
      "            ) + input_mask\n",
      "            segment_ids = ([0] * padding_length) + segment_ids\n",
      "            token_boxes = ([pad_token_box] * padding_length) + token_boxes\n",
      "        else:\n",
      "            input_ids += [pad_token] * padding_length\n",
      "            input_mask += [0 if mask_padding_with_zero else 1] * padding_length\n",
      "            segment_ids += [0] * padding_length\n",
      "            token_boxes += [pad_token_box] * padding_length\n",
      "\n",
      "        assert len(input_ids) == max_seq_length\n",
      "        assert len(input_mask) == max_seq_length\n",
      "        assert len(segment_ids) == max_seq_length\n",
      "        assert len(token_boxes) == max_seq_length\n",
      "\n",
      "        if ex_index < 5:\n",
      "            logger.info(\"*** Example ***\")\n",
      "            logger.info(\"guid: %s\", example.guid)\n",
      "            logger.info(\"tokens: %s\", \" \".join([str(x) for x in tokens]))\n",
      "            logger.info(\"input_ids: %s\", \" \".join([str(x) for x in input_ids]))\n",
      "            logger.info(\"input_mask: %s\", \" \".join([str(x) for x in input_mask]))\n",
      "            logger.info(\"label_id: %s\", label_id)\n",
      "            logger.info(\"boxes: %s\", \" \".join([str(x) for x in token_boxes]))\n",
      "            logger.info(\"actual_bboxes: %s\", \" \".join([str(x) for x in actual_bboxes]))\n",
      "        \n",
      "        #import ipdb; ipdb.set_trace()\n",
      "        features.append(\n",
      "            InputFeatures(\n",
      "                input_ids=input_ids,\n",
      "                input_mask=input_mask,\n",
      "                segment_ids=segment_ids,\n",
      "                label_id=label_id,\n",
      "                boxes=token_boxes,\n",
      "                actual_bboxes=actual_bboxes,\n",
      "                file_name=file_name,\n",
      "                page_size=page_size,\n",
      "            )\n",
      "        )\n",
      "    return features\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from transformers import BertTokenizer\n",
      "    #labels = open('receipt_data/labels.txt').read().split('\\n')\n",
      "    labels = [\"\", \"\", \"\", \"\"]\n",
      "    tokenizer = BertTokenizer.from_pretrained(\"receipt_data/vocab.txt\", do_lower_case=True)\n",
      "\n",
      "    examples = read_examples_from_file(\"test_data\", \"test\")\n",
      "    features = convert_examples_to_features(\n",
      "        examples,\n",
      "        labels,\n",
      "        512,\n",
      "        tokenizer,\n",
      "        cls_token=tokenizer.cls_token,\n",
      "        sep_token=tokenizer.sep_token,\n",
      "        pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0]\n",
      "    )\n",
      "   \n",
      "    for f in features:\n",
      "        print(f)\n",
      "\n",
      "#     from torch.utils.data import DataLoader\n",
      "\n",
      "#     dataset = OcrDataset(\"receipt_data\", tokenizer, labels, \"train\")\n",
      "\n",
      "#     dataloader = DataLoader(dataset, batch_size=10)\n",
      "\n",
      "#     for item in dataset:\n",
      "#         for k, v in item.items():\n",
      "#             print(k, v.size())\n",
      "#         print(item['label'])\n",
      "\n",
      "#     for item in dataloader:\n",
      "#         for k, v in item.items():\n",
      "#             print(k, v.size())\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\wangwenhaoxiaotie_Document_classify\\doc_cls\\ocr_dataset.py\n",
      "[]\n",
      "********************pycgContent*************************\n",
      "[[('layoutlm', 'logging getLogger'), ('layoutlm LayoutlmEmbeddings __init__', 'torch nn Dropout'), ('layoutlm LayoutlmEmbeddings __init__', 'torch nn Embedding'), ('layoutlm LayoutlmEmbeddings __init__', 'transformers modeling_bert BertLayerNorm'), ('layoutlm LayoutlmEmbeddings forward', 'torch zeros_like'), ('layoutlm LayoutlmEmbeddings forward', 'torch arange'), ('layoutlm LayoutlmModel __init__', 'layoutlm LayoutlmEmbeddings __init__'), ('layoutlm LayoutlmModel __init__', 'transformers BertModel init_weights'), ('layoutlm LayoutlmModel forward', 'layoutlm LayoutlmEmbeddings __init__'), ('layoutlm LayoutlmModel forward', 'transformers BertModel parameters'), ('layoutlm LayoutlmModel forward', 'transformers BertModel encoder'), ('layoutlm LayoutlmModel forward', 'torch zeros_like'), ('layoutlm LayoutlmModel forward', 'transformers BertModel pooler'), ('layoutlm LayoutlmModel forward', 'torch ones_like'), ('layoutlm LayoutlmForTokenClassification __init__', 'torch nn Linear'), ('layoutlm LayoutlmForTokenClassification __init__', 'layoutlm LayoutlmModel __init__'), ('layoutlm LayoutlmForTokenClassification __init__', 'torch nn Dropout'), ('layoutlm LayoutlmForTokenClassification __init__', 'transformers BertPreTrainedModel init_weights'), ('layoutlm LayoutlmForTokenClassification forward', 'torch nn CrossEntropyLoss'), ('layoutlm LayoutlmForTokenClassification forward', 'layoutlm LayoutlmModel __init__'), ('layoutlm LayoutlmForSequenceClassification __init__', 'torch nn Linear'), ('layoutlm LayoutlmForSequenceClassification __init__', 'layoutlm LayoutlmModel __init__'), ('layoutlm LayoutlmForSequenceClassification __init__', 'torch nn Dropout'), ('layoutlm LayoutlmForSequenceClassification __init__', 'transformers BertPreTrainedModel init_weights'), ('layoutlm LayoutlmForSequenceClassification forward', 'torch nn MSELoss'), ('layoutlm LayoutlmForSequenceClassification forward', 'torch nn CrossEntropyLoss'), ('layoutlm LayoutlmForSequenceClassification forward', 'layoutlm LayoutlmModel __init__'), ('layoutlm LayoutlmForFeatureExtraction __init__', 'torch nn Dropout'), ('layoutlm LayoutlmForFeatureExtraction __init__', 'transformers BertPreTrainedModel init_weights'), ('layoutlm LayoutlmForFeatureExtraction __init__', 'layoutlm LayoutlmModel __init__')], [('doc_cls DocumentClassifier __init__', 'torchvision models mobilenet_v2'), ('doc_cls DocumentClassifier __init__', 'torchvision models resnet50'), ('doc_cls DocumentClassifier __init__', 'torch nn Sequential'), ('doc_cls DocumentClassifier __init__', 'torch nn Linear'), ('doc_cls DocumentClassifier __init__', 'torch nn ReLU'), ('doc_cls DocumentClassifier __init__', 'torch nn Dropout'), ('doc_cls DocumentClassifier __init__', 'torchvision models shufflenet_v2_x1_0'), ('doc_cls DocumentClassifier __init__', 'layoutlm LayoutlmForFeatureExtraction'), ('doc_cls DocumentClassifier __init__', 'torchvision models resnet34'), ('doc_cls DocumentClassifier __init__', 'torch nn BatchNorm1d'), ('doc_cls DocumentClassifier __init__', 'torchvision models resnet18'), ('doc_cls DocumentClassifier __init__', 'torchvision models mnasnet1_0'), ('doc_cls DocumentClassifier forward', 'torch cat'), ('doc_cls DocumentClassifier forward', 'torch nn CrossEntropyLoss')]]\n",
      "********************doctrings*************************\n",
      "['', '']\n",
      "embed index dataset: 3\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\AimoreRRD_Reinforcement-Learning-Research\\\\Class.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\AimoreRRD_Reinforcement-Learning-Research\\\\Compile_Excel_Files.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\AimoreRRD_Reinforcement-Learning-Research\\\\Plot.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\AimoreRRD_Reinforcement-Learning-Research\\\\Script_Compiler.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\AimoreRRD_Reinforcement-Learning-Research\\\\NEW_GAME.py']\n",
      "import pygame, math\n",
      "\n",
      "white = (255,255,255)\n",
      "black = (0,0,0)\n",
      "grey = (80,80,80)\n",
      "red = (255,0,0)\n",
      "dark_red = (155,0,0)\n",
      "blue = (0,0,255)\n",
      "green = (0,255,0)\n",
      "yellow = (250,250,0)\n",
      "pink = (250,105,180)\n",
      "\n",
      "'''Size of the game'''\n",
      "size = 'Big'\n",
      "if size == 'Big':\n",
      "    m = 5 # Big\n",
      "    x_g,y_g = 30, 30 # Big\n",
      "    w,h = 30, 30 # Big\n",
      "else:\n",
      "    m = 1 # Small\n",
      "    x_g,y_g = 5, 5 # Small\n",
      "    w,h = 5, 5 # Small\n",
      "\n",
      "class Grid(object):\n",
      "    grid_w = w\n",
      "    w = 6\n",
      "    grid_h = h\n",
      "    h = 5\n",
      "\n",
      "    def draw_grid(screen):\n",
      "        pygame.draw.rect(screen, black, [x_g, y_g, Grid.grid_w , Grid.grid_h])\n",
      "        for row in range(Grid.h):\n",
      "            for column in range(Grid.w):\n",
      "                color = white\n",
      "                pygame.draw.rect(screen,\n",
      "                                 color,\n",
      "                                 [x_g + (m + Grid.grid_w) * column + m,\n",
      "                                  y_g + (m + Grid.grid_h) * row + m,\n",
      "                                  Grid.grid_w, Grid.grid_h])\n",
      "\n",
      "class Wall(pygame.Rect):\n",
      "    color = grey\n",
      "    def __init__(self,img,x,y):\n",
      "        self.icon = pygame.image.load(str(img) + size + '.png')\n",
      "        self.pos = [x, y]\n",
      "        self.x = x\n",
      "        self.y = y\n",
      "\n",
      "class Obj:\n",
      "    def __init__(self, tp, loc):\n",
      "        self.tp = tp\n",
      "        self.loc = loc\n",
      "\n",
      "class Agent(pygame.Rect):\n",
      "    color = yellow\n",
      "    def __init__(self,img,x,y):\n",
      "        self.icon = pygame.image.load(str(img) + size + '.png')\n",
      "        self.pos = [x, y]\n",
      "        self.x = x\n",
      "        self.y = y\n",
      "\n",
      "    def try_move(self, dir, wall_list):\n",
      "        x_step = 0\n",
      "        y_step = 0\n",
      "        past_pos = self.pos\n",
      "        if dir == 'up':\n",
      "            y_step = - 1\n",
      "        if dir == 'down':\n",
      "            y_step = + 1\n",
      "        if dir == 'left':\n",
      "            x_step = - 1\n",
      "        if dir == 'right':\n",
      "            x_step = + 1\n",
      "        fut_x = self.pos[0] + x_step\n",
      "        fut_y = self.pos[1] + y_step\n",
      "        fut_pos = [fut_x, fut_y]\n",
      "\n",
      "        for wall in wall_list:\n",
      "            if fut_pos == wall.pos:\n",
      "                self.pos = past_pos\n",
      "                break\n",
      "            else:\n",
      "                self.pos = fut_pos\n",
      "\n",
      "class Start(pygame.Rect):\n",
      "    color = blue\n",
      "    def __init__(self,img,x,y):\n",
      "         self.icon = pygame.image.load(str(img) + size +  '.png')\n",
      "         self.pos = [x, y]\n",
      "\n",
      "class Negativo(pygame.Rect):\n",
      "    color = pink\n",
      "    def __init__(self,img,x,y):\n",
      "         self.icon = pygame.image.load(str(img) + size + '.png')\n",
      "         self.pos = [x, y]\n",
      "         self.x = x\n",
      "         self.y = y\n",
      "\n",
      "class Positivo(pygame.Rect):\n",
      "    color = green\n",
      "    def __init__(self,img,x,y):\n",
      "         self.icon = pygame.image.load(str(img) + size + '.png')\n",
      "         self.pos = [x, y]\n",
      "         self.x = x\n",
      "         self.y = y\n",
      "Output: {'Class': [], 'Class.Grid.draw_grid': ['pygame.draw.rect', '<builtin>.range'], 'pygame.draw.rect': [], '<builtin>.range': [], 'Class.Wall.__init__': ['<builtin>.str', 'pygame.image.load'], '<builtin>.str': [], 'pygame.image.load': [], 'Class.Obj.__init__': [], 'Class.Agent.__init__': ['<builtin>.str', 'pygame.image.load'], 'Class.Agent.try_move': [], 'Class.Start.__init__': ['<builtin>.str', 'pygame.image.load'], 'Class.Negativo.__init__': ['<builtin>.str', 'pygame.image.load'], 'Class.Positivo.__init__': ['<builtin>.str', 'pygame.image.load']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\AimoreRRD_Reinforcement-Learning-Research\\Class.py\n",
      "[('Class Grid draw_grid', 'pygame draw rect'), ('Class Wall __init__', 'pygame image load'), ('Class Agent __init__', 'pygame image load'), ('Class Start __init__', 'pygame image load'), ('Class Negativo __init__', 'pygame image load'), ('Class Positivo __init__', 'pygame image load')]\n",
      "0\n",
      "found files: []\n",
      "import pandas as pd\n",
      "import openpyxl\n",
      "import numpy as np\n",
      "import os\n",
      "import string\n",
      "import glob\n",
      "\n",
      "''' This program compiles all (individual) saved excel files to compare different models in one environment\n",
      "'''\n",
      "\n",
      "\n",
      "__location__ = os.path.realpath(os.path.join(os.getcwd(), os.path.dirname(__file__)))\n",
      "path_core = __location__+ \"/Results/Train/\"\n",
      "\n",
      "print(\"OK\")\n",
      "# SELECT THE ENVIRONMENTS\n",
      "# env_path_list = [\"Env_1\",\n",
      "#                  \"Env_2\",\n",
      "#                  \"Env_3\",\n",
      "#                  \"Env_8\",\n",
      "#                  \"Env_9\",\n",
      "#                  \"Env_10\",\n",
      "#                  \"Env_11\"]\n",
      "env_path_list = [\"Env_1\",\n",
      "                 \"Env_2\",\n",
      "                 \"Env_3\",\n",
      "                 \"Env_4\"]\n",
      "\n",
      "env_path_list = [\"Env_1\"]\n",
      "alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'AA', 'AB', 'AC', 'AD', 'AE', 'AF', 'AG', 'AH', 'AI', 'AJ', 'AK', 'AL', 'AM', 'AN', 'AO', 'AP', 'AQ', 'AR', 'AS', 'AT', 'AU', 'AV', 'AW', 'AX', 'AY', 'AZ']\n",
      "list_sheets = [\"Run_Conf\", \"Score\", \"Percent\", \"Loss\", \"Time\"]\n",
      "\n",
      "\n",
      "for env_path in env_path_list:\n",
      "    file_path_list = []\n",
      "    path = path_core + env_path + \"/Train_Env_1_DQN*.xlsx\"\n",
      "    for fname in sorted(glob.glob(path)):\n",
      "        file_path_list.append(fname)\n",
      "    print(\"LEN(FILE_PATH_LIST):\", len(file_path_list))\n",
      "\n",
      "    load_path = __location__+ \"/Results/Train/Compare_Models.xlsx\"\n",
      "    excel_data_base = pd.ExcelFile(load_path)\n",
      "    load_path_new = __location__+ \"/Results/Train/\" + env_path + \"/Compare_Models_new_\" + env_path + \".xlsx\"\n",
      "    excel_writer_to_append = pd.ExcelWriter(load_path_new)\n",
      "\n",
      "    workbook = excel_writer_to_append.book\n",
      "\n",
      "    excel_data_base_col = pd.read_excel(excel_data_base, sheetname=\"Run_Conf\")\n",
      "\n",
      "    df_Run_Conf_list = pd.DataFrame()\n",
      "    df_Score_list = pd.DataFrame()\n",
      "    df_Percent_list = pd.DataFrame()\n",
      "    df_Loss_list = pd.DataFrame()\n",
      "    df_Time_list = pd.DataFrame()\n",
      "\n",
      "    for i in range(len(file_path_list)):\n",
      "        print(\"File:\", i)\n",
      "        excel_file = pd.ExcelFile(file_path_list[i])\n",
      "        # print(\"excel_file \", excel_file )\n",
      "        df_Run_Conf = pd.read_excel(excel_file, sheetname=list_sheets[0], converters={'A': str})\n",
      "        df_Run_Conf = df_Run_Conf.set_index(list_sheets[0])\n",
      "        df_Score = pd.read_excel(excel_file, sheetname=list_sheets[1], parse_cols=\"A:B\")\n",
      "        df_Score = df_Score.set_index(list_sheets[1])\n",
      "        df_Percent = pd.read_excel(excel_file, sheetname=list_sheets[2], parse_cols=\"A:B\")\n",
      "        df_Percent = df_Percent.set_index(list_sheets[2])\n",
      "        df_Loss = pd.read_excel(excel_file, sheetname=list_sheets[3], parse_cols=\"A:B\")\n",
      "        df_Loss = df_Loss.set_index(list_sheets[3])\n",
      "        df_Time = pd.read_excel(excel_file, sheetname=list_sheets[4], parse_cols=\"A:B\")\n",
      "        df_Time = df_Time.set_index(list_sheets[4])\n",
      "\n",
      "        df_Run_Conf_list = pd.concat([df_Run_Conf_list, df_Run_Conf], axis=1, join=\"outer\")\n",
      "        df_Score_list = pd.concat([df_Score_list, df_Score], axis=1, join=\"outer\")\n",
      "        df_Percent_list = pd.concat([df_Percent_list, df_Percent], axis=1, join=\"outer\")\n",
      "        df_Loss_list = pd.concat([df_Loss_list, df_Loss], axis=1, join=\"outer\")\n",
      "        df_Time_list = pd.concat([df_Time_list, df_Time], axis=1, join=\"outer\")\n",
      "\n",
      "        list_of_df = [df_Run_Conf_list,df_Score_list,df_Percent_list,df_Loss_list,df_Time_list]\n",
      "\n",
      "    # print(\"df_Run_Conf_list\\n\\n\", df_Run_Conf_list)\n",
      "\n",
      "    i = 0\n",
      "    df = pd.DataFrame()\n",
      "    for sheet in list_sheets:\n",
      "        print(\"Sheet:\", sheet)\n",
      "        # if sheet == \"Run_Conf\":\n",
      "        #     dict = {} # In order to parse the correct data the headers should be strings\n",
      "        #     for n in range(len(excel_data_base_col.columns)):\n",
      "        #         dict[n] = str\n",
      "        #     df_data_base = pd.read_excel(excel_data_base, sheetname=sheet, converters=dict)\n",
      "        # else:\n",
      "        df_data_base = pd.read_excel(excel_data_base, sheetname=sheet)\n",
      "        new_df_data_base = df_data_base.set_index(sheet)\n",
      "        # print(\"df_Run_Conf_list\\n\\n\", new_df_data_base)\n",
      "\n",
      "        df = list_of_df[i]\n",
      "        new_df_data_base = pd.concat([new_df_data_base, df], axis=1, join_axes=[df.index], join=\"outer\")\n",
      "        # print(\"new_df_data_base \\n\\n\", new_df_data_base )\n",
      "\n",
      "        new_df_data_base.to_excel(excel_writer_to_append, sheet_name=sheet, index=True)\n",
      "\n",
      "        if sheet == \"Run_Conf\":\n",
      "            worksheet = excel_writer_to_append.sheets[sheet]\n",
      "            format1 = workbook.add_format()\n",
      "            format1.set_center_across()\n",
      "            l = len(new_df_data_base.columns)\n",
      "            worksheet.set_column('A:A', 18)\n",
      "            worksheet.set_column(1,l, 12, format1)\n",
      "            worksheet.write(0, l, str(range(1, l, 1)))\n",
      "\n",
      "        worksheet = excel_writer_to_append.sheets[sheet]\n",
      "        for j in range(len(new_df_data_base.columns)):\n",
      "            worksheet.write(0, j+1, alphabet[j])\n",
      "\n",
      "        i += 1\n",
      "\n",
      "    excel_writer_to_append.save()\n",
      "Output: {'Compile_Excel_Files': ['os.path.realpath', '<builtin>.range', 'glob.glob', '<builtin>.sorted', 'os.path.dirname', 'pandas.DataFrame', 'pandas.ExcelFile', 'pandas.concat', '<builtin>.len', '<builtin>.print', 'pandas.ExcelWriter', '<builtin>.str', 'os.path.join', 'pandas.read_excel', 'os.getcwd'], 'os.getcwd': [], 'os.path.dirname': [], 'os.path.join': [], 'os.path.realpath': [], '<builtin>.print': [], 'glob.glob': [], '<builtin>.sorted': [], '<builtin>.len': [], 'pandas.ExcelFile': [], 'pandas.ExcelWriter': [], 'pandas.read_excel': [], 'pandas.DataFrame': [], '<builtin>.range': [], 'pandas.concat': [], '<builtin>.str': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\AimoreRRD_Reinforcement-Learning-Research\\Compile_Excel_Files.py\n",
      "[('Compile_Excel_Files', 'os path realpath'), ('Compile_Excel_Files', 'glob glob'), ('Compile_Excel_Files', 'os path dirname'), ('Compile_Excel_Files', 'pandas DataFrame'), ('Compile_Excel_Files', 'pandas ExcelFile'), ('Compile_Excel_Files', 'pandas concat'), ('Compile_Excel_Files', 'pandas ExcelWriter'), ('Compile_Excel_Files', 'os path join'), ('Compile_Excel_Files', 'pandas read_excel'), ('Compile_Excel_Files', 'os getcwd')]\n",
      "0\n",
      "found files: []\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import glob\n",
      "import matplotlib.patches as mpatches\n",
      "import os\n",
      "\n",
      "# plt.style.use('ggplot')\n",
      "plt.interactive(False)\n",
      "\n",
      "# FOR SERVER:\n",
      "# __location__ = os.path.realpath(os.path.join(os.getcwd(), os.path.dirname(__file__)))\n",
      "# path = __location__+ \"/Results/Train/\"\n",
      "\n",
      "# FOR MY MACHINE:\n",
      "\n",
      "path = r\"E:\\ENGLAND\\City University of London\\Events\\NIPS\\NIPS_RESULTS\\Comparison between DSRL, QL, DSRL_trick in ALL ENVs/env\"\n",
      "file_path_list = []\n",
      "#######################################################\n",
      "''' CHOOSE WHAT TO PLOT '''\n",
      "plot_Score = True\n",
      "plot_Percent_2 = False\n",
      "plot_Percent = False\n",
      "\n",
      "''' CHOOSE ENVIRONMENTS '''\n",
      "# env_list = [1,2,3,4,8,9,10,11,12,13,14,15,16,17,18,19]\n",
      "env_list = [2,3]\n",
      "# path_core = \"/Train_Env_\"\n",
      "path_core = \"/Test_Env_\"\n",
      "\n",
      "percent_env_list = [8, 9, 10, 11]\n",
      "''' CHOOSE SAVE and SHOW '''\n",
      "save_Plot = True\n",
      "save_path = r\"E:\\ENGLAND\\City University of London\\Events\\NIPS\\NIPS_RESULTS\\Comparison between DSRL, QL, DSRL_trick in ALL ENVs/\"\n",
      "show_Plot = True\n",
      "\n",
      "\n",
      "''' CHOOSE MODELS '''\n",
      "# choose_models_list = [0]\n",
      "choose_models_list = [0,1,2,3]\n",
      "color_dict = {\"DSRL_object_near \": \"purple\", \"QL \": \"green\", \"SRL \": \"red\", \"DSRL-\": \"black\", \"DQN_\": \"blue\", \"DQN-\":\"blue\"}\n",
      "# Becareful with the spaces after the names:\n",
      "names = [\"DSRL_object_near \",\n",
      "         \"QL \",\n",
      "         \"SRL \",\n",
      "         \"DQN_\"\n",
      "         ]\n",
      "\n",
      "''' ACTIVATE THIS FOR ENV 11 - THE SIMULATED PLOTS'''\n",
      "# names = [\"DSRL_object_near \",\n",
      "#          \"QL \",\n",
      "#          \"SRL \",\n",
      "#          \"DQN-\",\n",
      "#          \"DSRL-\",\n",
      "#          ]\n",
      "\n",
      "\n",
      "\n",
      "sub_name = {\"QL \": \"Q-Learning\", \"DQN_\":\"DQN\", \"DQN-\":\"DQN\", \"DSRL-\":\"DSRL \", \"SRL \":\"SRL\", \"DSRL_object_near \":\"SRL+CS\"}\n",
      "#######################################################\n",
      "alpha = 0.45 # 0.55\n",
      "linewidth = 2.4 # 1.4\n",
      "if plot_Score == True:\n",
      "    print(\"\\nPLOTTING SCORE\")\n",
      "    for i in env_list:\n",
      "        print(\"\\nEnv\", i)\n",
      "        Score_list = []\n",
      "\n",
      "        title_name = \"Env \" + str(i)\n",
      "        colors = []\n",
      "        n=0\n",
      "        for model in choose_models_list:\n",
      "\n",
      "            name = names[model]\n",
      "            file_name = path_core + str(i) + \"_\" + name + \"*.xlsx\"\n",
      "            path_new = path + str(i) + file_name\n",
      "            print(\"name:\", name)\n",
      "            for fname in glob.glob(path_new):\n",
      "                print(\"fname:\", fname)\n",
      "                '''SCORE'''\n",
      "            Score = pd.read_excel(fname, parse_cols=\"C:L\", sheetname=\"Score\")\n",
      "            if n == 0:\n",
      "                plot1 = Score.plot(grid=True,\n",
      "                                   color=color_dict[name],\n",
      "                                   alpha=alpha,\n",
      "                                   linewidth=linewidth,\n",
      "                                   fontsize=14)\n",
      "            else:\n",
      "                Score.plot(ax=plot1,\n",
      "                           grid=True,\n",
      "                           color=color_dict[name],\n",
      "                           alpha=alpha,\n",
      "                           linewidth=linewidth,\n",
      "                           fontsize=14)\n",
      "\n",
      "            color = mpatches.Patch(alpha=0.8, color=color_dict[name], label=sub_name[name])\n",
      "            print(\"color_dict[name]:\", color_dict[name])\n",
      "            colors.append(color)\n",
      "            n += 1\n",
      "\n",
      "\n",
      "        # plt.title(title_name, fontsize=16)\n",
      "        print(colors)\n",
      "        plot1.legend(handles=colors,\n",
      "                   loc=0,\n",
      "                   borderaxespad=1,\n",
      "                   fontsize=14)\n",
      "\n",
      "        plt.xlabel(\"Steps (during 1000 episodes)\", fontsize=20)\n",
      "        plt.ylabel(\"Accumulated Score\", fontsize=20)\n",
      "        plt.tight_layout()\n",
      "        # plt.ylim(ymax=-1000)\n",
      "        # plt.ylim(ymin=-1000)\n",
      "        if save_Plot:\n",
      "            plt.savefig(save_path + 'SCORE_'+str(i)+'_NEW.png')\n",
      "        if show_Plot:\n",
      "            plt.show()\n",
      "\n",
      "\n",
      "alpha = 0.4\n",
      "linewidth = 1\n",
      "if plot_Percent_2 == True:\n",
      "    print(\"\\nPLOTTING PERCENT 2\")\n",
      "    for i in env_list:\n",
      "        if i in percent_env_list:\n",
      "            print(\"\\nEnv\", i)\n",
      "            Score_list = []\n",
      "\n",
      "            title_name = \"Env \" + str(i)\n",
      "            colors = []\n",
      "            n=0\n",
      "            for model in choose_models_list:\n",
      "\n",
      "                name = names[model]\n",
      "                if name == \"DSRL_object_near \":\n",
      "                    file_name = \"/Test_Env_\" + str(i) + \"_\" + name + \"*.xlsx\"\n",
      "                else:\n",
      "                    file_name = \"/Train_Env_\" + str(i) + \"_\" + name + \"*.xlsx\"\n",
      "\n",
      "                path_new = path + str(i) + file_name\n",
      "                print(\"name:\", name)\n",
      "                for fname in glob.glob(path_new):\n",
      "                    print(\"fname:\", fname)\n",
      "                    '''SCORE'''\n",
      "                Percent = pd.read_excel(fname, parse_cols=\"B:B\", sheetname=\"Percent\")\n",
      "\n",
      "                rolling = Percent.rolling(window=10)\n",
      "                rolling_mean = 100 * rolling.mean()\n",
      "\n",
      "                if n == 0:\n",
      "                    plot3 = rolling_mean.plot(ls=\"-\",\n",
      "                                              grid=True,\n",
      "                                              color=color_dict[name],\n",
      "                                              linewidth=2,\n",
      "                                              fontsize=14)\n",
      "                    plt.tick_params(axis='y', labelleft='on', labelright='on')\n",
      "\n",
      "                else:\n",
      "                    rolling_mean.plot(ax=plot3,\n",
      "                                      ls=\"-\",\n",
      "                                      grid=True,\n",
      "                                      color=color_dict[name],\n",
      "                                      linewidth=2,\n",
      "                                      fontsize=14)\n",
      "\n",
      "                color = mpatches.Patch(alpha=0.8, color=color_dict[name], label=sub_name[name])\n",
      "                print(color_dict[name])\n",
      "                colors.append(color)\n",
      "                n += 1\n",
      "\n",
      "            # plt.title(title_name, fontsize=16)\n",
      "            axes = plt.gca()\n",
      "            axes.set_xlim([0, 1000])\n",
      "            print(colors)\n",
      "            plt.legend(handles=colors,\n",
      "                       loc=4,\n",
      "                       borderaxespad=1,\n",
      "                       fontsize=14)\n",
      "\n",
      "            # plt.tick_params(axis='y', labelleft='on', labelright='on')\n",
      "            plot3.set_xlabel(\"Episodes\", fontsize=20)\n",
      "            plot3.set_ylabel(\"% of collected positive objects\", fontsize=18)\n",
      "            plt.yticks(np.arange(0, 105, 10))\n",
      "            plt.ylim((0, 100))\n",
      "\n",
      "            # plt.yaxis.tick_right()\n",
      "            plt.tight_layout()\n",
      "            if save_Plot:\n",
      "                plt.savefig(save_path + 'PERCENT_'+str(i)+'_NEW.png')\n",
      "            if show_Plot:\n",
      "                plt.show()\n",
      "\n",
      "#\n",
      "# if plot_Percent == True:\n",
      "#     print(\"\\nPLOTTING PERCENT\")\n",
      "#     for i in env_list:\n",
      "#         if i in percent_env_list:\n",
      "#             print(\"Env\", i)\n",
      "#             file_name_list = []\n",
      "#             for name in names:\n",
      "#                 file_name = \"/Train_Env_\" + str(i) + \"_\" + name + \"*.xlsx\"\n",
      "#                 path_new = path + str(i) + file_name\n",
      "#                 print(\"name:\", name)\n",
      "#                 for fname in glob.glob(path_new):\n",
      "#                     print(\"fname:\", fname)\n",
      "#                     if fname == None:\n",
      "#                         print(\"FAILED to Load:\", name)\n",
      "#                     '''PERCENT'''\n",
      "#                 Percent = pd.read_excel(fname, parse_cols=\"B:B\", sheetname=\"Percent\")\n",
      "#\n",
      "#                 title_name = \"Env \" + str(i)\n",
      "#                 plot2 = Percent.plot(title=title_name,\n",
      "#                                      grid=True,\n",
      "#                                      alpha = 0.6)\n",
      "#\n",
      "#                 rolling = Percent.rolling(window=100)\n",
      "#                 rolling_mean = rolling.mean()\n",
      "#                 rolling_mean.plot(ax=plot2,\n",
      "#                                   ls=\"-\",\n",
      "#                                   grid=True,\n",
      "#                                   color='red',\n",
      "#                                   linewidth=2)\n",
      "#\n",
      "#                 blue_percent = mpatches.Patch(color='b', label=name)\n",
      "#                 red_mov_avg = mpatches.Patch(color='red', label=name + '_Mov_Avg')\n",
      "#                 plt.legend(handles=[blue_percent, red_mov_avg],\n",
      "#                            loc=4,\n",
      "#                            borderaxespad=1)\n",
      "#\n",
      "#                 plot2.set_xlabel(\"Episodes\")\n",
      "#                 plot2.set_ylabel(\"% of collected objects with positive reward\")\n",
      "#                 plt.yticks(np.arange(0, 1.05, 0.1))\n",
      "#                 plt.ylim((0, 1))\n",
      "#                 plt.tick_params(axis='y',labelleft='on', labelright='on')\n",
      "#\n",
      "#                 if save_Plot:\n",
      "#                     plt.savefig(save_path + 'PERCENT_Env_' + str(i) + \"_\" + name + '.png')\n",
      "#                 if show_Plot:\n",
      "#                     plt.show()\n",
      "\n",
      "Output: {'Plot': ['glob.glob', 'matplotlib.pyplot.ylabel', 'matplotlib.pyplot.tight_layout', 'matplotlib.pyplot.tick_params', 'matplotlib.pyplot.yticks', 'matplotlib.pyplot.gca', 'matplotlib.pyplot.savefig', '<builtin>.print', 'pandas.read_excel', 'matplotlib.pyplot.ylim', 'matplotlib.patches.Patch', 'matplotlib.pyplot.legend', '<builtin>.str', 'matplotlib.pyplot.interactive', 'matplotlib.pyplot.xlabel', 'matplotlib.pyplot.show', 'numpy.arange'], 'matplotlib.pyplot.interactive': [], '<builtin>.print': [], '<builtin>.str': [], 'glob.glob': [], 'pandas.read_excel': [], 'matplotlib.patches.Patch': [], 'matplotlib.pyplot.xlabel': [], 'matplotlib.pyplot.ylabel': [], 'matplotlib.pyplot.tight_layout': [], 'matplotlib.pyplot.savefig': [], 'matplotlib.pyplot.show': [], 'matplotlib.pyplot.tick_params': [], 'matplotlib.pyplot.gca': [], 'matplotlib.pyplot.legend': [], 'numpy.arange': [], 'matplotlib.pyplot.yticks': [], 'matplotlib.pyplot.ylim': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\AimoreRRD_Reinforcement-Learning-Research\\Plot.py\n",
      "[('Plot', 'glob glob'), ('Plot', 'matplotlib pyplot ylabel'), ('Plot', 'matplotlib pyplot tight_layout'), ('Plot', 'matplotlib pyplot tick_params'), ('Plot', 'matplotlib pyplot yticks'), ('Plot', 'matplotlib pyplot gca'), ('Plot', 'matplotlib pyplot savefig'), ('Plot', 'pandas read_excel'), ('Plot', 'matplotlib pyplot ylim'), ('Plot', 'matplotlib patches Patch'), ('Plot', 'matplotlib pyplot legend'), ('Plot', 'matplotlib pyplot interactive'), ('Plot', 'matplotlib pyplot xlabel'), ('Plot', 'matplotlib pyplot show'), ('Plot', 'numpy arange')]\n",
      "0\n",
      "found files: []\n",
      "import pandas as pd\n",
      "import os\n",
      "\n",
      "__location__ = os.path.realpath(os.path.join(os.getcwd(), os.path.dirname(__file__)))\n",
      "\n",
      "s_env = 10\n",
      "path_core = \"/Results/Train/Env_\" + str(s_env) + \"/\"\n",
      "\n",
      "Save_Path_Comp = path_core + \"Env_\" + str(s_env) + \"_COMPILED\"\n",
      "writer = pd.ExcelWriter(__location__ + Save_Path_Comp + \".xlsx\", engine='xlsxwriter')\n",
      "\n",
      "ps_list = [\"Score\",\"Percent\"]\n",
      "for ps in ps_list:\n",
      "    QL = pd.read_excel(__location__ + path_core + \"QL/QL_averaged\" + \".xlsx\", sheetname=ps, skiprows=10, parse_cols=\"B:B\", index=True)\n",
      "    DSRL = pd.read_excel(__location__ + path_core + \"DSRL/DSRL_averaged\" + \".xlsx\", sheetname=ps, skiprows=10, parse_cols=\"B:B\", index=True)\n",
      "    DSRL_trick = pd.read_excel(__location__ + path_core + \"DSRL/DSRL_tricked_averaged\" + \".xlsx\",  sheetname=ps, skiprows=10,parse_cols=\"B:B\")\n",
      "    DQN = pd.read_excel(__location__ + path_core + \"DQN/DQN_averaged\" + \".xlsx\", sheetname=ps, skiprows=10, parse_cols=\"B:B\")\n",
      "\n",
      "    QL.to_excel(startrow=1, startcol=0, excel_writer=writer,sheet_name=ps,index=False, header=False)\n",
      "    DSRL.to_excel(startrow=1, startcol=1, excel_writer=writer,sheet_name=ps,index=False, header=False)\n",
      "    DSRL_trick.to_excel(startrow=1, startcol=2, excel_writer=writer, sheet_name=ps, index=False, header=False)\n",
      "    DQN.to_excel(startrow=1, startcol=3, excel_writer=writer, sheet_name=ps, index=False, header=False)\n",
      "\n",
      "    worksheet = writer.sheets[ps]\n",
      "    worksheet.write(0, 0, \"QL\")\n",
      "    worksheet.write(0, 1, \"DSRL\")\n",
      "    worksheet.write(0, 2, \"DSRL_trick\")\n",
      "    worksheet.write(0, 3, \"DQN\")\n",
      "writer.save()\n",
      "\n",
      "\n",
      "\n",
      "Output: {'Script_Compiler': ['<builtin>.str', 'os.path.realpath', 'pandas.read_excel', 'os.path.dirname', 'os.getcwd', 'pandas.ExcelWriter', 'os.path.join'], 'os.getcwd': [], 'os.path.dirname': [], 'os.path.join': [], 'os.path.realpath': [], '<builtin>.str': [], 'pandas.ExcelWriter': [], 'pandas.read_excel': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\AimoreRRD_Reinforcement-Learning-Research\\Script_Compiler.py\n",
      "[('Script_Compiler', 'os path realpath'), ('Script_Compiler', 'pandas read_excel'), ('Script_Compiler', 'os path dirname'), ('Script_Compiler', 'os getcwd'), ('Script_Compiler', 'pandas ExcelWriter'), ('Script_Compiler', 'os path join')]\n",
      "0\n",
      "found files: []\n",
      "'Author: Aimore Resende Riquetti Dutra'\n",
      "'''email: aimorerrd@hotmail.com'''\n",
      "# -------------------------------------------------------------------------------------------------- #\n",
      "# This code can run 4 different models of Reinforcement Learning:\n",
      "# Q-Learning (QL), DQN, SRL (DSRL), SRL+CS(DSRL_object_near) and some other variations of SRL\n",
      "# The setting for each run can be set at the end of the code\n",
      "# It can load and save the models in Excel form\n",
      "# There are some pre-defined environments, but you can create your own\n",
      "# Press G to get intermediate Graphs and P to stop\n",
      "# -------------------------------------------------------------------------------------------------- #\n",
      "\n",
      "import Class\n",
      "import pprint\n",
      "import random\n",
      "import sys\n",
      "import numpy as np\n",
      "import pygame\n",
      "# from pyglet import clock\n",
      "import pandas as pd\n",
      "import time\n",
      "import json\n",
      "from time import sleep\n",
      "import math\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "import glob\n",
      "\n",
      "## Comment this part if not using DQN model:\n",
      "# import keras\n",
      "# from keras.models import Sequential\n",
      "# from keras.layers import Dense, Activation, Flatten\n",
      "# from keras.models import model_from_json\n",
      "# from keras.optimizers import sgd\n",
      "# from keras.utils import plot_model\n",
      "# import tensorflow as tf\n",
      "# from keras.backend.tensorflow_backend import set_session\n",
      "# config = tf.ConfigProto()\n",
      "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
      "# set_session(tf.Session(config=config))\n",
      "\n",
      "# region COLOR DEFINITION\n",
      "white = (255, 255, 255)\n",
      "black = (0, 0, 0)\n",
      "grey = (80, 80, 80)\n",
      "red = (255, 0, 0)\n",
      "blue = (0, 0, 255)\n",
      "green = (0, 255, 0)\n",
      "yellow = (250, 250, 0)\n",
      "pink = (250, 105, 180)\n",
      "# endregion\n",
      "\n",
      "# region PANDAS DEFINITION\n",
      "pd.set_option('display.max_columns', None)\n",
      "pd.set_option('display.large_repr', 'info')\n",
      "desired_width = 180\n",
      "pd.set_option('display.width', desired_width)\n",
      "pd.set_option('precision', 4)\n",
      "# endregion\n",
      "\n",
      "np.random.seed(123)  # For reproducibility\n",
      "pygame.init()  # Pygame initialialization\n",
      "pp = pprint.PrettyPrinter(indent=4)\n",
      "actions = ['up', 'down', 'right', 'left']\n",
      "actions_dict = {'up':0, 'down':1, 'right':2, 'left':3}\n",
      "p_keys = [pygame.K_w, pygame.K_a, pygame.K_s, pygame.K_d]\n",
      "# clock.tick(20)\n",
      "\n",
      "def pop(self):\n",
      "    '''Removes a layer instance on top of the layer stack.\n",
      "    '''\n",
      "    while self.outputs:\n",
      "        self.layers.pop()\n",
      "        if not self.layers:\n",
      "            self.outputs = []\n",
      "            self.inbound_nodes = []\n",
      "            self.outbound_nodes = []\n",
      "        else:\n",
      "            self.layers[-1].outbound_nodes = []\n",
      "            self.outputs = [self.layers[-1].output]\n",
      "        self.built = False\n",
      "\n",
      "# region REWARDS\n",
      "negative_reward = 10  # Negative Reward\n",
      "positive_reward = 1  # Positive Reward\n",
      "step_reward = 0  # Reward received by each step\n",
      "# endregion\n",
      "\n",
      "# region TEXT FONTS DEFINITION\n",
      "smallfont = pygame.font.SysFont('comicsansms', 13)\n",
      "smallfont_act = pygame.font.SysFont('arial', 13)\n",
      "mediumfont_act = pygame.font.SysFont('arial', 18, bold=True)\n",
      "pygame.font.init()\n",
      "# endregion\n",
      "\n",
      "# region DISPLAY FUNCTIONS\n",
      "def show_Alg(alg, screen):\n",
      "    text = smallfont.render(\"Alg: \" + alg, True, black)\n",
      "    screen.blit(text, [5 + 90 * 0, 0])\n",
      "\n",
      "def show_Samples(sample, screen):\n",
      "    text = smallfont.render(\"Sample: \" + str(sample), True, black)\n",
      "    screen.blit(text, [60+100*1, 0])\n",
      "\n",
      "def show_Level(level, screen):\n",
      "    text = smallfont.render(\"Episode: \" + str(level), True, black)\n",
      "    screen.blit(text, [50+100*2, 0])\n",
      "\n",
      "def show_Score(score, screen):\n",
      "    text = smallfont.render(\"Score: \" + str(score), True, black)\n",
      "    screen.blit(text, [50+100*3, 0])\n",
      "\n",
      "def show_Steps(steps, screen):\n",
      "    text = smallfont.render(\"Steps: \" + str(steps), True, black)\n",
      "    screen.blit(text, [50+100*4, 0])\n",
      "\n",
      "def show_Percent(percent, screen):\n",
      "    text = smallfont.render(\"Percent: \" + str(['%.2f' % elem for elem in percent]), True, black)\n",
      "    screen.blit(text, [5, 30 * 4])\n",
      "\n",
      "def show_Steps_list(steps_list, screen):\n",
      "    text = smallfont.render(\"Steps_list: \" + str(steps_list), True, black)\n",
      "    screen.blit(text, [5, 30 * 1])\n",
      "\n",
      "def show_Act_List(act_list, screen):\n",
      "    text = smallfont_act.render(\"act_list: \" + str(act_list), True, black)\n",
      "    screen.blit(text, [5, 30 * 2])\n",
      "\n",
      "def show_Action(act, screen):\n",
      "    text = smallfont_act.render(\"Chosen Action: \" + act, True, black)\n",
      "    screen.blit(text, [5, 30 * 3])\n",
      "\n",
      "def show_Env(env, screen):\n",
      "    text = mediumfont_act.render(\"Environment:  \" + str(env), True, black)\n",
      "    screen.blit(text, [50, 30 * 5])\n",
      "# endregion\n",
      "\n",
      "# region CREATE OBJ_LIST FROM STATE AND RELATIONSHIP LIST BETWEEN AGENT AND OBJECTS\n",
      "''' CREATE obj_list - FROM env '''\n",
      "def create_obj_list(env):\n",
      "    obj_list_fun = []\n",
      "    tp_list = []\n",
      "    loc_list = []\n",
      "    env = env.transpose()\n",
      "    h_max = env.shape[0]\n",
      "    # print(\"h_max\", h_max)\n",
      "    v_max = env.shape[1]\n",
      "    # print(\"v_max\",v_max)\n",
      "    for h in range(1, (h_max - 1)):\n",
      "        for v in range(1, (v_max - 1)):\n",
      "            if env[h][v] != 0:\n",
      "                tp_list.append(env[h][v])\n",
      "                loc_list.append((h, v))\n",
      "    for i in range(len(loc_list)):\n",
      "        tp = tp_list[i]\n",
      "        loc = loc_list[i]\n",
      "        obj = Class.Obj(tp, loc)\n",
      "        obj_list_fun.append(obj)\n",
      "    return obj_list_fun\n",
      "\n",
      "''' CREATE A RELATIONSHIP LIST BETWEEN AGENT AND OBJECTS - FROM obj_list '''\n",
      "def relation_obj_list(obj_list, agent_pos):\n",
      "    rel_list = []\n",
      "    xA = agent_pos[0]\n",
      "    yA = agent_pos[1]\n",
      "    # print(\"xA\", xA)\n",
      "    # print(\"yA\", yA)\n",
      "    for obj in obj_list:\n",
      "        xB = obj.loc[0]\n",
      "        yB = obj.loc[1]\n",
      "        x = xA - xB\n",
      "        y = yA - yB\n",
      "        loc_dif = (x, y)\n",
      "        # loc_dif = (x[0], y[0])\n",
      "        tp = obj.tp\n",
      "        obj = Class.Obj(tp, loc_dif)\n",
      "        rel_list.append(obj)\n",
      "    return rel_list\n",
      "# endregion\n",
      "\n",
      "# region DRAW OBJECTS\n",
      "x_zero_screen = 50\n",
      "y_zero_screen = 180\n",
      "size_obj = 37\n",
      "def draw_objects(agent, positivo_list, negativo_list, wall_list, screen):\n",
      "    # Class.Grid.draw_grid(screen) # Uncomment to display a Grid\n",
      "    for i in positivo_list:  # POSITIVO\n",
      "        screen.blit(i.icon, (i.pos[0] * size_obj + x_zero_screen, y_zero_screen + i.pos[1] * size_obj))\n",
      "    for i in negativo_list:  # NEGATIVO\n",
      "        screen.blit(i.icon, (i.pos[0] * size_obj + x_zero_screen, y_zero_screen + i.pos[1] * size_obj))\n",
      "    screen.blit(agent.icon, (agent.pos[0] * size_obj + x_zero_screen, y_zero_screen + agent.pos[1] * size_obj))  # AGENT\n",
      "    for i in wall_list:  # WALL\n",
      "        screen.blit(i.icon, (i.pos[0] * size_obj + x_zero_screen, y_zero_screen + i.pos[1] * size_obj))\n",
      "# endregion\n",
      "\n",
      "# region CREATE THE STATE FROM THE ENVIRONMENT\n",
      "def update_state(h_max, v_max, agent, positivo_list, negativo_list, wall_list):\n",
      "    state = np.zeros((v_max, h_max)).astype(np.int16)\n",
      "    for i in positivo_list:\n",
      "        state[i.pos[1]][i.pos[0]] = 60  # SYMBOL 60 POSITIVE\n",
      "    for i in negativo_list:\n",
      "        state[i.pos[1]][i.pos[0]] = 180  # SYMBOL 180 NEGATIVE\n",
      "    for i in wall_list:\n",
      "        state[i.pos[1]][i.pos[0]] = 255  # SYMBOL 255\n",
      "    # state[agent.pos[1]][agent.pos[0]] = 120  # SYMBOL 60\n",
      "    return state\n",
      "    # TODO I have to check if this v_max and h_max have to be declared eveytime\n",
      "# endregion\n",
      "\n",
      "# region ENVIRONMENT CONFIGURATION\n",
      "def environment_conf(s_env):\n",
      "    if s_env == 1:\n",
      "        v_max = 4\n",
      "        h_max = 5\n",
      "        x_agent = 1\n",
      "        y_agent = 2\n",
      "        m_nega = np.matrix([[0, 0, 0],\n",
      "                            [0, 1, 0]])\n",
      "        m_posi = np.matrix([[0, 1, 0],\n",
      "                            [0, 0, 0]])\n",
      "\n",
      "    elif s_env == 2:\n",
      "        v_max = 4\n",
      "        h_max = 5\n",
      "        x_agent = 1\n",
      "        y_agent = 2\n",
      "        m_nega = np.matrix([[0, 0, 0],\n",
      "                            [0, 0, 1]])\n",
      "        m_posi = np.matrix([[0, 0, 1],\n",
      "                            [0, 0, 0]])\n",
      "\n",
      "    elif s_env == 3:\n",
      "        v_max = 4\n",
      "        h_max = 5\n",
      "        x_agent = 1\n",
      "        y_agent = 2\n",
      "        m_nega = np.matrix([[1, 0, 0],\n",
      "                            [0, 0, 0]])\n",
      "        m_posi = np.matrix([[0, 1, 0],\n",
      "                            [0, 0, 0]])\n",
      "\n",
      "    elif s_env == 4:\n",
      "        v_max = 4\n",
      "        h_max = 4\n",
      "        x_agent = 1\n",
      "        y_agent = 1\n",
      "        m_nega = np.matrix([[0, 0],\n",
      "                            [0, 0]])\n",
      "        m_posi = np.matrix([[0, 0],\n",
      "                            [0, 1]])\n",
      "\n",
      "    elif s_env == 5:\n",
      "        v_max = 5\n",
      "        h_max = 5\n",
      "        x_agent = 2\n",
      "        y_agent = 2\n",
      "        m_nega = np.zeros(shape=(v_max - 2, h_max - 2))\n",
      "        m_posi = np.zeros(shape=(v_max - 2, h_max - 2))\n",
      "        while (True):\n",
      "            x = random.randrange(0, h_max - 2)\n",
      "            y = random.randrange(0, v_max - 2)\n",
      "            if x != x_agent-1 or y != y_agent-1:\n",
      "                element = (x, y)\n",
      "                break\n",
      "        m_posi[element] = 1\n",
      "\n",
      "    elif s_env == 6:\n",
      "        v_max = 7\n",
      "        h_max = 7\n",
      "        x_agent = 3\n",
      "        y_agent = 3\n",
      "        m_nega = np.zeros(shape=(v_max - 2, h_max - 2))\n",
      "        m_posi = np.zeros(shape=(v_max - 2, h_max - 2))\n",
      "        while (True):\n",
      "            x = random.randrange(0, h_max - 2)\n",
      "            y = random.randrange(0, v_max - 2)\n",
      "            if x != x_agent - 1 or y != y_agent - 1:\n",
      "                element = (x, y)\n",
      "                break\n",
      "        m_posi[element] = 1\n",
      "\n",
      "    elif s_env == 7:\n",
      "        v_max = 9\n",
      "        h_max = 9\n",
      "        x_agent = 4\n",
      "        y_agent = 4\n",
      "        m_nega = np.zeros(shape=(v_max - 2, h_max - 2))\n",
      "        m_posi = np.zeros(shape=(v_max - 2, h_max - 2))\n",
      "        while (True):\n",
      "            x = random.randrange(0, h_max - 2)\n",
      "            y = random.randrange(0, v_max - 2)\n",
      "            if x != x_agent - 1 or y != y_agent - 1:\n",
      "                element = (x, y)\n",
      "                break\n",
      "        m_posi[element] = 1\n",
      "\n",
      "    elif s_env == 8:\n",
      "        v_max = 5\n",
      "        h_max = 5\n",
      "        x_agent = 2\n",
      "        y_agent = 2\n",
      "        m_nega = np.matrix([[0, 0, 0],\n",
      "                            [0, 0, 0],\n",
      "                            [1, 0, 1]])\n",
      "        m_posi = np.matrix([[1, 0, 1],\n",
      "                            [0, 0, 0],\n",
      "                            [0, 0, 0]])\n",
      "\n",
      "    elif s_env == 9:\n",
      "        v_max = 5\n",
      "        h_max = 5\n",
      "        x_agent = 2\n",
      "        y_agent = 2\n",
      "        m_nega = np.matrix([[1, 0, 0],\n",
      "                            [0, 0, 0],\n",
      "                            [0, 0, 1]])\n",
      "        m_posi = np.matrix([[0, 0, 1],\n",
      "                            [0, 0, 0],\n",
      "                            [1, 0, 0]])\n",
      "\n",
      "    elif s_env == 10:\n",
      "        v_max = 9\n",
      "        h_max = 9\n",
      "        x_agent = 4\n",
      "        y_agent = 4\n",
      "        m_nega = np.matrix([[1, 0, 0, 0, 1, 0, 0],\n",
      "                            [0, 0, 0, 0, 0, 0, 0],\n",
      "                            [0, 0, 1, 0, 0, 0, 1],\n",
      "                            [0, 0, 0, 0, 0, 0, 0],\n",
      "                            [1, 0, 0, 0, 1, 0, 0],\n",
      "                            [0, 0, 0, 0, 0, 0, 0],\n",
      "                            [0, 0, 1, 0, 0, 0, 1]])\n",
      "        m_posi = np.matrix([[0, 0, 1, 0, 0, 0, 1],\n",
      "                            [0, 0, 0, 0, 0, 0, 0],\n",
      "                            [1, 0, 0, 0, 1, 0, 0],\n",
      "                            [0, 0, 0, 0, 0, 0, 0],\n",
      "                            [0, 0, 1, 0, 0, 0, 1],\n",
      "                            [0, 0, 0, 0, 0, 0, 0],\n",
      "                            [1, 0, 0, 0, 1, 0, 0]])\n",
      "\n",
      "    elif s_env == 11:\n",
      "        v_max = 9\n",
      "        h_max = 9\n",
      "        x_agent = 4\n",
      "        y_agent = 4\n",
      "        element_list = []\n",
      "        for n in range(14):\n",
      "            while(True):\n",
      "                x = random.randrange(0,7)\n",
      "                y = random.randrange(0,7)\n",
      "                if x != 3 and y != 3 and (x,y) not in element_list:\n",
      "                    element = (x, y)\n",
      "                    break\n",
      "            element_list.append(element)\n",
      "\n",
      "        m_nega = np.zeros(shape=(v_max-2, h_max-2))\n",
      "        m_posi = np.zeros(shape=(v_max-2, h_max-2))\n",
      "        half = len(element_list) / 2\n",
      "        nega_list = element_list[:int(half)]\n",
      "        posi_list = element_list[int(half):]\n",
      "        for ele in nega_list:\n",
      "            m_nega[ele] = 1\n",
      "        for ele in posi_list:\n",
      "            m_posi[ele] = 1\n",
      "\n",
      "    elif s_env == 12:\n",
      "        v_max = 3\n",
      "        h_max = 5\n",
      "        x_agent = 2\n",
      "        y_agent = 1\n",
      "        m_nega = np.matrix([1, 0, 0])\n",
      "        m_posi = np.matrix([0, 0, 1])\n",
      "\n",
      "    elif s_env == 13:\n",
      "        v_max = 3\n",
      "        h_max = 5\n",
      "        x_agent = 2\n",
      "        y_agent = 1\n",
      "        m_nega = np.matrix([0, 0, 0])\n",
      "        m_posi = np.matrix([1, 0, 1])\n",
      "\n",
      "    elif s_env == 14:\n",
      "        v_max = 3\n",
      "        h_max = 6\n",
      "        x_agent = 2\n",
      "        y_agent = 1\n",
      "        m_nega = np.matrix([1, 0, 0, 0])\n",
      "        m_posi = np.matrix([0, 0, 0, 1])\n",
      "\n",
      "    elif s_env == 15:\n",
      "        v_max = 3\n",
      "        h_max = 6\n",
      "        x_agent = 2\n",
      "        y_agent = 1\n",
      "        m_nega = np.matrix([0, 0, 0, 0])\n",
      "        m_posi = np.matrix([1, 0, 0, 1])\n",
      "\n",
      "    elif s_env == 16:\n",
      "        v_max = 3\n",
      "        h_max = 7\n",
      "        x_agent = 3\n",
      "        y_agent = 1\n",
      "        m_nega = np.matrix([1, 0, 0, 0, 0])\n",
      "        m_posi = np.matrix([0, 0, 0, 0, 1])\n",
      "\n",
      "    elif s_env == 17:\n",
      "        v_max = 3\n",
      "        h_max = 7\n",
      "        x_agent = 3\n",
      "        y_agent = 1\n",
      "        m_nega = np.matrix([0, 0, 0, 0, 0])\n",
      "        m_posi = np.matrix([1, 0, 0, 0, 1])\n",
      "\n",
      "    elif s_env == 18:\n",
      "        v_max = 3\n",
      "        h_max = 9\n",
      "        x_agent = 4\n",
      "        y_agent = 1\n",
      "        m_nega = np.matrix([1, 0, 0, 0, 0, 0, 0])\n",
      "        m_posi = np.matrix([0, 0, 0, 0, 0, 0, 1])\n",
      "\n",
      "    elif s_env == 19:\n",
      "        v_max = 3\n",
      "        h_max = 9\n",
      "        x_agent = 4\n",
      "        y_agent = 1\n",
      "        m_nega = np.matrix([0, 0, 0, 0, 0, 0, 0])\n",
      "        m_posi = np.matrix([1, 0, 0, 0, 0, 0, 1])\n",
      "\n",
      "    elif s_env == 20:\n",
      "        v_max = 5\n",
      "        h_max = 5\n",
      "        x_agent = 2\n",
      "        y_agent = 2\n",
      "        m_nega = np.matrix([[0, 0, 0],\n",
      "                            [0, 0, 0],\n",
      "                            [0, 0, 0]])\n",
      "        m_posi = np.matrix([[1, 0, 1],\n",
      "                            [0, 0, 0],\n",
      "                            [0, 1, 0]])\n",
      "\n",
      "    elif s_env == 21:\n",
      "        v_max = 5\n",
      "        h_max = 5\n",
      "        x_agent = 2\n",
      "        y_agent = 2\n",
      "        m_nega = np.matrix([[0, 1, 0],\n",
      "                            [0, 0, 0],\n",
      "                            [1, 0, 1]])\n",
      "        m_posi = np.matrix([[1, 0, 1],\n",
      "                            [0, 0, 0],\n",
      "                            [0, 1, 0]])\n",
      "\n",
      "    elif s_env == 22:\n",
      "        v_max = 5\n",
      "        h_max = 5\n",
      "        x_agent = 2\n",
      "        y_agent = 2\n",
      "        m_nega = np.matrix([[0, 0, 0],\n",
      "                            [0, 0, 0],\n",
      "                            [0, 0, 0]])\n",
      "        m_posi = np.matrix([[1, 0, 1],\n",
      "                            [0, 0, 0],\n",
      "                            [1, 0, 1]])\n",
      "\n",
      "    if s_env == 31:\n",
      "        v_max = 5\n",
      "        h_max = 5\n",
      "        x_agent = 1\n",
      "        y_agent = 2\n",
      "        m_nega = np.matrix([[0, 0, 0],\n",
      "                            [0, 1, 0],\n",
      "                            [0, 0, 0]])\n",
      "        m_posi = np.matrix([[0, 1, 0],\n",
      "                            [0, 0, 0],\n",
      "                            [0, 0, 0]])\n",
      "\n",
      "    elif s_env == 32:\n",
      "        v_max = 5\n",
      "        h_max = 5\n",
      "        x_agent = 1\n",
      "        y_agent = 2\n",
      "        m_nega = np.matrix([[0, 0, 0],\n",
      "                            [0, 0, 1],\n",
      "                            [0, 0, 0]])\n",
      "        m_posi = np.matrix([[0, 0, 1],\n",
      "                            [0, 0, 0],\n",
      "                            [0, 0, 0]])\n",
      "\n",
      "    elif s_env == 33:\n",
      "        v_max = 5\n",
      "        h_max = 5\n",
      "        x_agent = 1\n",
      "        y_agent = 2\n",
      "        m_nega = np.matrix([[1, 0, 0],\n",
      "                            [0, 0, 0],\n",
      "                            [0, 0, 0]])\n",
      "        m_posi = np.matrix([[0, 1, 0],\n",
      "                            [0, 0, 0],\n",
      "                            [0, 0, 0]])\n",
      "\n",
      "    else:\n",
      "        pass\n",
      "\n",
      "    \"INSTANCE THE wall_list\"\n",
      "    wall_list = []\n",
      "    for y in range(v_max):\n",
      "        for x in range(h_max):\n",
      "            if y == v_max - 1 or y == 0 or x == h_max - 1 or x == 0:\n",
      "                wall = Class.Wall('wall', x, y)\n",
      "                wall_list.append(wall)\n",
      "    \"INSTANCE THE AGENT\"\n",
      "    agent = Class.Agent('agent', x_agent, y_agent)\n",
      "\n",
      "    \"INSTANCE POSITIVE OBJECTS\"\n",
      "    positivo_list = []\n",
      "    for x in range(m_posi.shape[0]):\n",
      "        for y in range(m_posi.shape[1]):\n",
      "            if m_posi[x, y] == 1:\n",
      "                positivo = Class.Positivo('positivo', y + 1, x + 1)\n",
      "                positivo_list.append(positivo)\n",
      "\n",
      "    \"INSTANCE NEGATIVE OBJECTS\"\n",
      "    negativo_list = []\n",
      "    for x in range(m_nega.shape[0]):\n",
      "        for y in range(m_nega.shape[1]):\n",
      "            if m_nega[x, y] == 1:\n",
      "                negativo = Class.Negativo('negativo', y + 1, x + 1)\n",
      "                negativo_list.append(negativo)\n",
      "\n",
      "    return negativo_list, positivo_list, agent, wall_list, h_max, v_max\n",
      "# endregion\n",
      "\n",
      "# region SAVE - LOAD - CREATE\n",
      "def save_model(model, path):\n",
      "    model.save_weights(path + \".h5\", overwrite=True)\n",
      "    with open(path + \".json\", \"w\") as outfile:\n",
      "        json.dump(model.to_json(), outfile)\n",
      "\n",
      "def load_model(s_alg, path):\n",
      "    optimizer_config = []\n",
      "    print(path)\n",
      "    if s_alg == \"QL\":\n",
      "        path = path + \".xlsx\"\n",
      "        model = pd.read_excel(path, sheetname=\"model\")\n",
      "\n",
      "    elif s_alg == \"DSRL\":\n",
      "        path = path + \".xlsx\"\n",
      "        model = pd.read_excel(path, sheetname=\"model\", header=[0], index_col=[0,1])\n",
      "\n",
      "    elif s_alg == \"DSRL_dist\":\n",
      "        path = path + \".xlsx\"\n",
      "        model = pd.read_excel(path, sheetname=\"model\", header=[0], index_col=[0,1])\n",
      "\n",
      "    elif s_alg == \"DSRL_dist_type\":\n",
      "        path = path + \".xlsx\"\n",
      "        model = pd.read_excel(path, sheetname=\"model\", header=[0], index_col=[0,1])\n",
      "\n",
      "    elif s_alg == \"DSRL_dist_type_near\":\n",
      "        path = path + \".xlsx\"\n",
      "        model = pd.read_excel(path, sheetname=\"model\", header=[0], index_col=[0,1])\n",
      "\n",
      "    elif s_alg == \"DSRL_dist_type_near_propNeg\":\n",
      "        path = path + \".xlsx\"\n",
      "        model = pd.read_excel(path, sheetname=\"model\", header=[0], index_col=[0,1])\n",
      "\n",
      "    elif s_alg == \"DSRL_object_near\":\n",
      "        path = path + \".xlsx\"\n",
      "        model = pd.read_excel(path, sheetname=\"model\", header=[0], index_col=[0,1])\n",
      "\n",
      "    elif s_alg == \"DSRL_object\":\n",
      "        path = path + \".xlsx\"\n",
      "        model = pd.read_excel(path, sheetname=\"model\", header=[0], index_col=[0, 1])\n",
      "\n",
      "    elif s_alg == \"DQN\":\n",
      "        with open(path + \".json\", \"r\") as jfile:\n",
      "            model = model_from_json(json.load(jfile))\n",
      "        model.load_weights(path + \".h5\")\n",
      "        conf = pd.read_excel(path + \".xlsx\", sheetname=\"Run_Conf\", header=[0])\n",
      "        # net_conf = conf.loc[[16:20],:]\n",
      "        # print(\"net_conf\", net_conf)\n",
      "        optimizer = conf.loc[19, \"A\"]\n",
      "        print(\"op_conf \", optimizer)\n",
      "        # pd.Series({'N_actions': net_conf[\"N_actions\"]}),\n",
      "        # pd.Series({'Max_memory': net_conf[\"Max_memory\"]}),\n",
      "        # pd.Series({'Hidden_size': net_conf[\"Hidden_size\"]}),\n",
      "        # pd.Series({'Batch_size': net_conf[\"Batch_size\"]}),\n",
      "        # pd.Series({'Optimizer': net_conf[\"Optimizer\"]}),\n",
      "        # pd.Series({'lr': op_conf[0]}),\n",
      "        # pd.Series({'beta_1': op_conf[1]}),\n",
      "        # pd.Series({'beta_2': op_conf[2]}),\n",
      "        # pd.Series({'epsilon': op_conf[3]}),\n",
      "        # pd.Series({'decay': op_conf[4]}),\n",
      "        # pd.Series({'rho': op_conf[5]})\n",
      "\n",
      "        use_optimizer, optimizer_config = define_optimizer(optimizer)\n",
      "        model.compile(loss='mse', optimizer=use_optimizer)\n",
      "        model.summary()\n",
      "        # pass\n",
      "    return model, optimizer_config\n",
      "\n",
      "def create_model(s_alg, state_shape, net_conf):\n",
      "    optimizer_config = []\n",
      "    if s_alg == \"QL\":\n",
      "        model = pd.DataFrame()\n",
      "        model.index.name = [\"States\", \"Action\"]\n",
      "\n",
      "    elif s_alg == \"DSRL\" or s_alg == \"DSRL_dist\" or s_alg == \"DSRL_dist_type\" or s_alg == \"DSRL_dist_type_near\" or s_alg == \"DSRL_dist_type_near_propNeg\" or s_alg == \"DSRL_object_near\" or s_alg == \"DSRL_object\":\n",
      "        m_index = pd.MultiIndex(levels=[[''], [\"\"]],\n",
      "                                labels=[[], []],\n",
      "                                names=['state', 'actions'])\n",
      "        model = pd.DataFrame(index=m_index)\n",
      "\n",
      "    elif s_alg == \"DQN\":\n",
      "        model = Sequential()\n",
      "        pop(model)\n",
      "        model = Sequential()\n",
      "        model.add(Dense(net_conf[\"Hidden_size\"],\n",
      "                        input_dim=state_shape[0]*state_shape[1],\n",
      "                        activation=\"relu\",\n",
      "                        name=\"DENSE_1\"))\n",
      "\n",
      "        model.add(Dense(net_conf[\"Hidden_size\"],\n",
      "                        activation='relu',\n",
      "                        name=\"DENSE_2\"))\n",
      "\n",
      "        model.add(Dense(net_conf[\"N_actions\"],\n",
      "                        name=\"DENSE_3\"))\n",
      "\n",
      "        use_optimizer, optimizer_config = define_optimizer(net_conf[\"Optimizer\"])\n",
      "        model.compile(loss='mse', optimizer=use_optimizer)\n",
      "        print(model.summary())\n",
      "        # plot_model(model, to_file='model.png')\n",
      "        # d3v.d3viz(model.get_output(), 'test.html')\n",
      "    return model, optimizer_config\n",
      "\n",
      "# endregion\n",
      "\n",
      "# region DQN - CONFIGURATIONS\n",
      "class ExperienceReplay(object):\n",
      "    \"\"\"\n",
      "    During gameplay all the experiences < s, a, r, s > are stored in a replay memory.\n",
      "    In training, batches of randomly drawn experiences are used to generate the input and target for training.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, max_memory=100, discount=.9):\n",
      "        \"\"\"\n",
      "        Setup\n",
      "        max_memory: the maximum number of experiences we want to store\n",
      "        memory: a list of experiences\n",
      "        discount: the discount factor for future experience\n",
      "\n",
      "        In the memory the information whether the game ended at the state is stored seperately in a nested array\n",
      "        [...\n",
      "        [experience, game_over]\n",
      "        [experience, game_over]\n",
      "        ...]\n",
      "        \"\"\"\n",
      "        self.max_memory = max_memory\n",
      "        self.memory = list()\n",
      "        self.discount = discount\n",
      "\n",
      "    def remember(self, states, game_over):\n",
      "        # Save a state to memory\n",
      "        self.memory.append([states, game_over])\n",
      "        # We don't want to store infinite memories, so if we have too many, we just delete the oldest one\n",
      "        if len(self.memory) > self.max_memory:\n",
      "            del self.memory[0]\n",
      "\n",
      "        # print(\">>> states:\", states)\n",
      "\n",
      "    def get_batch(self, model, batch_size=10):\n",
      "        # How many experiences do we have?\n",
      "        len_memory = len(self.memory)\n",
      "\n",
      "        # Calculate the number of actions that can possibly be taken in the game\n",
      "        num_actions = model.output_shape[-1]\n",
      "\n",
      "        # Dimensions of the game field\n",
      "        env_dim = self.memory[0][0][0].shape[1]\n",
      "\n",
      "        # We want to return an input and target vector with inputs from an observed state...\n",
      "        inputs = np.zeros((min(len_memory, batch_size), env_dim))\n",
      "\n",
      "        # ...and the target r + gamma * max Q(s,a)\n",
      "        # Note that our target is a matrix, with possible fields not only for the action taken but also for the other possible actions.\n",
      "        # The actions not take the same value as the prediction to not affect them\n",
      "        targets = np.zeros((inputs.shape[0], num_actions))\n",
      "\n",
      "        # We draw states to learn from randomly\n",
      "        for i, idx in enumerate(np.random.randint(0, len_memory, size=inputs.shape[0])):\n",
      "            \"\"\"\n",
      "            Here we load one transition <s, a, r, s> from memory\n",
      "            state_t: initial state s\n",
      "            action_t: action taken a\n",
      "            reward_t: reward earned r\n",
      "            state_tp1: the state that followed s\n",
      "            \"\"\"\n",
      "            state_t, action_t, reward_t, state_tp1 = self.memory[idx][0]\n",
      "            # We also need to know whether the game ended at this state\n",
      "            game_over = self.memory[idx][1]\n",
      "\n",
      "            inputs[i:i + 1] = state_t\n",
      "\n",
      "            # First we fill the target values with the predictions of the model.\n",
      "            # They will not be affected by training (since the training loss for them is 0)\n",
      "            targets[i] = model.predict(state_t)[0]\n",
      "            # print(\"targets\\n\", targets)\n",
      "            # print(\"action_t\", action_t)\n",
      "            \"\"\"\n",
      "            If the game ended, the expected reward Q(s,a) should be the final reward r.\n",
      "            Otherwise the target value is r + gamma * max Q(s,a)\n",
      "            \"\"\"\n",
      "            #  Here Q_sa is max_a'Q(s', a')\n",
      "            Q_sa = np.max(model.predict(state_tp1)[0])\n",
      "\n",
      "            # if the game ended, the reward is the final reward\n",
      "            if game_over:  # if game_over is True\n",
      "                targets[i, action_t] = reward_t\n",
      "            else:\n",
      "                # r + gamma * max Q(s,a)\n",
      "                targets[i, action_t] = reward_t + self.discount * Q_sa\n",
      "        return inputs, targets\n",
      "\n",
      "def define_optimizer(s_optimizer):\n",
      "    lr = 0\n",
      "    beta_1 = 0\n",
      "    beta_2 = 0\n",
      "    epsilon = 0\n",
      "    decay = 0\n",
      "    rho = 0\n",
      "    if s_optimizer == \"adam\":\n",
      "        lr = 0.001  # 0.001\n",
      "        beta_1 = 0.9  # 0.9\n",
      "        beta_2 = 0.999  # 0.999\n",
      "        epsilon = 1e-08  # 1e-08\n",
      "        decay = 0.0  # 0.0\n",
      "        optimizer_selected = keras.optimizers.Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon, decay=decay)\n",
      "    elif s_optimizer == \"rms_opt\":\n",
      "        lr = 0.001  # 0.001\n",
      "        rho = 0.9  # 0.9\n",
      "        epsilon = 1e-08  # e-08\n",
      "        decay = 0.0  # 0.0\n",
      "        optimizer_selected = keras.optimizers.RMSprop(lr=lr, rho=rho, epsilon=epsilon, decay=decay)\n",
      "    optimizer_config = [lr, beta_1, beta_2, epsilon, decay, rho]\n",
      "    return optimizer_selected, optimizer_config\n",
      "#\n",
      "\n",
      "def choose_action(s_alg, state, agent_pos, model, s_prob):\n",
      "    # print(\"\\nPREVIOUS MODEL - CHOOSE ACTION\\n\", model)\n",
      "    zero = False\n",
      "    if s_alg == \"QL\":\n",
      "        state[agent_pos[1]][agent_pos[0]] = 120\n",
      "        s = str(state)\n",
      "        if s not in model.index:\n",
      "            indices = [np.array([s, s, s, s]), np.array(['up', 'down', 'right', 'left'])]\n",
      "            df_zero = pd.DataFrame(np.zeros([4, 1]), index=indices)\n",
      "            model = model.append(df_zero)\n",
      "            model = model.fillna(0)\n",
      "        n_action = np.argmax(model.loc[s][0])  # Choose the max argument\n",
      "        if max(model.loc[s][0]) == 0: zero = True\n",
      "\n",
      "    elif s_alg == \"DSRL\" or s_alg == \"DSRL_dist\" or s_alg == \"DSRL_dist_type\" or s_alg == \"DSRL_dist_type_near\" or s_alg == \"DSRL_dist_type_near_propNeg\" or s_alg == \"DSRL_object_near\" or s_alg == \"DSRL_object\":\n",
      "        a_v_list = []\n",
      "        d = {}\n",
      "        obj_list = create_obj_list(state)\n",
      "        rel_list = relation_obj_list(obj_list, agent_pos)\n",
      "        new_state = rel_list\n",
      "\n",
      "        for obj in new_state: # FOR ALL OBJECTS SEEN\n",
      "            tp_n_c = str(obj.tp) # GET THE TYPE FROM THE NEW STATE\n",
      "            s_n_c = str(obj.loc) # GET THE LOCATION FROM THE NEW STATE\n",
      "            if tp_n_c not in model.columns:\n",
      "                # print(\"tp_n_c not in model.columns\", tp_n_c)\n",
      "                model[tp_n_c] = 0\n",
      "            if s_n_c not in model.index:\n",
      "                # print(\"s_n_c not in model.index\", s_n_c)\n",
      "                m_index = pd.MultiIndex(levels=[[s_n_c], actions],\n",
      "                                        labels=[[0, 0, 0, 0], [0, 1, 2, 3]],\n",
      "                                        names=['state', 'actions'])\n",
      "                df_zero = pd.DataFrame(index=m_index)\n",
      "                model = model.append(df_zero)\n",
      "                model = model.fillna(0)\n",
      "            Qts_a = model[tp_n_c].loc[s_n_c]\n",
      "            # print(\"Qts_a - \", Qts_a)\n",
      "            if s_alg == \"DSRL_dist_type_near\" or s_alg == \"DSRL_dist_type_near_propNeg\" or s_alg == \"DSRL_object_near\": # Calculate the distance\n",
      "                s_n_c_abs = [int(s) for s in s_n_c if s.isdigit()]  # s_n_c_abs = state_new_absolute_distance\n",
      "                distance = np.sqrt(s_n_c_abs[0]**2 + s_n_c_abs[1]**2)\n",
      "                # print(\"distance\",distance)\n",
      "                Qts_a = Qts_a.divide(distance*distance, axis=0)\n",
      "            a_v = [(value, key) for value, key in Qts_a.items()]\n",
      "            # print(\"Qts_a - NEW\", Qts_a)\n",
      "            a_v_list.append(a_v) # Append Q-value\n",
      "\n",
      "        # Sum the values of all Qs into a single Q\n",
      "        for element in a_v_list:\n",
      "            for a in element:\n",
      "                act = a[0] # Action\n",
      "                val = a[1] # Value\n",
      "                d[act] = d.get(act, 0) + val # Sum values for each Q\n",
      "\n",
      "        # print('a_v_list: (List of the action values for each object in the scene): ')\n",
      "        # print('{0}'.format(a_v_list))\n",
      "        # print('\\nd: (The sum of all object`s action values )')\n",
      "        # pp.pprint(d)\n",
      "\n",
      "        if d != {}: # BE CAREFUL THIS IS A DICT (argmax does not work as usual)\n",
      "            inverse = [(value, key) for key, value in d.items()] # CALCULATE ALL KEYS\n",
      "            n_action = max(inverse)[1] # Choose the max argument\n",
      "\n",
      "            if max(d.values()) == 0: zero = True\n",
      "        else:\n",
      "            n_action = \"down\"\n",
      "\n",
      "    elif s_alg == \"DQN\":\n",
      "        state[agent_pos[1]][agent_pos[0]] = 120\n",
      "        state = state.reshape((1, -1))\n",
      "        q = model.predict(state)\n",
      "        n_act = np.argmax(q[0])\n",
      "        n_action = actions[n_act]\n",
      "        if max(q[0]) == 0: zero = True\n",
      "\n",
      "    x = random.random()  # E greedy exploration\n",
      "    if x < s_prob:\n",
      "        n_action = random.choice(actions)\n",
      "        print_action = 'Random Act (Prob):'\n",
      "    elif zero == True:\n",
      "        n_action = random.choice(actions)\n",
      "        print_action = 'Random Act (Zero):'\n",
      "    else:\n",
      "        print_action = 'Chosen Act:'\n",
      "    # print(\"\\nNEW MODEL - CHOOSE ACTION\\n\", model)\n",
      "    return n_action, model, print_action\n",
      "\n",
      "alfa = 1 # Learning Rate\n",
      "gamma = 0.9 # Temporal Discount Factor\n",
      "def learn(s_alg, model, state_t, state_t1, agent_t_pos, agent_t1_pos, reward, action_t, end_game, net_conf, exp_replay):\n",
      "    # print(\"\\nPREVIOUS MODEL - LEARN\\n\", model)\n",
      "    batch_loss = 0\n",
      "    if s_alg == \"QL\":\n",
      "        state_t[agent_t_pos[1]][agent_t_pos[0]] = 120\n",
      "        state_t1[agent_t1_pos[1]][agent_t1_pos[0]] = 120\n",
      "        s_t = str(state_t)\n",
      "        s_t1 = str(state_t1)\n",
      "        if s_t1 not in model.index:\n",
      "            indices = [np.array([s_t1, s_t1, s_t1, s_t1]), np.array(['up', 'down', 'right', 'left'])]\n",
      "            df_zero = pd.DataFrame(np.zeros([4, 1]), index=indices)\n",
      "            model = model.append(df_zero)\n",
      "        if s_t not in model.index:\n",
      "            indices = [np.array([s_t, s_t, s_t, s_t]), np.array(['up', 'down', 'right', 'left'])]\n",
      "            df_zero = pd.DataFrame(np.zeros([4, 1]), index=indices)\n",
      "            model = model.append(df_zero)\n",
      "        model = model.fillna(0)\n",
      "\n",
      "        if end_game == False:\n",
      "            max_value = max(model.loc[s_t1][0])  # max(df.loc[new_state][0])\n",
      "            Q_value = model.loc[s_t, action_t][0]\n",
      "            updated_model = Q_value + alfa * (reward + (gamma * (max_value)) - Q_value)\n",
      "        else:\n",
      "            updated_model = reward\n",
      "        model.loc[s_t, action_t] = updated_model\n",
      "\n",
      "    elif s_alg == \"DSRL\" or s_alg == \"DSRL_dist\" or s_alg == \"DSRL_dist_type\" or s_alg == \"DSRL_dist_type_near\" or s_alg == \"DSRL_dist_type_near_propNeg\" or s_alg == \"DSRL_object_near\" or s_alg == \"DSRL_object\":\n",
      "        max_value = 0\n",
      "\n",
      "        obj_list = create_obj_list(state_t)\n",
      "        rel_list = relation_obj_list(obj_list, agent_t_pos)\n",
      "        old_state = rel_list\n",
      "\n",
      "        obj_list = create_obj_list(state_t1)\n",
      "        rel_list = relation_obj_list(obj_list, agent_t1_pos)\n",
      "        new_state = rel_list\n",
      "\n",
      "        for i in range(len(old_state)):\n",
      "            # Check all items in old state\n",
      "            obj_prev = old_state[i]\n",
      "            tp_prev = str(obj_prev.tp)\n",
      "            s_prev = str(obj_prev.loc)\n",
      "            # Check all items in new state\n",
      "            obj_new = new_state[i]\n",
      "            tp_new = str(obj_new.tp)\n",
      "            s_new = str(obj_new.loc)\n",
      "\n",
      "            if tp_new not in model.columns: # If type is new, then add type\n",
      "                model[tp_new] = 0\n",
      "            if s_new not in model.index: # If state is new, then add state\n",
      "                m_index = pd.MultiIndex(levels=[[s_new], actions],\n",
      "                                        labels=[[0, 0, 0, 0], [0, 1, 2, 3]],\n",
      "                                        names=['state', 'actions'])\n",
      "                df_zero = pd.DataFrame(index=m_index)\n",
      "                model = model.append(df_zero)\n",
      "                model = model.fillna(0)\n",
      "\n",
      "            max_value = max(model[tp_new].loc[s_new])\n",
      "            if s_alg == \"DSRL\": # THEY STILL HAVE THE PROBLEM OF NOT PROPAGATING THE NEGATIVE SIGNAL\n",
      "                if end_game == False:\n",
      "                    Q_v = model[tp_prev].loc[s_prev, action_t]\n",
      "                    model[tp_prev].loc[s_prev, action_t] = Q_v + alfa * (reward + (gamma * max_value) - Q_v)\n",
      "                else:\n",
      "                    model[tp_prev].loc[s_prev, action_t] = reward\n",
      "\n",
      "            elif s_alg == \"DSRL_dist\": # THEY STILL HAVE THE PROBLEM OF NOT PROPAGATING THE NEGATIVE SIGNAL\n",
      "                if reward != 0:\n",
      "                    s_p_c = [int(s) for s in s_prev if s.isdigit()]\n",
      "                    if s_p_c[0] < 2 and s_p_c[1] < 2:\n",
      "                        # EDITIONG DELETE\n",
      "                        if end_game == False:\n",
      "                            Q_v = model[tp_prev].loc[s_prev, action_t]\n",
      "                            model[tp_prev].loc[s_prev, action_t] = Q_v + alfa * (reward + (gamma * max_value) - Q_v)\n",
      "                        else:\n",
      "                            model[tp_prev].loc[s_prev, action_t] = reward\n",
      "                else:\n",
      "                    if end_game == False:\n",
      "                        Q_v = model[tp_prev].loc[s_prev, action_t]\n",
      "                        model[tp_prev].loc[s_prev, action_t] = Q_v + alfa * (reward + (gamma * max_value) - Q_v)\n",
      "                    else:\n",
      "                        model[tp_prev].loc[s_prev, action_t] = reward\n",
      "\n",
      "            elif s_alg == \"DSRL_dist_type\" or s_alg == \"DSRL_dist_type_near\": # THEY STILL HAVE THE PROBLEM OF NOT PROPAGATING THE NEGATIVE SIGNAL\n",
      "                max_value_positive = max(model[tp_new].loc[s_new])\n",
      "                if reward != 0:\n",
      "                    s_p_c = [int(s) for s in s_prev if s.isdigit()]  # s_p_c = state_previous_absolute_distance\n",
      "                    if s_p_c[0] < 2 and s_p_c[1] < 2: # IF IT IS CLOSE BY, THEN UPDATE ONLY THE CLOSE ONE:\n",
      "                        if reward < 0 and tp_new == \"180\": # IF REWARD IS NEGATIVE and NEW OBJECT IS NEGATIVE UPDATE ONLY NEGATIVE TYPE:\n",
      "                            if end_game == False:\n",
      "                                Q_v = model[tp_prev].loc[s_prev, action_t]\n",
      "                                model[tp_prev].loc[s_prev, action_t] = Q_v + alfa * (reward + (gamma * max_value_positive) - Q_v)\n",
      "                            else:\n",
      "                                model[tp_prev].loc[s_prev, action_t] = reward\n",
      "                        elif reward > 0 and tp_new == \"60\":  # IF REWARD IS POSITIVE and NEW OBJECT IS POSITIVE UPDATE ONLY POSITIVE TYPE:\n",
      "                            if end_game == False:\n",
      "                                Q_v = model[tp_prev].loc[s_prev, action_t]\n",
      "                                model[tp_prev].loc[s_prev, action_t] = Q_v + alfa * (reward + (gamma * max_value_positive) - Q_v)\n",
      "                            else:\n",
      "                                model[tp_prev].loc[s_prev, action_t] = reward\n",
      "                # IF reward is zero\n",
      "                else:\n",
      "                    if end_game == False:\n",
      "                        Q_v = model[tp_prev].loc[s_prev, action_t]\n",
      "                        if tp_prev == \"180\": # IF THE PREVIOUS OBJECT WAS NEGATIVE\n",
      "                            model[tp_prev].loc[s_prev, action_t] = Q_v + alfa * (reward + (gamma * max_value_positive) - Q_v)\n",
      "                        elif tp_prev == \"60\": # IF THE PREVIOUS OBJECT WAS POSITIVE\n",
      "                            model[tp_prev].loc[s_prev, action_t] = Q_v + alfa * (reward + (gamma * max_value_positive) - Q_v)\n",
      "                    else:\n",
      "                        model[tp_prev].loc[s_prev, action_t] = reward\n",
      "\n",
      "            elif s_alg == \"DSRL_dist_type_near_propNeg\": # I try to solve this with max and min, but it did not work very well(THEY STILL HAVE THE PROBLEM OF NOT PROPAGATING THE NEGATIVE SIGNAL)\n",
      "                max_value_positive = max(model[tp_new].loc[s_new])\n",
      "                min_value_negative = min(model[tp_new].loc[s_new])\n",
      "                if reward != 0:\n",
      "                    s_p_c = [int(s) for s in s_prev if s.isdigit()]  # s_p_c = state_previous_absolute_distance\n",
      "                    if s_p_c[0] < 2 and s_p_c[1] < 2: # IF IT IS CLOSE BY, THEN UPDATE ONLY THE CLOSE ONE:\n",
      "                        if reward < 0 and tp_new == \"180\": # IF REWARD IS NEGATIVE and NEW OBJECT IS NEGATIVE UPDATE ONLY NEGATIVE TYPE:\n",
      "                            if end_game == False:\n",
      "                                Q_v = model[tp_prev].loc[s_prev, action_t]\n",
      "                                model[tp_prev].loc[s_prev, action_t] = Q_v + alfa * (reward + (gamma * min_value_negative) - Q_v)\n",
      "                            else:\n",
      "                                model[tp_prev].loc[s_prev, action_t] = reward\n",
      "                        elif reward > 0 and tp_new == \"60\":  # IF REWARD IS POSITIVE and NEW OBJECT IS POSITIVE UPDATE ONLY POSITIVE TYPE:\n",
      "                            if end_game == False:\n",
      "                                Q_v = model[tp_prev].loc[s_prev, action_t]\n",
      "                                model[tp_prev].loc[s_prev, action_t] = Q_v + alfa * (reward + (gamma * max_value_positive) - Q_v)\n",
      "                            else:\n",
      "                                model[tp_prev].loc[s_prev, action_t] = reward\n",
      "                # IF reward is zero\n",
      "                else:\n",
      "                    if end_game == False:\n",
      "                        Q_v = model[tp_prev].loc[s_prev, action_t]\n",
      "                        if tp_prev == \"180\": # IF THE PREVIOUS OBJECT WAS NEGATIVE\n",
      "                            model[tp_prev].loc[s_prev, action_t] = Q_v + alfa * (reward + (gamma * min_value_negative) - Q_v)\n",
      "                        elif tp_prev == \"60\": # IF THE PREVIOUS OBJECT WAS POSITIVE\n",
      "                            model[tp_prev].loc[s_prev, action_t] = Q_v + alfa * (reward + (gamma * max_value_positive) - Q_v)\n",
      "                    else:\n",
      "                        model[tp_prev].loc[s_prev, action_t] = reward\n",
      "\n",
      "            elif s_alg == \"DSRL_object_near\" or s_alg == \"DSRL_object\":\n",
      "                max_value_positive = max(model[tp_new].loc[s_new])\n",
      "\n",
      "                # Find the object that the agent interacted with:\n",
      "                # This means that the agents has to know that the object which interacted with\n",
      "                # After finding it, he has to assign the value to that object.\n",
      "                # This means that I have to find the type and the state of this object that has now x=zero y=zero\n",
      "\n",
      "                # print(\"obj_new.loc[0]\\n\", obj_new.loc[0])\n",
      "                # print(\"obj_new.loc[1]\\n\", obj_new.loc[1])\n",
      "                # print(\"action_t\\n\", action_t)\n",
      "                # print(\"s_prev\\n\", s_prev)\n",
      "\n",
      "                if obj_new.loc[0] == 0 and obj_new.loc[1] == 0:\n",
      "                    tp_to_update = tp_new\n",
      "                    # print(\"tp_new\\n\", tp_new)\n",
      "                    if action_t == \"up\":\n",
      "                        s_prev_to_update = str((0,1))\n",
      "                    elif action_t == \"down\":\n",
      "                        s_prev_to_update = str((0,-1))\n",
      "                    elif action_t == \"right\":\n",
      "                        s_prev_to_update = str((-1,0))\n",
      "                    elif action_t == \"left\":\n",
      "                        s_prev_to_update = str((1,0))\n",
      "                    # print(\"s_prev_to_update\\n\", s_prev_to_update)\n",
      "                    if end_game == False:\n",
      "                        Q_v = model[tp_to_update].loc[s_prev_to_update, action_t]\n",
      "                        model[tp_to_update].loc[s_prev_to_update, action_t] = Q_v + alfa * (reward + (gamma * max_value_positive) - Q_v)\n",
      "                    else:\n",
      "                        model[tp_to_update].loc[s_prev_to_update, action_t] = reward\n",
      "\n",
      "                if reward == 0:\n",
      "                    if end_game == False:\n",
      "                        Q_v = model[tp_prev].loc[s_prev, action_t]\n",
      "                        model[tp_prev].loc[s_prev, action_t] = Q_v + alfa * (reward + (gamma * max_value_positive) - Q_v)\n",
      "                    else:\n",
      "                        model[tp_prev].loc[s_prev, action_t] = reward\n",
      "\n",
      "    elif s_alg == \"DQN\":\n",
      "        state_t[agent_t_pos[1]][agent_t_pos[0]] = 120\n",
      "        state_t1[agent_t1_pos[1]][agent_t1_pos[0]] = 120\n",
      "        state_t = state_t.reshape((1, -1))\n",
      "        state_t1 = state_t1.reshape((1, -1))\n",
      "        action_t = actions_dict[action_t]\n",
      "        exp_replay.remember([state_t, action_t, reward, state_t1], end_game) # [old_state, old_action, reward, new_state]\n",
      "        inputs, targets = exp_replay.get_batch(model, batch_size=net_conf[\"Batch_size\"])\n",
      "        batch_loss = model.train_on_batch(inputs, targets)\n",
      "\n",
      "    # print(\"\\nNEW MODEL - LEARN\\n\", model)\n",
      "    return model, batch_loss, exp_replay\n",
      "\n",
      "''' PROGRAM START '''\n",
      "__location__ = os.path.realpath(os.path.join(os.getcwd(), os.path.dirname(__file__)))\n",
      "def run(s_env, s_alg, s_learn, s_load, s_print, s_auto, s_episode, s_cond_to_end, s_server, s_net_comb_param, s_load_path, s_prob, s_sample, s_save):\n",
      "    net_conf = {\"N_actions\": n_actions,\n",
      "                \"Max_memory\": max_memory_list[s_net_comb_param],\n",
      "                \"Hidden_size\": hidden_size_list[s_net_comb_param],\n",
      "                \"Batch_size\": batch_size_list[s_net_comb_param],\n",
      "                \"Optimizer\": optimizer_list[0]}\n",
      "    exp_replay = ExperienceReplay(max_memory=net_conf[\"Max_memory\"])\n",
      "    begin = time.time()\n",
      "    begin_time = time.strftime('%X %x')\n",
      "    print(\"\\n\\n --- BEGINING --- s_sample: %s \\n begin_time: %s \\n\" % (s_sample, begin_time))\n",
      "\n",
      "    df_score = pd.DataFrame()\n",
      "    df_percent_list = pd.DataFrame()\n",
      "    df_loss_list = pd.DataFrame()\n",
      "    df_time_sample = pd.DataFrame()\n",
      "    avg_last_score_list = []\n",
      "\n",
      "    if s_server == False: screen = pygame.display.set_mode((400 + 37 * 5, 330 + 37 * 5))\n",
      "\n",
      "    score_list_best = [0]\n",
      "    for sample in list(range(1, s_sample+1)):\n",
      "        experiment_configurations = (sample, s_env, s_alg, s_episode, s_learn, s_load, s_print, s_auto, s_cond_to_end, s_server, s_net_comb_param, s_prob)\n",
      "        print(\"\\n - START - \"\n",
      "              \"\\n sample: %s\"\n",
      "              \"\\n s_env: %s\"\n",
      "              \"\\n s_alg: %s\"\n",
      "              \"\\n s_episode: %s\"\n",
      "              \"\\n s_learn: %s\"\n",
      "              \"\\n s_load: %s\"\n",
      "              \"\\n s_print: %s\"\n",
      "              \"\\n s_auto: %s\"\n",
      "              \"\\n s_cond_to_end: %s\"\n",
      "              \"\\n s_server: %s\"\n",
      "              \"\\n s_net_comb_param: %s\"\n",
      "              \"\\n s_prob: %s\" % experiment_configurations)\n",
      "\n",
      "        start = time.time()\n",
      "        start_time = time.strftime('%X %x')\n",
      "        print(\"\\nStart time: \", start_time)\n",
      "        negativo_list, positivo_list, agent, wall_list, h_max, v_max = environment_conf(s_env)\n",
      "\n",
      "        env_dim = [h_max, v_max]\n",
      "        if s_load == True:\n",
      "            try:\n",
      "                model, op_conf = load_model(s_alg, __location__ + s_load_path)\n",
      "            except:\n",
      "                print(\"DID NOT FIND THE FILE\")\n",
      "        else:\n",
      "            model, op_conf = create_model(s_alg, env_dim, net_conf)\n",
      "\n",
      "        # region INITIALIZE VARIABLES 1\n",
      "        percent_list = []\n",
      "        score = 0\n",
      "        score_list = []\n",
      "        episodes = 0\n",
      "        episodes_list = []\n",
      "        steps = 0\n",
      "        steps_list = []\n",
      "        batch_loss = 0\n",
      "        loss_list = []\n",
      "        # endregion\n",
      "\n",
      "        while (episodes < s_episode):  # max_episodes\n",
      "            negativo_list, positivo_list, agent, wall_list, h_max, v_max = environment_conf(s_env)\n",
      "            # region INITIALIZE VARIABLES 2\n",
      "            episodes += 1\n",
      "            episodes_list.append(episodes)\n",
      "            max_steps = 10\n",
      "            steps_list.append(steps)\n",
      "            steps = 0\n",
      "            act_list = []\n",
      "            last_move = False\n",
      "            action_chosen = \"\"\n",
      "            encountered = 0\n",
      "            pos_collected = 0\n",
      "            prob = s_prob\n",
      "            # endregion\n",
      "\n",
      "            if s_server == False:\n",
      "                # region DRAW SCREEN\n",
      "                screen.fill(white)\n",
      "                show_Alg(s_alg, screen)\n",
      "                show_Samples(sample, screen)\n",
      "                show_Level(episodes, screen)\n",
      "                show_Score(score, screen)\n",
      "                show_Steps(steps, screen)\n",
      "                show_Percent(percent_list[-10:], screen)\n",
      "                show_Steps_list(steps_list[-30:], screen)\n",
      "                show_Act_List(act_list[-20:], screen)\n",
      "                show_Action(action_chosen, screen)\n",
      "                show_Env(s_env, screen)\n",
      "                draw_objects(agent, positivo_list, negativo_list, wall_list, screen)\n",
      "                pygame.display.flip()\n",
      "                # endregion\n",
      "\n",
      "            while (True):  # max_steps or condition to finish\n",
      "                sleep(speed)\n",
      "                ''' EVENT HANDLE '''\n",
      "                key_pressed = False\n",
      "                set_action = False\n",
      "                while (s_server == False):\n",
      "                    for event in pygame.event.get():\n",
      "                        # QUIT GAME\n",
      "                        if event.type == pygame.QUIT:\n",
      "                            pygame.quit()\n",
      "                            sys.exit()\n",
      "                        # ADD OR DELETE WALL\n",
      "                        if event.type == pygame.MOUSEBUTTONDOWN:\n",
      "                            pass\n",
      "                            # if (pygame.mouse.get_pressed() == (1, 0, 0)):  # LEFT BUTTON (add wall)\n",
      "                            #     pos = pygame.mouse.get_pos()\n",
      "                            #     x = (pos[0] - x_g) / (m + w)\n",
      "                            #     y = (pos[1] - y_g) / (m + h)\n",
      "                            #     x = math.trunc(x)\n",
      "                            #     y = math.trunc(y)\n",
      "                            #     w_has = False\n",
      "                            #     for item in wall_list:\n",
      "                            #         if math.trunc((item[0] - x_g) / (m + w)) == x and math.trunc(\n",
      "                            #                         (item[1] - y_g) / (m + h)) == y:\n",
      "                            #             w_has = True\n",
      "                            #     if w_has == False:\n",
      "                            #         wall = Class.Wall('wall', x, y)\n",
      "                            #         print('wall ', wall, 'added')\n",
      "                            #         wall_list.append(wall)\n",
      "\n",
      "                            # if (pygame.mouse.get_pressed() == (0, 0, 1)):  # RIGHTBUTTON (delete wall)\n",
      "                            #     pos = pygame.mouse.get_pos()\n",
      "                            #     x = (pos[0] - x_g) / (m + w)\n",
      "                            #     y = (pos[1] - y_g) / (m + h)\n",
      "                            #     x = math.trunc(x)\n",
      "                            #     y = math.trunc(y)\n",
      "                            #     wall = Class.Wall('wall', x, y)\n",
      "                            #     for i in wall_list:\n",
      "                            #         if i == wall:\n",
      "                            #             wall_list.remove(wall)\n",
      "                            #             print('wall ', wall, 'removed')\n",
      "\n",
      "                            # EVENT - ANY PRESSED KEY\n",
      "                        # PRESS A KEY\n",
      "                        if event.type == pygame.KEYDOWN:\n",
      "                            # SAVE AND QUIT - KEY P\n",
      "                            if event.key == pygame.K_p:\n",
      "                                pygame.quit()\n",
      "                                sys.exit()\n",
      "                            # PLOT AGENT`S PERFORMENCE - KEY G\n",
      "                            if event.key == pygame.K_g:\n",
      "                                plt.plot(score_list)\n",
      "                                plt.ylabel('Score')\n",
      "                                plt.xlabel('Total Steps')\n",
      "                                plt.title('Performance of the Agent')\n",
      "                                plt.show()\n",
      "\n",
      "                                plt.plot(percent_list)\n",
      "                                plt.ylabel('Percentage of objects +')\n",
      "                                plt.xlabel('Total Steps')\n",
      "                                plt.title('Episode over 100 times step each')\n",
      "                                plt.show()\n",
      "                                if s_alg == \"DQN\":\n",
      "                                    plt.plot(loss_list)\n",
      "                                    plt.ylabel('loss')\n",
      "                                    plt.xlabel('Total Steps')\n",
      "                                    plt.title('batch_loss')\n",
      "                                    plt.show()\n",
      "                            # MOVE - SPACE BAR\n",
      "                            if event.key == pygame.K_SPACE:\n",
      "                                key_pressed = True\n",
      "                                break\n",
      "                            # MOVE - ARROW KEYS\n",
      "                            if event.key in p_keys:\n",
      "                                key_pressed = True\n",
      "                                set_action = True\n",
      "                                if event.key == pygame.K_w:  # North # add_act('')    \n",
      "                                    key_action = \"up\"\n",
      "                                if event.key == pygame.K_s:  # South # add_act('')      \n",
      "                                    key_action = \"down\"\n",
      "                                if event.key == pygame.K_d:  # West # add_act('')\n",
      "                                    key_action = \"right\"\n",
      "                                if event.key == pygame.K_a:  # East # add_act('')\n",
      "                                    key_action = \"left\"\n",
      "                                break\n",
      "                    # Run game if key is preseed or automatic is selected\n",
      "                    if key_pressed or s_auto:\n",
      "                        break\n",
      "                # BREAK IF IT WAS THE LAST MOVE\n",
      "                if last_move == True:\n",
      "                    break\n",
      "                # RUN_GAME\n",
      "                steps += 1\n",
      "                ''' OLD STATE - S 1 - 1'''\n",
      "                state_t = update_state(h_max, v_max, agent, positivo_list, negativo_list, wall_list)\n",
      "                agent_t = agent.pos\n",
      "                ''' CHOOSE ACTION - AGENT ACT - 2'''\n",
      "                action_chosen, model, print_action = choose_action(s_alg, state_t, agent_t, model, prob)\n",
      "\n",
      "                if set_action: action_chosen = key_action\n",
      "\n",
      "                ''' CHANGE THE WORLD - UP_ENV - 3'''\n",
      "                agent.try_move(action_chosen, wall_list)\n",
      "                act_list.append(action_chosen)\n",
      "                if s_print: print(print_action, action_chosen)\n",
      "\n",
      "                ''' NEW STATE - S2 - 4'''\n",
      "                state_t1 = update_state(h_max, v_max, agent, positivo_list, negativo_list, wall_list)\n",
      "                agent_t1 = agent.pos\n",
      "                if s_print:\n",
      "                    print('\\n>>>>   Level: ' + str(episodes) + ' |  Step: ' + str(\n",
      "                        steps) + ' |  New_agent_pos: ' + str(agent.pos) + '  <<<<')\n",
      "\n",
      "                ''' GET REWARD - 5 '''\n",
      "                # region GET REWARD AND DELETE COLLECTED OBJECT\n",
      "                prev_score = score\n",
      "                score += step_reward\n",
      "\n",
      "                for positivo in positivo_list:\n",
      "                    if agent.pos == positivo.pos:\n",
      "                        encountered += 1\n",
      "                        pos_collected += 1\n",
      "                        score += positive_reward\n",
      "                        positivo = Class.Positivo('positivo', agent.pos[0], agent.pos[1])\n",
      "                        positivo_list.remove(positivo)\n",
      "                        if s_print == True and s_server == False:\n",
      "                            print('                                 Hit the Positivo')\n",
      "                for negativo in negativo_list:\n",
      "                    if agent.pos == negativo.pos:\n",
      "                        encountered += 1\n",
      "                        score -= negative_reward\n",
      "                        negativo = Class.Negativo('negativo', agent.pos[0], agent.pos[1])\n",
      "                        negativo_list.remove(negativo)\n",
      "                        if s_print == True and s_server == False:\n",
      "                            print('                                 Hit the Negativo')\n",
      "\n",
      "                new_score = score\n",
      "                score_list.append(score)\n",
      "                reward = new_score - prev_score\n",
      "                # endregion\n",
      "\n",
      "                ''' LEARN - 6 '''\n",
      "                # CONDITION TO FINISH THE Episode\n",
      "                if s_cond_to_end == 'max_steps':\n",
      "                    if steps == max_steps:\n",
      "                        last_move = True\n",
      "                elif s_cond_to_end == 'coll_all' or steps > max_steps:\n",
      "                    if len(positivo_list) == 0 and len(negativo_list) == 0 or steps > max_steps:\n",
      "                        last_move = True\n",
      "                elif s_cond_to_end == 'only_positive' or steps > max_steps:\n",
      "                    if len(positivo_list) == 0 or steps > max_steps:\n",
      "                        last_move = True\n",
      "                elif s_cond_to_end == 'only_negative' or steps > max_steps:\n",
      "                    if len(negativo_list) == 0 or steps > max_steps:\n",
      "                        last_move = True\n",
      "\n",
      "                # LEARN\n",
      "                if s_learn == True:\n",
      "                    action_t = action_chosen\n",
      "                    if last_move == False:\n",
      "                        ''' LEARN '''\n",
      "                        model, batch_loss, exp_replay = learn(s_alg, model, state_t, state_t1, agent_t, agent_t1, reward, action_t, False, net_conf, exp_replay)\n",
      "                    else:\n",
      "                        ''' LEARN FINAL '''\n",
      "                        model, batch_loss, exp_replay = learn(s_alg, model, state_t, state_t1, agent_t, agent_t1, reward, action_t, True, net_conf, exp_replay)\n",
      "\n",
      "                if s_server == False:\n",
      "                    # region DRAW SCREEN\n",
      "                    screen.fill(white)\n",
      "                    show_Alg(s_alg, screen)\n",
      "                    show_Samples(sample, screen)\n",
      "                    show_Level(episodes, screen)\n",
      "                    show_Score(score, screen)\n",
      "                    show_Steps(steps, screen)\n",
      "                    show_Percent(percent_list[-10:], screen)\n",
      "                    show_Steps_list(steps_list[-30:], screen)\n",
      "                    show_Act_List(act_list[-20:], screen)\n",
      "                    show_Action(action_chosen, screen)\n",
      "                    show_Env(s_env, screen)\n",
      "\n",
      "                    draw_objects(agent, positivo_list, negativo_list, wall_list, screen)\n",
      "                    pygame.display.flip()\n",
      "                    # endregion\n",
      "\n",
      "            try:\n",
      "                percent = pos_collected / encountered\n",
      "            except ZeroDivisionError:\n",
      "                percent = 0\n",
      "            percent_list.append(percent)\n",
      "            loss_list.append(batch_loss)\n",
      "            print(\"Episode: \", episodes)\n",
      "\n",
      "        # region TIME 1\n",
      "        print(\"Start time: \", start_time)\n",
      "        end = time.time()\n",
      "        end_time = time.strftime('%X %x')\n",
      "        print(\"End time: \", end_time)\n",
      "        time_elapsed = end - start\n",
      "        print(\"Time elapsed: \", time_elapsed)\n",
      "        # endregion\n",
      "\n",
      "        '''GET THE BEST MODEL'''\n",
      "        if max(score_list) > max(score_list_best):\n",
      "            best_model = model\n",
      "            score_list_best = score_list\n",
      "\n",
      "        # region MAKE LIST OF THE RESULTS\n",
      "        avg_last_score_list.append(score_list[-1])\n",
      "\n",
      "        score_list_df = pd.DataFrame({'Score': score_list})\n",
      "        percent_list_df = pd.DataFrame({'Percent': percent_list})\n",
      "        loss_list_df = pd.DataFrame({'Batch_loss': loss_list})\n",
      "        time_sample_df = pd.DataFrame({'Time': [time_elapsed]})\n",
      "\n",
      "        df_score = pd.concat([df_score, score_list_df], ignore_index=True, axis=1)\n",
      "        df_percent_list = pd.concat([df_percent_list, percent_list_df], ignore_index=True, axis=1)\n",
      "        df_loss_list = pd.concat([df_loss_list, loss_list_df], ignore_index=True, axis=1)\n",
      "        df_time_sample = pd.concat([df_time_sample, time_sample_df], ignore_index=True, axis=1)\n",
      "        # endregion\n",
      "\n",
      "    if s_save == True:\n",
      "        # region PATH TO SAVE\n",
      "        save_path_core = __location__ + \"/Results/\"\n",
      "        if s_learn == True: save_path = save_path_core + \"Train/Env_\" + str(s_env) + \"/Train_Env_\" + str(s_env) + \"_\" + s_alg\n",
      "        else: save_path = save_path_core + \"Test/Env_\" + str(s_env) + \"/Test_Env_\" + str(s_env) + \"_\" + s_alg\n",
      "        if s_alg == \"DQN\": save_path += \"_\" + str(s_net_comb_param)\n",
      "\n",
      "        # convert begin_time to string and format it\n",
      "        time_path = begin_time.replace(\" \", \"   \")\n",
      "        time_path = time_path.replace(\":\", \" \")\n",
      "        time_path = time_path.replace(\"/\", \"-\")\n",
      "        # append to the save path\n",
      "        save_path = save_path + \"   \" + time_path\n",
      "\n",
      "        if s_load == True:\n",
      "            load_path = \" loaded_with \" + s_load_path.replace(\"/\", \"_\")\n",
      "            save_path = save_path + load_path\n",
      "\n",
      "        # If it doesnt find the path, then create a new path\n",
      "        if not os.path.exists(os.path.dirname(save_path)):\n",
      "            try:\n",
      "                os.makedirs(os.path.dirname(save_path))\n",
      "            except OSError as exc:  # Guard against race condition\n",
      "                print(\"ERROR when saving the File\")\n",
      "        # endregion\n",
      "        print(\"save_path: \", save_path)\n",
      "\n",
      "        # region SAVE ALL\n",
      "        # IF IT IS NOT DQN NULL NET CONF. VALUES\n",
      "        if s_alg != \"DQN\":\n",
      "            op_conf = [0, 0, 0, 0, 0, 0]\n",
      "            net_conf = {\"N_actions\":0, \"Max_memory\":0, \"Hidden_size\":0, \"Batch_size\":0, \"Optimizer\":\"none\"}\n",
      "\n",
      "        avg_last_score = np.average(avg_last_score_list)\n",
      "        config_list = pd.concat([pd.Series({'Run_Conf': \"A\"}),\n",
      "                                 pd.Series({'Env_conf': s_env}),\n",
      "                                 pd.Series({'Algort': s_alg}),\n",
      "                                 pd.Series({'Learn': s_learn}),\n",
      "                                 pd.Series({'Load': s_load}),\n",
      "                                 pd.Series({'Samples': s_sample}),\n",
      "                                 pd.Series({'Episode': s_episode}),\n",
      "                                 pd.Series({'Max_steps': max_steps}),\n",
      "                                 pd.Series({'s_cond_to_end': s_cond_to_end}),\n",
      "                                 pd.Series({'Auto': s_auto}),\n",
      "                                 pd.Series({'Server': s_server}),\n",
      "                                 pd.Series({'Print': s_print}),\n",
      "                                 pd.Series({'MODEL CONF': \"\"}),\n",
      "                                 pd.Series({'alfa': alfa}),\n",
      "                                 pd.Series({'gamma': gamma}),\n",
      "                                 pd.Series({'Prob': Prob}),\n",
      "                                 pd.Series({'N_actions': net_conf[\"N_actions\"]}),\n",
      "                                 pd.Series({'Max_memory': net_conf[\"Max_memory\"]}),\n",
      "                                 pd.Series({'Hidden_size': net_conf[\"Hidden_size\"]}),\n",
      "                                 pd.Series({'Batch_size': net_conf[\"Batch_size\"]}),\n",
      "                                 pd.Series({'Optimizer': net_conf[\"Optimizer\"]}),\n",
      "                                 pd.Series({'lr': op_conf[0]}),\n",
      "                                 pd.Series({'beta_1': op_conf[1]}),\n",
      "                                 pd.Series({'beta_2': op_conf[2]}),\n",
      "                                 pd.Series({'epsilon': op_conf[3]}),\n",
      "                                 pd.Series({'decay': op_conf[4]}),\n",
      "                                 pd.Series({'rho': op_conf[5]}),\n",
      "                                 pd.Series({'': \"\"}),\n",
      "                                 pd.Series({'AVG SCORE': avg_last_score})])\n",
      "        config_list = config_list.to_frame()\n",
      "\n",
      "        if s_print: print(\"\\nconfig_list:\\n\", config_list)\n",
      "\n",
      "        # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
      "        writer = pd.ExcelWriter(save_path + \".xlsx\", engine='xlsxwriter')\n",
      "\n",
      "        # SAVING CONFIG:\n",
      "        config_list.to_excel(writer, sheet_name='Run_Conf', header=False)\n",
      "        worksheet = writer.sheets['Run_Conf']\n",
      "        worksheet.set_column('A:B', 15)\n",
      "        # SAVING SCORE:\n",
      "        df_score_mean = df_score.mean(axis=1)\n",
      "        df_score.insert(0, \"Avg \" + str(s_sample), df_score_mean)\n",
      "        df_score.to_excel(writer, sheet_name='Score')\n",
      "        worksheet = writer.sheets['Score']\n",
      "        worksheet.write(0, 0, \"Score\")\n",
      "        # SAVING PERCENT:\n",
      "        df_percent_list_mean = df_percent_list.mean(axis=1)\n",
      "        df_percent_list.insert(0, \"Avg \" + str(s_sample), df_percent_list_mean)\n",
      "        df_percent_list.to_excel(writer, sheet_name='Percent')\n",
      "        worksheet = writer.sheets['Percent']\n",
      "        worksheet.write(0, 0, \"Percent\")\n",
      "        # SAVING LOSS:\n",
      "        df_loss_list.to_excel(writer, sheet_name='Loss')\n",
      "        worksheet = writer.sheets['Loss']\n",
      "        worksheet.write(0, 0, \"Loss\")\n",
      "        # SAVING TIME:\n",
      "        df_time_sample.to_excel(writer, sheet_name='Time')\n",
      "        worksheet = writer.sheets['Time']\n",
      "        worksheet.write(0, 0, \"Time\")\n",
      "        # region CELL SIZE\n",
      "\n",
      "        # worksheet = writer.sheets['Score']\n",
      "        # worksheet.set_column('A:B', 15)\n",
      "        # worksheet = writer.sheets['Time']\n",
      "        # worksheet.set_column('A:B', 15)\n",
      "        # endregion\n",
      "\n",
      "        # SAVING BEST MODEL (out of # Samples):\n",
      "        if s_alg == \"DSRL\" or s_alg == \"QL\" or s_alg == \"DSRL_dist\" or s_alg == \"DSRL_dist_type\" or s_alg == \"DSRL_dist_type_near\" or s_alg == \"DSRL_dist_type_near_propNeg\" or s_alg == \"DSRL_object_near\" or s_alg == \"DSRL_object\":\n",
      "            # SAVING MODEL CONFIGURATIONS:\n",
      "            best_model.to_excel(writer, sheet_name='model')\n",
      "            # CONDITIONAL COLOR\n",
      "            worksheet = writer.sheets['model']\n",
      "            for x in range(2, 700, 4):\n",
      "                cell = \"C\" + str(x) + \":D\" + str(x + 3)\n",
      "                worksheet.conditional_format(cell, {'type': '3_color_scale'})\n",
      "            # CELL SIZE\n",
      "            worksheet = writer.sheets['model']\n",
      "            worksheet.set_column('A:A', 50)\n",
      "\n",
      "            # region ADD PLOTS\n",
      "        # worksheet = writer.sheets['results']\n",
      "        # workbook = writer.book\n",
      "        # chart = workbook.add_chart({'type': 'line'})\n",
      "        # chart2 = workbook.add_chart({'type': 'line'})\n",
      "        # chart.add_series({'values': '=results!$B$2:$B$100'})\n",
      "        # chart2.add_series({'values': '=results!$C$2:$C$10'})\n",
      "        # worksheet.insert_chart('F3', chart)\n",
      "        # worksheet.insert_chart('N3', chart2)\n",
      "\n",
      "        # SAVE DQN MODEL\n",
      "        if s_learn == True and s_alg == \"DQN\":\n",
      "            save_model(best_model, save_path)\n",
      "\n",
      "        writer.save()\n",
      "        # endregion\n",
      "\n",
      "    print(\"\\n - END - \"\n",
      "          \"\\n sample: %s\"\n",
      "          \"\\n s_env: %s\"\n",
      "          \"\\n s_alg: %s\"\n",
      "          \"\\n s_episode: %s\"\n",
      "          \"\\n s_learn: %s\"\n",
      "          \"\\n s_load: %s\"\n",
      "          \"\\n s_print: %s\"\n",
      "          \"\\n s_auto: %s\"\n",
      "          \"\\n s_cond_to_end: %s\"\n",
      "          \"\\n s_server: %s\"\n",
      "          \"\\n s_net_comb_param: %s\"\n",
      "          \"\\n s_prob: %s\" % experiment_configurations)\n",
      "\n",
      "    # region TIME 2\n",
      "    print(\"\\n\\nBegin time: \", begin_time)\n",
      "    finish = time.time()\n",
      "    finish_time = time.strftime('%X %x')\n",
      "    print(\"Final time: \", finish_time)\n",
      "    total_time = finish - begin\n",
      "    print(\"Total time: \", total_time)\n",
      "    # endregion\n",
      "\n",
      "    return\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------- #\n",
      "''' SELECT PARAMETERS TO RUN THE SOFTWARE '''\n",
      "Env = 11\n",
      "Alg_list = [\"QL\",\n",
      "            \"DSRL\",\n",
      "            \"DSRL_object_near\",\n",
      "            \"DQN\",\n",
      "            \"DSRL_dist\",\n",
      "            \"DSRL_dist_type\",\n",
      "            \"DSRL_dist_type_near\",\n",
      "            \"DSRL_dist_type_near_propNeg\",\n",
      "            \"DSRL_object\"]\n",
      "Alg = Alg_list[8] # Select the algorithm to be used\n",
      "Learn = True # To update its knowledge\n",
      "Load = False # To load a learned model\n",
      "Load_path = \"/Results/Train/Env_1/Train_Env_1_DQN_4   00 33 03   01-05-18\"\n",
      "\n",
      "Samples = 2 # Usually 10 samples\n",
      "Print = False # Print some info in the terminal\n",
      "Auto = True # Agent moves Automatic or if False it moves by pressing the Spacebar key\n",
      "Server = False # If running in the server since\n",
      "Prob = 0 # Probability to make a random move (exploration rate)\n",
      "Cond_to_end = \"only_positive\" # Choose from below (there are 4)\n",
      "Save = False # Save the model\n",
      "speed = 0 # seconds per frame\n",
      "\n",
      "# Cond_to_end = \"max_steps\"\n",
      "# Cond_to_end = \"coll_all\"\n",
      "# Cond_to_end = \"only_negative\"\n",
      "Episodes = 1000 # Usually 1000 or 100\n",
      "\n",
      "# region DQN Model Configurations:\n",
      "# max_memory_list =  [5, 5,  5,   30,  30, 30,  100, 100, 100]\n",
      "# hidden_size_list = [5, 30, 270, 5,   30, 270, 5,   30,  270]\n",
      "# batch_size_list =  [1, 1,  1,   10,  10, 10,  32,  32,  32]\n",
      "max_memory_list =  [100,    100,    100,    300, 300,   300,    900, 900, 900]\n",
      "hidden_size_list = [5,      10,     15,     5,   10,    15,     5,   10,  15]\n",
      "batch_size_list =  [32,     32,     32,     32,  32,    32,     32,  32,  32]\n",
      "optimizer_list = [\"adam\", \"rms_opt\"]\n",
      "n_actions = 4  # [move_up, move_down, move_left, move_right]\n",
      "# endregion\n",
      "Net_comb_param = 4\n",
      "\n",
      "\n",
      "# ------------------------------------------------------------------------------------------- #\n",
      "run(Env, Alg, Learn, Load, Print, Auto, Episodes, Cond_to_end, Server, Net_comb_param, Load_path, Prob, Samples, Save)\n",
      "# ------------------------------------------------------------------------------------------- #\n",
      "\n",
      "'''                 REPEAT DQN Net_Comb_Param                  '''\n",
      "# for i in range(9):\n",
      "#     Net_comb_param = i\n",
      "#     run(Env, Alg, Learn, Load, Print, Auto, Episodes, Cond_to_end, Server, Net_comb_param, Load_path, Prob, Samples, Save)\n",
      "\n",
      "\n",
      "'''                 REPEAT Alg for a list of Env                  '''\n",
      "# env_list = [2,3]\n",
      "# for Env in env_list:\n",
      "#     run(Env, Alg, Learn, Load, Print, Auto, Episodes, Cond_to_end, Server, Net_comb_param, Load_path, Prob, Samples, Save)\n",
      "\n",
      "\n",
      "'''                 Alg_list for Env_list                  '''\n",
      "# env_list = [2,3]\n",
      "# alg_list = [\"QL\", \"DSRL\", \"DSRL_object_near\", \"DQN\"]\n",
      "# for Env in env_list:\n",
      "#     for Alg in alg_list:\n",
      "#         run(Env, Alg, Learn, Load, Print, Auto, Episodes, Cond_to_end, Server, Net_comb_param, Load_path, Prob, Samples, Save)\n",
      "\n",
      "\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\AimoreRRD_Reinforcement-Learning-Research\\NEW_GAME.py\n",
      "[]\n",
      "********************pycgContent*************************\n",
      "[[('Class Grid draw_grid', 'pygame draw rect'), ('Class Wall __init__', 'pygame image load'), ('Class Agent __init__', 'pygame image load'), ('Class Start __init__', 'pygame image load'), ('Class Negativo __init__', 'pygame image load'), ('Class Positivo __init__', 'pygame image load')], [('Compile_Excel_Files', 'os path realpath'), ('Compile_Excel_Files', 'glob glob'), ('Compile_Excel_Files', 'os path dirname'), ('Compile_Excel_Files', 'pandas DataFrame'), ('Compile_Excel_Files', 'pandas ExcelFile'), ('Compile_Excel_Files', 'pandas concat'), ('Compile_Excel_Files', 'pandas ExcelWriter'), ('Compile_Excel_Files', 'os path join'), ('Compile_Excel_Files', 'pandas read_excel'), ('Compile_Excel_Files', 'os getcwd')], [('Plot', 'glob glob'), ('Plot', 'matplotlib pyplot ylabel'), ('Plot', 'matplotlib pyplot tight_layout'), ('Plot', 'matplotlib pyplot tick_params'), ('Plot', 'matplotlib pyplot yticks'), ('Plot', 'matplotlib pyplot gca'), ('Plot', 'matplotlib pyplot savefig'), ('Plot', 'pandas read_excel'), ('Plot', 'matplotlib pyplot ylim'), ('Plot', 'matplotlib patches Patch'), ('Plot', 'matplotlib pyplot legend'), ('Plot', 'matplotlib pyplot interactive'), ('Plot', 'matplotlib pyplot xlabel'), ('Plot', 'matplotlib pyplot show'), ('Plot', 'numpy arange')], [('Script_Compiler', 'os path realpath'), ('Script_Compiler', 'pandas read_excel'), ('Script_Compiler', 'os path dirname'), ('Script_Compiler', 'os getcwd'), ('Script_Compiler', 'pandas ExcelWriter'), ('Script_Compiler', 'os path join')]]\n",
      "********************doctrings*************************\n",
      "['', '', '', '']\n",
      "embed index dataset: 4\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\seolhokim_BipedalWalker-BranchingDQN\\\\network.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\seolhokim_BipedalWalker-BranchingDQN\\\\agent.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\seolhokim_BipedalWalker-BranchingDQN\\\\main.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\seolhokim_BipedalWalker-BranchingDQN\\\\utils.py']\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class QNetwork(nn.Module):\n",
      "    def __init__(self,state_space : int, action_num : int,action_scale : int):\n",
      "        super(QNetwork,self).__init__()\n",
      "        self.linear_1 = nn.Linear(state_space,state_space*20)\n",
      "        self.linear_2 = nn.Linear(state_space*20,state_space*10)\n",
      "        \n",
      "        self.actions = [nn.Sequential(nn.Linear(state_space*10,state_space*5),\n",
      "              nn.ReLU(),\n",
      "              nn.Linear(state_space*5,action_scale)\n",
      "              ) for _ in range(action_num)]\n",
      "\n",
      "        self.actions = nn.ModuleList(self.actions)\n",
      "\n",
      "        self.value = nn.Sequential(nn.Linear(state_space*10,state_space*5),\n",
      "              nn.ReLU(),\n",
      "              nn.Linear(state_space*5,1)\n",
      "              )\n",
      "        \n",
      "    def forward(self,x):\n",
      "        x = F.relu(self.linear_1(x))\n",
      "        encoded = F.relu(self.linear_2(x))\n",
      "        actions = [x(encoded) for x in self.actions]\n",
      "        value = self.value(encoded)\n",
      "        for i in range(len(actions)):\n",
      "            actions[i] = actions[i] - actions[i].max(-1)[0].reshape(-1,1)\n",
      "            actions[i] += value\n",
      "        return actions\n",
      "Output: {'network': [], 'network.QNetwork.__init__': ['torch.nn.ReLU', '<builtin>.range', 'torch.nn.Linear', '<builtin>.super', 'torch.nn.Sequential', 'torch.nn.ModuleList'], '<builtin>.super': [], 'torch.nn.Linear': [], 'torch.nn.ReLU': [], 'torch.nn.Sequential': [], '<builtin>.range': [], 'torch.nn.ModuleList': [], 'network.QNetwork.forward': ['<builtin>.range', 'torch.nn.functional.relu', '<builtin>.len'], 'torch.nn.functional.relu': [], '<builtin>.len': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\seolhokim_BipedalWalker-BranchingDQN\\network.py\n",
      "[('network QNetwork __init__', 'torch nn ReLU'), ('network QNetwork __init__', 'torch nn Linear'), ('network QNetwork __init__', 'torch nn Sequential'), ('network QNetwork __init__', 'torch nn ModuleList'), ('network QNetwork forward', 'torch nn functional relu')]\n",
      "0\n",
      "found files: []\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "import torch.optim as optim\n",
      "\n",
      "from network import QNetwork\n",
      "\n",
      "class BQN(nn.Module):\n",
      "    def __init__(self,state_space : int, action_num : int,action_scale : int, learning_rate, device : str):\n",
      "        super(BQN,self).__init__()\n",
      "\n",
      "        self.q = QNetwork(state_space, action_num,action_scale).to(device)\n",
      "        self.target_q = QNetwork(state_space, action_num,action_scale).to(device)\n",
      "        self.target_q.load_state_dict(self.q.state_dict())\n",
      "\n",
      "        self.optimizer = optim.Adam([\\\n",
      "                                    {'params' : self.q.linear_1.parameters(),'lr': learning_rate / (action_num+2)},\\\n",
      "                                    {'params' : self.q.linear_2.parameters(),'lr': learning_rate / (action_num+2)},\\\n",
      "                                    {'params' : self.q.value.parameters(), 'lr' : learning_rate/ (action_num+2)},\\\n",
      "                                    {'params' : self.q.actions.parameters(), 'lr' : learning_rate},\\\n",
      "                                    ])\n",
      "        self.update_freq = 1000\n",
      "        self.update_count = 0\n",
      "    def action(self,x):\n",
      "        return self.q(x)\n",
      "    \n",
      "    def train_mode(self,n_epi,memory,batch_size,gamma,use_tensorboard,writer):\n",
      "        state, actions, reward, next_state, done_mask = memory.sample(batch_size)\n",
      "        actions = torch.stack(actions).transpose(0,1).unsqueeze(-1)\n",
      "        done_mask = torch.abs(done_mask-1)\n",
      "        \n",
      "        cur_actions = self.q(state)\n",
      "        cur_actions = torch.stack(cur_actions).transpose(0,1)\n",
      "        cur_actions = cur_actions.gather(2,actions.long()).squeeze(-1)\n",
      "\n",
      "        target_cur_actions = self.target_q(next_state)\n",
      "        target_cur_actions = torch.stack(target_cur_actions).transpose(0,1)\n",
      "        target_cur_actions = target_cur_actions.max(-1,keepdim = True)[0]\n",
      "        target_action = (done_mask * gamma * target_cur_actions.mean(1) + reward)\n",
      "        \n",
      "        loss = F.mse_loss(cur_actions,target_action.repeat(1,4))\n",
      "\n",
      "        self.optimizer.zero_grad()\n",
      "        loss.backward()\n",
      "        self.optimizer.step()\n",
      "        \n",
      "        self.update_count += 1\n",
      "        if (self.update_count % self.update_freq == 0) and (self.update_count > 0):\n",
      "            self.update_count = 0\n",
      "            self.target_q.load_state_dict(self.q.state_dict())\n",
      "            \n",
      "        if use_tensorboard:\n",
      "            writer.add_scalar(\"Loss/loss\", loss, n_epi)\n",
      "        return loss\n",
      "\n",
      "Output: {'agent': [], 'agent.BQN.__init__': ['torch.optim.Adam', 'torch.nn.Module.to', 'network.QNetwork.__init__', '<builtin>.super'], '<builtin>.super': [], 'network.QNetwork.__init__': ['torch.nn.Linear', '<builtin>.super', 'torch.nn.ReLU', 'torch.nn.Sequential', 'torch.nn.ModuleList', '<builtin>.range'], 'torch.nn.Module.to': [], 'torch.optim.Adam': [], 'agent.BQN.action': [], 'agent.BQN.train_mode': ['torch.abs', 'torch.nn.functional.mse_loss', 'torch.stack'], 'torch.stack': [], 'torch.abs': [], 'torch.nn.functional.mse_loss': [], 'network': [], 'torch.nn.Linear': [], 'torch.nn.ReLU': [], 'torch.nn.Sequential': [], '<builtin>.range': [], 'torch.nn.ModuleList': [], 'network.QNetwork.forward': ['<builtin>.range', 'torch.nn.functional.relu', '<builtin>.len'], 'torch.nn.functional.relu': [], '<builtin>.len': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\seolhokim_BipedalWalker-BranchingDQN\\agent.py\n",
      "[('agent BQN __init__', 'torch optim Adam'), ('agent BQN __init__', 'torch nn Module to'), ('agent BQN __init__', 'network QNetwork __init__'), ('network QNetwork __init__', 'torch nn Linear'), ('network QNetwork __init__', 'torch nn ReLU'), ('network QNetwork __init__', 'torch nn Sequential'), ('network QNetwork __init__', 'torch nn ModuleList'), ('agent BQN train_mode', 'torch abs'), ('agent BQN train_mode', 'torch nn functional mse_loss'), ('agent BQN train_mode', 'torch stack'), ('network QNetwork forward', 'torch nn functional relu')]\n",
      "0\n",
      "found files: []\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "import torch.optim as optim\n",
      "\n",
      "import numpy as np\n",
      "import os\n",
      "import time\n",
      "import random\n",
      "import argparse\n",
      "\n",
      "from utils import ReplayBuffer\n",
      "from agent import BQN\n",
      "\n",
      "import gym\n",
      "\n",
      "parser = argparse.ArgumentParser('parameters')\n",
      "parser.add_argument('--train', type=bool, default=True, help=\"(default: True)\")\n",
      "parser.add_argument('--render', type=bool, default=False, help=\"(default: False)\")\n",
      "parser.add_argument('--epochs', type=int, default=1000, help='number of epochs, (default: 1000)')\n",
      "parser.add_argument('--tensorboard', type=bool, default=False, help='use_tensorboard, (default: False)')\n",
      "parser.add_argument('--lr_rate', type=float, default=0.0001, help='learning rate (default : 0.0001)')\n",
      "parser.add_argument('--batch_size', type=int, default=64, help='batch size(default : 64)')\n",
      "parser.add_argument('--gamma', type=float, default=0.99, help='gamma (default : 0.99)')\n",
      "parser.add_argument('--action_scale', type=int, default=6, help='action scale between -1 ~ +1')\n",
      "\n",
      "parser.add_argument(\"--load\", type=str, default = 'no', help = 'load network name in ./model_weights')\n",
      "parser.add_argument(\"--save_interval\", type=int, default = 100, help = 'save interval(default: 100)')\n",
      "parser.add_argument(\"--print_interval\", type=int, default = 1, help = 'print interval(default : 1)')\n",
      "args = parser.parse_args()\n",
      "\n",
      "use_tensorboard = args.tensorboard\n",
      "action_scale = args.action_scale\n",
      "learning_rate = args.lr_rate\n",
      "batch_size = args.batch_size\n",
      "gamma = args.gamma\n",
      "\n",
      "if use_tensorboard : \n",
      "    from torch.utils.tensorboard import SummaryWriter\n",
      "    writer = SummaryWriter()\n",
      "else:\n",
      "    writer = None\n",
      "os.makedirs('./model_weights', exist_ok=True)\n",
      "\n",
      "\n",
      "env = gym.make(\"BipedalWalker-v3\")\n",
      "state_space = env.observation_space.shape[0]\n",
      "action_space = env.action_space.shape[0]\n",
      "print('observation space : ', env.observation_space)\n",
      "print('action space : ', env.action_space)\n",
      "print(env.action_space.low, env.action_space.high)\n",
      "\n",
      "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
      "if device == 'cuda':\n",
      "    agent = BQN(state_space,action_space,(action_scale), learning_rate, device).cuda()\n",
      "else : \n",
      "    agent = BQN(state_space,action_space,(action_scale), learning_rate, device)\n",
      "if args.load != 'no':\n",
      "    agent.load_state_dict(torch.load('./model_weights/'+args.load))\n",
      "memory = ReplayBuffer(100000,action_space,device)\n",
      "real_action = np.linspace(-1.,1., action_scale)\n",
      "\n",
      "for n_epi in range(2000):\n",
      "    state = env.reset()\n",
      "    done = False\n",
      "    score = 0.0\n",
      "    while not done:\n",
      "        if args.render :\n",
      "            env.render()\n",
      "        epsilon = max(0.01, 0.9 - 0.01*(n_epi/10))\n",
      "        if epsilon > random.random():\n",
      "            action = random.sample(range(0,(action_scale)),4)\n",
      "        else:\n",
      "            action_prob = agent.action(torch.tensor(state).float().reshape(1,-1).to(device))\n",
      "            action = [int(x.max(1)[1]) for x in action_prob]\n",
      "        next_state, reward, done, info = env.step(np.array([real_action[x] for x in action]))\n",
      "        \n",
      "        score += reward\n",
      "        done = 0 if done == False else 1\n",
      "        memory.put((state,action,reward,next_state, done))\n",
      "        if (memory.size()>5000) and (args.train):\n",
      "            agent.train_mode(n_epi, memory, batch_size, gamma, use_tensorboard,writer)\n",
      "        state = next_state\n",
      "    if use_tensorboard:\n",
      "        writer.add_scalar(\"reward\", score, n_epi)\n",
      "    if (n_epi % args.save_interval == 0) and (n_epi > 0):\n",
      "        torch.save(agent.state_dict(),'./model_weights/agent_'+str(n_epi))\n",
      "    if (n_epi % args.print_interval == 0):\n",
      "        print(\"epi : \",n_epi,\", score : \",score)\n",
      "\n",
      "Output: {'main': ['torch.utils.tensorboard.SummaryWriter', 'torch.cuda.is_available', 'random.sample', 'agent.BQN.__init__', 'utils.ReplayBuffer.put', 'torch.nn.Module.load_state_dict', '<builtin>.print', 'gym.make', 'torch.load', '<builtin>.range', 'agent.BQN.train_mode', 'numpy.linspace', 'random.random', 'torch.tensor', 'utils.ReplayBuffer.size', 'torch.save', 'numpy.array', 'os.makedirs', '<builtin>.int', 'torch.nn.Module.cuda', 'agent.BQN.action', 'utils.ReplayBuffer.__init__', 'torch.nn.Module.state_dict', '<builtin>.str', 'argparse.ArgumentParser', '<builtin>.max'], 'argparse.ArgumentParser': [], 'torch.utils.tensorboard.SummaryWriter': [], 'os.makedirs': [], 'gym.make': [], '<builtin>.print': [], 'torch.cuda.is_available': [], 'agent.BQN.__init__': ['network.QNetwork.__init__', '<builtin>.super', 'torch.nn.Module.to', 'torch.optim.Adam'], 'torch.nn.Module.cuda': [], 'torch.load': [], 'torch.nn.Module.load_state_dict': [], 'utils.ReplayBuffer.__init__': ['collections.deque'], 'numpy.linspace': [], '<builtin>.range': [], '<builtin>.max': [], 'random.random': [], 'random.sample': [], 'torch.tensor': [], 'agent.BQN.action': [], '<builtin>.int': [], 'numpy.array': [], 'utils.ReplayBuffer.put': [], 'utils.ReplayBuffer.size': ['<builtin>.len'], 'agent.BQN.train_mode': ['torch.stack', 'utils.ReplayBuffer.sample', 'torch.abs', 'torch.nn.functional.mse_loss'], 'torch.nn.Module.state_dict': [], '<builtin>.str': [], 'torch.save': [], 'agent': [], '<builtin>.super': [], 'network.QNetwork.__init__': ['torch.nn.ModuleList', '<builtin>.super', 'torch.nn.Sequential', '<builtin>.range', 'torch.nn.Linear', 'torch.nn.ReLU'], 'torch.nn.Module.to': [], 'torch.optim.Adam': [], 'utils.ReplayBuffer.sample': ['random.sample', '<builtin>.range', 'torch.tensor'], 'torch.stack': [], 'torch.abs': [], 'torch.nn.functional.mse_loss': [], 'network': [], 'torch.nn.Linear': [], 'torch.nn.ReLU': [], 'torch.nn.Sequential': [], 'torch.nn.ModuleList': [], 'network.QNetwork.forward': ['torch.nn.functional.relu', '<builtin>.len', '<builtin>.range'], 'torch.nn.functional.relu': [], '<builtin>.len': [], 'utils': [], 'collections.deque': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\seolhokim_BipedalWalker-BranchingDQN\\main.py\n",
      "[('main', 'torch utils tensorboard SummaryWriter'), ('main', 'torch cuda is_available'), ('main', 'random sample'), ('main', 'agent BQN __init__'), ('main', 'utils ReplayBuffer put'), ('main', 'torch nn Module load_state_dict'), ('main', 'gym make'), ('main', 'torch load'), ('main', 'agent BQN train_mode'), ('main', 'numpy linspace'), ('main', 'random random'), ('main', 'torch tensor'), ('main', 'utils ReplayBuffer size'), ('main', 'torch save'), ('main', 'numpy array'), ('main', 'os makedirs'), ('main', 'torch nn Module cuda'), ('main', 'agent BQN action'), ('main', 'utils ReplayBuffer __init__'), ('main', 'torch nn Module state_dict'), ('main', 'argparse ArgumentParser'), ('agent BQN __init__', 'network QNetwork __init__'), ('agent BQN __init__', 'torch nn Module to'), ('agent BQN __init__', 'torch optim Adam'), ('utils ReplayBuffer __init__', 'collections deque'), ('agent BQN train_mode', 'torch stack'), ('agent BQN train_mode', 'utils ReplayBuffer sample'), ('agent BQN train_mode', 'torch abs'), ('agent BQN train_mode', 'torch nn functional mse_loss'), ('network QNetwork __init__', 'torch nn ModuleList')]\n",
      "0\n",
      "found files: []\n",
      "import torch\n",
      "\n",
      "import collections\n",
      "import random\n",
      "\n",
      "class ReplayBuffer():\n",
      "    def __init__(self,buffer_limit,action_space,device):\n",
      "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
      "        self.action_space = action_space\n",
      "        self.device = device\n",
      "    def put(self, transition):\n",
      "        self.buffer.append(transition)\n",
      "    \n",
      "    def sample(self, n):\n",
      "        mini_batch = random.sample(self.buffer, n)\n",
      "        state_lst, reward_lst, next_state_lst, done_mask_lst = [], [], [], []\n",
      "        actions_lst = [[] for i in range(self.action_space)]\n",
      "\n",
      "        for transition in mini_batch:\n",
      "            state, actions,reward, next_state, done_mask = transition\n",
      "            state_lst.append(state)\n",
      "            for idx in range(self.action_space):\n",
      "                actions_lst[idx].append(actions[idx])\n",
      "            reward_lst.append([reward])\n",
      "            next_state_lst.append(next_state)\n",
      "            done_mask_lst.append([done_mask])\n",
      "        actions_lst = [torch.tensor(x,dtype= torch.float).to(self.device) for x in actions_lst]\n",
      "        return torch.tensor(state_lst, dtype=torch.float).to(self.device),\\\n",
      "               actions_lst ,torch.tensor(reward_lst).to(self.device),\\\n",
      "                torch.tensor(next_state_lst, dtype=torch.float).to(self.device),\\\n",
      "               torch.tensor(done_mask_lst).to(self.device)\n",
      "    def size(self):\n",
      "        return len(self.buffer)\n",
      "Output: {'utils': [], 'utils.ReplayBuffer.__init__': ['collections.deque'], 'collections.deque': [], 'utils.ReplayBuffer.put': [], 'utils.ReplayBuffer.sample': ['random.sample', 'torch.tensor', '<builtin>.range'], 'random.sample': [], '<builtin>.range': [], 'torch.tensor': [], 'utils.ReplayBuffer.size': ['<builtin>.len'], '<builtin>.len': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\seolhokim_BipedalWalker-BranchingDQN\\utils.py\n",
      "[('utils ReplayBuffer __init__', 'collections deque'), ('utils ReplayBuffer sample', 'random sample'), ('utils ReplayBuffer sample', 'torch tensor')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('network QNetwork __init__', 'torch nn ReLU'), ('network QNetwork __init__', 'torch nn Linear'), ('network QNetwork __init__', 'torch nn Sequential'), ('network QNetwork __init__', 'torch nn ModuleList'), ('network QNetwork forward', 'torch nn functional relu')], [('agent BQN __init__', 'torch optim Adam'), ('agent BQN __init__', 'torch nn Module to'), ('agent BQN __init__', 'network QNetwork __init__'), ('network QNetwork __init__', 'torch nn Linear'), ('network QNetwork __init__', 'torch nn ReLU'), ('network QNetwork __init__', 'torch nn Sequential'), ('network QNetwork __init__', 'torch nn ModuleList'), ('agent BQN train_mode', 'torch abs'), ('agent BQN train_mode', 'torch nn functional mse_loss'), ('agent BQN train_mode', 'torch stack'), ('network QNetwork forward', 'torch nn functional relu')], [('main', 'torch utils tensorboard SummaryWriter'), ('main', 'torch cuda is_available'), ('main', 'random sample'), ('main', 'agent BQN __init__'), ('main', 'utils ReplayBuffer put'), ('main', 'torch nn Module load_state_dict'), ('main', 'gym make'), ('main', 'torch load'), ('main', 'agent BQN train_mode'), ('main', 'numpy linspace'), ('main', 'random random'), ('main', 'torch tensor'), ('main', 'utils ReplayBuffer size'), ('main', 'torch save'), ('main', 'numpy array'), ('main', 'os makedirs'), ('main', 'torch nn Module cuda'), ('main', 'agent BQN action'), ('main', 'utils ReplayBuffer __init__'), ('main', 'torch nn Module state_dict'), ('main', 'argparse ArgumentParser'), ('agent BQN __init__', 'network QNetwork __init__'), ('agent BQN __init__', 'torch nn Module to'), ('agent BQN __init__', 'torch optim Adam'), ('utils ReplayBuffer __init__', 'collections deque'), ('agent BQN train_mode', 'torch stack'), ('agent BQN train_mode', 'utils ReplayBuffer sample'), ('agent BQN train_mode', 'torch abs'), ('agent BQN train_mode', 'torch nn functional mse_loss'), ('network QNetwork __init__', 'torch nn ModuleList')], [('utils ReplayBuffer __init__', 'collections deque'), ('utils ReplayBuffer sample', 'random sample'), ('utils ReplayBuffer sample', 'torch tensor')]]\n",
      "********************doctrings*************************\n",
      "['', '', '', '']\n",
      "embed index dataset: 5\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\benibienz_TAMER\\\\tamer\\\\agent.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\benibienz_TAMER\\\\tamer\\\\interface.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\benibienz_TAMER\\\\run.py']\n",
      "import datetime as dt\n",
      "import os\n",
      "import pickle\n",
      "import time\n",
      "import uuid\n",
      "from itertools import count\n",
      "from pathlib import Path\n",
      "from sys import stdout\n",
      "from csv import DictWriter\n",
      "\n",
      "import numpy as np\n",
      "from sklearn import pipeline, preprocessing\n",
      "from sklearn.kernel_approximation import RBFSampler\n",
      "from sklearn.linear_model import SGDRegressor\n",
      "\n",
      "MOUNTAINCAR_ACTION_MAP = {0: 'left', 1: 'none', 2: 'right'}\n",
      "MODELS_DIR = Path(__file__).parent.joinpath('saved_models')\n",
      "LOGS_DIR = Path(__file__).parent.joinpath('logs')\n",
      "\n",
      "\n",
      "class SGDFunctionApproximator:\n",
      "    \"\"\" SGD function approximator with RBF preprocessing. \"\"\"\n",
      "    def __init__(self, env):\n",
      "        \n",
      "        # Feature preprocessing: Normalize to zero mean and unit variance\n",
      "        # We use a few samples from the observation space to do this\n",
      "        observation_examples = np.array(\n",
      "            [env.observation_space.sample() for _ in range(10000)], dtype='float64'\n",
      "        )\n",
      "        self.scaler = preprocessing.StandardScaler()\n",
      "        self.scaler.fit(observation_examples)\n",
      "\n",
      "        # Used to convert a state to a featurized represenation.\n",
      "        # We use RBF kernels with different variances to cover different parts of the space\n",
      "        self.featurizer = pipeline.FeatureUnion(\n",
      "            [\n",
      "                ('rbf1', RBFSampler(gamma=5.0, n_components=100)),\n",
      "                ('rbf2', RBFSampler(gamma=2.0, n_components=100)),\n",
      "                ('rbf3', RBFSampler(gamma=1.0, n_components=100)),\n",
      "                ('rbf4', RBFSampler(gamma=0.5, n_components=100)),\n",
      "            ]\n",
      "        )\n",
      "        self.featurizer.fit(self.scaler.transform(observation_examples))\n",
      "\n",
      "        self.models = []\n",
      "        for _ in range(env.action_space.n):\n",
      "            model = SGDRegressor(learning_rate='constant')\n",
      "            model.partial_fit([self.featurize_state(env.reset())], [0])\n",
      "            self.models.append(model)\n",
      "\n",
      "    def predict(self, state, action=None):\n",
      "        features = self.featurize_state(state)\n",
      "        if not action:\n",
      "            return [m.predict([features])[0] for m in self.models]\n",
      "        else:\n",
      "            return self.models[action].predict([features])[0]\n",
      "\n",
      "    def update(self, state, action, td_target):\n",
      "        features = self.featurize_state(state)\n",
      "        self.models[action].partial_fit([features], [td_target])\n",
      "\n",
      "    def featurize_state(self, state):\n",
      "        \"\"\" Returns the featurized representation for a state. \"\"\"\n",
      "        scaled = self.scaler.transform([state])\n",
      "        featurized = self.featurizer.transform(scaled)\n",
      "        return featurized[0]\n",
      "\n",
      "\n",
      "class Tamer:\n",
      "    \"\"\"\n",
      "    QLearning Agent adapted to TAMER using steps from:\n",
      "    http://www.cs.utexas.edu/users/bradknox/kcap09/Knox_and_Stone,_K-CAP_2009.html\n",
      "    \"\"\"\n",
      "    def __init__(\n",
      "        self,\n",
      "        env,\n",
      "        num_episodes,\n",
      "        discount_factor=1,  # only affects Q-learning\n",
      "        epsilon=0, # only affects Q-learning\n",
      "        min_eps=0,  # minimum value for epsilon after annealing\n",
      "        tame=True,  # set to false for normal Q-learning\n",
      "        ts_len=0.2,  # length of timestep for training TAMER\n",
      "        output_dir=LOGS_DIR,\n",
      "        model_file_to_load=None  # filename of pretrained model\n",
      "    ):\n",
      "        self.tame = tame\n",
      "        self.ts_len = ts_len\n",
      "        self.env = env\n",
      "        self.uuid = uuid.uuid4()\n",
      "        self.output_dir = output_dir\n",
      "\n",
      "        # init model\n",
      "        if model_file_to_load is not None:\n",
      "            print(f'Loaded pretrained model: {model_file_to_load}')\n",
      "            self.load_model(filename=model_file_to_load)\n",
      "        else:\n",
      "            if tame:\n",
      "                self.H = SGDFunctionApproximator(env)  # init H function\n",
      "            else:  # optionally run as standard Q Learning\n",
      "                self.Q = SGDFunctionApproximator(env)  # init Q function\n",
      "\n",
      "        # hyperparameters\n",
      "        self.discount_factor = discount_factor\n",
      "        self.epsilon = epsilon if not tame else 0\n",
      "        self.num_episodes = num_episodes\n",
      "        self.min_eps = min_eps\n",
      "\n",
      "        # calculate episodic reduction in epsilon\n",
      "        self.epsilon_step = (epsilon - min_eps) / num_episodes\n",
      "\n",
      "        # reward logging\n",
      "        self.reward_log_columns = [\n",
      "            'Episode',\n",
      "            'Ep start ts',\n",
      "            'Feedback ts',\n",
      "            'Human Reward',\n",
      "            'Environment Reward',\n",
      "        ]\n",
      "        self.reward_log_path = os.path.join(self.output_dir, f'{self.uuid}.csv')\n",
      "\n",
      "    def act(self, state):\n",
      "        \"\"\" Epsilon-greedy Policy \"\"\"\n",
      "        if np.random.random() < 1 - self.epsilon:\n",
      "            preds = self.H.predict(state) if self.tame else self.Q.predict(state)\n",
      "            return np.argmax(preds)\n",
      "        else:\n",
      "            return np.random.randint(0, self.env.action_space.n)\n",
      "\n",
      "    def _train_episode(self, episode_index, disp):\n",
      "        print(f'Episode: {episode_index + 1}  Timestep:', end='')\n",
      "        rng = np.random.default_rng()\n",
      "        tot_reward = 0\n",
      "        state = self.env.reset()\n",
      "        ep_start_time = dt.datetime.now().time()\n",
      "        with open(self.reward_log_path, 'a+', newline='') as write_obj:\n",
      "            dict_writer = DictWriter(write_obj, fieldnames=self.reward_log_columns)\n",
      "            dict_writer.writeheader()\n",
      "            for ts in count():\n",
      "                print(f' {ts}', end='')\n",
      "                self.env.render()\n",
      "\n",
      "                # Determine next action\n",
      "                action = self.act(state)\n",
      "                if self.tame:\n",
      "                    disp.show_action(action)\n",
      "\n",
      "                # Get next state and reward\n",
      "                next_state, reward, done, info = self.env.step(action)\n",
      "\n",
      "                if not self.tame:\n",
      "                    if done and next_state[0] >= 0.5:\n",
      "                        td_target = reward\n",
      "                    else:\n",
      "                        td_target = reward + self.discount_factor * np.max(\n",
      "                            self.Q.predict(next_state)\n",
      "                        )\n",
      "                    self.Q.update(state, action, td_target)\n",
      "                else:\n",
      "                    now = time.time()\n",
      "                    while time.time() < now + self.ts_len:\n",
      "                        frame = None\n",
      "\n",
      "                        time.sleep(0.01)  # save the CPU\n",
      "\n",
      "                        human_reward = disp.get_scalar_feedback()\n",
      "                        feedback_ts = dt.datetime.now().time()\n",
      "                        if human_reward != 0:\n",
      "                            dict_writer.writerow(\n",
      "                                {\n",
      "                                    'Episode': episode_index + 1,\n",
      "                                    'Ep start ts': ep_start_time,\n",
      "                                    'Feedback ts': feedback_ts,\n",
      "                                    'Human Reward': human_reward,\n",
      "                                    'Environment Reward': reward\n",
      "                                }\n",
      "                            )\n",
      "                            self.H.update(state, action, human_reward)\n",
      "                            break\n",
      "\n",
      "                tot_reward += reward\n",
      "                if done:\n",
      "                    print(f'  Reward: {tot_reward}')\n",
      "                    break\n",
      "\n",
      "                stdout.write('\\b' * (len(str(ts)) + 1))\n",
      "                state = next_state\n",
      "\n",
      "        # Decay epsilon\n",
      "        if self.epsilon > self.min_eps:\n",
      "            self.epsilon -= self.epsilon_step\n",
      "\n",
      "    async def train(self, model_file_to_save=None):\n",
      "        \"\"\"\n",
      "        TAMER (or Q learning) training loop\n",
      "        Args:\n",
      "            model_file_to_save: save Q or H model to this filename\n",
      "        \"\"\"\n",
      "        # render first so that pygame display shows up on top\n",
      "        self.env.render()\n",
      "        disp = None\n",
      "        if self.tame:\n",
      "            # only init pygame display if we're actually training tamer\n",
      "            from .interface import Interface\n",
      "            disp = Interface(action_map=MOUNTAINCAR_ACTION_MAP)\n",
      "\n",
      "        for i in range(self.num_episodes):\n",
      "            self._train_episode(i, disp)\n",
      "\n",
      "        print('\\nCleaning up...')\n",
      "        self.env.close()\n",
      "        if model_file_to_save is not None:\n",
      "            self.save_model(filename=model_file_to_save)\n",
      "\n",
      "    def play(self, n_episodes=1, render=False):\n",
      "        \"\"\"\n",
      "        Run episodes with trained agent\n",
      "        Args:\n",
      "            n_episodes: number of episodes\n",
      "            render: optionally render episodes\n",
      "\n",
      "        Returns: list of cumulative episode rewards\n",
      "        \"\"\"\n",
      "        self.epsilon = 0\n",
      "        ep_rewards = []\n",
      "        for i in range(n_episodes):\n",
      "            state = self.env.reset()\n",
      "            done = False\n",
      "            tot_reward = 0\n",
      "            while not done:\n",
      "                action = self.act(state)\n",
      "                next_state, reward, done, info = self.env.step(action)\n",
      "                tot_reward += reward\n",
      "                if render:\n",
      "                    self.env.render()\n",
      "                state = next_state\n",
      "            ep_rewards.append(tot_reward)\n",
      "            print(f'Episode: {i + 1} Reward: {tot_reward}')\n",
      "        self.env.close()\n",
      "        return ep_rewards\n",
      "\n",
      "    def evaluate(self, n_episodes=100):\n",
      "        print('Evaluating agent')\n",
      "        rewards = self.play(n_episodes=n_episodes)\n",
      "        avg_reward = np.mean(rewards)\n",
      "        print(\n",
      "            f'Average total episode reward over {n_episodes} '\n",
      "            f'episodes: {avg_reward:.2f}'\n",
      "        )\n",
      "        return avg_reward\n",
      "\n",
      "    def save_model(self, filename):\n",
      "        \"\"\"\n",
      "        Save H or Q model to models dir\n",
      "        Args:\n",
      "            filename: name of pickled file\n",
      "        \"\"\"\n",
      "        model = self.H if self.tame else self.Q\n",
      "        filename = filename + '.p' if not filename.endswith('.p') else filename\n",
      "        with open(MODELS_DIR.joinpath(filename), 'wb') as f:\n",
      "            pickle.dump(model, f)\n",
      "\n",
      "    def load_model(self, filename):\n",
      "        \"\"\"\n",
      "        Load H or Q model from models dir\n",
      "        Args:\n",
      "            filename: name of pickled file\n",
      "        \"\"\"\n",
      "        filename = filename + '.p' if not filename.endswith('.p') else filename\n",
      "        with open(MODELS_DIR.joinpath(filename), 'rb') as f:\n",
      "            model = pickle.load(f)\n",
      "        if self.tame:\n",
      "            self.H = model\n",
      "        else:\n",
      "            self.Q = model\n",
      "\n",
      "Output: {'agent': ['pathlib.Path'], 'pathlib.Path': [], 'agent.SGDFunctionApproximator.__init__': ['sklearn.pipeline.FeatureUnion', 'sklearn.linear_model.SGDRegressor', 'numpy.array', '<builtin>.range', 'sklearn.preprocessing.StandardScaler', 'sklearn.kernel_approximation.RBFSampler'], '<builtin>.range': [], 'numpy.array': [], 'sklearn.preprocessing.StandardScaler': [], 'sklearn.kernel_approximation.RBFSampler': [], 'sklearn.pipeline.FeatureUnion': [], 'sklearn.linear_model.SGDRegressor': [], 'agent.SGDFunctionApproximator.predict': ['agent.SGDFunctionApproximator.featurize_state'], 'agent.SGDFunctionApproximator.featurize_state': [], 'agent.SGDFunctionApproximator.update': ['agent.SGDFunctionApproximator.featurize_state'], 'agent.Tamer.__init__': ['<builtin>.print', 'os.path.join', 'agent.Tamer.load_model', 'agent.SGDFunctionApproximator.__init__'], '<builtin>.print': [], 'agent.Tamer.load_model': ['<builtin>.open', 'pickle.load'], 'os.path.join': [], 'agent.Tamer.act': ['agent.SGDFunctionApproximator.predict', 'numpy.argmax', 'numpy.random.randint', 'numpy.random.random'], 'numpy.random.random': [], 'numpy.argmax': [], 'numpy.random.randint': [], 'agent.Tamer._train_episode': ['numpy.random.default_rng', '<builtin>.open', 'time.sleep', 'agent.Tamer.act', '<builtin>.len', 'itertools.count', 'numpy.max', 'time.time', 'sys.stdout.write', '<builtin>.print', 'agent.SGDFunctionApproximator.update', 'csv.DictWriter', 'agent.SGDFunctionApproximator.predict', 'datetime.datetime.now', '<builtin>.str'], 'numpy.random.default_rng': [], 'datetime.datetime.now': [], '<builtin>.open': [], 'csv.DictWriter': [], 'itertools.count': [], 'numpy.max': [], 'time.time': [], 'time.sleep': [], '<builtin>.str': [], '<builtin>.len': [], 'sys.stdout.write': [], 'agent.Tamer.train': ['agent.Tamer.save_model', 'interface.Interface', '<builtin>.print', 'agent.Tamer._train_episode', '<builtin>.range'], 'interface.Interface': [], 'agent.Tamer.save_model': ['<builtin>.open', 'pickle.dump'], 'agent.Tamer.play': ['<builtin>.print', 'agent.Tamer.act', '<builtin>.range'], 'agent.Tamer.evaluate': ['numpy.mean', '<builtin>.print', 'agent.Tamer.play'], 'numpy.mean': [], 'pickle.dump': [], 'pickle.load': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\benibienz_TAMER\\tamer\\agent.py\n",
      "[('agent', 'pathlib Path'), ('agent SGDFunctionApproximator __init__', 'sklearn pipeline FeatureUnion'), ('agent SGDFunctionApproximator __init__', 'sklearn linear_model SGDRegressor'), ('agent SGDFunctionApproximator __init__', 'numpy array'), ('agent SGDFunctionApproximator __init__', 'sklearn preprocessing StandardScaler'), ('agent SGDFunctionApproximator __init__', 'sklearn kernel_approximation RBFSampler'), ('agent SGDFunctionApproximator predict', 'agent SGDFunctionApproximator featurize_state'), ('agent SGDFunctionApproximator update', 'agent SGDFunctionApproximator featurize_state'), ('agent Tamer __init__', 'os path join'), ('agent Tamer __init__', 'agent Tamer load_model'), ('agent Tamer __init__', 'agent SGDFunctionApproximator __init__'), ('agent Tamer load_model', 'pickle load'), ('agent Tamer act', 'agent SGDFunctionApproximator predict'), ('agent Tamer act', 'numpy argmax'), ('agent Tamer act', 'numpy random randint'), ('agent Tamer act', 'numpy random random'), ('agent Tamer _train_episode', 'numpy random default_rng'), ('agent Tamer _train_episode', 'time sleep'), ('agent Tamer _train_episode', 'agent Tamer act'), ('agent Tamer _train_episode', 'itertools count'), ('agent Tamer _train_episode', 'numpy max'), ('agent Tamer _train_episode', 'time time'), ('agent Tamer _train_episode', 'sys stdout write'), ('agent Tamer _train_episode', 'agent SGDFunctionApproximator update'), ('agent Tamer _train_episode', 'csv DictWriter'), ('agent Tamer _train_episode', 'agent SGDFunctionApproximator predict'), ('agent Tamer _train_episode', 'datetime datetime now'), ('agent Tamer train', 'agent Tamer save_model'), ('agent Tamer train', 'interface Interface'), ('agent Tamer train', 'agent Tamer _train_episode')]\n",
      "0\n",
      "found files: []\n",
      "import os\n",
      "import pygame\n",
      "\n",
      "\n",
      "class Interface:\n",
      "    \"\"\" Pygame interface for training TAMER \"\"\"\n",
      "\n",
      "    def __init__(self, action_map):\n",
      "        self.action_map = action_map\n",
      "        pygame.init()\n",
      "        self.font = pygame.font.Font(\"freesansbold.ttf\", 32)\n",
      "\n",
      "        # set position of pygame window (so it doesn't overlap with gym)\n",
      "        os.environ[\"SDL_VIDEO_WINDOW_POS\"] = \"1000,100\"\n",
      "        os.environ[\"SDL_VIDEO_CENTERED\"] = \"0\"\n",
      "\n",
      "        self.screen = pygame.display.set_mode((200, 100))\n",
      "        area = self.screen.fill((0, 0, 0))\n",
      "        pygame.display.update(area)\n",
      "\n",
      "    def get_scalar_feedback(self):\n",
      "        \"\"\"\n",
      "        Get human input. 'W' key for positive, 'A' key for negative.\n",
      "        Returns: scalar reward (1 for positive, -1 for negative)\n",
      "        \"\"\"\n",
      "        reward = 0\n",
      "        area = None\n",
      "        for event in pygame.event.get():\n",
      "            if event.type == pygame.KEYDOWN:\n",
      "                if event.key == pygame.K_w:\n",
      "                    area = self.screen.fill((0, 255, 0))\n",
      "                    reward = 1\n",
      "                    break\n",
      "                elif event.key == pygame.K_a:\n",
      "                    area = self.screen.fill((255, 0, 0))\n",
      "                    reward = -1\n",
      "                    break\n",
      "        pygame.display.update(area)\n",
      "        return reward\n",
      "\n",
      "    def show_action(self, action):\n",
      "        \"\"\"\n",
      "        Show agent's action on pygame screen\n",
      "        Args:\n",
      "            action: numerical action (for MountainCar environment only currently)\n",
      "        \"\"\"\n",
      "        area = self.screen.fill((0, 0, 0))\n",
      "        pygame.display.update(area)\n",
      "        text = self.font.render(self.action_map[action], True, (255, 255, 255))\n",
      "        text_rect = text.get_rect()\n",
      "        text_rect.center = (100, 50)\n",
      "        area = self.screen.blit(text, text_rect)\n",
      "        pygame.display.update(area)\n",
      "\n",
      "Output: {'interface': [], 'interface.Interface.__init__': ['pygame.init', 'pygame.font.Font', 'pygame.display.update', 'pygame.display.set_mode'], 'pygame.init': [], 'pygame.font.Font': [], 'pygame.display.set_mode': [], 'pygame.display.update': [], 'interface.Interface.get_scalar_feedback': ['pygame.display.update', 'pygame.event.get'], 'pygame.event.get': [], 'interface.Interface.show_action': ['pygame.display.update']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\benibienz_TAMER\\tamer\\interface.py\n",
      "[('interface Interface __init__', 'pygame init'), ('interface Interface __init__', 'pygame font Font'), ('interface Interface __init__', 'pygame display update'), ('interface Interface __init__', 'pygame display set_mode'), ('interface Interface get_scalar_feedback', 'pygame display update'), ('interface Interface get_scalar_feedback', 'pygame event get'), ('interface Interface show_action', 'pygame display update')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"\n",
      "Implementation of TAMER (Knox + Stone, 2009)\n",
      "When training, use 'W' and 'A' keys for positive and negative rewards\n",
      "\"\"\"\n",
      "\n",
      "import asyncio\n",
      "import gym\n",
      "\n",
      "from tamer.agent import Tamer\n",
      "\n",
      "\n",
      "async def main():\n",
      "    env = gym.make('MountainCar-v0')\n",
      "\n",
      "    # hyperparameters\n",
      "    discount_factor = 1\n",
      "    epsilon = 0  # vanilla Q learning actually works well with no random exploration\n",
      "    min_eps = 0\n",
      "    num_episodes = 2\n",
      "    tame = True  # set to false for vanilla Q learning\n",
      "\n",
      "    # set a timestep for training TAMER\n",
      "    # the more time per step, the easier for the human\n",
      "    # but the longer it takes to train (in real time)\n",
      "    # 0.2 seconds is fast but doable\n",
      "    tamer_training_timestep = 0.3\n",
      "\n",
      "    agent = Tamer(env, num_episodes, discount_factor, epsilon, min_eps, tame,\n",
      "                  tamer_training_timestep, model_file_to_load=None)\n",
      "\n",
      "    await agent.train(model_file_to_save='autosave')\n",
      "    agent.play(n_episodes=1, render=True)\n",
      "    agent.evaluate(n_episodes=30)\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    asyncio.run(main())\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Output: {'run': ['asyncio.run', 'run.main'], 'run.main': ['tamer.agent.Tamer', 'gym.make'], 'gym.make': [], 'tamer.agent.Tamer': [], 'asyncio.run': [], 'tamer.agent': ['pathlib.Path'], 'pathlib.Path': [], 'tamer.agent.SGDFunctionApproximator.__init__': ['<builtin>.range', 'numpy.array', 'sklearn.kernel_approximation.RBFSampler', 'sklearn.preprocessing.StandardScaler', 'sklearn.linear_model.SGDRegressor', 'sklearn.pipeline.FeatureUnion'], '<builtin>.range': [], 'numpy.array': [], 'sklearn.preprocessing.StandardScaler': [], 'sklearn.kernel_approximation.RBFSampler': [], 'sklearn.pipeline.FeatureUnion': [], 'sklearn.linear_model.SGDRegressor': [], 'tamer.agent.SGDFunctionApproximator.predict': ['tamer.agent.SGDFunctionApproximator.featurize_state'], 'tamer.agent.SGDFunctionApproximator.featurize_state': [], 'tamer.agent.SGDFunctionApproximator.update': ['tamer.agent.SGDFunctionApproximator.featurize_state'], 'tamer.agent.Tamer.__init__': ['<builtin>.print', 'tamer.agent.SGDFunctionApproximator.__init__', 'uuid.uuid4', 'os.path.join'], 'uuid.uuid4': [], '<builtin>.print': [], 'os.path.join': [], 'tamer.agent.Tamer.act': ['numpy.argmax', 'numpy.random.randint', 'numpy.random.random'], 'numpy.random.random': [], 'numpy.argmax': [], 'numpy.random.randint': [], 'tamer.agent.Tamer._train_episode': ['sys.stdout.write', 'time.time', 'itertools.count', 'datetime.datetime.now', '<builtin>.len', '<builtin>.str', 'numpy.random.default_rng', 'numpy.max', '<builtin>.open', '<builtin>.print', 'time.sleep', 'csv.DictWriter'], 'numpy.random.default_rng': [], 'datetime.datetime.now': [], '<builtin>.open': [], 'csv.DictWriter': [], 'itertools.count': [], 'numpy.max': [], 'time.time': [], 'time.sleep': [], '<builtin>.str': [], '<builtin>.len': [], 'sys.stdout.write': [], 'tamer.agent.Tamer.train': ['<builtin>.range', '<builtin>.print', 'interface.Interface'], 'interface.Interface': [], 'tamer.agent.Tamer.play': ['<builtin>.range', '<builtin>.print'], 'tamer.agent.Tamer.evaluate': ['<builtin>.print', 'numpy.mean'], 'numpy.mean': [], 'tamer.agent.Tamer.save_model': ['pickle.dump', '<builtin>.open'], 'pickle.dump': [], 'tamer.agent.Tamer.load_model': ['pickle.load', '<builtin>.open'], 'pickle.load': [], 'tamer.interface': [], 'tamer.interface.Interface.__init__': ['pygame.font.Font', 'pygame.display.update', 'pygame.init', 'pygame.display.set_mode'], 'pygame.init': [], 'pygame.font.Font': [], 'pygame.display.set_mode': [], 'pygame.display.update': [], 'tamer.interface.Interface.get_scalar_feedback': ['pygame.event.get', 'pygame.display.update'], 'pygame.event.get': [], 'tamer.interface.Interface.show_action': ['pygame.display.update']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\benibienz_TAMER\\run.py\n",
      "[('run', 'asyncio run'), ('run', 'run main'), ('run main', 'tamer agent Tamer'), ('run main', 'gym make'), ('tamer agent', 'pathlib Path'), ('tamer agent SGDFunctionApproximator __init__', 'numpy array'), ('tamer agent SGDFunctionApproximator __init__', 'sklearn kernel_approximation RBFSampler'), ('tamer agent SGDFunctionApproximator __init__', 'sklearn preprocessing StandardScaler'), ('tamer agent SGDFunctionApproximator __init__', 'sklearn linear_model SGDRegressor'), ('tamer agent SGDFunctionApproximator __init__', 'sklearn pipeline FeatureUnion'), ('tamer agent SGDFunctionApproximator predict', 'tamer agent SGDFunctionApproximator featurize_state'), ('tamer agent SGDFunctionApproximator update', 'tamer agent SGDFunctionApproximator featurize_state'), ('tamer agent Tamer __init__', 'tamer agent SGDFunctionApproximator __init__'), ('tamer agent Tamer __init__', 'uuid uuid4'), ('tamer agent Tamer __init__', 'os path join'), ('tamer agent Tamer act', 'numpy argmax'), ('tamer agent Tamer act', 'numpy random randint'), ('tamer agent Tamer act', 'numpy random random'), ('tamer agent Tamer _train_episode', 'sys stdout write'), ('tamer agent Tamer _train_episode', 'time time'), ('tamer agent Tamer _train_episode', 'itertools count'), ('tamer agent Tamer _train_episode', 'datetime datetime now'), ('tamer agent Tamer _train_episode', 'numpy random default_rng'), ('tamer agent Tamer _train_episode', 'numpy max'), ('tamer agent Tamer _train_episode', 'time sleep'), ('tamer agent Tamer _train_episode', 'csv DictWriter'), ('tamer agent Tamer train', 'interface Interface'), ('tamer agent Tamer evaluate', 'numpy mean'), ('tamer agent Tamer save_model', 'pickle dump'), ('tamer agent Tamer load_model', 'pickle load')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('agent', 'pathlib Path'), ('agent SGDFunctionApproximator __init__', 'sklearn pipeline FeatureUnion'), ('agent SGDFunctionApproximator __init__', 'sklearn linear_model SGDRegressor'), ('agent SGDFunctionApproximator __init__', 'numpy array'), ('agent SGDFunctionApproximator __init__', 'sklearn preprocessing StandardScaler'), ('agent SGDFunctionApproximator __init__', 'sklearn kernel_approximation RBFSampler'), ('agent SGDFunctionApproximator predict', 'agent SGDFunctionApproximator featurize_state'), ('agent SGDFunctionApproximator update', 'agent SGDFunctionApproximator featurize_state'), ('agent Tamer __init__', 'os path join'), ('agent Tamer __init__', 'agent Tamer load_model'), ('agent Tamer __init__', 'agent SGDFunctionApproximator __init__'), ('agent Tamer load_model', 'pickle load'), ('agent Tamer act', 'agent SGDFunctionApproximator predict'), ('agent Tamer act', 'numpy argmax'), ('agent Tamer act', 'numpy random randint'), ('agent Tamer act', 'numpy random random'), ('agent Tamer _train_episode', 'numpy random default_rng'), ('agent Tamer _train_episode', 'time sleep'), ('agent Tamer _train_episode', 'agent Tamer act'), ('agent Tamer _train_episode', 'itertools count'), ('agent Tamer _train_episode', 'numpy max'), ('agent Tamer _train_episode', 'time time'), ('agent Tamer _train_episode', 'sys stdout write'), ('agent Tamer _train_episode', 'agent SGDFunctionApproximator update'), ('agent Tamer _train_episode', 'csv DictWriter'), ('agent Tamer _train_episode', 'agent SGDFunctionApproximator predict'), ('agent Tamer _train_episode', 'datetime datetime now'), ('agent Tamer train', 'agent Tamer save_model'), ('agent Tamer train', 'interface Interface'), ('agent Tamer train', 'agent Tamer _train_episode')], [('interface Interface __init__', 'pygame init'), ('interface Interface __init__', 'pygame font Font'), ('interface Interface __init__', 'pygame display update'), ('interface Interface __init__', 'pygame display set_mode'), ('interface Interface get_scalar_feedback', 'pygame display update'), ('interface Interface get_scalar_feedback', 'pygame event get'), ('interface Interface show_action', 'pygame display update')], [('run', 'asyncio run'), ('run', 'run main'), ('run main', 'tamer agent Tamer'), ('run main', 'gym make'), ('tamer agent', 'pathlib Path'), ('tamer agent SGDFunctionApproximator __init__', 'numpy array'), ('tamer agent SGDFunctionApproximator __init__', 'sklearn kernel_approximation RBFSampler'), ('tamer agent SGDFunctionApproximator __init__', 'sklearn preprocessing StandardScaler'), ('tamer agent SGDFunctionApproximator __init__', 'sklearn linear_model SGDRegressor'), ('tamer agent SGDFunctionApproximator __init__', 'sklearn pipeline FeatureUnion'), ('tamer agent SGDFunctionApproximator predict', 'tamer agent SGDFunctionApproximator featurize_state'), ('tamer agent SGDFunctionApproximator update', 'tamer agent SGDFunctionApproximator featurize_state'), ('tamer agent Tamer __init__', 'tamer agent SGDFunctionApproximator __init__'), ('tamer agent Tamer __init__', 'uuid uuid4'), ('tamer agent Tamer __init__', 'os path join'), ('tamer agent Tamer act', 'numpy argmax'), ('tamer agent Tamer act', 'numpy random randint'), ('tamer agent Tamer act', 'numpy random random'), ('tamer agent Tamer _train_episode', 'sys stdout write'), ('tamer agent Tamer _train_episode', 'time time'), ('tamer agent Tamer _train_episode', 'itertools count'), ('tamer agent Tamer _train_episode', 'datetime datetime now'), ('tamer agent Tamer _train_episode', 'numpy random default_rng'), ('tamer agent Tamer _train_episode', 'numpy max'), ('tamer agent Tamer _train_episode', 'time sleep'), ('tamer agent Tamer _train_episode', 'csv DictWriter'), ('tamer agent Tamer train', 'interface Interface'), ('tamer agent Tamer evaluate', 'numpy mean'), ('tamer agent Tamer save_model', 'pickle dump'), ('tamer agent Tamer load_model', 'pickle load')]]\n",
      "********************doctrings*************************\n",
      "['', '', '']\n",
      "embed index dataset: 6\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\codebasic_pyko\\\\setup.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\codebasic_pyko\\\\tests\\\\test_tokenizer.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\codebasic_pyko\\\\pyko\\\\reader.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\codebasic_pyko\\\\pyko\\\\tokenizer.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\codebasic_pyko\\\\tests\\\\test_reader.py']\n",
      "import os\n",
      "from setuptools import setup, find_packages\n",
      "\n",
      "with open('README.md', encoding='utf8') as f:\n",
      "     = f.read()\n",
      "\n",
      "setup(\n",
      "    name='pyko',\n",
      "    version=os.environ['VERSION'],\n",
      "    description='Korean Text Processor',\n",
      "    author='Lee Seongjoo',\n",
      "    author_email='seongjoo@codebasic.io',\n",
      "    url='https://github.com/codebasic/pyko',\n",
      "    keywords='natural language processing text korean',\n",
      "    packages=find_packages(),\n",
      "    install_requires=['nltk', 'beautifulsoup4', 'lxml'],\n",
      "    classifiers=[\n",
      "        'Programming Language :: Python :: 3 :: Only',\n",
      "        'Natural Language :: Korean',\n",
      "        'Operating System :: POSIX :: Linux',\n",
      "        'Operating System :: MacOS :: MacOS X'\n",
      "    ],\n",
      "    long_description=,\n",
      "    long_description_content_type=\"text/markdown\",\n",
      "    python_requires='>=3.4'\n",
      ")\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\codebasic_pyko\\setup.py\n",
      "[]\n",
      "found files: []\n",
      "import inspect\n",
      "import os\n",
      "import tempfile\n",
      "import pytest\n",
      "from nltk.corpus import PlaintextCorpusReader\n",
      "from pyko import tokenizer as _\n",
      "\n",
      "def test_tokenize():\n",
      "     = '   .'\n",
      "    _ = _.tokenize()\n",
      "\n",
      "    expected = ['', '', '', '', '', '', '', '', '', '.']\n",
      "    assert _ == expected\n",
      "\n",
      "    #   \n",
      "    assert not _.tokenize('')\n",
      "\n",
      "def test_corpus_reader():\n",
      "     = \"\"\"(, 1397 5 7 ( 4 10) ~ 1450 3 30( 2 17),  : 1418 ~ 1450)  4  .        ()  .\n",
      " (),  (),  (),  (),  ().  (),  (),    ().   ().\"\"\"\n",
      "\n",
      "    #   \n",
      "    with tempfile.NamedTemporaryFile(mode='w+', encoding='utf8') as fp:\n",
      "        fp.write()\n",
      "        fp.seek(0)\n",
      "         = fp.name\n",
      "         = os.path.dirname()\n",
      "         = os.path.basename()\n",
      "        # #   \n",
      "        reader = PlaintextCorpusReader(root=, fileids=[], word_tokenizer=_)\n",
      "        #   \n",
      "         = reader.words()\n",
      "        assert \n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\codebasic_pyko\\tests\\test_tokenizer.py\n",
      "[]\n",
      "found files: []\n",
      "\"\"\"\n",
      "Copyright (C) 2017-2020 Codebasic\n",
      "Author: Lee Seongjoo <seongjoo@codebasic.io>\n",
      "\"\"\"\n",
      "import itertools\n",
      "import abc\n",
      "import reprlib\n",
      "import re\n",
      "\n",
      "from nltk.corpus import CorpusReader\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "\n",
      "class TokenSeq(abc.ABC):\n",
      "    def __init__(self, fileids, encoding):\n",
      "        self.fileids = fileids\n",
      "        self.encoding = encoding\n",
      "\n",
      "    def __iter__(self):\n",
      "        return itertools.chain(\n",
      "            token for fid in self.fileids for token in self._get_token(fid) if token)\n",
      "\n",
      "    def __len__(self):\n",
      "        if not hasattr(self, 'length'):\n",
      "            self.length = 0\n",
      "            for _ in iter(self):\n",
      "                self.length += 1\n",
      "        return self.length\n",
      "\n",
      "    def __getitem__(self, index):\n",
      "        it = iter(self)\n",
      "        if isinstance(index, slice):\n",
      "            item_it = itertools.islice(it, index.start, index.stop, index.step)\n",
      "            return [token for token in item_it]\n",
      "        else:\n",
      "            item_it = itertools.islice(it, index, index+1)\n",
      "            return next(item_it)\n",
      "\n",
      "    def __repr__(self):\n",
      "        return reprlib.repr([token for token in itertools.islice(iter(self), 10)])\n",
      "\n",
      "    @abc.abstractmethod\n",
      "    def _get_token(self, fileid):\n",
      "        \"\"\"yield a token\"\"\"\n",
      "\n",
      "\n",
      "class SejongCorpusReader(CorpusReader):\n",
      "    \"\"\"\n",
      "    Corpus reader for   (Sejong Corpus)\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, root, fileids, encoding='utf-16'):\n",
      "        super().__init__(root, fileids, encoding)\n",
      "\n",
      "    def words(self, fileids=None, tagged=False, =True):\n",
      "        \"\"\"\n",
      "          \n",
      "\n",
      "        :param fileids:   ID\n",
      "        :type fileids: list[str] or None\n",
      "        :return:  \n",
      "        :rtype: generator\n",
      "        \"\"\"\n",
      "        return SejongWordSeq([fid for fid in self.abspaths(fileids)], encoding=self._encoding, tagged=tagged, =)\n",
      "\n",
      "    def sents(self, fileids=None, tagged=False, =False):\n",
      "        return SejongWordSeq([fid for fid in self.abspaths(fileids)], encoding=self._encoding, tagged=tagged, =, sents=True)\n",
      "\n",
      "\n",
      "class SejongWordSeq(TokenSeq):\n",
      "    def __init__(self, fileids, encoding, tagged, , sents=False):\n",
      "        super().__init__(fileids, encoding)\n",
      "        self._tagged = tagged\n",
      "        self._ = \n",
      "        self._sents = sents\n",
      "\n",
      "    def _get_token(self, fileid):\n",
      "        \"\"\"   \"\"\"\n",
      "        soup = BeautifulSoup(open(fileid, encoding=self.encoding), 'lxml')\n",
      "        body = soup.find('text')\n",
      "        sent_elt = body.find_all(re.compile('^s$|^p$'))\n",
      "\n",
      "        for elt in sent_elt:\n",
      "             = []\n",
      "            if elt.find('note'):\n",
      "                continue  # skip <note>\n",
      "            for line in elt.text.split('\\n'):\n",
      "                raw_token = line.split('\\t')[-2:]\n",
      "                if not raw_token[-1]:\n",
      "                    continue\n",
      "\n",
      "                token = raw_token[0]\n",
      "                #    \n",
      "                if not token:\n",
      "                    continue\n",
      "\n",
      "                 = self._(raw_token)\n",
      "                #      \n",
      "                if not len():\n",
      "                    continue\n",
      "                \n",
      "                if not self._sents:\n",
      "                    if self._tagged:\n",
      "                        yield (token, )\n",
      "                    else:\n",
      "                        yield token\n",
      "                else: #   \n",
      "                    if self._tagged:\n",
      "                        .append((token, ))\n",
      "                    elif self._:\n",
      "                        .extend( for ,  in )\n",
      "                    else:\n",
      "                        .append(token)\n",
      "            \n",
      "            yield \n",
      "\n",
      "    def _(self, raw_token):\n",
      "         = []\n",
      "        for tag in raw_token[-1].split('+'):\n",
      "            try:\n",
      "                , _,  = [ for  in re.split('(/)', tag) if ]\n",
      "            except ValueError:\n",
      "                continue\n",
      "            else:\n",
      "                #   . : __02 --> \n",
      "                 = re.sub(r'__\\d{1,}', '', )\n",
      "                #  \n",
      "                 = .strip()\n",
      "                if not  or not :\n",
      "                    continue\n",
      "                .append((, ))\n",
      "        return tuple()\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\codebasic_pyko\\pyko\\reader.py\n",
      "[]\n",
      "found files: []\n",
      "from typing import List\n",
      "from khaiii import KhaiiiApi\n",
      "\n",
      "_tokenizer = KhaiiiApi()\n",
      "\n",
      "def tokenize(, tagged=False) -> List:\n",
      "     = []\n",
      "    if not .strip():\n",
      "        return \n",
      "\n",
      "     = _tokenizer.analyze()\n",
      "    for _ in :\n",
      "        for  in _.morphs:\n",
      "            if tagged:\n",
      "                .append((.lex, .tag))\n",
      "            else:\n",
      "                .append(.lex)\n",
      "    return \n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\codebasic_pyko\\pyko\\tokenizer.py\n",
      "[]\n",
      "found files: []\n",
      "import os\n",
      "import re\n",
      "import pytest\n",
      "\n",
      "from pyko.reader import SejongCorpusReader\n",
      "\n",
      "\n",
      "CORPUS_ROOT = os.environ['CORPUS_ROOT']\n",
      "SEJONG_CORPUS_PATH = os.path.join(CORPUS_ROOT, 'sejong')\n",
      "\n",
      "@pytest.fixture(scope='module', \n",
      "    params=[r'spoken/word_tag/.+\\.txt', r'written/word_tag/.+\\.txt'])\n",
      "def (request):\n",
      "    return SejongCorpusReader(SEJONG_CORPUS_PATH, request.param)\n",
      "        \n",
      "def test_fileids():\n",
      "    assert .fileids()\n",
      "    \n",
      "def test_words():\n",
      "     = .words(tagged=True)\n",
      "    assert len()\n",
      "    \n",
      "    for ,  in :\n",
      "        assert \n",
      "        assert len()\n",
      "        for ,  in :\n",
      "            assert \n",
      "            assert \n",
      "\n",
      "            #     : __02 --> \n",
      "            assert not re.search(r'__\\d{1,}', )\n",
      "        \n",
      "def test_sents():\n",
      "     = .sents(tagged=True)\n",
      "    # : ['', '', '', '', '', '', '', '', '', '', '.']\n",
      "     = .sents(tagged=False)\n",
      "    \"\"\"\n",
      "    : ['', ' ', '', ' ', '', '', '', '', '', '', '',\n",
      "    '', '', '', '', '', '', '', '', '','.']\n",
      "    \"\"\"\n",
      "     = .sents(tagged=False, =True)\n",
      "\n",
      "    assert len() == len() == len()\n",
      "\n",
      "    for , ,  in zip(, , ):\n",
      "        assert \n",
      "        assert \n",
      "        assert \n",
      "\n",
      "         = [ for ,  in ]\n",
      "         = [ for ,  in  for ,  in ]\n",
      "        assert  == \n",
      "        assert  == \n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\codebasic_pyko\\tests\\test_reader.py\n",
      "[]\n",
      "********************pycgContent*************************\n",
      "[]\n",
      "********************doctrings*************************\n",
      "[]\n",
      "embed index dataset: 7\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\CSVComparisons\\\\mergeAndDestroy.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\CSVComparisons\\\\CSVComparisons.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\TextExtraction.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\finalDev\\\\EntityExtraction.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\finalDev\\\\convert.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\sample.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\convert.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\VerbPhraseTests\\\\ExtractVerbPhrases.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\CSVComparisons\\\\CountRows.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\sampleDev\\\\convert.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\sampleDev\\\\SectionExtraction.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\CSVComparisons\\\\EditDistance.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\CSVComparisons\\\\JWDistance.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\CSVComparisons\\\\EditDistanceDP.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\sampleDev\\\\EntityExtraction.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\sampleDev\\\\pipeline.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\sampleDev\\\\TextExtraction.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\CSVComparisons\\\\parse_csv.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\sampleDev\\\\csvImprove.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\java\\\\manualTokenization\\\\ManualTokens.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\Corporas\\\\deleteEmptyRows.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\carrliitos_NLPInformationExtraction\\\\src\\\\python\\\\SE\\\\main.py']\n",
      "import os\n",
      "import shutil\n",
      "import glob\n",
      "from csv import DictReader, DictWriter\n",
      "from tempfile import NamedTemporaryFile\n",
      "\n",
      "def append_csv(csv_filename, data):\n",
      "\twith open(csv_filename, 'a+') as csv_file:\n",
      "\t\treader = DictReader(csv_file)\n",
      "\t\tnew_keys = set(data.keys()).difference(reader.fieldnames)\n",
      "\t\tif not new_keys:\n",
      "\t\t\tcsv_file.seek(0, os.SEEK_END)\n",
      "\t\t\twriter = DictWriter(csv_file, reader.fieldnames)\n",
      "\t\t\twriter.writerow(data)\n",
      "\t\telse:\n",
      "\t\t\treader.fieldnames.extend(sorted(new_keys))\n",
      "\t\t\twith NamedTemporaryFile(dir='.', delete=False) as csv_tmpfile:\n",
      "\t\t\t\twriter = DictWriter(csv_tmpfile, reader.fieldnames, lineterminator='\\n')\n",
      "\t\t\t\twriter.writeheader()\n",
      "\t\t\t\twriter.writerows(row for row in reader)\n",
      "\t\t\t\twriter.writerow(data)\n",
      "\t\t\tshutil.move(csv_tmpfile.name, csv_filename)\n",
      "\n",
      "def folderWalk(folder_path):\n",
      "\tfor filename in glob.glob(os.path.join(folder_path, '*.csv')):\n",
      "\t\twith open(filename, 'r') as f:\n",
      "\t\t\ttext = f.read()\n",
      "\t\t\tappend_csv(filename, text)\n",
      "\n",
      "def main():\n",
      "\tfolder_path = './NER-OUTPUT'\n",
      "\tfolderWalk(folder_path)\n",
      "\n",
      "main()\n",
      "Output: {'mergeAndDestroy': ['mergeAndDestroy.main'], 'mergeAndDestroy.append_csv': ['csv.DictWriter', '<builtin>.open', 'shutil.move', 'tempfile.NamedTemporaryFile', '<builtin>.sorted', '<builtin>.set', 'csv.DictReader'], '<builtin>.open': [], 'csv.DictReader': [], '<builtin>.set': [], 'csv.DictWriter': [], '<builtin>.sorted': [], 'tempfile.NamedTemporaryFile': [], 'shutil.move': [], 'mergeAndDestroy.folderWalk': ['os.path.join', 'mergeAndDestroy.append_csv', '<builtin>.open', 'glob.glob'], 'os.path.join': [], 'glob.glob': [], 'mergeAndDestroy.main': ['mergeAndDestroy.folderWalk']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\python\\CSVComparisons\\mergeAndDestroy.py\n",
      "[('mergeAndDestroy', 'mergeAndDestroy main'), ('mergeAndDestroy append_csv', 'csv DictWriter'), ('mergeAndDestroy append_csv', 'shutil move'), ('mergeAndDestroy append_csv', 'tempfile NamedTemporaryFile'), ('mergeAndDestroy append_csv', 'csv DictReader'), ('mergeAndDestroy folderWalk', 'os path join'), ('mergeAndDestroy folderWalk', 'mergeAndDestroy append_csv'), ('mergeAndDestroy folderWalk', 'glob glob'), ('mergeAndDestroy main', 'mergeAndDestroy folderWalk')]\n",
      "0\n",
      "found files: []\n",
      "import csv, sys\n",
      "from itertools import zip_longest\n",
      "\n",
      "def main():\n",
      "\tif len(sys.argv) < 3:\n",
      "\t\traise Exception(\"Need two CSVs\")\n",
      "\n",
      "\tcsv1 = sys.argv[1]\n",
      "\tcsv2 = sys.argv[2]\n",
      "\tcsvComparisons(csv1, csv2)\n",
      "\n",
      "\tprint(f\"Succesfully calculated.\")\n",
      "\n",
      "def csvComparisons(csv1, csv2):\n",
      "\twith open(csv1, 'r', newline='') as csv_file1, open(csv2, 'r',\n",
      "\t\t\t\tnewline='') as csv_file2, open('csvComparisons.csv', 'w') as outfile:\n",
      "\t\tcsv_reader1 = csv.reader(csv_file1)\n",
      "\t\tcsv_reader2 = csv.reader(csv_file2)\n",
      "\n",
      "\t\tcsv1_length = 0\n",
      "\t\tcsv2_length = 0\n",
      "\n",
      "\t\tword1_array = []\n",
      "\t\tword2_array = []\n",
      "\n",
      "\t\tfor line in csv_reader1:\n",
      "\t\t\tfor words in line:\n",
      "\t\t\t\tword1_array.append(words)\n",
      "\t\t\t\t# print(f\"{words}: {word_length}\")\n",
      "\t\t\tcsv1_length += 1\n",
      "\n",
      "\t\tfor line in csv_reader2:\n",
      "\t\t\tfor words in line:\n",
      "\t\t\t\tword2_array.append(words)\n",
      "\t\t\t\t# print(f\"{words}: {word_length}\")\n",
      "\t\t\tcsv2_length += 1\n",
      "\n",
      "\t\t# print(f\"CSV 1: {word1_array}\\nCSV 2: {word2_array}\\n\")\n",
      "\t\t# print(f\"CSV 1 length: {csv1_length}\\n\")\n",
      "\t\t# print(f\"CSV 2 length: {csv2_length}\\n\")\n",
      "\n",
      "\t\t# print(\"*****Levenshtein Distance*****\")\n",
      "\t\t# for (string1, string2) in zip_longest(word1_array, word2_array):\n",
      "\t\t# \tprint(f\"edit distance for <{string1}> and <{string2}>: \")\n",
      "\t\t\t\t\n",
      "\t\t# \t# If first string's length is object of type 'NoneType'\n",
      "\t\t# \t# set length to zero\n",
      "\t\t# \tif string1 == None:\n",
      "\t\t# \t\tprint(editDistanceDP(string1, string2, 0, len(string2)))\n",
      "\t\t# \t# If second string's length is object of type 'NoneType'\n",
      "\t\t# \t# set length to zero\n",
      "\t\t# \telif string2 == None:\n",
      "\t\t# \t\tprint(editDistanceDP(string1, string2, len(string1), 0))\n",
      "\t\t# \telse:\n",
      "\t\t# \t\tprint(editDistanceDP(string1, string2, len(string1), len(string2)))\n",
      "\n",
      "\t\t# print(\"\\n*****Jaro and Jaro-Winkler Distances*****\")\n",
      "\t\t# for (string1, string2) in zip_longest(word1_array, word2_array):\n",
      "\t\t# \tprint(f\"Finding distance for <{string1}> and <{string2}>: \\n\"\n",
      "\t\t# \t\tf\"Jaro Distance: {jaroDistance(string1, string1)}\\n\"\n",
      "\t\t# \t\tf\"Jaro-Winkler Distance: {jwDistance(string1, string1)}\\n\")\n",
      "\n",
      "\t\toutfile_writer = csv.writer(outfile, delimiter=',')\n",
      "\t\toutfile_writer.writerow(['string1', 'string2', 'LevenshteinDistance', \n",
      "\t\t\t\t'Jaro', 'JaroWinklerDistance'])\n",
      "\n",
      "\t\tfor (string1, string2) in zip_longest(word1_array, word2_array):\n",
      "\t\t\t# Calculate Levenshtein distance\n",
      "\t\t\t# If first string's length is object of type 'NoneType'\n",
      "\t\t\t# set length to zero\n",
      "\t\t\tif string1 == None:\n",
      "\t\t\t\tlevenshtein = editDistanceDP(string1, string2, 0, len(string2))\n",
      "\t\t\t# If second string's length is object of type 'NoneType'\n",
      "\t\t\t# set length to zero\n",
      "\t\t\telif string2 == None:\n",
      "\t\t\t\tlevenshtein = editDistanceDP(string1, string2, len(string1), 0)\n",
      "\t\t\telse:\n",
      "\t\t\t\tlevenshtein = editDistanceDP(string1, string2, len(string1), len(string2))\n",
      "\n",
      "\t\t\t# Calculate Jaro distance\n",
      "\t\t\tjaro = jaroDistance(string1, string1)\n",
      "\t\t\t# Calculate Jaro-Winkler distance\n",
      "\t\t\tjaroWink = jwDistance(string1, string1)\n",
      "\n",
      "\t\t\t# output the results\n",
      "\t\t\toutfile_writer.writerow([string1, string2, levenshtein, jaro, jaroWink])\n",
      "\n",
      "def make1shorter(str1, str2):\n",
      "\tif len(str1) > len(str2):\n",
      "\t\ttemp = str1\n",
      "\t\tstr1 = str2\n",
      "\t\tstr2 = temp\n",
      "\treturn str1, str2\n",
      "\n",
      "def jaroDistance(str1, str2):\n",
      "\tif len(str1) == 0 or len(str2) == 0:\n",
      "\t\traise Exception(\"No words provided.\")\n",
      "\n",
      "\tstr1, str2 = make1shorter(str1, str2)\n",
      "\n",
      "\tword2chars = list(str2)\n",
      "\tm = 0\n",
      "\tfor char in str1:\n",
      "\t\tif char in word2chars:\n",
      "\t\t\tm += 1\n",
      "\t\t\tword2chars.pop(word2chars.index(char))\n",
      "\n",
      "\tt = 0\n",
      "\tfor i in range(len(str1)):\n",
      "\t\tif str1[i] != str2[i]:\n",
      "\t\t\tt += 1\n",
      "\n",
      "\treturn 1/3*(m/len(str1) + m/len(str2) + (m - t / 2)/m)\n",
      "\n",
      "def jwDistance(str1, str2, p = 0.1, lmax = 4):\n",
      "\tstr1, str2 = make1shorter(str1, str2)\n",
      "\tjDistance = jaroDistance(str1, str2)\n",
      "\n",
      "\tl = 0\n",
      "\tfor i in range(min(len(str1), lmax)):\n",
      "\t\tif str1[i] == str2[i]:\n",
      "\t\t\tl += 1\n",
      "\t\telse:\n",
      "\t\t\tbreak\n",
      "\n",
      "\treturn jDistance + l * p * (1 - jDistance)\n",
      "\n",
      "def editDistanceDP(str1, str2, m, n): \n",
      "\ttable = [[0 for x in range(n + 1)] for x in range(m + 1)] \n",
      "\n",
      "\tfor i in range(m + 1): \n",
      "\t\tfor j in range(n + 1): \n",
      "\t\t\tif i == 0: \n",
      "\t\t\t\ttable[i][j] = j # Min. operations = j \n",
      "\t\t\telif j == 0: \n",
      "\t\t\t\ttable[i][j] = i # Min. operations = i \n",
      "\t\t\telif str1[i-1] == str2[j-1]: \n",
      "\t\t\t\ttable[i][j] = table[i-1][j-1] \n",
      "\t\t\telse: \n",
      "\t\t\t\ttable[i][j] = 1 + min(table[i][j-1],\t# Insert \n",
      "\t\t\t\t\t\t\t\ttable[i-1][j],\t\t \t# Remove \n",
      "\t\t\t\t\t\t\t\ttable[i-1][j-1]) \t\t# Replace \n",
      "\treturn table[m][n]\n",
      "\n",
      "main()\n",
      "Output: {'CSVComparisons': ['CSVComparisons.main'], 'CSVComparisons.main': ['<builtin>.Exception', 'CSVComparisons.csvComparisons', '<builtin>.len', '<builtin>.print'], '<builtin>.len': [], '<builtin>.Exception': [], 'CSVComparisons.csvComparisons': ['CSVComparisons.jwDistance', 'csv.writer', '<builtin>.len', '<builtin>.open', 'CSVComparisons.jaroDistance', 'CSVComparisons.editDistanceDP', 'itertools.zip_longest', 'csv.reader'], '<builtin>.print': [], '<builtin>.open': [], 'csv.reader': [], 'csv.writer': [], 'itertools.zip_longest': [], 'CSVComparisons.editDistanceDP': ['<builtin>.min', '<builtin>.range'], 'CSVComparisons.jaroDistance': ['<builtin>.len', '<builtin>.Exception', 'CSVComparisons.make1shorter', '<builtin>.list', '<builtin>.range'], 'CSVComparisons.jwDistance': ['<builtin>.len', 'CSVComparisons.jaroDistance', '<builtin>.min', 'CSVComparisons.make1shorter', '<builtin>.range'], 'CSVComparisons.make1shorter': ['<builtin>.len'], '<builtin>.list': [], '<builtin>.range': [], '<builtin>.min': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\python\\CSVComparisons\\CSVComparisons.py\n",
      "[('CSVComparisons', 'CSVComparisons main'), ('CSVComparisons main', 'CSVComparisons csvComparisons'), ('CSVComparisons csvComparisons', 'CSVComparisons jwDistance'), ('CSVComparisons csvComparisons', 'csv writer'), ('CSVComparisons csvComparisons', 'CSVComparisons jaroDistance'), ('CSVComparisons csvComparisons', 'CSVComparisons editDistanceDP'), ('CSVComparisons csvComparisons', 'itertools zip_longest'), ('CSVComparisons csvComparisons', 'csv reader'), ('CSVComparisons jaroDistance', 'CSVComparisons make1shorter'), ('CSVComparisons jwDistance', 'CSVComparisons jaroDistance'), ('CSVComparisons jwDistance', 'CSVComparisons make1shorter')]\n",
      "0\n",
      "found files: []\n",
      "import sys\n",
      "from pdfminer.pdfdocument import PDFDocument\n",
      "from pdfminer.pdfparser import PDFParser\n",
      "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
      "from pdfminer.pdfdevice import PDFDevice, TagExtractor\n",
      "from pdfminer.pdfpage import PDFPage\n",
      "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
      "from pdfminer.cmapdb import CMapDB\n",
      "from pdfminer.layout import LAParams\n",
      "from pdfminer.image import ImageWriter\n",
      "\n",
      "# main\n",
      "def main(argv):\n",
      "\timport getopt\n",
      "\tdef usage():\n",
      "\t\tprint(f'usage: {argv[0]} [-P password] [-o output] [-t text|html|xml|tag]'\n",
      "\t\t\t   ' [-O output_dir] [-c encoding] [-s scale] [-R rotation]'\n",
      "\t\t\t   ' [-Y normal|loose|exact] [-p pagenos] [-m maxpages]'\n",
      "\t\t\t   ' [-S] [-C] [-n] [-A] [-V] [-M char_margin] [-L line_margin]'\n",
      "\t\t\t   ' [-W word_margin] [-F boxes_flow] [-d] input.pdf ...')\n",
      "\t\treturn 100\n",
      "\ttry:\n",
      "\t\t(opts, args) = getopt.getopt(argv[1:], 'dP:o:t:O:c:s:R:Y:p:m:SCnAVM:W:L:F:')\n",
      "\texcept getopt.GetoptError:\n",
      "\t\treturn usage()\n",
      "\tif not args: return usage()\n",
      "\t# debug option\n",
      "\tdebug = 0\n",
      "\t# input option\n",
      "\tpassword = b''\n",
      "\tpagenos = set()\n",
      "\tmaxpages = 0\n",
      "\t# output option\n",
      "\toutfile = None\n",
      "\touttype = None\n",
      "\timagewriter = None\n",
      "\trotation = 0\n",
      "\tstripcontrol = False\n",
      "\tlayoutmode = 'normal'\n",
      "\tencoding = 'utf-8'\n",
      "\tpageno = 1\n",
      "\tscale = 1\n",
      "\tcaching = True\n",
      "\tshowpageno = True\n",
      "\tlaparams = LAParams()\n",
      "\tfor (k, v) in opts:\n",
      "\t\tif k == '-d': debug += 1\n",
      "\t\telif k == '-P': password = v.encode('ascii')\n",
      "\t\telif k == '-o': outfile = v\n",
      "\t\telif k == '-t': outtype = v\n",
      "\t\telif k == '-O': imagewriter = ImageWriter(v)\n",
      "\t\telif k == '-c': encoding = v\n",
      "\t\telif k == '-s': scale = float(v)\n",
      "\t\telif k == '-R': rotation = int(v)\n",
      "\t\telif k == '-Y': layoutmode = v\n",
      "\t\telif k == '-p': pagenos.update( int(x)-1 for x in v.split(',') )\n",
      "\t\telif k == '-m': maxpages = int(v)\n",
      "\t\telif k == '-S': stripcontrol = True\n",
      "\t\telif k == '-C': caching = False\n",
      "\t\telif k == '-n': laparams = None\n",
      "\t\telif k == '-A': laparams.all_texts = True\n",
      "\t\telif k == '-V': laparams.detect_vertical = True\n",
      "\t\telif k == '-M': laparams.char_margin = float(v)\n",
      "\t\telif k == '-W': laparams.word_margin = float(v)\n",
      "\t\telif k == '-L': laparams.line_margin = float(v)\n",
      "\t\telif k == '-F': laparams.boxes_flow = float(v)\n",
      "\t#\n",
      "\tPDFDocument.debug = debug\n",
      "\tPDFParser.debug = debug\n",
      "\tCMapDB.debug = debug\n",
      "\tPDFPageInterpreter.debug = debug\n",
      "\t#\n",
      "\trsrcmgr = PDFResourceManager(caching=caching)\n",
      "\tif not outtype:\n",
      "\t\touttype = 'text'\n",
      "\t\tif outfile:\n",
      "\t\t\tif outfile.endswith('.htm') or outfile.endswith('.html'):\n",
      "\t\t\t\touttype = 'html'\n",
      "\t\t\telif outfile.endswith('.xml'):\n",
      "\t\t\t\touttype = 'xml'\n",
      "\t\t\telif outfile.endswith('.tag'):\n",
      "\t\t\t\touttype = 'tag'\n",
      "\tif outfile:\n",
      "\t\toutfp = open(outfile, 'w', encoding='utf-8', errors='replace')\n",
      "\telse:\n",
      "\t\toutfp = sys.stdout\n",
      "\tif outtype == 'text':\n",
      "\t\tdevice = TextConverter(rsrcmgr, outfp, laparams=laparams,\n",
      "\t\t\t\t\t\t\t   imagewriter=imagewriter)\n",
      "\telif outtype == 'xml':\n",
      "\t\tdevice = XMLConverter(rsrcmgr, outfp, laparams=laparams,\n",
      "\t\t\t\t\t\t\t  imagewriter=imagewriter,\n",
      "\t\t\t\t\t\t\t  stripcontrol=stripcontrol)\n",
      "\telif outtype == 'html':\n",
      "\t\tdevice = HTMLConverter(rsrcmgr, outfp, scale=scale,\n",
      "\t\t\t\t\t\t\t   layoutmode=layoutmode, laparams=laparams,\n",
      "\t\t\t\t\t\t\t   imagewriter=imagewriter, debug=debug)\n",
      "\telif outtype == 'tag':\n",
      "\t\tdevice = TagExtractor(rsrcmgr, outfp)\n",
      "\telse:\n",
      "\t\treturn usage()\n",
      "\tfor fname in args:\n",
      "\t\twith open(fname, 'rb') as fp:\n",
      "\t\t\tinterpreter = PDFPageInterpreter(rsrcmgr, device)\n",
      "\t\t\tfor page in PDFPage.get_pages(fp, pagenos,\n",
      "\t\t\t\t\t\t\t\t\t\t  maxpages=maxpages, password=password,\n",
      "\t\t\t\t\t\t\t\t\t\t  caching=caching, check_extractable=True):\n",
      "\t\t\t\tpage.rotate = (page.rotate+rotation) % 360\n",
      "\t\t\t\tinterpreter.process_page(page)\n",
      "\tdevice.close()\n",
      "\toutfp.close()\n",
      "\treturn\n",
      "\n",
      "if __name__ == '__main__': sys.exit(main(sys.argv))\n",
      "Output: {'TextExtraction': ['sys.exit', 'TextExtraction.main'], 'TextExtraction.main': ['pdfminer.image.ImageWriter', '<builtin>.open', 'pdfminer.pdfdevice.TagExtractor', 'pdfminer.pdfpage.PDFPage.get_pages', 'sys.stdout.close', 'pdfminer.converter.XMLConverter', 'pdfminer.converter.HTMLConverter', 'pdfminer.pdfinterp.PDFResourceManager', 'pdfminer.layout.LAParams', 'TextExtraction.main.usage', '<builtin>.set', '<builtin>.int', 'pdfminer.converter.TextConverter', 'pdfminer.pdfinterp.PDFPageInterpreter', '<builtin>.float', 'getopt.getopt'], 'TextExtraction.main.usage': ['<builtin>.print'], '<builtin>.print': [], 'getopt.getopt': [], '<builtin>.set': [], 'pdfminer.layout.LAParams': [], 'pdfminer.image.ImageWriter': [], '<builtin>.float': [], '<builtin>.int': [], 'pdfminer.pdfinterp.PDFResourceManager': [], '<builtin>.open': [], 'pdfminer.converter.TextConverter': [], 'pdfminer.converter.XMLConverter': [], 'pdfminer.converter.HTMLConverter': [], 'pdfminer.pdfdevice.TagExtractor': [], 'pdfminer.pdfinterp.PDFPageInterpreter': [], 'pdfminer.pdfpage.PDFPage.get_pages': [], 'sys.stdout.close': [], 'sys.exit': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\python\\TextExtraction.py\n",
      "[('TextExtraction', 'sys exit'), ('TextExtraction', 'TextExtraction main'), ('TextExtraction main', 'pdfminer image ImageWriter'), ('TextExtraction main', 'pdfminer pdfdevice TagExtractor'), ('TextExtraction main', 'pdfminer pdfpage PDFPage get_pages'), ('TextExtraction main', 'sys stdout close'), ('TextExtraction main', 'pdfminer converter XMLConverter'), ('TextExtraction main', 'pdfminer converter HTMLConverter'), ('TextExtraction main', 'pdfminer pdfinterp PDFResourceManager'), ('TextExtraction main', 'pdfminer layout LAParams'), ('TextExtraction main', 'TextExtraction main usage'), ('TextExtraction main', 'pdfminer converter TextConverter'), ('TextExtraction main', 'pdfminer pdfinterp PDFPageInterpreter'), ('TextExtraction main', 'getopt getopt')]\n",
      "0\n",
      "found files: []\n",
      "import sys\n",
      "import os\n",
      "import spacy\n",
      "import pandas as pd\n",
      "import operator\n",
      "from functools import reduce\n",
      "import csv\n",
      "import sys\n",
      "\n",
      "nlp = spacy.load(\"UWW_NER_TRAUMA\")\n",
      "\n",
      "def main(argv):\n",
      "\tfile = argv\n",
      "\tmy_dict = []\n",
      "\twith open(file, \"r\") as inputText:\n",
      "\t\tfor line in inputText:\n",
      "\t\t\tdoc = nlp(line)\n",
      "\t\t\tfor ent in doc.ents:\n",
      "\t\t\t\t# print(ent.label_, \",\", ent.text)\n",
      "\t\t\t\tmy_dict.append(dict([(ent.label_, ent.text)]))\n",
      "\t\tall_keys = reduce(operator.or_, (d.keys() for d in my_dict))\n",
      "\t\t# print(all_keys)\n",
      "\t\tnewDict = {key: [d.get(key) for d in my_dict] for key in all_keys}\n",
      "\t\t# print(newDict)\n",
      "\n",
      "\t\tdf = pd.DataFrame.from_dict(newDict)\n",
      "\t\t# df.to_csv(sys.argv[2], sep=',', index=False, na_rep=\"null\")\n",
      "\t\tdf.reindex(columns=['B-PI','B-GOAL','B-IM','B-SurgicalPreparation','B-SurgicalProcedure']).to_csv(sys.argv[2], sep=',', index=False, na_rep=\"null\")\n",
      "\n",
      "if __name__ == '__main__': sys.exit(main(sys.argv[1]))\n",
      "Output: {'EntityExtraction': ['EntityExtraction.main', 'sys.exit', 'spacy.load'], 'spacy.load': [], 'EntityExtraction.main': ['<builtin>.dict', 'pandas.DataFrame.from_dict', 'functools.reduce', '<builtin>.open'], '<builtin>.open': [], '<builtin>.dict': [], 'functools.reduce': [], 'pandas.DataFrame.from_dict': [], 'sys.exit': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\finalDev\\EntityExtraction.py\n",
      "[('EntityExtraction', 'EntityExtraction main'), ('EntityExtraction', 'sys exit'), ('EntityExtraction', 'spacy load'), ('EntityExtraction main', 'pandas DataFrame from_dict'), ('EntityExtraction main', 'functools reduce')]\n",
      "0\n",
      "found files: []\n",
      "import sys\n",
      "from pdfminer.pdfdocument import PDFDocument\n",
      "from pdfminer.pdfparser import PDFParser\n",
      "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
      "from pdfminer.pdfpage import PDFPage\n",
      "from pdfminer.converter import TextConverter\n",
      "from pdfminer.cmapdb import CMapDB\n",
      "from pdfminer.layout import LAParams\n",
      "\n",
      "def main(argv):\n",
      "\tdebug = 1\n",
      "\tpassword = b''\n",
      "\tpagenos = set()\n",
      "\tmaxpages = 0\n",
      "\toutfile = None\n",
      "\touttype = \"text\"\n",
      "\timageWriter = None\n",
      "\trotation = 0\n",
      "\tstripcontrol = False\n",
      "\tlayoutmode = 'normal'\n",
      "\tencoding = 'utf-8'\n",
      "\tpageno = 1\n",
      "\tscale = 1\n",
      "\tcaching = True\n",
      "\tshowpageno = True\n",
      "\tlaparams = LAParams()\n",
      "\t#\n",
      "\tPDFDocument.debug = debug\n",
      "\tPDFParser.debug = debug\n",
      "\tCMapDB.debug = debug\n",
      "\tPDFPageInterpreter.debug = debug\n",
      "\t#\n",
      "\tresourceManager = PDFResourceManager(caching=caching)\n",
      "\toutfp = sys.stdout\n",
      "\tdevice = TextConverter(resourceManager, outfp, laparams=laparams,\n",
      "\t\t\t\t\t\t\timagewriter=imageWriter)\n",
      "\t#\n",
      "\tfname = argv\n",
      "\twith open(fname, 'rb') as fp:\n",
      "\t\tinterpreter = PDFPageInterpreter(resourceManager, device)\n",
      "\t\tfor page in PDFPage.get_pages(fp, pagenos,\n",
      "\t\t\t\t\t\t\t\t\t   maxpages=maxpages, password=password,\n",
      "\t\t\t\t\t\t\t\t\t   caching=caching, check_extractable=True):\n",
      "\t\t\tpage.rotate = (page.rotate+rotation) % 360\n",
      "\t\t\tinterpreter.process_page(page)\n",
      "\tdevice.close()\n",
      "\toutfp.close()\n",
      "\treturn\n",
      "\n",
      "if __name__ == '__main__': sys.exit(main(sys.argv[1]))\n",
      "Output: {'convert': ['sys.exit', 'convert.main'], 'convert.main': ['<builtin>.set', 'pdfminer.pdfpage.PDFPage.get_pages', 'pdfminer.pdfinterp.PDFResourceManager', 'pdfminer.layout.LAParams', 'pdfminer.pdfinterp.PDFPageInterpreter', 'sys.stdout.close', 'pdfminer.converter.TextConverter', '<builtin>.open'], '<builtin>.set': [], 'pdfminer.layout.LAParams': [], 'pdfminer.pdfinterp.PDFResourceManager': [], 'pdfminer.converter.TextConverter': [], '<builtin>.open': [], 'pdfminer.pdfinterp.PDFPageInterpreter': [], 'pdfminer.pdfpage.PDFPage.get_pages': [], 'sys.stdout.close': [], 'sys.exit': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\finalDev\\convert.py\n",
      "[('convert', 'sys exit'), ('convert', 'convert main'), ('convert main', 'pdfminer pdfpage PDFPage get_pages'), ('convert main', 'pdfminer pdfinterp PDFResourceManager'), ('convert main', 'pdfminer layout LAParams'), ('convert main', 'pdfminer pdfinterp PDFPageInterpreter'), ('convert main', 'sys stdout close'), ('convert main', 'pdfminer converter TextConverter')]\n",
      "0\n",
      "found files: []\n",
      "import os\n",
      "\n",
      "def fileConvert(file):\n",
      "\tos.system(\"python C:\\\\convert.py C:\\\\input.pdf > C:\\\\output.txt\")\n",
      "\n",
      "directory = f\"sopas/\"\n",
      "\n",
      "def main():\n",
      "\tfor file in os.listdir(directory):\n",
      "\t\t# print(file)\n",
      "\t\t# os.system(\"python convert.py \" + directory + file)\n",
      "\t\tfileConvert(directory + file)\n",
      "\treturn\n",
      "\n",
      "main()\n",
      "Output: {'sample': ['sample.main'], 'sample.fileConvert': ['os.system'], 'os.system': [], 'sample.main': ['os.listdir', 'sample.fileConvert'], 'os.listdir': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\python\\sample.py\n",
      "[('sample', 'sample main'), ('sample fileConvert', 'os system'), ('sample main', 'os listdir'), ('sample main', 'sample fileConvert')]\n",
      "0\n",
      "found files: []\n",
      "import sys\n",
      "from pdfminer.pdfdocument import PDFDocument\n",
      "from pdfminer.pdfparser import PDFParser\n",
      "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
      "from pdfminer.pdfpage import PDFPage\n",
      "from pdfminer.converter import TextConverter\n",
      "from pdfminer.cmapdb import CMapDB\n",
      "from pdfminer.layout import LAParams\n",
      "\n",
      "def main(argv):\n",
      "\tdebug = 1\n",
      "\tpassword = b''\n",
      "\tpagenos = set()\n",
      "\tmaxpages = 0\n",
      "\toutfile = None\n",
      "\touttype = \"text\"\n",
      "\timageWriter = None\n",
      "\trotation = 0\n",
      "\tstripcontrol = False\n",
      "\tlayoutmode = 'normal'\n",
      "\tencoding = 'utf-8'\n",
      "\tpageno = 1\n",
      "\tscale = 1\n",
      "\tcaching = True\n",
      "\tshowpageno = True\n",
      "\tlaparams = LAParams()\n",
      "\t#\n",
      "\tPDFDocument.debug = debug\n",
      "\tPDFParser.debug = debug\n",
      "\tCMapDB.debug = debug\n",
      "\tPDFPageInterpreter.debug = debug\n",
      "\t#\n",
      "\tresourceManager = PDFResourceManager(caching=caching)\n",
      "\toutfp = sys.stdout\n",
      "\tdevice = TextConverter(resourceManager, outfp, laparams=laparams,\n",
      "\t\t\t\t\t\t\timagewriter=imageWriter)\n",
      "\t#\n",
      "\tfname = argv\n",
      "\twith open(fname, 'rb') as fp:\n",
      "\t\tinterpreter = PDFPageInterpreter(resourceManager, device)\n",
      "\t\tfor page in PDFPage.get_pages(fp, pagenos,\n",
      "\t\t\t\t\t\t\t\t\t   maxpages=maxpages, password=password,\n",
      "\t\t\t\t\t\t\t\t\t   caching=caching, check_extractable=True):\n",
      "\t\t\tpage.rotate = (page.rotate+rotation) % 360\n",
      "\t\t\tinterpreter.process_page(page)\n",
      "\tdevice.close()\n",
      "\toutfp.close()\n",
      "\treturn\n",
      "\n",
      "if __name__ == '__main__': sys.exit(main(sys.argv[1]))\n",
      "Output: {'convert': ['convert.main', 'sys.exit'], 'convert.main': ['pdfminer.pdfpage.PDFPage.get_pages', 'pdfminer.converter.TextConverter', '<builtin>.open', 'pdfminer.pdfinterp.PDFResourceManager', 'pdfminer.pdfinterp.PDFPageInterpreter', 'sys.stdout.close', '<builtin>.set', 'pdfminer.layout.LAParams'], '<builtin>.set': [], 'pdfminer.layout.LAParams': [], 'pdfminer.pdfinterp.PDFResourceManager': [], 'pdfminer.converter.TextConverter': [], '<builtin>.open': [], 'pdfminer.pdfinterp.PDFPageInterpreter': [], 'pdfminer.pdfpage.PDFPage.get_pages': [], 'sys.stdout.close': [], 'sys.exit': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\python\\convert.py\n",
      "[('convert', 'convert main'), ('convert', 'sys exit'), ('convert main', 'pdfminer pdfpage PDFPage get_pages'), ('convert main', 'pdfminer converter TextConverter'), ('convert main', 'pdfminer pdfinterp PDFResourceManager'), ('convert main', 'pdfminer pdfinterp PDFPageInterpreter'), ('convert main', 'sys stdout close'), ('convert main', 'pdfminer layout LAParams')]\n",
      "0\n",
      "found files: []\n",
      "# textacy, a library to extract verb phrases based on grammar rules\n",
      "import textacy\n",
      "\n",
      "aboutTalkText = (\"The talk will introduct about Use cases of Natural Language\"\\\n",
      "\t\t\t\t\"Processing in Fintech.\")\n",
      "pattern = r'(<VERB>?<ADV>*<VERB>+)'\n",
      "aboutTalkDoc = textacy.make_spacy_doc(aboutTalkText, lang='en_core_web_sm')\n",
      "# we get error here -- en_core_web_sm is not downloaded\n",
      "\n",
      "verbPhrases = textacy.extract.pos_regex_matches(aboutTalkDoc, pattern)\n",
      "\n",
      "print(\"Print all verb phrases:\")\n",
      "for chunk in verbPhrases:\n",
      "\tprint(chunk.text)\n",
      "\n",
      "print(\"Extract Noun Phrase to explain what nouns are involved\")\n",
      "for chunk in aboutTalkDoc.noun_chunk:\n",
      "\tprint(chunk)\n",
      "Output: {'ExtractVerbPhrases': ['<builtin>.print', 'textacy.make_spacy_doc', 'textacy.extract.pos_regex_matches'], 'textacy.make_spacy_doc': [], 'textacy.extract.pos_regex_matches': [], '<builtin>.print': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\python\\VerbPhraseTests\\ExtractVerbPhrases.py\n",
      "[('ExtractVerbPhrases', 'textacy make_spacy_doc'), ('ExtractVerbPhrases', 'textacy extract pos_regex_matches')]\n",
      "0\n",
      "found files: []\n",
      "import os\n",
      "\n",
      "csv1fileSize = os.stat(\"TEST1.csv\").st_size\n",
      "csv2fileSize = os.stat(\"TEST2.csv\").st_size\n",
      "\n",
      "# Not including the header\n",
      "numRowsCSV1, numRowsCSV2 = -1, -1\n",
      "\n",
      "for row in open(\"TEST1.csv\"):\n",
      "\tnumRowsCSV1 += 1\n",
      "\n",
      "for row in open(\"TEST2.csv\"):\n",
      "\tnumRowsCSV2 += 1\n",
      "\n",
      "print(f\"CSV 1:\\nLength: {str(numRowsCSV1)}\\nSize: {csv1fileSize}\\n\")\n",
      "print(f\"CSV 2:\\nLength: {str(numRowsCSV2)}\\nSize: {csv2fileSize}\\n\")\n",
      "Output: {'CountRows': ['os.stat', '<builtin>.open', '<builtin>.print', '<builtin>.str'], 'os.stat': [], '<builtin>.open': [], '<builtin>.str': [], '<builtin>.print': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\python\\CSVComparisons\\CountRows.py\n",
      "[('CountRows', 'os stat')]\n",
      "0\n",
      "found files: []\n",
      "import sys\n",
      "from pdfminer.pdfdocument import PDFDocument\n",
      "from pdfminer.pdfparser import PDFParser\n",
      "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
      "from pdfminer.pdfpage import PDFPage\n",
      "from pdfminer.converter import TextConverter\n",
      "from pdfminer.cmapdb import CMapDB\n",
      "from pdfminer.layout import LAParams\n",
      "\n",
      "def main(argv):\n",
      "\tdebug = 1\n",
      "\tpassword = b''\n",
      "\tpagenos = set()\n",
      "\tmaxpages = 0\n",
      "\toutfile = None\n",
      "\touttype = \"text\"\n",
      "\timageWriter = None\n",
      "\trotation = 0\n",
      "\tstripcontrol = False\n",
      "\tlayoutmode = 'normal'\n",
      "\tencoding = 'utf-8'\n",
      "\tpageno = 1\n",
      "\tscale = 1\n",
      "\tcaching = True\n",
      "\tshowpageno = True\n",
      "\tlaparams = LAParams()\n",
      "\t#\n",
      "\tPDFDocument.debug = debug\n",
      "\tPDFParser.debug = debug\n",
      "\tCMapDB.debug = debug\n",
      "\tPDFPageInterpreter.debug = debug\n",
      "\t#\n",
      "\tresourceManager = PDFResourceManager(caching=caching)\n",
      "\toutfp = sys.stdout\n",
      "\tdevice = TextConverter(resourceManager, outfp, laparams=laparams,\n",
      "\t\t\t\t\t\t\timagewriter=imageWriter)\n",
      "\t#\n",
      "\tfname = argv\n",
      "\twith open(fname, 'rb') as fp:\n",
      "\t\tinterpreter = PDFPageInterpreter(resourceManager, device)\n",
      "\t\tfor page in PDFPage.get_pages(fp, pagenos,\n",
      "\t\t\t\t\t\t\t\t\t   maxpages=maxpages, password=password,\n",
      "\t\t\t\t\t\t\t\t\t   caching=caching, check_extractable=True):\n",
      "\t\t\tpage.rotate = (page.rotate+rotation) % 360\n",
      "\t\t\tinterpreter.process_page(page)\n",
      "\tdevice.close()\n",
      "\toutfp.close()\n",
      "\treturn\n",
      "\n",
      "if __name__ == '__main__': sys.exit(main(sys.argv[1]))\n",
      "Output: {'convert': ['sys.exit', 'convert.main'], 'convert.main': ['<builtin>.open', '<builtin>.set', 'pdfminer.pdfinterp.PDFPageInterpreter', 'pdfminer.converter.TextConverter', 'pdfminer.pdfpage.PDFPage.get_pages', 'pdfminer.layout.LAParams', 'sys.stdout.close', 'pdfminer.pdfinterp.PDFResourceManager'], '<builtin>.set': [], 'pdfminer.layout.LAParams': [], 'pdfminer.pdfinterp.PDFResourceManager': [], 'pdfminer.converter.TextConverter': [], '<builtin>.open': [], 'pdfminer.pdfinterp.PDFPageInterpreter': [], 'pdfminer.pdfpage.PDFPage.get_pages': [], 'sys.stdout.close': [], 'sys.exit': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\python\\sampleDev\\convert.py\n",
      "[('convert', 'sys exit'), ('convert', 'convert main'), ('convert main', 'pdfminer pdfinterp PDFPageInterpreter'), ('convert main', 'pdfminer converter TextConverter'), ('convert main', 'pdfminer pdfpage PDFPage get_pages'), ('convert main', 'pdfminer layout LAParams'), ('convert main', 'sys stdout close'), ('convert main', 'pdfminer pdfinterp PDFResourceManager')]\n",
      "0\n",
      "found files: []\n",
      "import sys\n",
      "\n",
      "def main(argv):\n",
      "\tfile = argv\n",
      "\ta = []\n",
      "\tout = open(\"OUTPUT.txt\", \"w\")\n",
      "\n",
      "\twith open(file, \"r\") as f:\n",
      "\t\tf = f.readlines()\n",
      "\t\tstart = 0\n",
      "\t\tend = 0\n",
      "\t\tfor(line_number, text) in enumerate(f):\n",
      "\t\t\tif (text.startswith(\"Case pre\")\n",
      "\t\t\t\tor text.startswith(\"Case Pre\") \n",
      "\t\t\t\tor text.startswith(\"Case rep\")\n",
      "\t\t\t\tor text.startswith(\"Case \")\n",
      "\t\t\t\t):\n",
      "\t\t\t\tstart = line_number + 1\n",
      "\t\t\t\ta.append(start)\n",
      "\t\t\tif (text.startswith(\"Discuss\")\n",
      "\t\t\t\tor text.startswith(\"discuss\")\n",
      "\t\t\t\t):\n",
      "\t\t\t\tend = line_number + 1\n",
      "\t\t\t\ta.append(end)\n",
      "\n",
      "\t\tfor first, second in zip(a[0::2], a[1::2]):\n",
      "\t\t\tprint(first, second)\n",
      "\t\t\tfor i in f[first:second]:\n",
      "\t\t\t\tprint(i)\n",
      "\t\t\t\tout.write(i)\n",
      "\n",
      "if __name__ == '__main__': sys.exit(main(sys.argv[1]))\n",
      "Output: {'SectionExtraction': ['SectionExtraction.main', 'sys.exit'], 'SectionExtraction.main': ['<builtin>.enumerate', '<builtin>.print', '<builtin>.open', '<builtin>.zip'], '<builtin>.open': [], '<builtin>.enumerate': [], '<builtin>.zip': [], '<builtin>.print': [], 'sys.exit': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\python\\sampleDev\\SectionExtraction.py\n",
      "[('SectionExtraction', 'SectionExtraction main'), ('SectionExtraction', 'sys exit')]\n",
      "0\n",
      "found files: []\n",
      "# A recursive Python program to find minimum number \n",
      "# operations to convert str1 to str2 \n",
      "def editDistance(str1, str2, m, n): \n",
      "\n",
      "\t# If first string is empty, the only option is to \n",
      "\t# insert all characters of second string into first \n",
      "\tif m == 0:\n",
      "\t\treturn n \n",
      "\n",
      "\t# If second string is empty, the only option is to \n",
      "\t# remove all characters of first string \n",
      "\tif n == 0:\n",
      "\t\treturn m \n",
      "\n",
      "\t# If last characters of two strings are same, nothing \n",
      "\t# much to do. Ignore last characters and get count for \n",
      "\t# remaining strings. \n",
      "\tif str1[m - 1] == str2[n - 1]: \n",
      "\t\treturn editDistance(str1, str2, m - 1, n - 1)\n",
      "\n",
      "\t# If last characters are not same, consider all three \n",
      "\t# operations on last character of first string, recursively \n",
      "\t# compute minimum cost for all three operations and take \n",
      "\t# minimum of three values.\n",
      "\treturn 1 + min(editDistance(str1, str2, m, n - 1), # Insert \n",
      "\t\t\t\teditDistance(str1, str2, m - 1, n), # Remove \n",
      "\t\t\t\teditDistance(str1, str2, m - 1, n - 1) # Replace \n",
      "\t\t\t\t)\n",
      "\n",
      "# Driver program to test the above function \n",
      "str1 = \"Carlitos\" # 8 chars\n",
      "str2 = \"Carolitos\" # 9 chars\n",
      "print(f\"Edit Distance for \\\"{str1}\\\" and \\\"{str2}\\\": \" + str(editDistance(str1, \n",
      "\t\tstr2, len(str1), len(str2))))\n",
      "\n",
      "# Compute similarity score\n",
      "'''\n",
      "\tSimilarity Score = 1 - (edit distance / length of the larger of the two strings)\n",
      "'''\n",
      "Output: {'EditDistance': ['<builtin>.len', 'EditDistance.editDistance', '<builtin>.print', '<builtin>.str'], 'EditDistance.editDistance': ['EditDistance.editDistance', '<builtin>.min'], '<builtin>.min': [], '<builtin>.len': [], '<builtin>.str': [], '<builtin>.print': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\python\\CSVComparisons\\EditDistance.py\n",
      "[('EditDistance', 'EditDistance editDistance'), ('EditDistance editDistance', 'EditDistance editDistance')]\n",
      "0\n",
      "found files: []\n",
      "import sys, csv\n",
      "\n",
      "def main():\n",
      "\tstdoutOrigin=sys.stdout\n",
      "\tsys.stdout = open(\"log.csv\", \"w\")\n",
      "\t\n",
      "\tif len(sys.argv) < 3:\n",
      "\t\traise Exception(\"Need two words\")\n",
      "\n",
      "\tstringA = sys.argv[1]\n",
      "\tstringB = sys.argv[2]\n",
      "\n",
      "\tprint(f\"word 1: {stringA}\\nword 2: {stringB}\\n\"\n",
      "\t\t\tf\"Jaro Distance: {jaroDistance(stringA, stringB)}\\n\"\n",
      "\t\t\tf\"Jaro-Winkler Distance: {jwDistance(stringA, stringB)}\")\n",
      "\n",
      "\tsys.stdout.close()\n",
      "\tsys.stdout = stdoutOrigin\n",
      "\n",
      "def make1shorter(stringA, stringB):\n",
      "\tif len(stringA) > len(stringB):\n",
      "\t\t# Make sure one is shorter\n",
      "\t\ttemp = stringA\n",
      "\t\tstringA = stringB\n",
      "\t\tstringB = temp\n",
      "\treturn stringA, stringB\n",
      "\n",
      "# Given two strings, Jaro Similarity calculates how similar both strings are.\n",
      "# @param stringA and stringB - the two strings to be compared\n",
      "def jaroDistance(stringA, stringB):\n",
      "\t# Check that words exists\n",
      "\tif len(stringA) == 0 or len(stringB) == 0:\n",
      "\t\traise Exception(\"No words provided.\")\n",
      "\t# make sure one is shorter for good comparison\n",
      "\tstringA, stringB = make1shorter(stringA, stringB)\n",
      "\n",
      "\t# we do our comparison of string B against string A\n",
      "\t# we just want to walk along the string of longest of the two which is \n",
      "\t# string B and compare each character to string A and keep track of each\n",
      "\t# matching characters\n",
      "\tword2chars = list(stringB)\n",
      "\tm = 0\n",
      "\tfor char in stringA:\n",
      "\t\tif char in word2chars:\n",
      "\t\t\tm += 1\n",
      "\t\t\tword2chars.pop(word2chars.index(char))\n",
      "\n",
      "\t# counting the transpositions\n",
      "\tt = 0\n",
      "\tfor i in range(len(stringA)):\n",
      "\t\tif stringA[i] != stringB[i]:\n",
      "\t\t\tt += 1\n",
      "\n",
      "\t# Jaro similarity = (1/3) * (m/|sA| + m/|sB| + (m-t)/m)\n",
      "\treturn 1 / 3 * (m / len(stringA) + m / len(stringB) + (m - t) / m)\n",
      "\n",
      "# @param p - constant scaling factor for how much the score is adjusted upwards\n",
      "# \tfor having common prefixes.\n",
      "# @param lmax - length of common prefix at the start of the string up to a max \n",
      "# \tof 4 characters\n",
      "def jwDistance(stringA, stringB, p = 0.1, lmax = 4):\n",
      "\t# normalize strings\n",
      "\tstringA, stringB = make1shorter(stringA, stringB)\n",
      "\t# find Jaro distance\n",
      "\tjDistance = jaroDistance(stringA, stringB)\n",
      "\n",
      "\t# find the amount of common prefixes\n",
      "\tl = 0\n",
      "\tfor i in range(min(len(stringA), lmax)):\n",
      "\t\tif stringA[i] == stringB[i]:\n",
      "\t\t\tl += 1\n",
      "\t\telse:\n",
      "\t\t\tbreak\n",
      "\n",
      "\t# similarity = jaroDistance + l*p(1 - jaroDistance)\n",
      "\treturn jDistance + l * p * (1 - jDistance)\n",
      "\n",
      "main()\n",
      "Output: {'JWDistance': ['JWDistance.main'], 'JWDistance.main': ['JWDistance.jaroDistance', '<builtin>.len', '<builtin>.print', '<builtin>.open', '<builtin>.Exception', 'JWDistance.jwDistance', 'sys.stdout.close'], '<builtin>.open': [], '<builtin>.len': [], '<builtin>.Exception': [], 'JWDistance.jaroDistance': ['<builtin>.list', '<builtin>.len', '<builtin>.range', '<builtin>.Exception', 'JWDistance.make1shorter'], 'JWDistance.jwDistance': ['JWDistance.jaroDistance', '<builtin>.min', '<builtin>.len', '<builtin>.range', 'JWDistance.make1shorter'], '<builtin>.print': [], 'sys.stdout.close': [], 'JWDistance.make1shorter': ['<builtin>.len'], '<builtin>.list': [], '<builtin>.range': [], '<builtin>.min': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\python\\CSVComparisons\\JWDistance.py\n",
      "[('JWDistance', 'JWDistance main'), ('JWDistance main', 'JWDistance jaroDistance'), ('JWDistance main', 'JWDistance jwDistance'), ('JWDistance main', 'sys stdout close'), ('JWDistance jaroDistance', 'JWDistance make1shorter'), ('JWDistance jwDistance', 'JWDistance jaroDistance'), ('JWDistance jwDistance', 'JWDistance make1shorter')]\n",
      "0\n",
      "found files: []\n",
      "# A Dynamic Programming based Python program for edit \n",
      "# distance problem between str1 and str2\n",
      "def editDistanceDP(str1, str2, m, n): \n",
      "\t# Create a table to store results of subproblems \n",
      "\tdp = [[0 for x in range(n + 1)] for x in range(m + 1)] \n",
      "\n",
      "\t# Fill d[][] in bottom up manner \n",
      "\tfor i in range(m + 1): \n",
      "\t\tfor j in range(n + 1): \n",
      "\n",
      "\t\t\t# If first string is empty, only option is to \n",
      "\t\t\t# insert all characters of second string \n",
      "\t\t\tif i == 0: \n",
      "\t\t\t\tdp[i][j] = j # Min. operations = j \n",
      "\n",
      "\t\t\t# If second string is empty, only option is to \n",
      "\t\t\t# remove all characters of second string \n",
      "\t\t\telif j == 0: \n",
      "\t\t\t\tdp[i][j] = i # Min. operations = i \n",
      "\n",
      "\t\t\t# If last characters are same, ignore last char \n",
      "\t\t\t# and recur for remaining string \n",
      "\t\t\telif str1[i-1] == str2[j-1]: \n",
      "\t\t\t\tdp[i][j] = dp[i-1][j-1] \n",
      "\n",
      "\t\t\t# If last character are different, consider all \n",
      "\t\t\t# possibilities and find minimum \n",
      "\t\t\telse: \n",
      "\t\t\t\tdp[i][j] = 1 + min(dp[i][j-1],\t # Insert \n",
      "\t\t\t\t\t\t\t\tdp[i-1][j],\t # Remove \n",
      "\t\t\t\t\t\t\t\tdp[i-1][j-1]) # Replace \n",
      "\n",
      "\treturn dp[m][n] \n",
      "\n",
      "# Driver program \n",
      "str1 = \"Carlitos\"\n",
      "str2 = \"Carliots\"\n",
      "print(f\"Edit Distance for \\\"{str1}\\\" and \\\"{str2}\\\": \" + str(editDistanceDP(str1, str2, len(str1), len(str2))))\n",
      "Output: {'EditDistanceDP': ['EditDistanceDP.editDistanceDP', '<builtin>.str', '<builtin>.len', '<builtin>.print'], 'EditDistanceDP.editDistanceDP': ['<builtin>.range', '<builtin>.min'], '<builtin>.range': [], '<builtin>.min': [], '<builtin>.len': [], '<builtin>.str': [], '<builtin>.print': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\python\\CSVComparisons\\EditDistanceDP.py\n",
      "[('EditDistanceDP', 'EditDistanceDP editDistanceDP')]\n",
      "0\n",
      "found files: []\n",
      "import sys\n",
      "import os\n",
      "import spacy\n",
      "import pandas as pd\n",
      "import operator\n",
      "from functools import reduce\n",
      "import csv\n",
      "import sys\n",
      "\n",
      "nlp = spacy.load(\"UWW_NER_TRAUMA\")\n",
      "\n",
      "def main(argv):\n",
      "\tfile = argv\n",
      "\tmy_dict = []\n",
      "\twith open(file, \"r\") as inputText:\n",
      "\t\tfor line in inputText:\n",
      "\t\t\tdoc = nlp(line)\n",
      "\t\t\tfor ent in doc.ents:\n",
      "\t\t\t\t# print(ent.label_, \",\", ent.text)\n",
      "\t\t\t\tmy_dict.append(dict([(ent.label_, ent.text)]))\n",
      "\t\tall_keys = reduce(operator.or_, (d.keys() for d in my_dict))\n",
      "\t\t# print(all_keys)\n",
      "\t\tnewDict = {key: [d.get(key) for d in my_dict] for key in all_keys}\n",
      "\t\t# print(newDict)\n",
      "\n",
      "\t\tdf = pd.DataFrame.from_dict(newDict)\n",
      "\t\t# df.to_csv(sys.argv[2], sep=',', index=False, na_rep=\"null\")\n",
      "\t\tdf.reindex(columns=['B-PI','B-GOAL','B-IM','B-SurgicalPreparation','B-SurgicalProcedure']).to_csv(sys.argv[2], sep=',', index=False, na_rep=\"null\")\n",
      "\n",
      "if __name__ == '__main__': sys.exit(main(sys.argv[1]))\n",
      "Output: {'EntityExtraction': ['EntityExtraction.main', 'spacy.load', 'sys.exit'], 'spacy.load': [], 'EntityExtraction.main': ['pandas.DataFrame.from_dict', 'functools.reduce', '<builtin>.open', '<builtin>.dict'], '<builtin>.open': [], '<builtin>.dict': [], 'functools.reduce': [], 'pandas.DataFrame.from_dict': [], 'sys.exit': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\carrliitos_NLPInformationExtraction\\src\\python\\sampleDev\\EntityExtraction.py\n",
      "[('EntityExtraction', 'EntityExtraction main'), ('EntityExtraction', 'spacy load'), ('EntityExtraction', 'sys exit'), ('EntityExtraction main', 'pandas DataFrame from_dict'), ('EntityExtraction main', 'functools reduce')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('mergeAndDestroy', 'mergeAndDestroy main'), ('mergeAndDestroy append_csv', 'csv DictWriter'), ('mergeAndDestroy append_csv', 'shutil move'), ('mergeAndDestroy append_csv', 'tempfile NamedTemporaryFile'), ('mergeAndDestroy append_csv', 'csv DictReader'), ('mergeAndDestroy folderWalk', 'os path join'), ('mergeAndDestroy folderWalk', 'mergeAndDestroy append_csv'), ('mergeAndDestroy folderWalk', 'glob glob'), ('mergeAndDestroy main', 'mergeAndDestroy folderWalk')], [('CSVComparisons', 'CSVComparisons main'), ('CSVComparisons main', 'CSVComparisons csvComparisons'), ('CSVComparisons csvComparisons', 'CSVComparisons jwDistance'), ('CSVComparisons csvComparisons', 'csv writer'), ('CSVComparisons csvComparisons', 'CSVComparisons jaroDistance'), ('CSVComparisons csvComparisons', 'CSVComparisons editDistanceDP'), ('CSVComparisons csvComparisons', 'itertools zip_longest'), ('CSVComparisons csvComparisons', 'csv reader'), ('CSVComparisons jaroDistance', 'CSVComparisons make1shorter'), ('CSVComparisons jwDistance', 'CSVComparisons jaroDistance'), ('CSVComparisons jwDistance', 'CSVComparisons make1shorter')], [('TextExtraction', 'sys exit'), ('TextExtraction', 'TextExtraction main'), ('TextExtraction main', 'pdfminer image ImageWriter'), ('TextExtraction main', 'pdfminer pdfdevice TagExtractor'), ('TextExtraction main', 'pdfminer pdfpage PDFPage get_pages'), ('TextExtraction main', 'sys stdout close'), ('TextExtraction main', 'pdfminer converter XMLConverter'), ('TextExtraction main', 'pdfminer converter HTMLConverter'), ('TextExtraction main', 'pdfminer pdfinterp PDFResourceManager'), ('TextExtraction main', 'pdfminer layout LAParams'), ('TextExtraction main', 'TextExtraction main usage'), ('TextExtraction main', 'pdfminer converter TextConverter'), ('TextExtraction main', 'pdfminer pdfinterp PDFPageInterpreter'), ('TextExtraction main', 'getopt getopt')], [('EntityExtraction', 'EntityExtraction main'), ('EntityExtraction', 'sys exit'), ('EntityExtraction', 'spacy load'), ('EntityExtraction main', 'pandas DataFrame from_dict'), ('EntityExtraction main', 'functools reduce')], [('convert', 'sys exit'), ('convert', 'convert main'), ('convert main', 'pdfminer pdfpage PDFPage get_pages'), ('convert main', 'pdfminer pdfinterp PDFResourceManager'), ('convert main', 'pdfminer layout LAParams'), ('convert main', 'pdfminer pdfinterp PDFPageInterpreter'), ('convert main', 'sys stdout close'), ('convert main', 'pdfminer converter TextConverter')], [('sample', 'sample main'), ('sample fileConvert', 'os system'), ('sample main', 'os listdir'), ('sample main', 'sample fileConvert')], [('convert', 'convert main'), ('convert', 'sys exit'), ('convert main', 'pdfminer pdfpage PDFPage get_pages'), ('convert main', 'pdfminer converter TextConverter'), ('convert main', 'pdfminer pdfinterp PDFResourceManager'), ('convert main', 'pdfminer pdfinterp PDFPageInterpreter'), ('convert main', 'sys stdout close'), ('convert main', 'pdfminer layout LAParams')], [('ExtractVerbPhrases', 'textacy make_spacy_doc'), ('ExtractVerbPhrases', 'textacy extract pos_regex_matches')], [('CountRows', 'os stat')], [('convert', 'sys exit'), ('convert', 'convert main'), ('convert main', 'pdfminer pdfinterp PDFPageInterpreter'), ('convert main', 'pdfminer converter TextConverter'), ('convert main', 'pdfminer pdfpage PDFPage get_pages'), ('convert main', 'pdfminer layout LAParams'), ('convert main', 'sys stdout close'), ('convert main', 'pdfminer pdfinterp PDFResourceManager')], [('SectionExtraction', 'SectionExtraction main'), ('SectionExtraction', 'sys exit')], [('EditDistance', 'EditDistance editDistance'), ('EditDistance editDistance', 'EditDistance editDistance')], [('JWDistance', 'JWDistance main'), ('JWDistance main', 'JWDistance jaroDistance'), ('JWDistance main', 'JWDistance jwDistance'), ('JWDistance main', 'sys stdout close'), ('JWDistance jaroDistance', 'JWDistance make1shorter'), ('JWDistance jwDistance', 'JWDistance jaroDistance'), ('JWDistance jwDistance', 'JWDistance make1shorter')], [('EditDistanceDP', 'EditDistanceDP editDistanceDP')], [('EntityExtraction', 'EntityExtraction main'), ('EntityExtraction', 'spacy load'), ('EntityExtraction', 'sys exit'), ('EntityExtraction main', 'pandas DataFrame from_dict'), ('EntityExtraction main', 'functools reduce')]]\n",
      "********************doctrings*************************\n",
      "['append csv folder alk main', 'main csv omparisons make1shorter jaro istance jw istance edit istance', 'main', 'main', 'main', 'file onvert main', 'main', '', '', 'main', 'main', 'edit istance', 'main make1shorter jaro istance jw istance', 'edit istance', 'main']\n",
      "embed index dataset: 8\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pemagrg1_Japanese-NLP\\\\Japanese Part of Speech\\\\test.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pemagrg1_Japanese-NLP\\\\Japanese Text Classification\\\\ja_word_tokenize.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pemagrg1_Japanese-NLP\\\\Japanese Text Preprocessing\\\\ja_word_tokenize.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pemagrg1_Japanese-NLP\\\\Japanese Text Classification\\\\ja_text_classifier.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pemagrg1_Japanese-NLP\\\\Japanese Text Preprocessing\\\\test.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pemagrg1_Japanese-NLP\\\\Japanese Text Preprocessing\\\\ja_sentence_tokenize.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pemagrg1_Japanese-NLP\\\\Japanese Sentence Similarity\\\\ja_word_tokenize.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pemagrg1_Japanese-NLP\\\\Japanese Word Similarity\\\\ja_word_similarity.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pemagrg1_Japanese-NLP\\\\Japanese Named Entity Recognition\\\\JapaneseNER_using_spacy.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pemagrg1_Japanese-NLP\\\\Japanese Part of Speech\\\\mecab_pos.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pemagrg1_Japanese-NLP\\\\Japanese Sentence Similarity\\\\ja_sentence_similarity.py']\n",
      "from mecab_pos import POSTagger\n",
      "\n",
      "mecab_pos = POSTagger()\n",
      "pos_tags =  mecab_pos.pos_tag(\"\")\n",
      "print (pos_tags)\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pemagrg1_Japanese-NLP\\Japanese Part of Speech\\test.py\n",
      "[]\n",
      "found files: []\n",
      "import MeCab\n",
      "from collections import namedtuple\n",
      "\n",
      "Morpheme = namedtuple(\"Morpheme\", \"surface pos pos_s1 pos_s2 pos_s3 conj form\")\n",
      "\n",
      "\n",
      "class Tokenizer:\n",
      "    \"\"\"\n",
      "\n",
      "    \"\"\"\n",
      "    def __init__(self, **kwargs):\n",
      "        \"\"\"\n",
      "\n",
      "        Args:\n",
      "            **kwargs:\n",
      "        \"\"\"\n",
      "        self.__mecab = MeCab.Tagger(**kwargs)\n",
      "        self.__mecab.parse(\"Initialize parse.\")\n",
      "\n",
      "    def tokenize(self, text):\n",
      "        \"\"\"\n",
      "\n",
      "        Args:\n",
      "            text:\n",
      "\n",
      "        Returns:\n",
      "\n",
      "        \"\"\"\n",
      "        return [m.surface for m in self.__iter_morpheme(text)]\n",
      "\n",
      "    def tokenize_with_nlp(self, text):\n",
      "        \"\"\"\n",
      "\n",
      "                Args:\n",
      "                    text:\n",
      "\n",
      "                Returns:\n",
      "\n",
      "                \"\"\"\n",
      "        return [m for m in self.__iter_morpheme(text)]\n",
      "\n",
      "    def __iter_morpheme(self, text):\n",
      "        \"\"\"\n",
      "\n",
      "        Args:\n",
      "            text:\n",
      "\n",
      "        Returns:\n",
      "\n",
      "        \"\"\"\n",
      "        node = self.__mecab.parseToNode(text)\n",
      "        node = node.next\n",
      "        while node:\n",
      "            surface = node.surface.encode('utf-8')[:node.length].decode('utf-8')\n",
      "            features = node.feature.split(\",\")\n",
      "            if surface != \"\":\n",
      "                yield Morpheme(surface, *features[:6])\n",
      "\n",
      "            node = node.next\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#################TEST#################\n",
      "# mecab_tokenizer = Tokenizer()\n",
      "# tokens =  mecab_tokenizer.tokenize(\"\")\n",
      "# print (tokens)\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pemagrg1_Japanese-NLP\\Japanese Text Classification\\ja_word_tokenize.py\n",
      "[]\n",
      "found files: []\n",
      "import MeCab\n",
      "from collections import namedtuple\n",
      "\n",
      "Morpheme = namedtuple(\"Morpheme\", \"surface pos pos_s1 pos_s2 pos_s3 conj form\")\n",
      "\n",
      "\n",
      "class Tokenizer:\n",
      "    \"\"\"\n",
      "\n",
      "    \"\"\"\n",
      "    def __init__(self, **kwargs):\n",
      "        \"\"\"\n",
      "\n",
      "        Args:\n",
      "            **kwargs:\n",
      "        \"\"\"\n",
      "        self.__mecab = MeCab.Tagger(**kwargs)\n",
      "        self.__mecab.parse(\"Initialize parse.\")\n",
      "\n",
      "    def tokenize(self, text):\n",
      "        \"\"\"\n",
      "\n",
      "        Args:\n",
      "            text:\n",
      "\n",
      "        Returns:\n",
      "\n",
      "        \"\"\"\n",
      "        return [m.surface for m in self.__iter_morpheme(text)]\n",
      "\n",
      "    def tokenize_with_nlp(self, text):\n",
      "        \"\"\"\n",
      "\n",
      "                Args:\n",
      "                    text:\n",
      "\n",
      "                Returns:\n",
      "\n",
      "                \"\"\"\n",
      "        return [m for m in self.__iter_morpheme(text)]\n",
      "\n",
      "    def __iter_morpheme(self, text):\n",
      "        \"\"\"\n",
      "\n",
      "        Args:\n",
      "            text:\n",
      "\n",
      "        Returns:\n",
      "\n",
      "        \"\"\"\n",
      "        node = self.__mecab.parseToNode(text)\n",
      "        node = node.next\n",
      "        while node:\n",
      "            surface = node.surface.encode('utf-8')[:node.length].decode('utf-8')\n",
      "            features = node.feature.split(\",\")\n",
      "            if surface != \"\":\n",
      "                yield Morpheme(surface, *features[:6])\n",
      "\n",
      "            node = node.next\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#################TEST#################\n",
      "# mecab_tokenizer = Tokenizer()\n",
      "# tokens =  mecab_tokenizer.tokenize(\"\")\n",
      "# print (tokens)\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pemagrg1_Japanese-NLP\\Japanese Text Preprocessing\\ja_word_tokenize.py\n",
      "[]\n",
      "found files: []\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "import pandas as pd\n",
      "from ja_word_tokenize import Tokenizer\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn import svm\n",
      "\n",
      "me = Tokenizer()\n",
      "\n",
      "def test_accuracy(xTestvect,yTestvect,model):\n",
      "    ypred = model.predict(xTestvect)\n",
      "    score = accuracy_score(yTestvect, ypred)\n",
      "    return score\n",
      "\n",
      "def test_text(text,model):\n",
      "    yPred = model.predict(vect.transform([text]))\n",
      "    return yPred\n",
      "\n",
      "def data_details(df):\n",
      "    print(\"================DATA DETAILS==============\")\n",
      "    print(\"TOTAL RECORDS:\", len(df))\n",
      "    print(\"COUNT OF EACH CATEGORY IN THE DATA\")\n",
      "    print(df.CARETYPE.value_counts())\n",
      "    print(\"==\" * 20)\n",
      "\n",
      "def word_tokenize(text):\n",
      "    return me.tokenize(text)\n",
      "\n",
      "vect = TfidfVectorizer(tokenizer= lambda x: word_tokenize(x),sublinear_tf=True, encoding='utf-8',\n",
      "                                  decode_error='ignore',\n",
      "                                 )\n",
      "\n",
      "df = pd.read_csv(\"<path_to_train_csv>\")\n",
      "test_df = pd.read_csv(\"<path_to_test_csv>\")\n",
      "data_details(df)\n",
      "\n",
      "X_train_data = vect.fit_transform( df[\"TEXT\"].values.astype('U'))\n",
      "Y_train_data = df[\"LABEL\"]\n",
      "xTestvect = vect.transform(test_df['TEXT'].values.astype('U'))\n",
      "yTestvect = test_df['LABEL']\n",
      "\n",
      "model = svm.SVC(gamma='scale', decision_function_shape='ovo') #74%\n",
      "model.fit(X_train_data, Y_train_data)\n",
      "\n",
      "print (\"ACCURACY: \",test_accuracy(xTestvect,yTestvect,model))\n",
      "while True:\n",
      "    text = input(\">\")\n",
      "    print (\"TEST:\",test_text(text,model))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pemagrg1_Japanese-NLP\\Japanese Text Classification\\ja_text_classifier.py\n",
      "[]\n",
      "found files: []\n",
      "from ja_word_tokenize import Tokenizer\n",
      "from ja_sentence_tokenize import SentenceTokenizer\n",
      "\n",
      "sent_tokenizer = SentenceTokenizer()\n",
      "mecab_tokenizer = Tokenizer()\n",
      "\n",
      "tokens =  mecab_tokenizer.tokenize(\"\")\n",
      "print (tokens)\n",
      "\n",
      "sentence_tokens = sent_tokenizer.tokenize(\"\")\n",
      "print (sentence_tokens)\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pemagrg1_Japanese-NLP\\Japanese Text Preprocessing\\test.py\n",
      "[]\n",
      "found files: []\n",
      "\"\"\"Sentence Tokenizer part of tiny Tokenizer\"\"\"\n",
      "import re\n",
      "\n",
      "\n",
      "class SentenceTokenizer:\n",
      "    PERIOD = \"\"\n",
      "    PERIOD_SPECIAL = \"__PERIOD__\"\n",
      "\n",
      "    def __init__(self):\n",
      "        pass\n",
      "\n",
      "    @staticmethod\n",
      "    def conv_period(item):\n",
      "        return item.group(0).replace(SentenceTokenizer.PERIOD, \"__PERIOD__\")\n",
      "\n",
      "    def tokenize(self, document):\n",
      "        \"\"\"\n",
      "        Divide a raw document into sentences.\n",
      "        :param document: a raw document\n",
      "        :type document: str\n",
      "        :return: list of sentences\n",
      "        :rtype list[str]\n",
      "        \"\"\"\n",
      "        pattern = r\".*?\"\n",
      "        pattern = re.compile(pattern)\n",
      "        document = re.sub(pattern, self.conv_period, document)\n",
      "\n",
      "        pattern = r\".*?\"\n",
      "        pattern = re.compile(pattern)\n",
      "        document = re.sub(pattern, self.conv_period, document)\n",
      "\n",
      "        result = []\n",
      "        for line in document.split(\"\\n\"):\n",
      "            line = line.rstrip()\n",
      "            line = line.replace(\"\\n\", \"\")\n",
      "            line = line.replace(\"\\r\", \"\")\n",
      "            line = line.replace(\"\", \"\\n\")\n",
      "            sentences = line.split(\"\\n\")\n",
      "\n",
      "            for sentence in sentences:\n",
      "                if not sentence:\n",
      "                    continue\n",
      "\n",
      "                period_special = SentenceTokenizer.PERIOD_SPECIAL\n",
      "                period = SentenceTokenizer.PERIOD\n",
      "                sentence = sentence.replace(period_special, period)\n",
      "                result.append(sentence)\n",
      "\n",
      "        return result\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pemagrg1_Japanese-NLP\\Japanese Text Preprocessing\\ja_sentence_tokenize.py\n",
      "[]\n",
      "found files: []\n",
      "import MeCab\n",
      "from collections import namedtuple\n",
      "\n",
      "Morpheme = namedtuple(\"Morpheme\", \"surface pos pos_s1 pos_s2 pos_s3 conj form\")\n",
      "\n",
      "\n",
      "class Tokenizer:\n",
      "    \"\"\"\n",
      "\n",
      "    \"\"\"\n",
      "    def __init__(self, **kwargs):\n",
      "        \"\"\"\n",
      "\n",
      "        Args:\n",
      "            **kwargs:\n",
      "        \"\"\"\n",
      "        self.__mecab = MeCab.Tagger(**kwargs)\n",
      "        self.__mecab.parse(\"Initialize parse.\")\n",
      "\n",
      "    def tokenize(self, text):\n",
      "        \"\"\"\n",
      "\n",
      "        Args:\n",
      "            text:\n",
      "\n",
      "        Returns:\n",
      "\n",
      "        \"\"\"\n",
      "        return [m.surface for m in self.__iter_morpheme(text)]\n",
      "\n",
      "    def tokenize_with_nlp(self, text):\n",
      "        \"\"\"\n",
      "\n",
      "                Args:\n",
      "                    text:\n",
      "\n",
      "                Returns:\n",
      "\n",
      "                \"\"\"\n",
      "        return [m for m in self.__iter_morpheme(text)]\n",
      "\n",
      "    def __iter_morpheme(self, text):\n",
      "        \"\"\"\n",
      "\n",
      "        Args:\n",
      "            text:\n",
      "\n",
      "        Returns:\n",
      "\n",
      "        \"\"\"\n",
      "        node = self.__mecab.parseToNode(text)\n",
      "        node = node.next\n",
      "        while node:\n",
      "            surface = node.surface.encode('utf-8')[:node.length].decode('utf-8')\n",
      "            features = node.feature.split(\",\")\n",
      "            if surface != \"\":\n",
      "                yield Morpheme(surface, *features[:6])\n",
      "\n",
      "            node = node.next\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#################TEST#################\n",
      "# mecab_tokenizer = Tokenizer()\n",
      "# tokens =  mecab_tokenizer.tokenize(\"\")\n",
      "# print (tokens)\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pemagrg1_Japanese-NLP\\Japanese Sentence Similarity\\ja_word_tokenize.py\n",
      "[]\n",
      "found files: []\n",
      "import gensim\n",
      "\n",
      "\n",
      "w2v_path = \"ja.text.model\"\n",
      "w2v_model =gensim.models.Word2Vec.load(w2v_path)\n",
      "\n",
      "word1 = \"\"\n",
      "word2 = \"\"\n",
      "\n",
      "similarity_score = w2v_model.similarity(word1,word2)\n",
      "print (\"Similarity score:\",similarity_score)\n",
      "\"\"\"\n",
      "Similarity score: 0.74636817\n",
      "\"\"\"\n",
      "print (\"Most similar word to word1\",w2v_model.most_similar([word1]))\n",
      "\"\"\"\n",
      "Most similar word to word1 [('', 0.7914901971817017), ('', 0.7463681697845459), ('', 0.6963348388671875), ('', 0.6686856746673584), ('', 0.6619090437889099), ('', 0.6546213626861572), ('', 0.6422077417373657), ('', 0.6295166015625), ('', 0.6250226497650146), ('', 0.6183037757873535)]\n",
      "\"\"\"\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pemagrg1_Japanese-NLP\\Japanese Word Similarity\\ja_word_similarity.py\n",
      "[]\n",
      "found files: []\n",
      "\"\"\"\n",
      "pip install spacy[ja]\n",
      "! python -m spacy download ja_core_news_lg\n",
      "\n",
      "\"\"\"\n",
      "import spacy\n",
      "\n",
      "\n",
      "ja_nlp = spacy.load(\"ja_core_news_lg\")\n",
      "\n",
      "doc1 = ja_nlp(\"\")\n",
      "\n",
      "try:\n",
      "    for ent in doc1.ents:\n",
      "        print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
      "except Exception as e:\n",
      "    print(e)\n",
      "\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pemagrg1_Japanese-NLP\\Japanese Named Entity Recognition\\JapaneseNER_using_spacy.py\n",
      "[]\n",
      "found files: []\n",
      "import MeCab\n",
      "from collections import namedtuple\n",
      "\n",
      "Morpheme = namedtuple(\"Morpheme\", \"surface pos pos_s1 pos_s2 pos_s3 conj form\")\n",
      "\n",
      "\n",
      "class POSTagger:\n",
      "    \"\"\"\n",
      "\n",
      "    \"\"\"\n",
      "    def __init__(self, **kwargs):\n",
      "        \"\"\"\n",
      "\n",
      "        Args:\n",
      "            **kwargs:\n",
      "        \"\"\"\n",
      "        self.__mecab = MeCab.Tagger(**kwargs)\n",
      "        self.__mecab.parse(\"Initialize parse.\")\n",
      "\n",
      "    def pos_tag(self, text):\n",
      "        \"\"\"\n",
      "\n",
      "        Args:\n",
      "            text:\n",
      "\n",
      "        Returns:\n",
      "\n",
      "        \"\"\"\n",
      "        dict = {}\n",
      "        for m in self.__iter_morpheme(text):\n",
      "            if m.surface != \"\":\n",
      "               dict[m.surface]=m.pos\n",
      "        return dict\n",
      "        # return [m.surface for m in self.__iter_morpheme(text)]\n",
      "\n",
      "\n",
      "    def __iter_morpheme(self, text):\n",
      "        \"\"\"\n",
      "\n",
      "        Args:\n",
      "            text:\n",
      "\n",
      "        Returns:\n",
      "\n",
      "        \"\"\"\n",
      "        node = self.__mecab.parseToNode(text)\n",
      "        node = node.next\n",
      "        while node:\n",
      "            surface = node.surface.encode('utf-8')[:node.length].decode('utf-8')\n",
      "            features = node.feature.split(\",\")\n",
      "            yield Morpheme(surface, *features[:6])\n",
      "\n",
      "            node = node.next\n",
      "\n",
      "###TEST####\n",
      "# mecab_pos = POSTagger()\n",
      "# pos_tags =  mecab_pos.pos_tag(\"\")\n",
      "# print (pos_tags)\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pemagrg1_Japanese-NLP\\Japanese Part of Speech\\mecab_pos.py\n",
      "[]\n",
      "found files: []\n",
      "import numpy as np\n",
      "from ja_word_tokenize import Tokenizer\n",
      "import gensim\n",
      "\n",
      "mecab_tokenizer = Tokenizer()\n",
      "\n",
      "w2v_path = \"ja.model\"\n",
      "w2v_model =gensim.models.Word2Vec.load(w2v_path)\n",
      "\n",
      "class DocSim(object):\n",
      "    def __init__(self, w2v_model ):\n",
      "        self.w2v_model = w2v_model\n",
      "\n",
      "    def vectorize(self, doc):\n",
      "        \"\"\"Identify the vector values for each word in the given document\"\"\"\n",
      "        doc = doc.lower()\n",
      "        words = [w for w in mecab_tokenizer.tokenize(doc)]\n",
      "        word_vecs = []\n",
      "        for word in words:\n",
      "            try:\n",
      "                vec = self.w2v_model[word]\n",
      "                word_vecs.append(vec)\n",
      "            except KeyError:\n",
      "                # Ignore, if the word doesn't exist in the vocabulary\n",
      "                pass\n",
      "\n",
      "        # Assuming that document vector is the mean of all the word vectors\n",
      "        # PS: There are other & better ways to do it.\n",
      "        vector = np.mean(word_vecs, axis=0)\n",
      "        return vector\n",
      "\n",
      "\n",
      "    def _cosine_sim(self, vecA, vecB):\n",
      "        \"\"\"Find the cosine similarity distance between two vectors.\"\"\"\n",
      "        csim = np.dot(vecA, vecB) / (np.linalg.norm(vecA) * np.linalg.norm(vecB))\n",
      "        if np.isnan(np.sum(csim)):\n",
      "            return 0\n",
      "        return csim\n",
      "\n",
      "    def calculate_similarity(self, source_doc, target_docs=[], threshold=0):\n",
      "        \"\"\"Calculates & returns similarity scores between given source document & all\n",
      "        the target documents.\"\"\"\n",
      "        if isinstance(target_docs, str):\n",
      "            target_docs = [target_docs]\n",
      "\n",
      "        source_vec = self.vectorize(source_doc)\n",
      "        results = []\n",
      "        for doc in target_docs:\n",
      "            target_vec = self.vectorize(doc)\n",
      "            sim_score = self._cosine_sim(source_vec, target_vec)\n",
      "            if sim_score > threshold:\n",
      "                results.append({\n",
      "                    'score' : sim_score,\n",
      "                    'doc' : doc\n",
      "                })\n",
      "            # Sort results by score in desc order\n",
      "            results.sort(key=lambda k : k['score'] , reverse=True)\n",
      "\n",
      "        return results\n",
      "\n",
      "\n",
      "ds = DocSim(w2v_model)\n",
      "test_doc = \"\"\n",
      "docs = [\n",
      "    \"\",\n",
      "    \"\",\n",
      "    \"\",\n",
      "    \"\",\n",
      "    \"\",\n",
      "    \"\"]\n",
      "print (\"===Similarty score for \",test_doc+\"with other docs===\")\n",
      "sim_scores = ds.calculate_similarity(test_doc, docs)\n",
      "for i in sim_scores:\n",
      "  print (i)\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pemagrg1_Japanese-NLP\\Japanese Sentence Similarity\\ja_sentence_similarity.py\n",
      "[]\n",
      "********************pycgContent*************************\n",
      "[]\n",
      "********************doctrings*************************\n",
      "[]\n",
      "embed index dataset: 9\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\LehiChiang_CV_toolkit\\\\dataset_converter\\\\mo.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\LehiChiang_CV_toolkit\\\\dataset_converter\\\\gtxt.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\LehiChiang_CV_toolkit\\\\choose_label\\\\main.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\LehiChiang_CV_toolkit\\\\image_generator\\\\index.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\LehiChiang_CV_toolkit\\\\image_downloader\\\\downloader.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\LehiChiang_CV_toolkit\\\\dataset_converter\\\\voc2yolo.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\LehiChiang_CV_toolkit\\\\choose_label\\\\gui\\\\CenterPanel.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\LehiChiang_CV_toolkit\\\\dataset_converter\\\\voc2coco.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\LehiChiang_CV_toolkit\\\\dataset_converter\\\\data_split.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\LehiChiang_CV_toolkit\\\\drawing_bounding_box\\\\index.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\LehiChiang_CV_toolkit\\\\choose_label\\\\thread\\\\mkdirThread.py']\n",
      "import xml.etree.ElementTree as ET\n",
      "import os\n",
      "\n",
      "# xml\n",
      "xml_dir = 'D:\\\\yolo\\\\coco\\\\annotations\\\\valset'\n",
      "list_fp = os.listdir(xml_dir)\n",
      "for line in list_fp:\n",
      "    line = line.strip()\n",
      "    xml_f = os.path.join(xml_dir, line)\n",
      "    tree = ET.parse(xml_f)\n",
      "    root = tree.getroot()\n",
      "    path = root.findall('filename') # filename\n",
      "    if not path:\n",
      "        print(line, '')\n",
      "        filename = line.split('.')[0] + '.jpg'\n",
      "        node = ET.Element('filename')\n",
      "        node.text = filename\n",
      "        root.append(node)\n",
      "        tree.write(xml_f, encoding='utf-8', xml_declaration=True)\n",
      "\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\LehiChiang_CV_toolkit\\dataset_converter\\mo.py\n",
      "[]\n",
      "found files: []\n",
      "import os\n",
      "\n",
      "# testsettrainsetvalset\n",
      "# txt\n",
      "\n",
      "ftest = open('D:\\\\yolo\\\\coco\\\\annotations\\\\testset.txt', 'w')\n",
      "ftrain = open('D:\\\\yolo\\\\coco\\\\annotations\\\\trainset.txt', 'w')\n",
      "fval = open('D:\\\\yolo\\\\coco\\\\annotations\\\\valset.txt', 'w')\n",
      "\n",
      "testset = os.listdir('D:\\\\yolo\\\\coco\\\\annotations\\\\testset')\n",
      "for name in testset:\n",
      "    name = name + '\\n'\n",
      "    ftest.write(name)\n",
      "ftest.close()\n",
      "\n",
      "trainset = os.listdir('D:\\\\yolo\\\\coco\\\\annotations\\\\trainset')\n",
      "for name in trainset:\n",
      "    name = name + '\\n'\n",
      "    ftrain.write(name)\n",
      "ftrain.close()\n",
      "\n",
      "valset = os.listdir('D:\\\\yolo\\\\coco\\\\annotations\\\\valset')\n",
      "for name in valset:\n",
      "    name = name + '\\n'\n",
      "    fval.write(name)\n",
      "fval.close()\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\LehiChiang_CV_toolkit\\dataset_converter\\gtxt.py\n",
      "[]\n",
      "found files: []\n",
      "import glob\n",
      "import os\n",
      "import sys\n",
      "\n",
      "from qtawesome import icon\n",
      "from PyQt5.QtCore import Qt\n",
      "from PyQt5.QtWidgets import QApplication, QMainWindow, QAction, QToolBar, QDesktopWidget, QLabel, \\\n",
      "    QFileDialog\n",
      "from PyQt5.QtGui import QCursor\n",
      "\n",
      "from gui.CenterPanel import CenterWidget\n",
      "from thread.mkdirThread import makeDirThread, copyFileThread\n",
      "\n",
      "\n",
      "class Choose_Label_MainWIndow(QMainWindow):\n",
      "\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.imagefilepath = ''\n",
      "        self.annotationfilepath = ''\n",
      "        self.savepath = ''\n",
      "        self.currentIndex = 0\n",
      "        self.tmppath = os.getcwd()\n",
      "        self.iconsizenum = 25\n",
      "        self.widthRatio = 0.65\n",
      "        self.heightRatio = 0.7\n",
      "        desktop = QApplication.desktop()\n",
      "        self.winWidth = desktop.width()\n",
      "        self.winHeight = desktop.height()\n",
      "        self.screenWidth = self.winWidth * self.widthRatio\n",
      "        self.screenHeight = self.winHeight * self.heightRatio\n",
      "        self.initUI()\n",
      "\n",
      "    def initUI(self):\n",
      "        self.statusBar()\n",
      "        self.initAction()\n",
      "        self.Creat_Menu()\n",
      "        self.Creat_ToolBar()\n",
      "        self.resize(self.screenWidth, self.screenHeight)\n",
      "        self.centerWidget = CenterWidget()\n",
      "        self.setCentralWidget(self.centerWidget)\n",
      "        self.setWindowTitle('Chestimouse')\n",
      "        self.show()\n",
      "\n",
      "    def Creat_Menu(self):\n",
      "        self.menu = self.menuBar()\n",
      "\n",
      "        fileMenu = self.menu.addMenu('&')\n",
      "        fileMenu.addAction(self.exitAction)\n",
      "\n",
      "    def initAction(self):\n",
      "        self.preLabelAction = QAction(icon('fa.arrow-left', color='green'), '', self)\n",
      "        self.preLabelAction.setShortcut('a')\n",
      "        self.preLabelAction.setStatusTip('')\n",
      "        self.preLabelAction.triggered.connect(self.preLabelEvent)\n",
      "\n",
      "        self.nextLabelAction = QAction(icon('fa.arrow-right', color='green'), '', self)\n",
      "        self.nextLabelAction.setShortcut('d')\n",
      "        self.nextLabelAction.setStatusTip('')\n",
      "        self.nextLabelAction.triggered.connect(self.nextLabelEvent)\n",
      "\n",
      "        self.saveLabelAction = QAction(icon('fa.save', color='orange'), '', self)\n",
      "        self.saveLabelAction.setShortcut('w')\n",
      "        self.saveLabelAction.setStatusTip('')\n",
      "        self.saveLabelAction.triggered.connect(self.saveLabelEvent)\n",
      "\n",
      "        self.exitAction = QAction(icon('fa.times', color='red'), '', self)\n",
      "        self.exitAction.setShortcut('Ctrl+Q')\n",
      "        self.exitAction.setStatusTip('')\n",
      "        self.exitAction.triggered.connect(self.close)\n",
      "\n",
      "        self.openImageAction = QAction(icon('fa5.images', color='blue'), '', self)\n",
      "        self.openImageAction.setShortcut('Ctrl+I')\n",
      "        self.openImageAction.setStatusTip('')\n",
      "        self.openImageAction.triggered.connect(self.openImageEvent)\n",
      "\n",
      "        self.openAnnotationAction = QAction(icon('fa5.file-excel', color='blue'), 'Annotation', self)\n",
      "        self.openAnnotationAction.setShortcut('Ctrl+A')\n",
      "        self.openAnnotationAction.setStatusTip('Annotation')\n",
      "        self.openAnnotationAction.triggered.connect(self.openAnnotationEvent)\n",
      "\n",
      "        self.saveImageAction = QAction(icon('fa.download', color='blue'), '', self)\n",
      "        self.saveImageAction.setShortcut('Ctrl+S')\n",
      "        self.saveImageAction.setStatusTip('')\n",
      "        self.saveImageAction.triggered.connect(self.saveImageEvent)\n",
      "\n",
      "    def Creat_ToolBar(self):\n",
      "        self.toolBar = QToolBar()\n",
      "        self.addToolBar(Qt.LeftToolBarArea, self.toolBar)\n",
      "\n",
      "        self.toolBar.addWidget(QLabel(''))\n",
      "        self.toolBar.addAction(self.openImageAction)\n",
      "        self.toolBar.addAction(self.openAnnotationAction)\n",
      "        self.toolBar.addAction(self.saveImageAction)\n",
      "\n",
      "        self.toolBar.addWidget(QLabel(''))\n",
      "        self.toolBar.addAction(self.preLabelAction)\n",
      "        self.toolBar.addAction(self.nextLabelAction)\n",
      "        self.toolBar.addAction(self.saveLabelAction)\n",
      "        self.toolBar.addAction(self.exitAction)\n",
      "\n",
      "    def openImageEvent(self):\n",
      "        self.imagefilepath = QFileDialog.getExistingDirectory(self, \"\", self.tmppath)\n",
      "        self.tmppath = self.imagefilepath\n",
      "        self.setStatusTip(self.imagefilepath)\n",
      "        if self.imagefilepath!='' and self.annotationfilepath!='':\n",
      "            self.load_data()\n",
      "\n",
      "    def openAnnotationEvent(self):\n",
      "        self.annotationfilepath = QFileDialog.getExistingDirectory(self, \"Annotation\", self.tmppath)\n",
      "        self.tmppath = self.annotationfilepath\n",
      "        self.setStatusTip(self.annotationfilepath)\n",
      "        if self.imagefilepath!='' and self.annotationfilepath!='':\n",
      "            self.load_data()\n",
      "\n",
      "    def saveImageEvent(self):\n",
      "        try:\n",
      "            self.savepath = QFileDialog.getExistingDirectory(self, \"\", self.tmppath)\n",
      "            self.tmppath = self.savepath\n",
      "            self.setStatusTip(self.savepath)\n",
      "            self.thread = makeDirThread(savepath=self.savepath)\n",
      "            self.thread.signal.connect(self.mkdir_callback)\n",
      "            self.thread.start()\n",
      "        except Exception as e:\n",
      "            print(e)\n",
      "\n",
      "    def mkdir_callback(self,dir1, dir2):\n",
      "        self.saveAnnotationFolder = dir2\n",
      "        self.saveImageFolder = dir1\n",
      "\n",
      "    def preLabelEvent(self):\n",
      "        try:\n",
      "            self.currentIndex -= 1\n",
      "            self.path = self.imagelist[self.currentIndex]\n",
      "            self.centerWidget.loadimage(self.path)\n",
      "            self.centerWidget.read_xml(self.get_xmlfile_name(self.path))\n",
      "        except Exception:\n",
      "            self.currentIndex = 0\n",
      "\n",
      "    def nextLabelEvent(self):\n",
      "        try:\n",
      "            self.currentIndex += 1\n",
      "            self.path = self.imagelist[self.currentIndex]\n",
      "            self.centerWidget.loadimage(self.path)\n",
      "            self.centerWidget.read_xml(self.get_xmlfile_name(self.path))\n",
      "        except Exception:\n",
      "            self.currentIndex = 0\n",
      "\n",
      "    def saveLabelEvent(self):\n",
      "        xml_path = self.get_xmlfile_name(self.path)\n",
      "        self.copythread = copyFileThread(self.path,\n",
      "                                         os.path.join(self.saveImageFolder, self.path.split('\\\\')[-1]),\n",
      "                                         xml_path,\n",
      "                                         os.path.join(self.saveAnnotationFolder, xml_path.split('\\\\')[-1]))\n",
      "        self.copythread.signal.connect(self.copy_callback)\n",
      "        self.copythread.start()\n",
      "\n",
      "    def copy_callback(self, index):\n",
      "        if index == 1:\n",
      "            self.setStatusTip('')\n",
      "\n",
      "    def load_data(self):\n",
      "        pathnew = os.path.join(self.imagefilepath, \"*.jpg\")\n",
      "        self.imagelist = glob.glob(pathnew)\n",
      "        self.path = self.imagelist[self.currentIndex]\n",
      "        self.centerWidget.loadimage(self.path)\n",
      "        self.centerWidget.read_xml(self.get_xmlfile_name(self.path))\n",
      "\n",
      "    def get_xmlfile_name(self, path):\n",
      "        return os.path.join(self.annotationfilepath, path.split('\\\\')[-1].split('.')[0]+'.xml')\n",
      "\n",
      "    def mousePressEvent(self, event):\n",
      "        if event.button() == Qt.LeftButton:\n",
      "            self.m_flag = True\n",
      "            self.m_Position = event.globalPos() - self.pos()\n",
      "            event.accept()\n",
      "            self.setCursor(QCursor(Qt.OpenHandCursor))\n",
      "\n",
      "    def mouseMoveEvent(self, QMouseEvent):\n",
      "        if Qt.LeftButton and self.m_flag:\n",
      "            self.move(QMouseEvent.globalPos() - self.m_Position)\n",
      "            QMouseEvent.accept()\n",
      "\n",
      "    def mouseReleaseEvent(self, QMouseEvent):\n",
      "        self.m_flag = False\n",
      "        self.setCursor(QCursor(Qt.ArrowCursor))\n",
      "\n",
      "    def center(self):\n",
      "        qr = self.frameGeometry()\n",
      "        cp = QDesktopWidget().availableGeometry().center()\n",
      "        qr.moveCenter(cp)\n",
      "        self.move(qr.topLeft())\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    # \n",
      "    app = QApplication(sys.argv)\n",
      "    ex = Choose_Label_MainWIndow()\n",
      "    sys.exit(app.exec_())\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\LehiChiang_CV_toolkit\\choose_label\\main.py\n",
      "[]\n",
      "found files: []\n",
      "from keras.preprocessing.image import ImageDataGenerator\n",
      "import os\n",
      "\n",
      "path = os.getcwd()+'/imgsrc/'\n",
      "dis_path = os.getcwd()+'/output/'\n",
      "\n",
      "data_generator = ImageDataGenerator(\n",
      "    rotation_range=20,\n",
      "    rescale=1./255,\n",
      "    width_shift_range=0.2,\n",
      "    height_shift_range=0.2,\n",
      "    shear_range=0.2,\n",
      "    zoom_range=0.2,\n",
      "    horizontal_flip=True,\n",
      "    fill_mode='nearest')\n",
      "\n",
      "gen = data_generator.flow_from_directory(\n",
      "    path,\n",
      "    batch_size=1,\n",
      "    target_size=(534, 800),\n",
      "    save_to_dir=dis_path,\n",
      "    save_prefix='convert',\n",
      "    save_format='jpg')\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    if not os.path.exists(path):\n",
      "        os.makedirs(path)\n",
      "\n",
      "    if not os.path.exists(dis_path):\n",
      "        os.makedirs(dis_path)\n",
      "\n",
      "    num = input('Input the number of pics you want to generate : ')\n",
      "    for i in range(int(num)):\n",
      "        gen.next()\n",
      "        print('Processing the %d th picture....' % (i+1))\n",
      "    print('All pictures processed!')\n",
      "\n",
      "Output: {'index': ['os.makedirs', '<builtin>.range', '<builtin>.print', '<builtin>.input', 'os.getcwd', 'keras.preprocessing.image.ImageDataGenerator', 'os.path.exists', '<builtin>.int'], 'os.getcwd': [], 'keras.preprocessing.image.ImageDataGenerator': [], 'os.path.exists': [], 'os.makedirs': [], '<builtin>.input': [], '<builtin>.int': [], '<builtin>.range': [], '<builtin>.print': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\LehiChiang_CV_toolkit\\image_generator\\index.py\n",
      "[('index', 'os makedirs'), ('index', 'os getcwd'), ('index', 'keras preprocessing image ImageDataGenerator'), ('index', 'os path exists')]\n",
      "0\n",
      "found files: []\n",
      "import re\n",
      "import requests\n",
      "from urllib import error\n",
      "from bs4 import BeautifulSoup\n",
      "import os\n",
      "\n",
      "num = 0\n",
      "numPicture = 0\n",
      "file = ''\n",
      "List = []\n",
      "\n",
      "\n",
      "def Find(url):\n",
      "    global List\n",
      "    print('Detecting total images, please wait.....')\n",
      "    t = 0\n",
      "    i = 1\n",
      "    s = 0\n",
      "    while t < 1000:\n",
      "        Url = url + str(t)\n",
      "        try:\n",
      "            Result = requests.get(Url, timeout=7)\n",
      "        except BaseException:\n",
      "            t = t + 60\n",
      "            continue\n",
      "        else:\n",
      "            result = Result.text\n",
      "            pic_url = re.findall('\"objURL\":\"(.*?)\",', result, re.S)  # First use regular expressions to find the image url\n",
      "            s += len(pic_url)\n",
      "            if len(pic_url) == 0:\n",
      "                break\n",
      "            else:\n",
      "                List.append(pic_url)\n",
      "                t = t + 60\n",
      "    return s\n",
      "\n",
      "\n",
      "def recommend(url):\n",
      "    Re = []\n",
      "    try:\n",
      "        html = requests.get(url)\n",
      "    except error.HTTPError as e:\n",
      "        return\n",
      "    else:\n",
      "        html.encoding = 'utf-8'\n",
      "        bsObj = BeautifulSoup(html.text, 'html.parser')\n",
      "        div = bsObj.find('div', id='topRS')\n",
      "        if div is not None:\n",
      "            listA = div.findAll('a')\n",
      "            for i in listA:\n",
      "                if i is not None:\n",
      "                    Re.append(i.get_text())\n",
      "        return Re\n",
      "\n",
      "\n",
      "def dowmloadPicture(html, keyword):\n",
      "    global num\n",
      "    # t =0\n",
      "    pic_url = re.findall('\"objURL\":\"(.*?)\",', html, re.S)  # First use regular expressions to find the image url\n",
      "    print('Keyword: ' + keyword + ' pictures, downloading pictures will start soon...')\n",
      "    for each in pic_url:\n",
      "        print('Downloading the ' + str(num + 1) + ' picture, picture address:' + str(each))\n",
      "        try:\n",
      "            if each is not None:\n",
      "                pic = requests.get(each, timeout=7)\n",
      "            else:\n",
      "                continue\n",
      "        except BaseException:\n",
      "            print('Error, current picture cannot be downloaded')\n",
      "            continue\n",
      "        else:\n",
      "            string = file + r'\\\\' + keyword + '_' + str(num) + '.jpg'\n",
      "            fp = open(string, 'wb')\n",
      "            fp.write(pic.content)\n",
      "            fp.close()\n",
      "            num += 1\n",
      "        if num >= numPicture:\n",
      "            return\n",
      "\n",
      "\n",
      "if __name__ == '__main__':  # main\n",
      "    word = input(\"Please enter search keywords (can be person name, place name, etc.): \")\n",
      "    # add = 'http://image.baidu.com/search/flip?tn=baiduimage&ie=utf-8&word=%E5%BC%A0%E5%A4%A9%E7%88%B1&pn=120'\n",
      "    url = 'http://image.baidu.com/search/flip?tn=baiduimage&ie=utf-8&word=' + word + '&pn='\n",
      "    tot = Find(url)\n",
      "    Recommend = recommend(url)  # Record related recommendations\n",
      "    print('A total of %d %s pictures have been tested' % (tot,word))\n",
      "    numPicture = int(input('Please enter the number of pictures you want to download :'))\n",
      "    file = input('Please create a folder for storing pictures, just enter the folder name :')\n",
      "    y = os.path.exists(file)\n",
      "    if y == 1:\n",
      "        print('The file already exists, please re-enter')\n",
      "        file = input('Please create a folder to store pictures.) Enter the folder name')\n",
      "        os.mkdir(file)\n",
      "    else:\n",
      "        os.mkdir(file)\n",
      "    t = 0\n",
      "    tmp = url\n",
      "    while t < numPicture:\n",
      "        try:\n",
      "            url = tmp + str(t)\n",
      "            result = requests.get(url, timeout=10)\n",
      "            print(url)\n",
      "        except error.HTTPError as e:\n",
      "            print('Network error, please adjust the network and try again')\n",
      "            t = t + 60\n",
      "        else:\n",
      "            dowmloadPicture(result.text, word)\n",
      "            t = t + 60\n",
      "\n",
      "    print('The current search is over, thanks for using')\n",
      "    print('You may also like:')\n",
      "    for re in Recommend:\n",
      "        print(re, end='  ')\n",
      "Output: {'downloader': ['<builtin>.str', 'os.mkdir', 'downloader.dowmloadPicture', 'downloader.recommend', '<builtin>.int', 'requests.get', 'os.path.exists', '<builtin>.print', 'downloader.Find', '<builtin>.input'], 'downloader.Find': ['<builtin>.str', 're.findall', 'requests.get', '<builtin>.len', '<builtin>.print'], '<builtin>.print': [], '<builtin>.str': [], 'requests.get': [], 're.findall': [], '<builtin>.len': [], 'downloader.recommend': ['bs4.BeautifulSoup', 'requests.get'], 'bs4.BeautifulSoup': [], 'downloader.dowmloadPicture': ['<builtin>.open', '<builtin>.str', 're.findall', 'requests.get', '<builtin>.print'], '<builtin>.open': [], '<builtin>.input': [], '<builtin>.int': [], 'os.path.exists': [], 'os.mkdir': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\LehiChiang_CV_toolkit\\image_downloader\\downloader.py\n",
      "[('downloader', 'os mkdir'), ('downloader', 'downloader dowmloadPicture'), ('downloader', 'downloader recommend'), ('downloader', 'requests get'), ('downloader', 'os path exists'), ('downloader', 'downloader Find'), ('downloader Find', 're findall'), ('downloader Find', 'requests get'), ('downloader recommend', 'bs4 BeautifulSoup'), ('downloader recommend', 'requests get'), ('downloader dowmloadPicture', 're findall'), ('downloader dowmloadPicture', 'requests get')]\n",
      "0\n",
      "found files: []\n",
      "import xml.etree.ElementTree as ET\n",
      "from os import listdir, getcwd, makedirs, path\n",
      "\n",
      "from tqdm import tqdm\n",
      "\n",
      "'''\n",
      "    labelImgVOCYOLO\n",
      "        XMLAnnotations\n",
      "        TXTyolo_format\n",
      "'''\n",
      "\n",
      "classes = ['0B', '1B', '2B']\n",
      "\n",
      "def convert(size, box):\n",
      "    dw = 1./(size[0])\n",
      "    dh = 1./(size[1])\n",
      "    x = (box[0] + box[1])/2.0\n",
      "    y = (box[2] + box[3])/2.0\n",
      "    w = box[1] - box[0]\n",
      "    h = box[3] - box[2]\n",
      "    x = x*dw\n",
      "    w = w*dw\n",
      "    y = y*dh\n",
      "    h = h*dh\n",
      "    return (x,y,w,h)\n",
      "\n",
      "def convert_annotation(image_id):\n",
      "    in_file = open('VOCdevkit/VOC2007/Annotations/%s.xml'%(image_id))\n",
      "    out_file = open('yolo_format/%s.txt'%(image_id), 'w')\n",
      "    tree=ET.parse(in_file)\n",
      "    root = tree.getroot()\n",
      "    size = root.find('size')\n",
      "    w = int(size.find('width').text)\n",
      "    h = int(size.find('height').text)\n",
      "    for obj in root.iter('object'):\n",
      "        difficult = obj.find('difficult').text\n",
      "        cls = obj.find('name').text\n",
      "        if cls not in classes :\n",
      "            continue\n",
      "        cls_id = classes.index(cls)\n",
      "        xmlbox = obj.find('bndbox')\n",
      "        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
      "        bb = convert((w,h), b)\n",
      "        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    if not path.exists('yolo_format'):\n",
      "        makedirs('yolo_format')\n",
      "\n",
      "    wd = getcwd()\n",
      "    b=0 #\n",
      "    list_file = listdir('VOCdevkit/VOC2007/Annotations')\n",
      "    for file in tqdm(list_file):\n",
      "        f=file.replace('.xml','')\n",
      "        convert_annotation(f)\n",
      "        b=b+1\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\LehiChiang_CV_toolkit\\dataset_converter\\voc2yolo.py\n",
      "[]\n",
      "found files: []\n",
      "from PyQt5.QtWidgets import QWidget, QTextEdit,  QVBoxLayout, QLabel, QHBoxLayout\n",
      "from PyQt5.QtGui import QImage, QPixmap\n",
      "import cv2\n",
      "from qtpy import QtCore\n",
      "\n",
      "\n",
      "class CenterWidget(QWidget):\n",
      "\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        self.initUI()\n",
      "\n",
      "    def initUI(self):\n",
      "        self.main_layout = QVBoxLayout()\n",
      "        self.top_layout = QHBoxLayout()\n",
      "        self.bottom_layout = QHBoxLayout()\n",
      "\n",
      "        self.main_layout.addLayout(self.top_layout)\n",
      "        self.main_layout.addLayout(self.bottom_layout)\n",
      "\n",
      "        self.img_label = QLabel()\n",
      "        self.xml_edit = QTextEdit()\n",
      "        self.xml_edit.setFocusPolicy(QtCore.Qt.NoFocus)\n",
      "\n",
      "        self.top_layout.addStretch(1)\n",
      "        self.top_layout.addWidget(self.img_label)\n",
      "        self.top_layout.addStretch(1)\n",
      "\n",
      "        self.bottom_layout.addWidget(self.xml_edit)\n",
      "        self.setLayout(self.main_layout)\n",
      "        self.show()\n",
      "\n",
      "    def loadimage(self,path):\n",
      "        self.image = cv2.imread(path)\n",
      "        self.showimage()\n",
      "\n",
      "    def showimage(self):\n",
      "        qimageformat = QImage.Format_Indexed8\n",
      "        if len(self.image.shape)==3:\n",
      "            if self.image.shape[2]==4:\n",
      "                qimageformat = QImage.Format_RGBA8888\n",
      "            else:\n",
      "                qimageformat = QImage.Format_RGB888\n",
      "        img = QImage(self.image,self.image.shape[1],self.image.shape[0],self.image.strides[0],qimageformat)\n",
      "        img = img.rgbSwapped()\n",
      "        self.img_label.setPixmap(QPixmap.fromImage(img))\n",
      "\n",
      "    def read_xml(self, path):\n",
      "        f = open(path, 'r')\n",
      "        with f:\n",
      "            data = f.read()\n",
      "            self.xml_edit.setText(data)\n",
      "\n",
      "Output: {'CenterPanel': [], 'CenterPanel.CenterWidget.__init__': ['<builtin>.super', 'CenterPanel.CenterWidget.initUI'], '<builtin>.super': [], 'CenterPanel.CenterWidget.initUI': ['PyQt5.QtWidgets.QWidget.setLayout', 'PyQt5.QtWidgets.QHBoxLayout', 'PyQt5.QtWidgets.QWidget.show', 'PyQt5.QtWidgets.QTextEdit', 'PyQt5.QtWidgets.QLabel', 'PyQt5.QtWidgets.QVBoxLayout'], 'PyQt5.QtWidgets.QVBoxLayout': [], 'PyQt5.QtWidgets.QHBoxLayout': [], 'PyQt5.QtWidgets.QLabel': [], 'PyQt5.QtWidgets.QTextEdit': [], 'PyQt5.QtWidgets.QWidget.setLayout': [], 'PyQt5.QtWidgets.QWidget.show': [], 'CenterPanel.CenterWidget.loadimage': ['CenterPanel.CenterWidget.showimage', 'cv2.imread'], 'cv2.imread': [], 'CenterPanel.CenterWidget.showimage': ['PyQt5.QtGui.QPixmap.fromImage', '<builtin>.len', 'PyQt5.QtGui.QImage'], '<builtin>.len': [], 'PyQt5.QtGui.QImage': [], 'PyQt5.QtGui.QPixmap.fromImage': [], 'CenterPanel.CenterWidget.read_xml': ['<builtin>.open'], '<builtin>.open': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\LehiChiang_CV_toolkit\\choose_label\\gui\\CenterPanel.py\n",
      "[('CenterPanel CenterWidget __init__', 'CenterPanel CenterWidget initUI'), ('CenterPanel CenterWidget initUI', 'PyQt5 QtWidgets QWidget setLayout'), ('CenterPanel CenterWidget initUI', 'PyQt5 QtWidgets QHBoxLayout'), ('CenterPanel CenterWidget initUI', 'PyQt5 QtWidgets QWidget show'), ('CenterPanel CenterWidget initUI', 'PyQt5 QtWidgets QTextEdit'), ('CenterPanel CenterWidget initUI', 'PyQt5 QtWidgets QLabel'), ('CenterPanel CenterWidget initUI', 'PyQt5 QtWidgets QVBoxLayout'), ('CenterPanel CenterWidget loadimage', 'CenterPanel CenterWidget showimage'), ('CenterPanel CenterWidget loadimage', 'cv2 imread'), ('CenterPanel CenterWidget showimage', 'PyQt5 QtGui QPixmap fromImage'), ('CenterPanel CenterWidget showimage', 'PyQt5 QtGui QImage')]\n",
      "0\n",
      "found files: []\n",
      "import sys\n",
      "import os\n",
      "import json\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "\n",
      "START_BOUNDING_BOX_ID = 1\n",
      "PRE_DEFINE_CATEGORIES = {}\n",
      "# If necessary, pre-define category and its id\n",
      "#  PRE_DEFINE_CATEGORIES = {\"aeroplane\": 1, \"bicycle\": 2, \"bird\": 3, \"boat\": 4,\n",
      "                         #  \"bottle\":5, \"bus\": 6, \"car\": 7, \"cat\": 8, \"chair\": 9,\n",
      "                         #  \"cow\": 10, \"diningtable\": 11, \"dog\": 12, \"horse\": 13,\n",
      "                         #  \"motorbike\": 14, \"person\": 15, \"pottedplant\": 16,\n",
      "                         #  \"sheep\": 17, \"sofa\": 18, \"train\": 19, \"tvmonitor\": 20}\n",
      "\n",
      "\n",
      "def get(root, name):\n",
      "    vars = root.findall(name)\n",
      "    return vars\n",
      "\n",
      "\n",
      "def get_and_check(xml_f, root, name, length):\n",
      "    vars = root.findall(name)\n",
      "    if len(vars) == 0:\n",
      "        print(xml_f)\n",
      "        raise NotImplementedError('Can not find %s in %s.'%(name, root.tag))\n",
      "    if length > 0 and len(vars) != length:\n",
      "        raise NotImplementedError('The size of %s is supposed to be %d, but is %d.'%(name, length, len(vars)))\n",
      "    if length == 1:\n",
      "        vars = vars[0]\n",
      "    return vars\n",
      "\n",
      "\n",
      "def get_filename_as_int(filename):\n",
      "    try:\n",
      "        filename = os.path.splitext(filename)[0]\n",
      "        return int(filename)\n",
      "    except:\n",
      "        raise NotImplementedError('Filename %s is supposed to be an integer.'%(filename))\n",
      "\n",
      "\n",
      "def convert(xml_list, xml_dir, json_file):\n",
      "    list_fp = open(xml_list, 'r')\n",
      "    json_dict = {\"images\":[], \"type\": \"instances\", \"annotations\": [],\n",
      "                 \"categories\": []}\n",
      "    categories = PRE_DEFINE_CATEGORIES\n",
      "    bnd_id = START_BOUNDING_BOX_ID\n",
      "    for line in list_fp:\n",
      "        line = line.strip()\n",
      "        print(\"Processing %s\"%(line))\n",
      "        xml_f = os.path.join(xml_dir, line)\n",
      "        tree = ET.parse(xml_f)\n",
      "        root = tree.getroot()\n",
      "        path = get(root, 'path')\n",
      "        if len(path) == 1:\n",
      "            filename = os.path.basename(path[0].text)\n",
      "        elif len(path) == 0:\n",
      "            filename = get_and_check(xml_f, root, 'filename', 1).text\n",
      "        else:\n",
      "            raise NotImplementedError('%d paths found in %s'%(len(path), line))\n",
      "        ## The filename must be a number\n",
      "        image_id = get_filename_as_int(filename)\n",
      "        size = get_and_check(xml_f, root, 'size', 1)\n",
      "        width = int(get_and_check(xml_f, size, 'width', 1).text)\n",
      "        height = int(get_and_check(xml_f, size, 'height', 1).text)\n",
      "        image = {'file_name': filename, 'height': height, 'width': width,\n",
      "                 'id':image_id}\n",
      "        json_dict['images'].append(image)\n",
      "        ## Cruuently we do not support segmentation\n",
      "        #  segmented = get_and_check(root, 'segmented', 1).text\n",
      "        #  assert segmented == '0'\n",
      "        for obj in get(root, 'object'):\n",
      "            category = get_and_check(xml_f, obj, 'name', 1).text\n",
      "            if category not in categories:\n",
      "                new_id = len(categories)\n",
      "                categories[category] = new_id\n",
      "            category_id = categories[category]\n",
      "            bndbox = get_and_check(xml_f, obj, 'bndbox', 1)\n",
      "            xmin = int(get_and_check(xml_f, bndbox, 'xmin', 1).text) - 1\n",
      "            ymin = int(get_and_check(xml_f, bndbox, 'ymin', 1).text) - 1\n",
      "            xmax = int(get_and_check(xml_f, bndbox, 'xmax', 1).text)\n",
      "            ymax = int(get_and_check(xml_f, bndbox, 'ymax', 1).text)\n",
      "            assert(xmax > xmin)\n",
      "            assert(ymax > ymin)\n",
      "            o_width = abs(xmax - xmin)\n",
      "            o_height = abs(ymax - ymin)\n",
      "            ann = {'area': o_width*o_height, 'iscrowd': 0, 'image_id':\n",
      "                   image_id, 'bbox':[xmin, ymin, o_width, o_height],\n",
      "                   'category_id': category_id, 'id': bnd_id, 'ignore': 0,\n",
      "                   'segmentation': []}\n",
      "            json_dict['annotations'].append(ann)\n",
      "            bnd_id = bnd_id + 1\n",
      "\n",
      "    for cate, cid in categories.items():\n",
      "        cat = {'supercategory': 'none', 'id': cid, 'name': cate}\n",
      "        json_dict['categories'].append(cat)\n",
      "    json_fp = open(json_file, 'w')\n",
      "    json_str = json.dumps(json_dict)\n",
      "    json_fp.write(json_str)\n",
      "    json_fp.close()\n",
      "    list_fp.close()\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    if len(sys.argv) <= 1:\n",
      "        print('3 auguments are need.')\n",
      "        print('Usage: %s XML_LIST.txt XML_DIR OUTPU_JSON.json'%(sys.argv[0]))\n",
      "        exit(1)\n",
      "\n",
      "    convert(sys.argv[1], sys.argv[2], sys.argv[3])\n",
      "Output: {'voc2coco': ['voc2coco.convert', '<builtin>.exit', '<builtin>.print', '<builtin>.len'], 'voc2coco.get': [], 'voc2coco.get_and_check': ['<builtin>.print', '<builtin>.NotImplementedError', '<builtin>.len'], '<builtin>.len': [], '<builtin>.print': [], '<builtin>.NotImplementedError': [], 'voc2coco.get_filename_as_int': ['<builtin>.int', 'os.path.splitext', '<builtin>.NotImplementedError'], 'os.path.splitext': [], '<builtin>.int': [], 'voc2coco.convert': ['<builtin>.open', 'voc2coco.get_filename_as_int', '<builtin>.print', 'json.dumps', 'voc2coco.get', '<builtin>.abs', '<builtin>.int', 'xml.etree.ElementTree.parse', 'os.path.basename', '<builtin>.len', '<builtin>.NotImplementedError', 'voc2coco.get_and_check', 'os.path.join'], '<builtin>.open': [], 'os.path.join': [], 'xml.etree.ElementTree.parse': [], 'os.path.basename': [], '<builtin>.abs': [], 'json.dumps': [], '<builtin>.exit': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\LehiChiang_CV_toolkit\\dataset_converter\\voc2coco.py\n",
      "[('voc2coco', 'voc2coco convert'), ('voc2coco get_filename_as_int', 'os path splitext'), ('voc2coco convert', 'voc2coco get_filename_as_int'), ('voc2coco convert', 'json dumps'), ('voc2coco convert', 'voc2coco get'), ('voc2coco convert', 'xml etree ElementTree parse'), ('voc2coco convert', 'os path basename'), ('voc2coco convert', 'voc2coco get_and_check'), ('voc2coco convert', 'os path join')]\n",
      "0\n",
      "found files: []\n",
      "import os\n",
      "import shutil\n",
      "import random\n",
      "\n",
      "# VOCCOCO\n",
      "# VOCAnnotationsJPEGImages:\n",
      "# trainset, valset, testset\n",
      "# VOCCOCO\n",
      "\n",
      "def move_path(name, folder):\n",
      "    old_img_path = os.path.join(img_path, name + '.jpg')\n",
      "    old_anno_path = os.path.join(anno_path, name + '.xml')\n",
      "    new_img_path = os.path.join(img_folder, folder)\n",
      "    new_anno_path = os.path.join(anno_folder, folder)\n",
      "    shutil.move(old_img_path, new_img_path)\n",
      "    shutil.move(old_anno_path, new_anno_path)\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    trainval_percent = 0.2\n",
      "    train_percent = 0.8\n",
      "    # path of img\n",
      "    img_path = 'D:\\\\yolo\\\\coco\\\\VOC2007\\\\JPEGImages'\n",
      "    # path of annotations\n",
      "    anno_path = 'D:\\\\yolo\\\\coco\\\\VOC2007\\\\Annotations'\n",
      "    # path of the annotation folder\n",
      "    anno_folder = 'D:\\\\yolo\\\\coco\\\\annotations'\n",
      "    # path of the images folder\n",
      "    img_folder = 'D:\\\\yolo\\\\coco\\\\data'\n",
      "\n",
      "    folder_name = ['trainset', 'valset', 'testset']\n",
      "\n",
      "    for name in folder_name:\n",
      "        img_folder_path = os.path.join(img_folder, '%s' % name)\n",
      "\n",
      "        if not os.path.exists(img_folder_path):\n",
      "            os.makedirs(img_folder_path)\n",
      "            print(\"new a folder named \" + str(name) + 'at the path of ' + img_folder_path)\n",
      "\n",
      "        anno_folder_path = os.path.join(anno_folder, '%s' % name)\n",
      "\n",
      "        if not os.path.exists(anno_folder_path):\n",
      "            os.makedirs(anno_folder_path)\n",
      "            print(\"new a folder named \" + str(name) + 'at the path of ' + anno_folder_path)\n",
      "\n",
      "    # give the img list\n",
      "    total_imgs = os.listdir(img_path)\n",
      "\n",
      "    num = len(total_imgs)\n",
      "    list = range(num)\n",
      "    tv = int(num * trainval_percent)\n",
      "    tr = int(tv * train_percent)\n",
      "    trainval = random.sample(list, tv)\n",
      "    train = random.sample(trainval, tr)\n",
      "\n",
      "    for i in list:\n",
      "        name = total_imgs[i][:-4]\n",
      "        if i in trainval:\n",
      "            if i in train:\n",
      "                move_path(name, 'testset')\n",
      "            else:\n",
      "                move_path(name, 'valset')\n",
      "        else:\n",
      "            move_path(name, 'trainset')\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\LehiChiang_CV_toolkit\\dataset_converter\\data_split.py\n",
      "[]\n",
      "found files: []\n",
      "import colorsys\n",
      "from os import path, listdir, makedirs, getcwd, _exit\n",
      "import time\n",
      "import cv2\n",
      "import argparse\n",
      "import xml.etree.ElementTree as ET\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "def get_parser():\n",
      "    parser = argparse.ArgumentParser(description='Input visualization parameters')\n",
      "    parser.add_argument('--label', type=str, required=False, default='Annotations',\n",
      "                        help='Input the labels folder')\n",
      "    parser.add_argument('--image', type=str, required=False, default='JPEGImages',\n",
      "                        help='Input the images folder')\n",
      "    parser.add_argument('--output', type=str, required=False, default='outcome',\n",
      "                        help='Input the folder of outcome images')\n",
      "    return parser\n",
      "\n",
      "\n",
      "def mkdir(dirpath):\n",
      "    if not path.exists(dirpath):\n",
      "        makedirs(dirpath)\n",
      "        logshow((\"Directory created successfully!\"))\n",
      "\n",
      "\n",
      "def logshow(message):\n",
      "    logtime = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
      "    if isinstance(message,tuple):\n",
      "        for m in message:\n",
      "            print(logtime, m)\n",
      "    else:\n",
      "        print(logtime, message)\n",
      "\n",
      "\n",
      "def get_class():\n",
      "    classes_path = path.expanduser('classes.txt')\n",
      "    with open(classes_path) as f:\n",
      "        class_names = f.readlines()\n",
      "    class_names = [c.strip() for c in class_names]\n",
      "    return class_names\n",
      "\n",
      "\n",
      "def get_colors(length):\n",
      "    # Generate colors for drawing bounding boxes.\n",
      "    hsv_tuples = [(x / length, 1., 1.)\n",
      "                  for x in range(length)]\n",
      "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
      "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
      "    np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
      "    np.random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
      "    np.random.seed(None)  # Reset seed to default.\n",
      "    return colors\n",
      "\n",
      "def main():\n",
      "    args = get_parser().parse_args()\n",
      "    label_input_dir = path.expanduser(args.label)\n",
      "    images_input_dir = path.expanduser(args.image)\n",
      "    outcome_dir = path.expanduser(args.output)\n",
      "    if not path.exists(label_input_dir) or not path.exists(images_input_dir):\n",
      "        logshow((\"*\"*50, 'Label folder or image folder do not exist! Please check it later.', '*'*50))\n",
      "        _exit(0)\n",
      "    logshow((label_input_dir, images_input_dir, outcome_dir))\n",
      "    mkdir(outcome_dir)\n",
      "\n",
      "    class_names = get_class()\n",
      "    colors = get_colors(len(class_names))\n",
      "\n",
      "    filenames =[name.split('.')[0] for name in listdir(label_input_dir)]\n",
      "    for name in filenames:\n",
      "        tree = ET.parse(path.join(label_input_dir, '{}.xml'.format(name)))\n",
      "        root = tree.getroot()\n",
      "        url = path.join(images_input_dir, name+'.jpg')\n",
      "        img = cv2.imread(url, 1)\n",
      "        for object in root.findall('object'):\n",
      "            cls = object.find('name').text\n",
      "            bndbox = object.find('bndbox')\n",
      "            xmin = int(bndbox.find('xmin').text)\n",
      "            ymin = int(bndbox.find('ymin').text)\n",
      "            xmax = int(bndbox.find('xmax').text)\n",
      "            ymax = int(bndbox.find('ymax').text)\n",
      "            cv2.putText(img, cls, (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 0.6, colors[class_names.index(cls)], 1, cv2.LINE_AA, False)\n",
      "            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), colors[class_names.index(cls)], 2, cv2.LINE_AA)\n",
      "\n",
      "        cv2.imshow('Image', img)\n",
      "        savepath = path.join(outcome_dir, '{}.jpg'.format(name))\n",
      "        cv2.imwrite(savepath,img, [int(cv2.IMWRITE_PNG_COMPRESSION), 9])\n",
      "        logshow('Saving image to {}'.format(savepath))\n",
      "        cv2.waitKey(100)\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n",
      "\n",
      "Output: {'index': ['index.main'], 'index.get_parser': ['argparse.ArgumentParser'], 'argparse.ArgumentParser': [], 'index.mkdir': ['os.makedirs', 'index.logshow', 'os.path.exists'], 'os.path.exists': [], 'os.makedirs': [], 'index.logshow': ['time.localtime', '<builtin>.print', '<builtin>.isinstance', 'time.strftime'], 'time.localtime': [], 'time.strftime': [], '<builtin>.isinstance': [], '<builtin>.print': [], 'index.get_class': ['os.path.expanduser', '<builtin>.open'], 'os.path.expanduser': [], '<builtin>.open': [], 'index.get_colors': ['numpy.random.seed', '<builtin>.map', 'numpy.random.shuffle', '<builtin>.range', '<builtin>.list'], '<builtin>.range': [], 'index.get_colors.<lambda1>': ['colorsys.hsv_to_rgb'], 'colorsys.hsv_to_rgb': [], '<builtin>.map': [], '<builtin>.list': [], 'index.get_colors.<lambda2>': ['<builtin>.int'], '<builtin>.int': [], 'numpy.random.seed': [], 'numpy.random.shuffle': [], 'index.main': ['cv2.imread', 'os.path.join', 'cv2.putText', 'cv2.rectangle', 'index.get_class', 'os._exit', 'cv2.imshow', 'os.path.expanduser', 'os.listdir', 'cv2.waitKey', 'index.get_parser', 'index.mkdir', 'index.logshow', 'xml.etree.ElementTree.parse', 'os.path.exists', '<builtin>.int', 'cv2.imwrite', 'index.get_colors', '<builtin>.len'], 'os._exit': [], '<builtin>.len': [], 'os.listdir': [], 'os.path.join': [], 'xml.etree.ElementTree.parse': [], 'cv2.imread': [], 'cv2.putText': [], 'cv2.rectangle': [], 'cv2.imshow': [], 'cv2.imwrite': [], 'cv2.waitKey': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\LehiChiang_CV_toolkit\\drawing_bounding_box\\index.py\n",
      "[('index', 'index main'), ('index get_parser', 'argparse ArgumentParser'), ('index mkdir', 'os makedirs'), ('index mkdir', 'index logshow'), ('index mkdir', 'os path exists'), ('index logshow', 'time localtime'), ('index logshow', 'time strftime'), ('index get_class', 'os path expanduser'), ('index get_colors', 'numpy random seed'), ('index get_colors', 'numpy random shuffle'), ('index get_colors <lambda1>', 'colorsys hsv_to_rgb'), ('index main', 'cv2 imread'), ('index main', 'os path join'), ('index main', 'cv2 putText'), ('index main', 'cv2 rectangle'), ('index main', 'index get_class'), ('index main', 'os _exit'), ('index main', 'cv2 imshow'), ('index main', 'os path expanduser'), ('index main', 'os listdir'), ('index main', 'cv2 waitKey'), ('index main', 'index get_parser'), ('index main', 'index mkdir'), ('index main', 'index logshow'), ('index main', 'xml etree ElementTree parse'), ('index main', 'os path exists'), ('index main', 'cv2 imwrite'), ('index main', 'index get_colors')]\n",
      "0\n",
      "found files: []\n",
      "import os\n",
      "from shutil import copyfile\n",
      "from traceback import format_exc\n",
      "\n",
      "from PyQt5.QtCore import QThread, pyqtSignal\n",
      "\n",
      "\n",
      "class makeDirThread(QThread):\n",
      "\n",
      "    signal = pyqtSignal(str, str)\n",
      "\n",
      "    def __init__(self, savepath):\n",
      "        super(makeDirThread, self).__init__()\n",
      "        self.savepath = savepath\n",
      "\n",
      "    def run(self):\n",
      "        try:\n",
      "            self.saveAnnotationFolder = os.path.join(self.savepath, 'VOCdevkit', 'Annotation')\n",
      "            os.makedirs(self.saveAnnotationFolder)\n",
      "            self.saveImageFolder = os.path.join(self.savepath, 'VOCdevkit', 'JPEGImages')\n",
      "            os.makedirs(self.saveImageFolder)\n",
      "            self.signal.emit(self.saveImageFolder, self.saveAnnotationFolder)\n",
      "        except Exception:\n",
      "            print(format_exc())\n",
      "\n",
      "class copyFileThread(QThread):\n",
      "\n",
      "    signal = pyqtSignal(int)\n",
      "\n",
      "    def __init__(self, dir1, dir2, dir3, dir4):\n",
      "        super(copyFileThread, self).__init__()\n",
      "        self.dir1 = dir1\n",
      "        self.dir2 = dir2\n",
      "        self.dir3 = dir3\n",
      "        self.dir4 = dir4\n",
      "\n",
      "    def run(self):\n",
      "        try:\n",
      "            copyfile(self.dir1, self.dir2)\n",
      "            copyfile(self.dir3, self.dir4)\n",
      "            self.signal.emit(1)\n",
      "        except Exception:\n",
      "            print(format_exc())\n",
      "\n",
      "Output: {'mkdirThread': [], 'PyQt5.QtCore.pyqtSignal': [], 'mkdirThread.makeDirThread': ['PyQt5.QtCore.pyqtSignal'], 'mkdirThread.makeDirThread.__init__': ['<builtin>.super'], '<builtin>.super': [], 'mkdirThread.makeDirThread.run': ['traceback.format_exc', '<builtin>.print', 'os.makedirs', 'os.path.join'], 'os.path.join': [], 'os.makedirs': [], 'traceback.format_exc': [], '<builtin>.print': [], 'mkdirThread.copyFileThread': ['PyQt5.QtCore.pyqtSignal'], 'mkdirThread.copyFileThread.__init__': ['<builtin>.super'], 'mkdirThread.copyFileThread.run': ['traceback.format_exc', 'shutil.copyfile', '<builtin>.print'], 'shutil.copyfile': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\LehiChiang_CV_toolkit\\choose_label\\thread\\mkdirThread.py\n",
      "[('mkdirThread makeDirThread', 'PyQt5 QtCore pyqtSignal'), ('mkdirThread makeDirThread run', 'traceback format_exc'), ('mkdirThread makeDirThread run', 'os makedirs'), ('mkdirThread makeDirThread run', 'os path join'), ('mkdirThread copyFileThread', 'PyQt5 QtCore pyqtSignal'), ('mkdirThread copyFileThread run', 'traceback format_exc'), ('mkdirThread copyFileThread run', 'shutil copyfile')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('index', 'os makedirs'), ('index', 'os getcwd'), ('index', 'keras preprocessing image ImageDataGenerator'), ('index', 'os path exists')], [('downloader', 'os mkdir'), ('downloader', 'downloader dowmloadPicture'), ('downloader', 'downloader recommend'), ('downloader', 'requests get'), ('downloader', 'os path exists'), ('downloader', 'downloader Find'), ('downloader Find', 're findall'), ('downloader Find', 'requests get'), ('downloader recommend', 'bs4 BeautifulSoup'), ('downloader recommend', 'requests get'), ('downloader dowmloadPicture', 're findall'), ('downloader dowmloadPicture', 'requests get')], [('CenterPanel CenterWidget __init__', 'CenterPanel CenterWidget initUI'), ('CenterPanel CenterWidget initUI', 'PyQt5 QtWidgets QWidget setLayout'), ('CenterPanel CenterWidget initUI', 'PyQt5 QtWidgets QHBoxLayout'), ('CenterPanel CenterWidget initUI', 'PyQt5 QtWidgets QWidget show'), ('CenterPanel CenterWidget initUI', 'PyQt5 QtWidgets QTextEdit'), ('CenterPanel CenterWidget initUI', 'PyQt5 QtWidgets QLabel'), ('CenterPanel CenterWidget initUI', 'PyQt5 QtWidgets QVBoxLayout'), ('CenterPanel CenterWidget loadimage', 'CenterPanel CenterWidget showimage'), ('CenterPanel CenterWidget loadimage', 'cv2 imread'), ('CenterPanel CenterWidget showimage', 'PyQt5 QtGui QPixmap fromImage'), ('CenterPanel CenterWidget showimage', 'PyQt5 QtGui QImage')], [('voc2coco', 'voc2coco convert'), ('voc2coco get_filename_as_int', 'os path splitext'), ('voc2coco convert', 'voc2coco get_filename_as_int'), ('voc2coco convert', 'json dumps'), ('voc2coco convert', 'voc2coco get'), ('voc2coco convert', 'xml etree ElementTree parse'), ('voc2coco convert', 'os path basename'), ('voc2coco convert', 'voc2coco get_and_check'), ('voc2coco convert', 'os path join')], [('index', 'index main'), ('index get_parser', 'argparse ArgumentParser'), ('index mkdir', 'os makedirs'), ('index mkdir', 'index logshow'), ('index mkdir', 'os path exists'), ('index logshow', 'time localtime'), ('index logshow', 'time strftime'), ('index get_class', 'os path expanduser'), ('index get_colors', 'numpy random seed'), ('index get_colors', 'numpy random shuffle'), ('index get_colors <lambda1>', 'colorsys hsv_to_rgb'), ('index main', 'cv2 imread'), ('index main', 'os path join'), ('index main', 'cv2 putText'), ('index main', 'cv2 rectangle'), ('index main', 'index get_class'), ('index main', 'os _exit'), ('index main', 'cv2 imshow'), ('index main', 'os path expanduser'), ('index main', 'os listdir'), ('index main', 'cv2 waitKey'), ('index main', 'index get_parser'), ('index main', 'index mkdir'), ('index main', 'index logshow'), ('index main', 'xml etree ElementTree parse'), ('index main', 'os path exists'), ('index main', 'cv2 imwrite'), ('index main', 'index get_colors')], [('mkdirThread makeDirThread', 'PyQt5 QtCore pyqtSignal'), ('mkdirThread makeDirThread run', 'traceback format_exc'), ('mkdirThread makeDirThread run', 'os makedirs'), ('mkdirThread makeDirThread run', 'os path join'), ('mkdirThread copyFileThread', 'PyQt5 QtCore pyqtSignal'), ('mkdirThread copyFileThread run', 'traceback format_exc'), ('mkdirThread copyFileThread run', 'shutil copyfile')]]\n",
      "********************doctrings*************************\n",
      "['', 'ind recommend dowmload icture', '', 'get get and check get filename as int convert', 'get parser mkdir logshow get class get colors main', '']\n",
      "embed index dataset: 10\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gaoyuanliang_cheque_detection\\\\jessica_cv.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gaoyuanliang_cheque_detection\\\\jessica_local_spark_building.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gaoyuanliang_cheque_detection\\\\cheque_tagging.py']\n",
      "import time\n",
      "import numpy\n",
      "import hashlib\n",
      "from PIL import *\n",
      "from keras.utils import *\n",
      "from keras.losses import *\n",
      "from keras.layers import *\n",
      "from keras.metrics import *\n",
      "\n",
      "from jessica_local_spark_building import sqlContext\n",
      "from pyspark.sql.types import StructType, StructField, StringType\n",
      "\n",
      "from pyspark import StorageLevel\n",
      "\n",
      "from keras.models import *\n",
      "from tensorflow.keras.preprocessing import image\n",
      "from tensorflow.keras.applications import xception\n",
      "\n",
      "base_model_Xception = xception.Xception(weights='xception_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False)\n",
      "\n",
      "def file_json2file_npy(input_json,\n",
      "\tsqlContext,\n",
      "\tfile_path_column_name = None,\n",
      "\tx_xception_npy = None,\n",
      "\tx_document_id_npy = None,\n",
      "\ty_npy = None,\n",
      "\toutput_json = None):\n",
      "\tstart_time = time.time()\n",
      "\tprint('loading data from %s'%(input_json))\n",
      "\tinput_df = sqlContext.read.json(input_json)\n",
      "\tinput_df.registerTempTable('input_df')\n",
      "\tinput_df = sqlContext.sql(u\"\"\"\n",
      "\t\tSELECT * FROM input_df ORDER BY document_id\n",
      "\t\t\"\"\")\n",
      "\tprint('loaded %d records from %s'%(input_df.count(), input_json))\n",
      "\tprint('collecting data')\n",
      "\tdata  =input_df.collect()\n",
      "\t###\n",
      "\tx_document_id = []\n",
      "\tx_file_path = []\n",
      "\tx_xception = []\n",
      "\tx_inception_v3 = []\n",
      "\tx_hash = []\n",
      "\ty = []\n",
      "\tfor r in data:\n",
      "\t\tr1 = r.asDict()\n",
      "\t\tif x_xception_npy is not None:\n",
      "\t\t\timg = image.load_img(r1[file_path_column_name], target_size=(224, 224))\n",
      "\t\t\tx = image.img_to_array(img)\n",
      "\t\t\tif output_json is not None:\n",
      "\t\t\t\thash_object = hashlib.md5(str(x.data.tobytes()).encode())\n",
      "\t\t\t\tx_hash.append(hash_object.hexdigest())\n",
      "\t\t\tx_xception.append(xception.preprocess_input(x))\n",
      "\t\t\tx_document_id.append(r.document_id)\n",
      "\t\tif y_npy is not None:\n",
      "\t\t\ty.append(r.label)\n",
      "\tif x_xception_npy is not None:\n",
      "\t\tprint('extracting and saving featurs')\n",
      "\t\tx_document_id = numpy.array(x_document_id)\n",
      "\t\tnumpy.save(x_document_id_npy, x_document_id)\n",
      "\t\tx_xception = numpy.array(x_xception)\n",
      "\t\tx_xception = base_model_Xception.predict(x_xception)\n",
      "\t\tnumpy.save(x_xception_npy, x_xception)\n",
      "\tif y_npy is not None:\n",
      "\t\tprint('saving labels')\n",
      "\t\ty = numpy.array(y)\n",
      "\t\ty = to_categorical(y)\n",
      "\t\tnumpy.save(y_npy, y)\n",
      "\tif output_json is not None:\n",
      "\t\tif 'content_hash' not in input_df.columns:\n",
      "\t\t\tdata = [(str(d), str(h)) \n",
      "\t\t\t\tfor d, h in \n",
      "\t\t\t\tzip(x_document_id, x_hash)]\n",
      "\t\t\tsqlContext.createDataFrame(data, ['document_id', 'content_hash']).registerTempTable('df_content_hash')\n",
      "\t\t\tsqlContext.sql(u\"\"\"\n",
      "\t\t\t\tSELECT input_df.*,\n",
      "\t\t\t\tdf_content_hash.content_hash\n",
      "\t\t\t\tFROM input_df\n",
      "\t\t\t\tLEFT JOIN df_content_hash\n",
      "\t\t\t\tON df_content_hash.document_id\n",
      "\t\t\t\t= input_df.document_id\n",
      "\t\t\t\t\"\"\").write.mode('Overwrite').json(output_json)\n",
      "\t\telse:\n",
      "\t\t\tinput_df.write.mode('Overwrite').json(output_json)\n",
      "\tprint('running time:\\t%f secondes'%(time.time()-start_time))\n",
      "\treturn None\n",
      "\n",
      "'''\n",
      ">>> x_xception.shape\n",
      "(8, 7, 7, 2048)\n",
      ">>> x_inception_v3.shape\n",
      "(8, 5, 5, 2048)\n",
      "'''\n",
      "\n",
      "def build_image_categorization_model(gpus = None):\n",
      "\tmodel = Sequential()\n",
      "\tmodel.add(GlobalAveragePooling2D(input_shape=(7, 7, 2048)))\n",
      "\tmodel.add(Dense(1024, activation='relu'))\n",
      "\tmodel.add(Dense(2, activation='softmax'))\n",
      "\tif gpus is not None:\n",
      "\t\tmodel = multi_gpu_model(model, gpus = gpus)\n",
      "\treturn model\n",
      "\n",
      "def train_image_categorization_model(\n",
      "\tx_npy, y_npy,\n",
      "\tx_document_id_npy,\n",
      "\tgpus = None,\n",
      "\tepochs = 3,\n",
      "\tpositive_weight = 1,\n",
      "\tbatch_size = 512,\n",
      "\tmodel_file = None,\n",
      "\toutput_prediction_json = None):\n",
      "\t#####\n",
      "\tprint('load data and label from npy files')\n",
      "\tx = numpy.load(x_npy)\n",
      "\tx_document_id = numpy.load(x_document_id_npy)\n",
      "\ty = numpy.load(y_npy)\n",
      "\t####\n",
      "\tprint('building model')\n",
      "\tmodel = build_image_categorization_model(gpus = gpus)\n",
      "\tmodel.compile(loss='categorical_crossentropy',\n",
      "\t\toptimizer='rmsprop', \n",
      "\t\tmetrics=['accuracy'])\n",
      "\tprint('training the model')\n",
      "\tmodel.fit(x, y, \n",
      "\t\tbatch_size=batch_size, \n",
      "\t\tepochs=epochs,\n",
      "\t\tclass_weight = {1:positive_weight, 0:1})\n",
      "\tif model_file is not None:\n",
      "\t\tprint('saving the model')\n",
      "\t\tmodel.save_weights(model_file)\n",
      "\t#####\n",
      "\tprint('predicting the labels from the trained model')\n",
      "\ty_score = model.predict(x)\n",
      "\tlabel_predicted = numpy.argmax(y_score,axis=-1)\n",
      "\tlabel = numpy.argmax(y,axis=-1)\n",
      "\tlabel_confidence = numpy.max(y_score,axis=1)\n",
      "\tprint('building the dataframe of the prediciton results')\n",
      "\tdata = [(str(d), int(l), int(p), float(s)) \n",
      "\t\tfor d, l, p, s in zip(x_document_id,\n",
      "\t\tlabel,\n",
      "\t\tlabel_predicted,\n",
      "\t\tlabel_confidence)]\n",
      "\t###\n",
      "\tdf_prediction = sqlContext.createDataFrame(data, \n",
      "\t['document_id', 'label', 'prediction', 'score']).persist(StorageLevel.MEMORY_AND_DISK)\n",
      "\t####\n",
      "\tif output_prediction_json is not None:\n",
      "\t\tprint('saving the prediction results')\n",
      "\t\tdf_prediction.write.mode('Overwrite').json(output_prediction_json)\n",
      "\t#####\n",
      "\tdf_prediction.registerTempTable('df_prediction')\n",
      "\tsqlContext.sql(u\"\"\"\n",
      "\t\tSELECT label, prediction, COUNT(*)\n",
      "\t\tFROM df_prediction\n",
      "\t\tGROUP BY label, prediction\n",
      "\t\t\"\"\").show()\n",
      "\treturn model\n",
      "\n",
      "def update_label_from_positive_file_csv(\n",
      "\tinput_json,\n",
      "\toutput_json,\n",
      "\tsqlContext,\n",
      "\tinput_positive_file_csv = None,\n",
      "\tinput_positive_hash_csv = None):\n",
      "\t####\n",
      "\t'''\n",
      "\tinput_positive_file_csv = 'uae_flag.csv'\n",
      "\tinput_json = 'image_set.json'\n",
      "\toutput_json = 'uae_flag_updated_label.json'\n",
      "\t'''\n",
      "\tsqlContext.read.json(input_json).withColumnRenamed('label', 'old_label').registerTempTable('input_df')\n",
      "\t####\n",
      "\tif input_positive_file_csv is not None:\n",
      "\t\tadditioal_postive_file = sqlContext.read.format('csv')\\\n",
      "\t\t.option(\"header\", \"false\")\\\n",
      "\t\t.schema(StructType([StructField(\"document_id\", StringType(), True)]))\\\n",
      "\t\t.load(input_positive_file_csv)\\\n",
      "\t\t.dropDuplicates()\n",
      "\t\tadditioal_postive_file.registerTempTable('additioal_postive_file')\n",
      "\t\tprint('loaded %d positive document_id'%(additioal_postive_file.count()))\n",
      "\telse:\n",
      "\t\tsqlContext.sql(u\"\"\"\n",
      "\t\t\tSELECT NULL AS document_id\n",
      "\t\t\t\"\"\").registerTempTable('additioal_postive_file')\n",
      "\t####\n",
      "\tif input_positive_hash_csv is not None:\n",
      "\t\tadditioal_postive_hash = sqlContext.read.format('csv')\\\n",
      "\t\t.option(\"header\", \"false\")\\\n",
      "\t\t.schema(StructType([StructField(\"content_hash\", StringType(), True)]))\\\n",
      "\t\t.load(input_positive_hash_csv)\\\n",
      "\t\t.dropDuplicates()\n",
      "\t\tadditioal_postive_hash.registerTempTable('additioal_postive_hash')\n",
      "\t\tprint('loaded %d positive content hash'%(additioal_postive_hash.count()))\n",
      "\telse:\n",
      "\t\tsqlContext.sql(u\"\"\"\n",
      "\t\t\tSELECT NULL AS content_hash\n",
      "\t\t\t\"\"\").registerTempTable('additioal_postive_hash')\n",
      "\t###\n",
      "\tsqlContext.sql(u\"\"\"\n",
      "\t\tSELECT input_df.*,\n",
      "\t\tCASE \n",
      "\t\t\tWHEN additioal_postive_file.document_id IS NOT NULL  \n",
      "\t\t\tOR additioal_postive_hash.content_hash IS NOT NULL\n",
      "\t\t\tTHEN 1\n",
      "\t\t\tELSE old_label \n",
      "\t\tEND AS label\n",
      "\t\tFROM input_df\n",
      "\t\tLEFT JOIN additioal_postive_file\n",
      "\t\tON  additioal_postive_file.document_id\n",
      "\t\t= input_df.document_id\n",
      "\t\tLEFT JOIN additioal_postive_hash\n",
      "\t\tON  additioal_postive_hash.content_hash\n",
      "\t\t= input_df.content_hash\n",
      "\t\tORDER BY input_df.document_id\n",
      "\t\t\"\"\").write.mode('Overwrite').json(output_json)\n",
      "\tsqlContext.read.json(output_json).registerTempTable('output_df')\n",
      "\tsqlContext.sql(u\"\"\"\n",
      "\t\tSELECT old_label, label, COUNT(*)\n",
      "\t\tFROM output_df\n",
      "\t\tGROUP BY old_label, label\n",
      "\t\t\"\"\").show()\n",
      "\n",
      "def load_build_image_categorization_model(\n",
      "\tmodel_file,\n",
      "\tgpus = None):\n",
      "\tmodel = build_image_categorization_model(gpus = gpus)\n",
      "\tmodel.load_weights(model_file)\n",
      "\tmodel.compile(loss='categorical_crossentropy',\n",
      "\t\toptimizer='rmsprop', \n",
      "\t\tmetrics=['accuracy'])\n",
      "\t#model._make_predict_function()\n",
      "\treturn model\n",
      "\n",
      "def image_tagging(\n",
      "\tx, model,\n",
      "\ttag_name):\n",
      "\toutput = {}\n",
      "\tx = xception.preprocess_input(x)\n",
      "\tx = numpy.array([x])\n",
      "\tx = base_model_Xception.predict(x)\n",
      "\ty_score = model.predict(x)\n",
      "\tprediction = numpy.argmax(y_score)\n",
      "\tscore = numpy.max(y_score)\n",
      "\tif prediction > 0:\n",
      "\t\toutput[\"tag\"] = tag_name\n",
      "\t\toutput[\"score\"] = score\n",
      "\treturn output\n",
      "\n",
      "def read_image_from_local(file_path):\n",
      "\timg = image.load_img(file_path, target_size=(224, 224))\n",
      "\tx = image.img_to_array(img)\n",
      "\treturn  x\n",
      "\n",
      "Output: {'jessica_cv': ['tensorflow.keras.applications.xception.Xception'], 'tensorflow.keras.applications.xception.Xception': [], 'jessica_cv.file_json2file_npy': ['hashlib.md5', 'tensorflow.keras.preprocessing.image.load_img', 'tensorflow.keras.applications.xception.preprocess_input', 'numpy.array', '<builtin>.print', '<builtin>.str', 'numpy.save', 'time.time', '<builtin>.zip', 'tensorflow.keras.preprocessing.image.img_to_array'], 'time.time': [], '<builtin>.print': [], 'tensorflow.keras.preprocessing.image.load_img': [], 'tensorflow.keras.preprocessing.image.img_to_array': [], '<builtin>.str': [], 'hashlib.md5': [], 'tensorflow.keras.applications.xception.preprocess_input': [], 'numpy.array': [], 'numpy.save': [], '<builtin>.zip': [], 'jessica_cv.build_image_categorization_model': [], 'jessica_cv.train_image_categorization_model': ['numpy.argmax', '<builtin>.float', 'jessica_cv.build_image_categorization_model', '<builtin>.print', '<builtin>.str', '<builtin>.zip', 'numpy.load', 'numpy.max', '<builtin>.int'], 'numpy.load': [], 'numpy.argmax': [], 'numpy.max': [], '<builtin>.int': [], '<builtin>.float': [], 'jessica_cv.update_label_from_positive_file_csv': ['<builtin>.print', 'pyspark.sql.types.StructType'], 'pyspark.sql.types.StructType': [], 'jessica_cv.load_build_image_categorization_model': ['jessica_cv.build_image_categorization_model'], 'jessica_cv.image_tagging': ['numpy.argmax', 'numpy.max', 'tensorflow.keras.applications.xception.preprocess_input', 'numpy.array'], 'jessica_cv.read_image_from_local': ['tensorflow.keras.preprocessing.image.load_img', 'tensorflow.keras.preprocessing.image.img_to_array'], 'jessica_local_spark_building': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gaoyuanliang_cheque_detection\\jessica_cv.py\n",
      "[('jessica_cv', 'tensorflow keras applications xception Xception'), ('jessica_cv file_json2file_npy', 'hashlib md5'), ('jessica_cv file_json2file_npy', 'tensorflow keras preprocessing image load_img'), ('jessica_cv file_json2file_npy', 'tensorflow keras applications xception preprocess_input'), ('jessica_cv file_json2file_npy', 'numpy array'), ('jessica_cv file_json2file_npy', 'numpy save'), ('jessica_cv file_json2file_npy', 'time time'), ('jessica_cv file_json2file_npy', 'tensorflow keras preprocessing image img_to_array'), ('jessica_cv train_image_categorization_model', 'numpy argmax'), ('jessica_cv train_image_categorization_model', 'jessica_cv build_image_categorization_model'), ('jessica_cv train_image_categorization_model', 'numpy load'), ('jessica_cv train_image_categorization_model', 'numpy max'), ('jessica_cv update_label_from_positive_file_csv', 'pyspark sql types StructType'), ('jessica_cv load_build_image_categorization_model', 'jessica_cv build_image_categorization_model'), ('jessica_cv image_tagging', 'numpy argmax'), ('jessica_cv image_tagging', 'numpy max'), ('jessica_cv image_tagging', 'tensorflow keras applications xception preprocess_input'), ('jessica_cv image_tagging', 'numpy array'), ('jessica_cv read_image_from_local', 'tensorflow keras preprocessing image load_img'), ('jessica_cv read_image_from_local', 'tensorflow keras preprocessing image img_to_array')]\n",
      "100\n",
      "found files: []\n",
      "import pyspark\n",
      "from pyspark import *\n",
      "from pyspark.sql import *\n",
      "from pyspark.sql.types import *\n",
      "from pyspark.sql.functions import *\n",
      "\n",
      "spark = SparkSession.builder.master(\"local[2]\").appName(\"jessica\").config(\"spark.driver.memory\", \"50g\").config(\"spark.driver.maxResultSize\", \"50g\").getOrCreate()\n",
      "sc = spark.sparkContext\n",
      "sqlContext = SQLContext(sc)\n",
      "spark.sparkContext._conf.getAll()\n",
      "\n",
      "Output: {'jessica_local_spark_building': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gaoyuanliang_cheque_detection\\jessica_local_spark_building.py\n",
      "[]\n",
      "found files: []\n",
      "########cheque_tagging.py########\n",
      "from jessica_cv import *\n",
      "\n",
      "model = load_build_image_categorization_model(\n",
      "\tmodel_file = 'cheque.h5py')\n",
      "\n",
      "def cheque_tagging(input_file):\n",
      "\toutput = {}\n",
      "\timg = image.load_img(input_file, target_size=(224, 224))\n",
      "\tx = image.img_to_array(img)\n",
      "\tx = xception.preprocess_input(x)\n",
      "\tx = numpy.array([x])\n",
      "\tx = base_model_Xception.predict(x)\n",
      "\ty_score = model.predict(x)\n",
      "\tprediction = numpy.argmax(y_score)\n",
      "\tscore = numpy.max(y_score)\n",
      "\tif prediction > 0:\n",
      "\t\toutput[\"tag\"] = 'cheque'\n",
      "\telse:\n",
      "\t\toutput[\"tag\"] = 'non_cheque'\n",
      "\toutput[\"score\"] = score\n",
      "\treturn output\n",
      "\n",
      "'''\n",
      "\n",
      "wget https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Sample_cheque.jpeg/1200px-Sample_cheque.jpeg\n",
      "\n",
      "\n",
      "cheque_tagging(\"1200px-Sample_cheque.jpeg\")\n",
      "\n",
      "{'score': 0.7404399, 'tag': 'cheque'}\n",
      "\n",
      "\n",
      "wget https://www.fundsindia.com/blog/wp-content/uploads/2017/05/Valid.png\n",
      "\n",
      "cheque_tagging(\"Valid.png\")\n",
      "\n",
      "{'score': 0.7928494, 'tag': 'non_cheque'}\n",
      "\n",
      "\n",
      "wget https://www.ilwindia.com/wp-content/uploads/2019/08/Heriot-Watt-University-Dubai-1.jpg\n",
      "\n",
      "cheque_tagging(\"Heriot-Watt-University-Dubai-1.jpg\")\n",
      "\n",
      "{'score': 1.0, 'tag': 'non_cheque'}\n",
      "\n",
      "'''\n",
      "\n",
      "########cheque_tagging.py########\n",
      "\n",
      "Output: {'cheque_tagging': ['jessica_cv.load_build_image_categorization_model'], 'jessica_cv.load_build_image_categorization_model': ['jessica_cv.build_image_categorization_model'], 'cheque_tagging.cheque_tagging': ['tensorflow.keras.preprocessing.image.load_img', 'numpy.array', 'tensorflow.keras.applications.xception.preprocess_input', 'numpy.max', 'numpy.argmax', 'tensorflow.keras.preprocessing.image.img_to_array'], 'tensorflow.keras.preprocessing.image.load_img': [], 'tensorflow.keras.preprocessing.image.img_to_array': [], 'tensorflow.keras.applications.xception.preprocess_input': [], 'numpy.array': [], 'numpy.argmax': [], 'numpy.max': [], 'jessica_cv': ['tensorflow.keras.applications.xception.Xception'], 'tensorflow.keras.applications.xception.Xception': [], 'jessica_cv.file_json2file_npy': ['<builtin>.zip', 'hashlib.md5', '<builtin>.print', 'tensorflow.keras.preprocessing.image.load_img', '<builtin>.str', 'numpy.array', 'tensorflow.keras.applications.xception.preprocess_input', 'numpy.save', 'time.time', 'tensorflow.keras.preprocessing.image.img_to_array'], 'time.time': [], '<builtin>.print': [], '<builtin>.str': [], 'hashlib.md5': [], 'numpy.save': [], '<builtin>.zip': [], 'jessica_cv.build_image_categorization_model': [], 'jessica_cv.train_image_categorization_model': ['<builtin>.zip', '<builtin>.print', '<builtin>.str', 'jessica_cv.build_image_categorization_model', '<builtin>.float', 'numpy.load', '<builtin>.int', 'numpy.max', 'numpy.argmax'], 'numpy.load': [], '<builtin>.int': [], '<builtin>.float': [], 'jessica_cv.update_label_from_positive_file_csv': ['pyspark.sql.types.StructType', '<builtin>.print'], 'pyspark.sql.types.StructType': [], 'jessica_cv.image_tagging': ['numpy.array', 'numpy.max', 'tensorflow.keras.applications.xception.preprocess_input', 'numpy.argmax'], 'jessica_cv.read_image_from_local': ['tensorflow.keras.preprocessing.image.load_img', 'tensorflow.keras.preprocessing.image.img_to_array'], 'jessica_local_spark_building': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gaoyuanliang_cheque_detection\\cheque_tagging.py\n",
      "[('cheque_tagging', 'jessica_cv load_build_image_categorization_model'), ('jessica_cv load_build_image_categorization_model', 'jessica_cv build_image_categorization_model'), ('cheque_tagging cheque_tagging', 'tensorflow keras preprocessing image load_img'), ('cheque_tagging cheque_tagging', 'numpy array'), ('cheque_tagging cheque_tagging', 'tensorflow keras applications xception preprocess_input'), ('cheque_tagging cheque_tagging', 'numpy max'), ('cheque_tagging cheque_tagging', 'numpy argmax'), ('cheque_tagging cheque_tagging', 'tensorflow keras preprocessing image img_to_array'), ('jessica_cv', 'tensorflow keras applications xception Xception'), ('jessica_cv file_json2file_npy', 'hashlib md5'), ('jessica_cv file_json2file_npy', 'tensorflow keras preprocessing image load_img'), ('jessica_cv file_json2file_npy', 'numpy array'), ('jessica_cv file_json2file_npy', 'tensorflow keras applications xception preprocess_input'), ('jessica_cv file_json2file_npy', 'numpy save'), ('jessica_cv file_json2file_npy', 'time time'), ('jessica_cv file_json2file_npy', 'tensorflow keras preprocessing image img_to_array'), ('jessica_cv train_image_categorization_model', 'jessica_cv build_image_categorization_model'), ('jessica_cv train_image_categorization_model', 'numpy load'), ('jessica_cv train_image_categorization_model', 'numpy max'), ('jessica_cv train_image_categorization_model', 'numpy argmax'), ('jessica_cv update_label_from_positive_file_csv', 'pyspark sql types StructType'), ('jessica_cv image_tagging', 'numpy array'), ('jessica_cv image_tagging', 'numpy max'), ('jessica_cv image_tagging', 'tensorflow keras applications xception preprocess_input'), ('jessica_cv image_tagging', 'numpy argmax'), ('jessica_cv read_image_from_local', 'tensorflow keras preprocessing image load_img'), ('jessica_cv read_image_from_local', 'tensorflow keras preprocessing image img_to_array')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('jessica_cv', 'tensorflow keras applications xception Xception'), ('jessica_cv file_json2file_npy', 'hashlib md5'), ('jessica_cv file_json2file_npy', 'tensorflow keras preprocessing image load_img'), ('jessica_cv file_json2file_npy', 'tensorflow keras applications xception preprocess_input'), ('jessica_cv file_json2file_npy', 'numpy array'), ('jessica_cv file_json2file_npy', 'numpy save'), ('jessica_cv file_json2file_npy', 'time time'), ('jessica_cv file_json2file_npy', 'tensorflow keras preprocessing image img_to_array'), ('jessica_cv train_image_categorization_model', 'numpy argmax'), ('jessica_cv train_image_categorization_model', 'jessica_cv build_image_categorization_model'), ('jessica_cv train_image_categorization_model', 'numpy load'), ('jessica_cv train_image_categorization_model', 'numpy max'), ('jessica_cv update_label_from_positive_file_csv', 'pyspark sql types StructType'), ('jessica_cv load_build_image_categorization_model', 'jessica_cv build_image_categorization_model'), ('jessica_cv image_tagging', 'numpy argmax'), ('jessica_cv image_tagging', 'numpy max'), ('jessica_cv image_tagging', 'tensorflow keras applications xception preprocess_input'), ('jessica_cv image_tagging', 'numpy array'), ('jessica_cv read_image_from_local', 'tensorflow keras preprocessing image load_img'), ('jessica_cv read_image_from_local', 'tensorflow keras preprocessing image img_to_array')], [('cheque_tagging', 'jessica_cv load_build_image_categorization_model'), ('jessica_cv load_build_image_categorization_model', 'jessica_cv build_image_categorization_model'), ('cheque_tagging cheque_tagging', 'tensorflow keras preprocessing image load_img'), ('cheque_tagging cheque_tagging', 'numpy array'), ('cheque_tagging cheque_tagging', 'tensorflow keras applications xception preprocess_input'), ('cheque_tagging cheque_tagging', 'numpy max'), ('cheque_tagging cheque_tagging', 'numpy argmax'), ('cheque_tagging cheque_tagging', 'tensorflow keras preprocessing image img_to_array'), ('jessica_cv', 'tensorflow keras applications xception Xception'), ('jessica_cv file_json2file_npy', 'hashlib md5'), ('jessica_cv file_json2file_npy', 'tensorflow keras preprocessing image load_img'), ('jessica_cv file_json2file_npy', 'numpy array'), ('jessica_cv file_json2file_npy', 'tensorflow keras applications xception preprocess_input'), ('jessica_cv file_json2file_npy', 'numpy save'), ('jessica_cv file_json2file_npy', 'time time'), ('jessica_cv file_json2file_npy', 'tensorflow keras preprocessing image img_to_array'), ('jessica_cv train_image_categorization_model', 'jessica_cv build_image_categorization_model'), ('jessica_cv train_image_categorization_model', 'numpy load'), ('jessica_cv train_image_categorization_model', 'numpy max'), ('jessica_cv train_image_categorization_model', 'numpy argmax'), ('jessica_cv update_label_from_positive_file_csv', 'pyspark sql types StructType'), ('jessica_cv image_tagging', 'numpy array'), ('jessica_cv image_tagging', 'numpy max'), ('jessica_cv image_tagging', 'tensorflow keras applications xception preprocess_input'), ('jessica_cv image_tagging', 'numpy argmax'), ('jessica_cv read_image_from_local', 'tensorflow keras preprocessing image load_img'), ('jessica_cv read_image_from_local', 'tensorflow keras preprocessing image img_to_array')]]\n",
      "********************doctrings*************************\n",
      "[\"file json2file npy build image categorization model train image categorization model update label from positive file csv load build image categorization model image tagging read image from local [SEP] input_positive_file_csv = 'uae_flag.csv' input_json = 'image_set.json' output_json = 'uae_flag_updat\", 'cheque tagging']\n",
      "embed index dataset: 11\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hackcha_deepcolor\\\\comic_main.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hackcha_deepcolor\\\\utils.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hackcha_deepcolor\\\\net.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hackcha_deepcolor\\\\download_images.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hackcha_deepcolor\\\\test.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hackcha_deepcolor\\\\baselines.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hackcha_deepcolor\\\\dc_main.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hackcha_deepcolor\\\\merge_image_main.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hackcha_deepcolor\\\\train_utils.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hackcha_deepcolor\\\\test_processing.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hackcha_deepcolor\\\\guess_colors.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hackcha_deepcolor\\\\server.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hackcha_deepcolor\\\\test_real.py']\n",
      "from dc_main import *\n",
      "\n",
      "\n",
      "def comic_it(c, files1, index, img_size = 512):\n",
      "    batch = np.array([cv2.resize(imread(batch_file), (img_size, img_size)) for batch_file in files1])\n",
      "    batch_normalized = batch / 255.0\n",
      "    batch_edge = np.array([cv2.adaptiveThreshold(cv2.cvtColor(ba, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
      "                                                 cv2.THRESH_BINARY, blockSize=9, C=2) for ba in batch]) / 255.0\n",
      "    batch_edge = np.expand_dims(batch_edge, 3)\n",
      "    batch_colors = np.array([c.imageblur(ba, True) for ba in batch]) / 255.0\n",
      "\n",
      "    recreation = c.sess.run(c.generated_images,\n",
      "                            feed_dict={c.real_images: batch_normalized, c.line_images: batch_edge,\n",
      "                                       c.color_images: batch_colors})\n",
      "    out_file = 'data/cmerge_{}.jpg'.format(index)\n",
      "    edge_file = 'data/cedge_{}.jpg'.format(i)\n",
      "    ims(edge_file, merge_color(batch_edge, [c.batch_size_sqrt, c.batch_size_sqrt]))\n",
      "    ims(out_file, merge_color(recreation, [c.batch_size_sqrt, c.batch_size_sqrt]))\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    img_size= 512\n",
      "    import dc_main\n",
      "    dc_main.upsplash = False\n",
      "    c = Color(img_size, 1)\n",
      "    c.loadmodel( False )\n",
      "    print('load model done.')\n",
      "    files1 = ['data/timg_.jpg','data/timg.jpg', 'data/lyf1.jpg', 'data/lyf2.jpg']\n",
      "    for i, file1 in enumerate( files1):\n",
      "        comic_it(c,[file1], i, img_size=img_size)\n",
      "    print('done.')\n",
      "\n",
      "Output: {'comic_main': ['dc_main.Color.__init__', 'dc_main.Color.loadmodel', 'comic_main.comic_it', '<builtin>.enumerate', '<builtin>.print'], 'comic_main.comic_it': ['utils.merge_color', 'numpy.expand_dims', 'cv2.cvtColor', 'cv2.adaptiveThreshold', 'utils.imread', 'numpy.array', 'utils.ims', 'dc_main.Color.imageblur', 'cv2.resize'], 'utils.imread': ['cv2.imread'], 'cv2.resize': [], 'numpy.array': [], 'cv2.cvtColor': [], 'cv2.adaptiveThreshold': [], 'numpy.expand_dims': [], 'dc_main.Color.imageblur': ['<builtin>.range', 'numpy.ones_like', 'random.randint', 'cv2.blur'], 'utils.merge_color': ['numpy.zeros', '<builtin>.int', '<builtin>.enumerate'], 'utils.ims': ['<builtin>.print', 'cv2.imwrite'], 'dc_main.Color.__init__': ['utils.batch_norm.__init__', '<builtin>.int', 'tensorflow.train.AdamOptimizer', 'tensorflow.placeholder', 'tensorflow.abs', 'tensorflow.zeros_like', 'tensorflow.trainable_variables', 'tensorflow.nn.sigmoid_cross_entropy_with_logits', 'tensorflow.concat', 'math.sqrt', 'dc_main.Color.generator', 'tensorflow.ones_like', 'dc_main.Color.discriminator', 'tensorflow.reduce_mean', 'tensorflow.variable_scope'], 'dc_main.Color.loadmodel': ['tensorflow.ConfigProto', 'tensorflow.train.Saver', 'tensorflow.Session', 'tensorflow.GPUOptions', 'dc_main.Color.load', 'tensorflow.initialize_all_variables', '<builtin>.print'], '<builtin>.print': [], '<builtin>.enumerate': [], 'dc_main': ['dc_main.Color.__init__', 'dc_main.Color.train', '<builtin>.print', 'dc_main.Color.sample', '<builtin>.len'], 'math.sqrt': [], '<builtin>.int': [], 'utils.batch_norm.__init__': [], 'tensorflow.placeholder': [], 'tensorflow.concat': [], 'dc_main.Color.generator': ['<builtin>.int', 'utils.bn', 'utils.deconv2d', 'tensorflow.concat', 'utils.conv2d', 'tensorflow.nn.tanh', 'tensorflow.nn.relu', 'utils.lrelu'], 'dc_main.Color.discriminator': ['utils.batch_norm.__init__', 'tensorflow.reshape', 'tensorflow.nn.sigmoid', 'tensorflow.get_variable_scope', 'utils.conv2d', 'utils.linear', 'utils.lrelu'], 'tensorflow.ones_like': [], 'tensorflow.nn.sigmoid_cross_entropy_with_logits': [], 'tensorflow.reduce_mean': [], 'tensorflow.zeros_like': [], 'tensorflow.abs': [], 'tensorflow.trainable_variables': [], 'tensorflow.variable_scope': [], 'tensorflow.train.AdamOptimizer': [], 'tensorflow.get_variable_scope': [], 'utils.conv2d': ['tensorflow.constant_initializer', 'tensorflow.get_variable', 'tensorflow.reshape', 'tensorflow.nn.bias_add', 'tensorflow.truncated_normal_initializer', 'tensorflow.nn.conv2d', 'tensorflow.variable_scope'], 'utils.lrelu': ['tensorflow.maximum'], 'tensorflow.reshape': [], 'utils.linear': ['tensorflow.constant_initializer', 'tensorflow.get_variable', 'tensorflow.random_normal_initializer', 'tensorflow.matmul', 'tensorflow.variable_scope'], 'tensorflow.nn.sigmoid': [], 'utils.bn': ['utils.batch_norm.__init__', '<builtin>.str'], 'tensorflow.nn.relu': [], 'utils.deconv2d': ['tensorflow.constant_initializer', 'tensorflow.get_variable', 'tensorflow.reshape', 'tensorflow.nn.conv2d_transpose', 'tensorflow.random_normal_initializer', 'tensorflow.nn.bias_add', 'tensorflow.variable_scope'], 'tensorflow.nn.tanh': [], 'numpy.ones_like': [], '<builtin>.range': [], 'random.randint': [], 'cv2.blur': [], 'dc_main.Color.train': ['utils.merge_color', 'numpy.expand_dims', '<builtin>.int', 'glob.glob', 'cv2.cvtColor', '<builtin>.range', 'utils.ims', 'cv2.adaptiveThreshold', 'dc_main.Color.loadmodel', 'dc_main.Color.save', 'utils.get_image', 'numpy.array', '<builtin>.str', 'os.path.join', 'dc_main.Color.imageblur', '<builtin>.print', 'utils.merge', '<builtin>.len'], 'os.path.join': [], 'glob.glob': [], 'utils.get_image': ['utils.imread', 'utils.transform'], 'utils.merge': ['numpy.zeros', '<builtin>.int', '<builtin>.enumerate'], '<builtin>.len': [], '<builtin>.str': [], 'dc_main.Color.save': ['os.path.join', 'os.makedirs', 'os.path.exists'], 'tensorflow.GPUOptions': [], 'tensorflow.ConfigProto': [], 'tensorflow.Session': [], 'tensorflow.initialize_all_variables': [], 'tensorflow.train.Saver': [], 'dc_main.Color.load': ['os.path.join', '<builtin>.print', 'tensorflow.train.get_checkpoint_state', 'os.path.basename'], 'dc_main.Color.sample': ['utils.merge_color', 'numpy.expand_dims', '<builtin>.min', 'glob.glob', 'cv2.cvtColor', 'dc_main.Color.imageblur', 'cv2.adaptiveThreshold', 'utils.imread', 'dc_main.Color.loadmodel', 'utils.ims', '<builtin>.str', 'numpy.array', 'os.path.join', 'cv2.resize', '<builtin>.range', '<builtin>.len'], '<builtin>.min': [], 'os.path.exists': [], 'os.makedirs': [], 'tensorflow.train.get_checkpoint_state': [], 'os.path.basename': [], 'utils': [], 'utils.batch_norm.__call__': ['tensorflow.contrib.layers.batch_norm'], 'tensorflow.contrib.layers.batch_norm': [], 'utils.bnreset': [], 'tensorflow.truncated_normal_initializer': [], 'tensorflow.get_variable': [], 'tensorflow.nn.conv2d': [], 'tensorflow.constant_initializer': [], 'tensorflow.nn.bias_add': [], 'tensorflow.random_normal_initializer': [], 'tensorflow.nn.conv2d_transpose': [], 'tensorflow.maximum': [], 'tensorflow.matmul': [], 'utils.transform': ['numpy.array', 'cv2.resize'], 'cv2.imread': [], 'numpy.zeros': [], 'cv2.imwrite': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hackcha_deepcolor\\comic_main.py\n",
      "[('comic_main', 'dc_main Color __init__'), ('comic_main', 'dc_main Color loadmodel'), ('comic_main', 'comic_main comic_it'), ('comic_main comic_it', 'utils merge_color'), ('comic_main comic_it', 'numpy expand_dims'), ('comic_main comic_it', 'cv2 cvtColor'), ('comic_main comic_it', 'cv2 adaptiveThreshold'), ('comic_main comic_it', 'utils imread'), ('comic_main comic_it', 'numpy array'), ('comic_main comic_it', 'utils ims'), ('comic_main comic_it', 'dc_main Color imageblur'), ('comic_main comic_it', 'cv2 resize'), ('utils imread', 'cv2 imread'), ('dc_main Color imageblur', 'numpy ones_like'), ('dc_main Color imageblur', 'random randint'), ('dc_main Color imageblur', 'cv2 blur'), ('utils merge_color', 'numpy zeros'), ('utils ims', 'cv2 imwrite'), ('dc_main Color __init__', 'utils batch_norm __init__'), ('dc_main Color __init__', 'tensorflow train AdamOptimizer'), ('dc_main Color __init__', 'tensorflow placeholder'), ('dc_main Color __init__', 'tensorflow abs'), ('dc_main Color __init__', 'tensorflow zeros_like'), ('dc_main Color __init__', 'tensorflow trainable_variables'), ('dc_main Color __init__', 'tensorflow nn sigmoid_cross_entropy_with_logits'), ('dc_main Color __init__', 'tensorflow concat'), ('dc_main Color __init__', 'math sqrt'), ('dc_main Color __init__', 'dc_main Color generator'), ('dc_main Color __init__', 'tensorflow ones_like'), ('dc_main Color __init__', 'dc_main Color discriminator')]\n",
      "0\n",
      "found files: []\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import cv2\n",
      "\n",
      "class batch_norm(object):\n",
      "            # h1 = lrelu(tf.contrib.layers.batch_norm(conv2d(h0, self.df_dim*2, name='d_h1_conv'),decay=0.9,updates_collections=None,epsilon=0.00001,scale=True,scope=\"d_h1_conv\"))\n",
      "    def __init__(self, epsilon=1e-5, momentum = 0.9, name=\"batch_norm\"):\n",
      "        #\n",
      "        # with tf.variable_scope(name):\n",
      "        self.epsilon = epsilon\n",
      "        self.momentum = momentum\n",
      "        self.name = name\n",
      "\n",
      "    def __call__(self, x, train=True):\n",
      "        return tf.contrib.layers.batch_norm(x, decay=self.momentum, updates_collections=None, epsilon=self.epsilon, scale=True, scope=self.name)\n",
      "\n",
      "batchnorm_count = 0\n",
      "def bnreset():\n",
      "    global batchnorm_count\n",
      "    batchnorm_count = 0\n",
      "def bn(x):\n",
      "    global batchnorm_count\n",
      "    batch_object = batch_norm(name=(\"bn\" + str(batchnorm_count)))\n",
      "    batchnorm_count += 1\n",
      "    return batch_object(x)\n",
      "\n",
      "def conv2d(input_, output_dim,\n",
      "           k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,\n",
      "           name=\"conv2d\"):\n",
      "    with tf.variable_scope(name):\n",
      "        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n",
      "                            initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
      "        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\n",
      "\n",
      "        biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
      "        conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n",
      "\n",
      "        return conv\n",
      "\n",
      "def deconv2d(input_, output_shape,\n",
      "             k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,\n",
      "             name=\"deconv2d\", with_w=False):\n",
      "    with tf.variable_scope(name):\n",
      "        # filter : [height, width, output_channels, in_channels]\n",
      "        w = tf.get_variable('w', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]], initializer=tf.random_normal_initializer(stddev=stddev))\n",
      "        deconv = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape, strides=[1, d_h, d_w, 1])\n",
      "        biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
      "        deconv = tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())\n",
      "        if with_w:\n",
      "            return deconv, w, biases\n",
      "        else:\n",
      "            return deconv\n",
      "\n",
      "\n",
      "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
      "  return tf.maximum(x, leak*x)\n",
      "\n",
      "def linear(input_, output_size, scope=None, stddev=0.02, bias_start=0.0, with_w=False):\n",
      "    shape = input_.get_shape().as_list()\n",
      "    with tf.variable_scope(scope or \"Linear\"):\n",
      "        matrix = tf.get_variable(\"Matrix\", [shape[1], output_size], tf.float32,\n",
      "                                 tf.random_normal_initializer(stddev=stddev))\n",
      "        bias = tf.get_variable(\"bias\", [output_size],\n",
      "            initializer=tf.constant_initializer(bias_start))\n",
      "        if with_w:\n",
      "            return tf.matmul(input_, matrix) + bias, matrix, bias\n",
      "        else:\n",
      "            return tf.matmul(input_, matrix) + bias\n",
      "\n",
      "def get_image(image_path, target_size=(256, 256)):\n",
      "    return transform(imread(image_path), target_size)\n",
      "\n",
      "def transform(image, target_size=(256, 256)):\n",
      "    cropped_image = cv2.resize(image, target_size)\n",
      "\n",
      "    return np.array(cropped_image)\n",
      "\n",
      "def imread(path):\n",
      "    readimage = cv2.imread(path, 1)\n",
      "    return readimage\n",
      "\n",
      "def merge_color(images, size):\n",
      "    h, w = images.shape[1], images.shape[2]\n",
      "    img = np.zeros((h * size[0], w * size[1], 3))\n",
      "\n",
      "    for idx, image in enumerate(images):\n",
      "        i = int(idx % size[1])\n",
      "        j = int(idx / size[1])\n",
      "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
      "\n",
      "    return img\n",
      "\n",
      "def merge(images, size):\n",
      "    h, w = images.shape[1], images.shape[2]\n",
      "    img = np.zeros((h * size[0], w * size[1], 1))\n",
      "\n",
      "    for idx, image in enumerate(images):\n",
      "        i = int(idx % size[1])\n",
      "        j = int(idx / size[1])\n",
      "        img[j*h:j*h+h, i*w:i*w+w] = image\n",
      "\n",
      "    return img[:,:,0]\n",
      "\n",
      "def ims(name, img):\n",
      "    print(\"saving img \" + name)\n",
      "    cv2.imwrite(name, img*255)\n",
      "\n",
      "Output: {'utils': [], 'utils.batch_norm.__init__': [], 'utils.batch_norm.__call__': ['tensorflow.contrib.layers.batch_norm'], 'tensorflow.contrib.layers.batch_norm': [], 'utils.bnreset': [], 'utils.bn': ['<builtin>.str', 'utils.batch_norm.__init__'], '<builtin>.str': [], 'utils.conv2d': ['tensorflow.get_variable', 'tensorflow.nn.bias_add', 'tensorflow.reshape', 'tensorflow.constant_initializer', 'tensorflow.truncated_normal_initializer', 'tensorflow.nn.conv2d', 'tensorflow.variable_scope'], 'tensorflow.variable_scope': [], 'tensorflow.truncated_normal_initializer': [], 'tensorflow.get_variable': [], 'tensorflow.nn.conv2d': [], 'tensorflow.constant_initializer': [], 'tensorflow.nn.bias_add': [], 'tensorflow.reshape': [], 'utils.deconv2d': ['tensorflow.random_normal_initializer', 'tensorflow.get_variable', 'tensorflow.nn.conv2d_transpose', 'tensorflow.nn.bias_add', 'tensorflow.reshape', 'tensorflow.constant_initializer', 'tensorflow.variable_scope'], 'tensorflow.random_normal_initializer': [], 'tensorflow.nn.conv2d_transpose': [], 'utils.lrelu': ['tensorflow.maximum'], 'tensorflow.maximum': [], 'utils.linear': ['tensorflow.random_normal_initializer', 'tensorflow.get_variable', 'tensorflow.constant_initializer', 'tensorflow.matmul', 'tensorflow.variable_scope'], 'tensorflow.matmul': [], 'utils.get_image': ['utils.transform', 'utils.imread'], 'utils.imread': ['cv2.imread'], 'utils.transform': ['numpy.array', 'cv2.resize'], 'cv2.resize': [], 'numpy.array': [], 'cv2.imread': [], 'utils.merge_color': ['<builtin>.enumerate', 'numpy.zeros', '<builtin>.int'], 'numpy.zeros': [], '<builtin>.enumerate': [], '<builtin>.int': [], 'utils.merge': ['<builtin>.enumerate', 'numpy.zeros', '<builtin>.int'], 'utils.ims': ['<builtin>.print', 'cv2.imwrite'], '<builtin>.print': [], 'cv2.imwrite': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hackcha_deepcolor\\utils.py\n",
      "[('utils batch_norm __call__', 'tensorflow contrib layers batch_norm'), ('utils bn', 'utils batch_norm __init__'), ('utils conv2d', 'tensorflow get_variable'), ('utils conv2d', 'tensorflow nn bias_add'), ('utils conv2d', 'tensorflow reshape'), ('utils conv2d', 'tensorflow constant_initializer'), ('utils conv2d', 'tensorflow truncated_normal_initializer'), ('utils conv2d', 'tensorflow nn conv2d'), ('utils conv2d', 'tensorflow variable_scope'), ('utils deconv2d', 'tensorflow random_normal_initializer'), ('utils deconv2d', 'tensorflow get_variable'), ('utils deconv2d', 'tensorflow nn conv2d_transpose'), ('utils deconv2d', 'tensorflow nn bias_add'), ('utils deconv2d', 'tensorflow reshape'), ('utils deconv2d', 'tensorflow constant_initializer'), ('utils deconv2d', 'tensorflow variable_scope'), ('utils lrelu', 'tensorflow maximum'), ('utils linear', 'tensorflow random_normal_initializer'), ('utils linear', 'tensorflow get_variable'), ('utils linear', 'tensorflow constant_initializer'), ('utils linear', 'tensorflow matmul'), ('utils linear', 'tensorflow variable_scope'), ('utils get_image', 'utils transform'), ('utils get_image', 'utils imread'), ('utils imread', 'cv2 imread'), ('utils transform', 'numpy array'), ('utils transform', 'cv2 resize'), ('utils merge_color', 'numpy zeros'), ('utils merge', 'numpy zeros'), ('utils ims', 'cv2 imwrite')]\n",
      "0\n",
      "found files: []\n",
      "import keras\n",
      "from keras.applications.inception_v3 import InceptionV3\n",
      "from keras.applications.inception_v3 import preprocess_input\n",
      "# from keras.applications.vgg16 import VGG16, preprocess_input\n",
      "from keras.preprocessing import image\n",
      "from keras.engine import Layer\n",
      "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate, Activation, Dense, Dropout, Flatten\n",
      "from keras.layers import add\n",
      "from keras.activations import relu\n",
      "from keras.layers.normalization import BatchNormalization\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.models import Sequential, Model\n",
      "from keras.layers.core import RepeatVector, Permute\n",
      "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
      "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "from keras.optimizers import SGD, Adam\n",
      "from skimage.transform import resize\n",
      "import keras.activations\n",
      "# from skimage.io import imsave\n",
      "from matplotlib import pyplot\n",
      "import numpy as np\n",
      "import os\n",
      "import random\n",
      "import tensorflow as tf\n",
      "import keras.backend as K\n",
      "from keras.layers.advanced_activations import LeakyReLU\n",
      "\n",
      "def lrelu(x, leak = 0.2, name = \"lrelu\"):\n",
      "    return K.maximum(x, leak * x)\n",
      "\n",
      "\n",
      "def conv_stack(data, filters, s, activation=lrelu, padding='same',name=None):#padding='same'?\n",
      "    x = Activation(activation)(data)\n",
      "    x = Conv2D(filters, (5, 5), strides=s, padding=padding,\n",
      "               kernel_initializer=keras.initializers.truncated_normal(stddev=0.02), name=name)(x)\n",
      "    bn_name = None\n",
      "    if name is not None:\n",
      "        bn_name = name+'_bn'\n",
      "    x = new_BatchNorm(bn_name)(x)\n",
      "    # output = BatchNormalization()(output)\n",
      "    return x\n",
      "\n",
      "def conv_stack_noname(data, filters, s, activation=lrelu, padding='same',name=None):#padding='same'?\n",
      "    x = Activation(activation)(data)\n",
      "    x = Conv2D(filters, (5, 5), strides=s, padding=padding,\n",
      "               kernel_initializer=keras.initializers.truncated_normal(stddev=0.02), name=name)(x)\n",
      "    x = new_BatchNorm()(x)\n",
      "    # output = BatchNormalization()(output)\n",
      "    return x\n",
      "\n",
      "def resnet_block( encoder_input, filter_size, stride ):\n",
      "    x = conv_stack(encoder_input, filter_size, stride)\n",
      "    x = conv_stack(x, filter_size, 1)\n",
      "    shortcut = Conv2D(filter_size, (1, 1), strides=stride)(encoder_input)\n",
      "    shortcut = BatchNormalization()(shortcut)\n",
      "    x = add([x, shortcut])\n",
      "    return x\n",
      "\n",
      "def abnet( img_size ):\n",
      "    # Encoder\n",
      "    encoder_input = Input(shape=(img_size, img_size, 1))\n",
      "    encoder_output = conv_stack(encoder_input, 32, 2)\n",
      "    encoder_output = conv_stack(encoder_output, 32, 1)\n",
      "\n",
      "    encoder_output = conv_stack(encoder_output, 64, 2)\n",
      "    encoder_output = conv_stack(encoder_output, 64, 1)\n",
      "    encoder_output = conv_stack(encoder_output, 128, 2)\n",
      "    encoder_output = conv_stack(encoder_output, 128, 1)\n",
      "    encoder_output = conv_stack(encoder_output, 256, 1)\n",
      "    encoder_output = conv_stack(encoder_output, 256, 1)\n",
      "    # Decoder\n",
      "    decoder_output = conv_stack(encoder_output, 128, 1)\n",
      "    decoder_output = conv_stack(decoder_output, 128, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = conv_stack(decoder_output, 64, 1)\n",
      "    decoder_output = conv_stack(decoder_output, 64, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = conv_stack(decoder_output, 32, 1)\n",
      "    decoder_output = conv_stack(decoder_output, 32, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)  #\n",
      "    # model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n",
      "    model = Model(inputs=encoder_input, outputs=decoder_output)\n",
      "    model.summary()\n",
      "    return model\n",
      "\n",
      "bni = 0\n",
      "def new_BatchNorm(name=None):\n",
      "    return BatchNormalization(momentum=0.9,epsilon=1e-5, scale=True, name=name)\n",
      "\n",
      "def rgbnet( img_size ):\n",
      "    # Encoder\n",
      "    name_prefix = \"gen_\"\n",
      "    encoder_input = Input(shape=(img_size, img_size, 1))\n",
      "    encoder_output = conv_stack(encoder_input, 32, 2, name=name_prefix+'c2')\n",
      "    encoder_output = conv_stack(encoder_output, 32, 1)\n",
      "\n",
      "    encoder_output = conv_stack(encoder_output, 64, 2)\n",
      "    encoder_output = conv_stack(encoder_output, 64, 1)\n",
      "    encoder_output = conv_stack(encoder_output, 128, 2)\n",
      "    encoder_output = conv_stack(encoder_output, 128, 1)\n",
      "    encoder_output = conv_stack(encoder_output, 256, 1)\n",
      "    encoder_output = conv_stack(encoder_output, 256, 1)\n",
      "    # Decoder\n",
      "    decoder_output = conv_stack(encoder_output, 128, 1)\n",
      "    decoder_output = conv_stack(decoder_output, 128, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = conv_stack(decoder_output, 64, 1)\n",
      "    decoder_output = conv_stack(decoder_output, 64, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = conv_stack(decoder_output, 32, 1)\n",
      "    decoder_output = conv_stack(decoder_output, 32, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(decoder_output)  #\n",
      "    # model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n",
      "    model = Model(inputs=encoder_input, outputs=decoder_output)\n",
      "    model.summary()\n",
      "    return model\n",
      "\n",
      "from keras.layers import Deconvolution2D, Conv2DTranspose\n",
      "def rgb_unet( img_size, cdim = 4 ):\n",
      "    # Encoder\n",
      "    name_prefix = \"gen_\"\n",
      "    # if as_tf:\n",
      "    #     x_in = tf.placeholder(tf.float32, shape=[None, img_size, img_size, cdim])\n",
      "    #     encoder_input = Input(tensor=x_in)\n",
      "    # else:\n",
      "    encoder_input = Input(shape=(img_size, img_size, cdim))\n",
      "    df_dim = 64\n",
      "    #e1 = conv_stack(encoder_input, df_dim, 2)#128\n",
      "    e1 = Conv2D(df_dim, (5, 5), strides=2, padding='same',\n",
      "               kernel_initializer=keras.initializers.truncated_normal(stddev=0.02), name=name_prefix+'c1')(encoder_input)\n",
      "    e2 = conv_stack_noname(e1, df_dim*2, 2, name=name_prefix+'c2')#64\n",
      "    e3 = conv_stack_noname(e2, df_dim*4, 2, name=name_prefix+'c3')#32\n",
      "    e4 = conv_stack_noname(e3, df_dim*8, 2, name=name_prefix+'c4')#16\n",
      "    # Decoder\n",
      "    e5 = conv_stack_noname(e4, df_dim * 8, 2, name=name_prefix+'c5')#8\n",
      "\n",
      "    d5 = Activation(lrelu)(e5)\n",
      "    d4 = Conv2DTranspose(df_dim*8, (5,5), strides=2, padding='same',\n",
      "                         kernel_initializer=keras.initializers.truncated_normal(stddev=0.02), name=name_prefix+'dc1')(d5)#16\n",
      "    d4 = new_BatchNorm()(d4)\n",
      "    d4 = concatenate([d4,e4], axis=-1)#64\n",
      "    d4 = Activation(lrelu)(d4)\n",
      "    d3 = Conv2DTranspose(df_dim * 2, (5, 5), strides=2, padding='same',\n",
      "                         kernel_initializer=keras.initializers.truncated_normal(stddev=0.02), name=name_prefix+'dc2')(d4)  #32\n",
      "    d3 = new_BatchNorm()(d3)\n",
      "    d3 = concatenate([d3, e3], axis=-1)\n",
      "    d3 = Activation(lrelu)(d3)\n",
      "    d2 = Conv2DTranspose(df_dim , (5, 5), strides=2, padding='same',\n",
      "                         kernel_initializer=keras.initializers.truncated_normal(stddev=0.02), name=name_prefix+'dc3')(d3)#64\n",
      "    d2 = new_BatchNorm()(d2)\n",
      "    d2 = concatenate([d2, e2],axis=-1)#256\n",
      "    d2 = Activation(lrelu)(d2)\n",
      "    d1 = Conv2DTranspose(df_dim, (5, 5), strides=2, padding='same',\n",
      "                         kernel_initializer=keras.initializers.truncated_normal(stddev=0.02), name=name_prefix+'dc4')(d2)#128\n",
      "    d1 = new_BatchNorm()(d1)\n",
      "    d1 = concatenate([d1, e1], axis=-1)\n",
      "    d1 = Activation(lrelu)(d1)\n",
      "\n",
      "    decoder_output = Conv2DTranspose(3, (5, 5), strides=2, padding='same',\n",
      "                            kernel_initializer=keras.initializers.truncated_normal(stddev=0.02), name=name_prefix+'dc5' )(d1)  #256\n",
      "    decoder_output = Activation('sigmoid')(decoder_output)\n",
      "    # model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n",
      "    model = Model(inputs=encoder_input, outputs=decoder_output)\n",
      "    return model\n",
      "\n",
      "def discriminator( img_size, cdim = 3):\n",
      "    name_frefix = \"dis_\"\n",
      "    encoder_input = Input(shape=(img_size, img_size, cdim))\n",
      "    df_dim = 64\n",
      "    # e1 = conv_stack(encoder_input, df_dim, 2)\n",
      "    #BN\n",
      "    e1 = Conv2D(df_dim, (5, 5), strides=2,\n",
      "               kernel_initializer=keras.initializers.truncated_normal(stddev=0.02), name=name_frefix+'c1')(encoder_input)\n",
      "    e2 = conv_stack(e1, df_dim*2, 2,padding='valid', name=name_frefix+'c2')#64\n",
      "    e3 = conv_stack(e2, df_dim*4, 2,padding='valid', name=name_frefix+'c3')#32\n",
      "    e4 = conv_stack(e3, df_dim*8, 1,padding='valid', name=name_frefix+'c4')#32\n",
      "    e4 = Activation(lrelu)(e4)\n",
      "    d5 = Flatten()(e4 ) #32\n",
      "    #instead of using activation='sigmoid', we can use cross_entropy_with_logits\n",
      "    pred = Dense(1,kernel_initializer=keras.initializers.truncated_normal(stddev=0.02), name=name_frefix+'ds1' )(d5)\n",
      "    model = Model(inputs=encoder_input, outputs=pred)\n",
      "    return model\n",
      "\n",
      "def CGAN( gm, dm, img_size, cdim=3 ):\n",
      "    input = Input(shape=(img_size, img_size, cdim))\n",
      "    generated_image = gm(input)\n",
      "    feats = concatenate([generated_image, input], axis=-1)\n",
      "    dcgan_output = dm(feats)\n",
      "    dc_gan = Model(inputs=[input], outputs=[generated_image, dcgan_output], name=\"DCGAN\")\n",
      "    return dc_gan\n",
      "\n",
      "\n",
      "\n",
      "def rgbnet_resnet(img_size):\n",
      "    # Encoder\n",
      "    encoder_input = Input(shape=(img_size, img_size, 1))\n",
      "    encoder_output = resnet_block( encoder_input, 32, 2)\n",
      "    encoder_output = resnet_block(encoder_output, 64, 2)\n",
      "    encoder_output = resnet_block(encoder_output, 128, 2)\n",
      "    # encoder_output = resnet_block(encoder_output, 256, 1)\n",
      "    # Decoder\n",
      "    decoder_output = resnet_block(encoder_output, 128, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = resnet_block(decoder_output, 64, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = resnet_block(decoder_output, 32, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(decoder_output)  #\n",
      "    # model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n",
      "    model = Model(inputs=encoder_input, outputs=decoder_output)\n",
      "    model.summary()\n",
      "    return model\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def abnet_resnet(img_size):\n",
      "    # Encoder\n",
      "    encoder_input = Input(shape=(img_size, img_size, 1))\n",
      "    encoder_output = resnet_block( encoder_input, 32, 2)\n",
      "    encoder_output = resnet_block(encoder_output, 64, 2)\n",
      "    encoder_output = resnet_block(encoder_output, 128, 2)\n",
      "    # encoder_output = resnet_block(encoder_output, 256, 1)\n",
      "    # Decoder\n",
      "    decoder_output = resnet_block(encoder_output, 128, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = resnet_block(decoder_output, 64, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = resnet_block(decoder_output, 32, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)  #\n",
      "    # model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n",
      "    model = Model(inputs=encoder_input, outputs=decoder_output)\n",
      "    model.summary()\n",
      "    return model\n",
      "\n",
      "def abnet_trans( img_size ):\n",
      "    embed_input = Input(shape=(1000,))\n",
      "    # Encoder\n",
      "    encoder_input = Input(shape=(img_size, img_size, 1))\n",
      "    # encoder_output = conv_stack(encoder_input, 32, 1)\n",
      "    # encoder_output = conv_stack(encoder_output, 32, 1)\n",
      "    # encoder_output = conv_stack(encoder_output, 64, 2)\n",
      "    # encoder_output = conv_stack(encoder_output, 64, 1)\n",
      "    # TODO 256 size\n",
      "    encoder_output = conv_stack(encoder_input, 64, 2)\n",
      "    encoder_output = conv_stack(encoder_output, 128, 1)\n",
      "    encoder_output = conv_stack(encoder_output, 128, 2)\n",
      "    encoder_output = conv_stack(encoder_output, 256, 1)\n",
      "    encoder_output = conv_stack(encoder_output, 256, 2)\n",
      "    encoder_output = conv_stack(encoder_output, 512, 1)\n",
      "    encoder_output = conv_stack(encoder_output, 512, 1)\n",
      "    encoder_output = conv_stack(encoder_output, 256, 1)\n",
      "\n",
      "    # Fusion\n",
      "    fusion_output = RepeatVector(32 * 32)(embed_input)\n",
      "    fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n",
      "    fusion_output = concatenate([fusion_output, encoder_output], axis=3)\n",
      "    fusion_output = Conv2D(256, (1, 1), activation='relu')(fusion_output)\n",
      "\n",
      "    # Decoder\n",
      "    decoder_output = conv_stack(fusion_output, 128, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = conv_stack(decoder_output, 64, 1)\n",
      "    decoder_output = conv_stack(decoder_output, 64, 1)\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "    decoder_output = conv_stack(decoder_output, 32, 1)\n",
      "    decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)  #\n",
      "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
      "\n",
      "    model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n",
      "    model.summary()\n",
      "    return model\n",
      "\n",
      "from dc_main import *\n",
      "def generator(img_in, batch_size=4):\n",
      "    output_size = 256\n",
      "    gf_dim  = 64\n",
      "    s = output_size\n",
      "    s2, s4, s8, s16, s32, s64, s128 = int(s/2), int(s/4), int(s/8), int(s/16), int(s/32), int(s/64), int(s/128)\n",
      "    # image is (256 x 256 x input_c_dim)\n",
      "    e1 = conv2d(img_in, gf_dim, name='g_e1_conv') # e1 is (128 x 128 x self.gf_dim)\n",
      "    e2 = bn(conv2d(lrelu(e1), gf_dim*2, name='g_e2_conv')) # e2 is (64 x 64 x self.gf_dim*2)\n",
      "    e3 = bn(conv2d(lrelu(e2), gf_dim*4, name='g_e3_conv')) # e3 is (32 x 32 x self.gf_dim*4)\n",
      "    e4 = bn(conv2d(lrelu(e3), gf_dim*8, name='g_e4_conv')) # e4 is (16 x 16 x self.gf_dim*8)\n",
      "    e5 = bn(conv2d(lrelu(e4), gf_dim*8, name='g_e5_conv')) # e5 is (8 x 8 x self.gf_dim*8)\n",
      "\n",
      "\n",
      "    d4, d4_w, d4_b = deconv2d(tf.nn.relu(e5), [batch_size, s16, s16, gf_dim*8], name='g_d4', with_w=True)\n",
      "    d4 = bn(d4)\n",
      "    d4 = tf.concat([d4, e4],3)\n",
      "    # d4 is (16 x 16 x self.gf_dim*8*2)\n",
      "\n",
      "    d5, d5_w, d5_b = deconv2d(tf.nn.relu(d4), [batch_size, s8, s8, gf_dim*4], name='g_d5', with_w=True)\n",
      "    d5 = bn(d5)\n",
      "    d5 = tf.concat([d5, e3],3)\n",
      "    # d5 is (32 x 32 x self.gf_dim*4*2)\n",
      "\n",
      "    d6, d6_w, d6_b = deconv2d(tf.nn.relu(d5), [batch_size, s4, s4, gf_dim*2], name='g_d6', with_w=True)\n",
      "    d6 = bn(d6)\n",
      "    d6 = tf.concat([d6, e2],3)\n",
      "    # d6 is (64 x 64 x self.gf_dim*2*2)\n",
      "\n",
      "    d7, d7_w, d7_b = deconv2d(tf.nn.relu(d6), [batch_size, s2, s2, gf_dim], name='g_d7', with_w=True)\n",
      "    d7 = bn(d7)\n",
      "    d7 = tf.concat([d7, e1],3)\n",
      "    # d7 is (128 x 128 x self.gf_dim*1*2)\n",
      "\n",
      "    d8, d8_w, d8_b = deconv2d(tf.nn.relu(d7), [batch_size, s, s, 3], name='g_d8', with_w=True)\n",
      "    # d8 is (256 x 256 x output_c_dim)\n",
      "    return tf.nn.sigmoid(d8)#tf.nn.tanh(d8)\n",
      "\n",
      "def discriminator_tf( image, d_bn1, d_bn2, d_bn3, reuse=False,batch_size=4):\n",
      "    # image is 256 x 256 x (input_c_dim + output_c_dim)\n",
      "    if reuse:\n",
      "        tf.get_variable_scope().reuse_variables()\n",
      "    else:\n",
      "        assert tf.get_variable_scope().reuse == False\n",
      "    df_dim = 64\n",
      "    h0 = lrelu(conv2d(image, df_dim, name='d_h0_conv')) # h0 is (128 x 128 x self.df_dim)\n",
      "    h1 = lrelu(d_bn1(conv2d(h0, df_dim*2, name='d_h1_conv'))) # h1 is (64 x 64 x self.df_dim*2)\n",
      "    h2 = lrelu(d_bn2(conv2d(h1, df_dim*4, name='d_h2_conv'))) # h2 is (32 x 32 x self.df_dim*4)\n",
      "    h3 = lrelu(d_bn3(conv2d(h2, df_dim*8, d_h=1, d_w=1, name='d_h3_conv'))) # h3 is (16 x 16 x self.df_dim*8)\n",
      "    h4 = linear(tf.reshape(h3, [batch_size, -1]), 1, 'd_h3_lin')\n",
      "    return tf.nn.sigmoid(h4), h4\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hackcha_deepcolor\\net.py\n",
      "[]\n",
      "found files: []\n",
      "import urllib.request, urllib.error, urllib.parse\n",
      "import urllib.request, urllib.parse, urllib.error\n",
      "import json\n",
      "import numpy as np\n",
      "import cv2\n",
      "import untangle\n",
      "\n",
      "maxsize = 512\n",
      "\n",
      "# tags = [\"asu_tora\",\"puuakachan\",\"mankun\",\"hammer_%28sunset_beach%29\",\"\"]\n",
      "\n",
      "# for tag in tags:\n",
      "\n",
      "count = 0\n",
      "\n",
      "for i in range(10000):\n",
      "    stringreturn = urllib.request.urlopen(\"http://safebooru.org/index.php?page=dapi&s=post&q=index&tags=1girl%20solo&pid=\"+str(i+3000)).read()\n",
      "    xmlreturn = untangle.parse(stringreturn)\n",
      "    for post in xmlreturn.posts.post:\n",
      "        imgurl = \"http:\" + post[\"sample_url\"]\n",
      "        print(imgurl)\n",
      "        if (\"png\" in imgurl) or (\"jpg\" in imgurl):\n",
      "\n",
      "            resp = urllib.request.urlopen(imgurl)\n",
      "            image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
      "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
      "            height, width = image.shape[:2]\n",
      "            if height > width:\n",
      "                scalefactor = (maxsize*1.0) / width\n",
      "                res = cv2.resize(image,(int(width * scalefactor), int(height*scalefactor)), interpolation = cv2.INTER_CUBIC)\n",
      "                cropped = res[0:maxsize,0:maxsize]\n",
      "            if width > height:\n",
      "                scalefactor = (maxsize*1.0) / height\n",
      "                res = cv2.resize(image,(int(width * scalefactor), int(height*scalefactor)), interpolation = cv2.INTER_CUBIC)\n",
      "                center_x = int(round(width*scalefactor*0.5))\n",
      "                print(center_x)\n",
      "                cropped = res[0:maxsize,center_x - maxsize/2:center_x + maxsize/2]\n",
      "\n",
      "            # img_edge = cv2.adaptiveThreshold(cropped, 255,\n",
      "            #                                  cv2.ADAPTIVE_THRESH_MEAN_C,\n",
      "            #                                  cv2.THRESH_BINARY,\n",
      "            #                                  blockSize=9,\n",
      "            #                                  C=2)\n",
      "\n",
      "            count += 1\n",
      "            cv2.imwrite(\"imgs/\"+str(count)+\".jpg\",cropped)\n",
      "            # cv2.imwrite(\"imgs/\"+str(post[\"id\"])+\"-edge.jpg\",img_edge)\n",
      "\n",
      "Output: {'download_images': ['cv2.imwrite', 'untangle.parse', '<builtin>.round', 'numpy.asarray', 'cv2.imdecode', '<builtin>.bytearray', 'cv2.resize', '<builtin>.str', '<builtin>.range', '<builtin>.int', '<builtin>.print'], '<builtin>.range': [], '<builtin>.str': [], 'untangle.parse': [], '<builtin>.print': [], '<builtin>.bytearray': [], 'numpy.asarray': [], 'cv2.imdecode': [], '<builtin>.int': [], 'cv2.resize': [], '<builtin>.round': [], 'cv2.imwrite': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hackcha_deepcolor\\download_images.py\n",
      "[('download_images', 'cv2 imwrite'), ('download_images', 'untangle parse'), ('download_images', 'numpy asarray'), ('download_images', 'cv2 imdecode'), ('download_images', 'cv2 resize')]\n",
      "0\n",
      "found files: []\n",
      "import keras\n",
      "from keras.applications.inception_v3 import InceptionV3\n",
      "from keras.preprocessing import image\n",
      "from keras.engine import Layer\n",
      "from keras.applications.inception_v3 import preprocess_input\n",
      "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate, Activation, Dense, Dropout, Flatten\n",
      "from keras.layers.normalization import BatchNormalization\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.models import Sequential, Model\n",
      "from keras.layers.core import RepeatVector, Permute\n",
      "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
      "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "from skimage.transform import resize\n",
      "# from skimage.io import imsave\n",
      "from matplotlib import pyplot\n",
      "import numpy as np\n",
      "import os\n",
      "import random\n",
      "import tensorflow as tf\n",
      "\n",
      "files = ['0Bwa2J.jpg','0bzkK4.jpg']\n",
      "X = []\n",
      "for filename in files:\n",
      "    X.append(img_to_array(load_img('data/Test/' + filename)))\n",
      "X = np.array(X, dtype=float)\n",
      "pyplot.imsave(\"data/result/img_\"+str(0)+\".jpg\", X[0].astype( 'uint8' ))\n",
      "# Xtrain = 1.0*X\n",
      "Xtrain = X\n",
      "datagen = ImageDataGenerator(\n",
      "        shear_range=0.2,\n",
      "        zoom_range=0.2,\n",
      "        rotation_range=20,\n",
      "        # shear_range=0.4,\n",
      "        # zoom_range=0.4,\n",
      "        # rotation_range=40,\n",
      "        horizontal_flip=True)\n",
      "def my_rgb_to_gray( rgb ):\n",
      "    gray = 0.2125 * rgb[..., 0]\n",
      "    gray[:] += 0.7154 * rgb[..., 1]\n",
      "    gray[:] += 0.0721 * rgb[..., 2]\n",
      "    # gray = 0.299 * rgb[..., 0]\n",
      "    # gray[:] += 0.587 * rgb[..., 1]\n",
      "    # gray[:] += 0.114 * rgb[..., 2]\n",
      "    return gray\n",
      "\n",
      "index = 1\n",
      "for imgs in datagen.flow( Xtrain, batch_size=1):\n",
      "    index += 1\n",
      "    #gray2rgb, rgb2gray255.0\n",
      "    print(imgs.dtype)\n",
      "    g_im = my_rgb_to_gray( imgs )\n",
      "    # print(g_im[-1])\n",
      "    # print('***********')\n",
      "    #concatenace( 3 * (image,) )\n",
      "    grayscaled_rgb = gray2rgb(g_im)\n",
      "    # print( grayscaled_rgb[-1] )\n",
      "    pyplot.imsave(\"data/result/img_\"+str(index)+\".jpg\", grayscaled_rgb[-1].astype( 'uint8' ))\n",
      "    resize_imgs = []\n",
      "    for i in range(len(imgs)):\n",
      "        img = imgs[i]\n",
      "        img_ = resize(img, (224, 224, 3), mode='constant', preserve_range=True)\n",
      "        resize_imgs.append(img_)\n",
      "    resize_imgs = np.array(resize_imgs)\n",
      "    print(resize_imgs[-1])\n",
      "    # resize_imgs = preprocess_input(resize_imgs)\n",
      "    pyplot.imsave(\"data/result/imgrs_\" + str(index) + \".jpg\", resize_imgs[-1].astype( 'uint8' ) )\n",
      "    #rgb2lab255.0\n",
      "    lab = rgb2lab(imgs/255.0)\n",
      "    print(lab)\n",
      "    recover = (lab2rgb(lab[-1]))*255.0\n",
      "    print(recover)\n",
      "    pyplot.imsave(\"data/result/imgre_\"+str(index)+\".jpg\", recover.astype('uint8'))\n",
      "    if index>5:\n",
      "        break\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hackcha_deepcolor\\test.py\n",
      "[]\n",
      "found files: []\n",
      "import keras\n",
      "from keras.applications.inception_v3 import InceptionV3\n",
      "from keras.applications.inception_v3 import preprocess_input\n",
      "# from keras.applications.vgg16 import VGG16, preprocess_input\n",
      "from keras.preprocessing import image\n",
      "from keras.engine import Layer\n",
      "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate, Activation, Dense, Dropout, Flatten\n",
      "from keras.layers.normalization import BatchNormalization\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.models import Sequential, Model\n",
      "from keras.layers.core import RepeatVector, Permute\n",
      "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
      "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "from keras.optimizers import SGD, Adam\n",
      "from skimage.transform import resize\n",
      "import keras.losses\n",
      "import keras.activations\n",
      "# from skimage.io import imsave\n",
      "from matplotlib import pyplot\n",
      "import numpy as np\n",
      "import os\n",
      "import random\n",
      "import tensorflow as tf\n",
      "import sys\n",
      "from train_utils import *\n",
      "from net import *\n",
      "from keras.utils import generic_utils as keras_generic_utils\n",
      "upsplash = False\n",
      "\n",
      "if upsplash:\n",
      "    model_dir = 'keras'\n",
      "    test_data_dir = \"data/images/Test/\"\n",
      "    train_data_dir = \"data/images/Train/\"\n",
      "    result_dir = \"data/result/\"\n",
      "else:\n",
      "    model_dir = 'manga'\n",
      "    test_data_dir = \"imgs/\"\n",
      "    train_data_dir = \"imgs/\"\n",
      "    result_dir = \"results/\"\n",
      "ckpt_dir = \"checkpoint/\"\n",
      "img_size = 256\n",
      "batch_size = 4\n",
      "def ab_main( trainit = True, cont = False):\n",
      "    # Image transformer\n",
      "    datagen = ImageDataGenerator(\n",
      "        shear_range=0.2,\n",
      "        zoom_range=0.2,\n",
      "        rotation_range=20,\n",
      "        horizontal_flip=True)\n",
      "    # Generate training data\n",
      "    model = abnet_resnet(img_size)\n",
      "    # Train model\n",
      "    filepath = \"color_model_best.h5\"\n",
      "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True, period=1,\n",
      "                                 save_best_only=True)\n",
      "    callbacks_list = [checkpoint]\n",
      "    opt = SGD(lr=0.0005, momentum=0.0, clipnorm=5.0, decay=0.999)\n",
      "    # opt = Adam(lr=0.001, clipnorm=5.0, epsilon=0.1)\n",
      "    model.compile(optimizer=opt, loss='mse')\n",
      "    if cont:\n",
      "        model.load_weights( filepath )\n",
      "    all_files = os.listdir('data/images/Train/')\n",
      "    steps_per_epoch = 512\n",
      "    train_it = True\n",
      "    if train_it:\n",
      "        Xtest = get_Xtrainlimit(img_size, data_dir='data/Test/', limit=64)\n",
      "        # Xtrain = get_Xtrainlimit(img_size)\n",
      "        # model.fit_generator(image_ab_gen(datagen, Xtrain, batch_size), epochs=1,\n",
      "        #                     steps_per_epoch=int(Xtrain.shape[0]/batch_size),\n",
      "        #                     callbacks=callbacks_list, verbose=1)\n",
      "        model.fit_generator(image_a_b_gen_batches(all_files, batch_size, img_size),\n",
      "                            validation_data= image_ab_valid(datagen, Xtest, batch_size),\n",
      "                            epochs=20, steps_per_epoch=int(len(all_files)/batch_size),\n",
      "                            callbacks=callbacks_list, verbose=1)\n",
      "        model.save_weights(\"color_model.h5\" )\n",
      "    # model.load_weights( filepath )\n",
      "    # Make predictions on validation images\n",
      "    if not train_it and (not cont):\n",
      "        model.load_weights(filepath)\n",
      "    imgs, color_me = load_test(img_size, data_dir='data/testdata/Validate/')\n",
      "    # Test model\n",
      "    # output = model.predict([color_me/100.0, color_me_embed])\n",
      "    output = model.predict(color_me)\n",
      "    output = output * 128.0\n",
      "    # Output colorizations\n",
      "    curs = []\n",
      "    for i in range(len(output)):\n",
      "        cur = np.zeros((img_size, img_size, 3), dtype=np.float64)\n",
      "        cur[:, :, 0] = color_me[i][:, :, 0]\n",
      "        cur[:, :, 1:] = output[i]\n",
      "        curs.append(cur)\n",
      "        img = lab2rgb(cur) * 255.0\n",
      "        # pylo\n",
      "        pyplot.imsave(\"data/result/img_\" + str(i) + \".jpg\", img.astype('uint8'))\n",
      "        # pyplot.imsave(\"data/result/imgo_\" + str(i) + \".jpg\", imgs[i].astype( 'uint8' )  )\n",
      "\n",
      "def ab_trans_main(train_it = True, cont = False):\n",
      "    # Image transformer\n",
      "    datagen = ImageDataGenerator(\n",
      "        shear_range=0.2,\n",
      "        zoom_range=0.2,\n",
      "        rotation_range=20,\n",
      "        horizontal_flip=True)\n",
      "    # Generate training data\n",
      "    model = abnet_trans(img_size)\n",
      "    # Train model\n",
      "    filepath = \"ab_trans_model_best.h5\"\n",
      "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True, period=1,\n",
      "                                 save_best_only=True)\n",
      "    callbacks_list = [checkpoint]\n",
      "    # opt = SGD(lr=0.0005, momentum=0.0, clipnorm=50.0, decay=1e-5)\n",
      "    opt = Adam(lr=0.001, beta_2=0.5, clipnorm=50.0, epsilon=0.01)#0.001\n",
      "    model.compile(optimizer=opt, loss='mse')\n",
      "    filepath = \"ab_trans_model.h5\"\n",
      "    if cont:\n",
      "        model.load_weights( filepath )\n",
      "    all_files = os.listdir(train_data_dir)\n",
      "    steps_per_epoch = 512\n",
      "    # train_it = False\n",
      "    inception = load_inception()\n",
      "    if train_it:\n",
      "        Xtest = get_Xtrainlimit(img_size, data_dir=test_data_dir, limit=64)\n",
      "        # Xtrain = get_Xtrainlimit(img_size)\n",
      "        # model.fit_generator(image_ab_gen(datagen, Xtrain, batch_size), epochs=1,\n",
      "        #                     steps_per_epoch=int(Xtrain.shape[0]/batch_size),\n",
      "        #                     callbacks=callbacks_list, verbose=1)\n",
      "        model.fit_generator(image_a_b_gen_batches(all_files, batch_size, img_size, trans=True, inception=inception, data_dir=train_data_dir),\n",
      "                            validation_data= image_ab_valid(datagen, Xtest, batch_size, trans=True, inception=inception),\n",
      "                            epochs=20000, steps_per_epoch=int(len(all_files)/batch_size),\n",
      "                            callbacks=callbacks_list, verbose=1)\n",
      "        model.save_weights(filepath )\n",
      "    if not train_it and (not cont):\n",
      "        model.load_weights( filepath )\n",
      "    # Make predictions on validation images\n",
      "    # model.load_weights(filepath)\n",
      "    imgs, color_me = load_test(img_size, data_dir=test_data_dir)\n",
      "    gray_imgs = my_rgb_to_gray(imgs)\n",
      "    grayscaled_rgb = gray2rgb(gray_imgs)\n",
      "    embed = create_inception_embedding(grayscaled_rgb, inception)\n",
      "    # Test model\n",
      "    # output = model.predict([color_me/100.0, color_me_embed])\n",
      "    output = model.predict([color_me, embed])\n",
      "    output = output * 128.0\n",
      "    # Output colorizations\n",
      "    curs = []\n",
      "    for i in range(len(output)):\n",
      "        cur = np.zeros((img_size, img_size, 3), dtype=np.float64)\n",
      "        cur[:, :, 0] = color_me[i][:, :, 0]\n",
      "        cur[:, :, 1:] = output[i]\n",
      "        curs.append(cur)\n",
      "        img = lab2rgb(cur) * 255.0\n",
      "        # pylo\n",
      "        pyplot.imsave(result_dir+\"img_\" + str(i) + \".jpg\", img.astype('uint8'))\n",
      "        # pyplot.imsave(\"data/result/imgo_\" + str(i) + \".jpg\", imgs[i].astype( 'uint8' )  )\n",
      "\n",
      "\n",
      "def rgb_gen( model, epoch, do_blur=False):\n",
      "    imgs, color_me = load_test(img_size, data_dir=test_data_dir)\n",
      "    color_me, _ = get_rgb_XY( imgs, do_blur)\n",
      "    output = model.predict(color_me)\n",
      "    # Output colorizations\n",
      "    lab_batch = rgb2lab(output)\n",
      "    size = int( np.ceil( np.sqrt( len(output) ) ) )\n",
      "    img = utils.merge_color( output, (size, size)) * 255\n",
      "    # pyplot.imsave(\"data/result/img_\" + str(epoch) + \".jpg\", img.astype('uint8'))\n",
      "    cv2.imwrite(result_dir+\"img_\" + str(epoch) + \".jpg\", img)\n",
      "\n",
      "def rgb_gen_tf( sess, g_in, real_images, gen_img, epoch, do_blur=False):\n",
      "    imgs, _ = load_test(img_size, data_dir=test_data_dir)\n",
      "    color_me, imgs, batch_edge, base_colors = get_rgb_XY( imgs, do_blur, return_edge=True)\n",
      "    output = sess.run(gen_img,\n",
      "                          feed_dict={real_images: imgs, g_in: color_me,K.learning_phase():0})\n",
      "    # print(output)\n",
      "    # print(output.dtype)\n",
      "    size = int( np.ceil( np.sqrt( len(output) ) ) )\n",
      "    img = utils.merge_color( output, (size, size))*255.0\n",
      "    tar = utils.merge_color(imgs, (size, size)) * 255.0\n",
      "    cv2.imwrite(result_dir+\"img_\" + str(epoch) + \".jpg\", img)\n",
      "    cv2.imwrite(result_dir + \"target_\" + str(epoch) + \".jpg\", tar)\n",
      "\n",
      "def rgb_main( trainit = True, cont=False):\n",
      "    # Image transformer\n",
      "    datagen = ImageDataGenerator(\n",
      "        shear_range=0.2,\n",
      "        zoom_range=0.2,\n",
      "        rotation_range=20,\n",
      "        horizontal_flip=True)\n",
      "    # Generate training data\n",
      "    do_blur = True\n",
      "    cdim = 1\n",
      "    if do_blur:\n",
      "        cdim = 4\n",
      "    model = rgb_unet(img_size, cdim = cdim)\n",
      "    # Train model\n",
      "    filepath = \"rgb_unet4_best_{}.h5\".format(do_blur)\n",
      "    filepath_last = \"rgb_unet4_{}.h5\".format(do_blur)\n",
      "    tb_cbk = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1, batch_size=batch_size, write_graph=False)\n",
      "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True, period=1,\n",
      "                                 save_best_only=True)\n",
      "    callbacks_list = [checkpoint, tb_cbk]\n",
      "    # opt = SGD(lr=0.01, momentum=0.0)\n",
      "    #0.003\n",
      "    #0.001\n",
      "    opt = Adam(lr=0.0001, beta_2=0.5)#0.001, epsilon=0.01 clipnorm=50.0,, decay=0.001\n",
      "    model.compile(optimizer=opt, loss='binary_crossentropy')\n",
      "    #\n",
      "    if cont:\n",
      "        model.load_weights( filepath )\n",
      "        print('load weight done.')\n",
      "    all_files = os.listdir(train_data_dir)\n",
      "    steps_per_epoch = 512\n",
      "    if trainit:\n",
      "        for epoch in range( 100 ):\n",
      "            Xtest = get_Xtrainlimit(img_size, data_dir=test_data_dir,limit=64)\n",
      "            # Xtrain = get_Xtrainlimit(img_size)\n",
      "            # model.fit_generator(image_rgb_gen(datagen, Xtrain, batch_size), epochs=20,\n",
      "            #                     steps_per_epoch=int(Xtrain.shape[0]/batch_size),\n",
      "            #                     validation_data=image_rgb_valid(datagen, Xtest, batch_size),\n",
      "            #                     callbacks=callbacks_list, verbose=1)\n",
      "            model.fit_generator(image_rgb_gen_batches(all_files, batch_size, img_size, do_blur=do_blur, train_data_dir=train_data_dir),\n",
      "                                validation_data=image_rgb_valid(datagen, Xtest, batch_size, do_blur=do_blur),\n",
      "                                epochs=1, steps_per_epoch=int(len(all_files)/batch_size),\n",
      "                                callbacks=callbacks_list, verbose=1)\n",
      "            rgb_gen( model, epoch, do_blur=do_blur )\n",
      "            model.save_weights(filepath_last)\n",
      "    else:\n",
      "        if not cont:\n",
      "            model.load_weights(filepath)\n",
      "        rgb_gen(model, 0, do_blur=do_blur)\n",
      "\n",
      "\n",
      "def save_model_tf( ckpt_dir, sess, saver, step):\n",
      "    model_name = \"model\"\n",
      "    checkpoint_dir = os.path.join(ckpt_dir, model_dir)\n",
      "    if not os.path.exists(checkpoint_dir):\n",
      "        os.makedirs(checkpoint_dir)\n",
      "    saver.save(sess, os.path.join(checkpoint_dir, model_name),\n",
      "                    global_step=step)\n",
      "\n",
      "def load_model_tf( ckpt_dir, sess, saver ):\n",
      "    checkpoint_dir = os.path.join(ckpt_dir, model_dir)\n",
      "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
      "    if ckpt and ckpt.model_checkpoint_path:\n",
      "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
      "        saver.restore(sess, os.path.join(checkpoint_dir, ckpt_name))\n",
      "        print('Loaded.')\n",
      "    else:\n",
      "        print(\"Load failed\")\n",
      "\n",
      "\n",
      "def rgb_gan_main( trainit = True, cont=False, load_discrim=True):\n",
      "    config = tf.ConfigProto()\n",
      "    config.gpu_options.allow_growth = True\n",
      "    config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
      "    sess = tf.Session(config=config)\n",
      "    set_session(sess)\n",
      "    # Generate training data\n",
      "    do_blur = True\n",
      "    cdim = 1\n",
      "    if do_blur:\n",
      "        cdim = 4\n",
      "    # gm  = rgb_unet(img_size, cdim = cdim)\n",
      "    # gm.summary()\n",
      "    # dm= discriminator(img_size, cdim=cdim+3)\n",
      "    # dm.summary()\n",
      "    d_bn1 = batch_norm(name='d_bn1')\n",
      "    d_bn2 = batch_norm(name='d_bn2')\n",
      "    d_bn3 = batch_norm(name='d_bn3')\n",
      "    g_in = tf.placeholder(tf.float32, shape=[batch_size, img_size, img_size, cdim])\n",
      "    real_images = tf.placeholder(tf.float32, [batch_size, img_size, img_size, 3])\n",
      "    # gen_img = gm(g_in)\n",
      "    gen_img = generator(g_in)\n",
      "    real_AB = tf.concat([g_in, real_images], 3)\n",
      "    fake_AB = tf.concat([g_in, gen_img], 3)\n",
      "    # disc_true_logits = dm(real_AB)\n",
      "    # disc_fake_logits = dm(fake_AB)\n",
      "    disc_true_logits = discriminator_tf(real_AB, d_bn1, d_bn2, d_bn3, reuse=False)\n",
      "    disc_fake_logits = discriminator_tf(fake_AB, d_bn1, d_bn2,d_bn3, reuse=True)\n",
      "\n",
      "\n",
      "    d_loss_real = tf.reduce_mean(\n",
      "        tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_true_logits, labels=tf.ones_like(disc_true_logits)))\n",
      "    d_loss_fake = tf.reduce_mean(\n",
      "        tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits, labels=tf.zeros_like(disc_fake_logits)))\n",
      "    d_loss = d_loss_real + d_loss_fake\n",
      "    mae_loss = tf.reduce_mean(tf.abs(real_images - gen_img))\n",
      "    g_loss = tf.reduce_mean(\n",
      "        tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits, labels=tf.ones_like(disc_fake_logits))) \\\n",
      "                  + 100.0 * mae_loss\n",
      "    t_vars = tf.trainable_variables()\n",
      "    d_vars = [var for var in t_vars if 'd_' in var.name]\n",
      "    g_vars = [var for var in t_vars if 'g_' in var.name]\n",
      "    d_var_names = [var.name for var in d_vars]\n",
      "    g_var_names = [var.name for var in g_vars]\n",
      "    print('\\n'.join(d_var_names) )\n",
      "    print('\\n'.join(g_var_names) )\n",
      "    with tf.variable_scope(name_or_scope='', reuse=tf.AUTO_REUSE):\n",
      "        d_optim = tf.train.AdamOptimizer(0.0002, beta1=0.5).minimize(d_loss, var_list=d_vars)\n",
      "        g_optim = tf.train.AdamOptimizer(0.0002, beta1=0.5).minimize(g_loss, var_list=g_vars)\n",
      "    sess.run(tf.global_variables_initializer() )\n",
      "    if load_discrim:\n",
      "        saver = tf.train.Saver()\n",
      "    else:\n",
      "        saver = tf.train.Saver(g_vars)\n",
      "    # Train model\n",
      "    #\n",
      "    if cont:\n",
      "        load_model_tf(ckpt_dir,sess, saver)\n",
      "    all_files = os.listdir(train_data_dir)\n",
      "    steps_per_epoch = 512\n",
      "\n",
      "    rgb_gen_tf(sess, g_in, real_images, gen_img, 10000, do_blur=do_blur)\n",
      "    # for var in tf.trainable_variables():\n",
      "    #     tf.summary.histogram(var.name, var)\n",
      "    if trainit:\n",
      "        imgs, _ = load_test(img_size, data_dir=test_data_dir)\n",
      "        color_me, imgs, batch_edge, base_colors = get_rgb_XY(imgs, do_blur, return_edge=True)\n",
      "        size = int(np.ceil(np.sqrt(len(imgs))))\n",
      "        ri = utils.merge_color(imgs, (size, size)) * 255.0\n",
      "        edge = utils.merge_color( batch_edge, (size, size))*255.0\n",
      "        color = utils.merge_color( base_colors, (size, size))*255.0\n",
      "        cv2.imwrite(result_dir + \"base.png\", color)\n",
      "        cv2.imwrite(result_dir + \"base_line.jpg\", edge)\n",
      "        cv2.imwrite(result_dir + \"real_img.jpg\", ri)\n",
      "        # merged = tf.summary.merge_all()\n",
      "        # train_writer = tf.summary.FileWriter('logs',\n",
      "        #                                      sess.graph)\n",
      "        all_batches = image_rgb_gen_batches(all_files, batch_size, img_size, do_blur=do_blur,\n",
      "                                            train_data_dir=train_data_dir)\n",
      "        for epoch in range( 20000 ):\n",
      "            # Xtest = get_Xtrainlimit(img_size, data_dir=test_data_dir,limit=64)\n",
      "            progbar = keras_generic_utils.Progbar( 100*batch_size )#len(all_files)\n",
      "            batch_epoch = 100#int(len(all_files)/batch_size)\n",
      "            batch_counter = 0\n",
      "            for batch_counter in range( batch_epoch ):\n",
      "                batch = next(all_batches)\n",
      "                disc_loss, gen_mae, _ = sess.run([d_loss, mae_loss, d_optim],\n",
      "                                          feed_dict={real_images: batch[1], g_in: batch[0],K.learning_phase():1 })\n",
      "\n",
      "                gen_loss, _ = sess.run([g_loss, g_optim],\n",
      "                                          feed_dict={real_images: batch[1], g_in: batch[0],K.learning_phase():1 })\n",
      "\n",
      "                gen_total_loss = min(gen_loss+gen_mae, 10000)\n",
      "                gen_mae = min(gen_mae,10000)\n",
      "                gen_log_loss = min(gen_loss, 10000)\n",
      "                progbar.add(batch_size, values=[(\"D_l\", disc_loss),\n",
      "                                                (\"G_lt\", gen_total_loss),\n",
      "                                                (\"G_mae\", gen_mae),\n",
      "                                                (\"G_l\", gen_log_loss)])\n",
      "                if batch_counter == batch_epoch-1:\n",
      "                    r_i = utils.merge_color(batch[1], (size, size)) * 255.0\n",
      "                    output = sess.run(gen_img,\n",
      "                                      feed_dict={real_images: batch[1], g_in: batch[0], K.learning_phase(): 0})\n",
      "                    o_i = utils.merge_color(output, (size, size)) * 255.0\n",
      "                    cv2.imwrite(result_dir + \"real_img_{}.png\".format(epoch), r_i)\n",
      "                    cv2.imwrite(result_dir + \"rec_img_{}.png\".format(epoch), o_i)\n",
      "            # train_writer.add_summary(summary1, epoch * 2)\n",
      "            # train_writer.add_summary(summary2, epoch * 2 + 1)\n",
      "\n",
      "            print()\n",
      "            save_model_tf( ckpt_dir, sess, saver, epoch)\n",
      "            rgb_gen_tf(sess, g_in, real_images, gen_img , epoch, do_blur=do_blur)\n",
      "    else:\n",
      "        if not cont:\n",
      "            load_model_tf(ckpt_dir, sess, saver)\n",
      "        rgb_gen_tf(sess, g_in, real_images, gen_img , 0, do_blur=do_blur)\n",
      "\n",
      "\n",
      "def rgb_gan_main_keras_tf( trainit = True, cont=False, load_discrim=True):\n",
      "    config = tf.ConfigProto()\n",
      "    config.gpu_options.allow_growth = True\n",
      "    config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
      "    sess = tf.Session(config=config)\n",
      "    set_session(sess)\n",
      "    # Generate training data\n",
      "    do_blur = True\n",
      "    cdim = 1\n",
      "    if do_blur:\n",
      "        cdim = 4\n",
      "    gm  = rgb_unet(img_size, cdim = cdim)\n",
      "    gm.summary()\n",
      "    dm= discriminator(img_size, cdim=cdim+3)\n",
      "    dm.summary()\n",
      "    g_in = tf.placeholder(tf.float32, shape=[batch_size, img_size, img_size, cdim])\n",
      "    real_images = tf.placeholder(tf.float32, [batch_size, img_size, img_size, 3])\n",
      "    gen_img = gm(g_in)\n",
      "    real_AB = tf.concat([g_in, real_images], 3)\n",
      "    fake_AB = tf.concat([g_in, gen_img], 3)\n",
      "    disc_true_logits = dm(real_AB)\n",
      "    disc_fake_logits = dm(fake_AB)\n",
      "\n",
      "\n",
      "    d_loss_real = tf.reduce_mean(\n",
      "        tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_true_logits, labels=tf.ones_like(disc_true_logits)))\n",
      "    d_loss_fake = tf.reduce_mean(\n",
      "        tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits, labels=tf.zeros_like(disc_fake_logits)))\n",
      "    d_loss = d_loss_real + d_loss_fake\n",
      "    mae_loss = tf.reduce_mean(tf.abs(real_images - gen_img))\n",
      "    g_loss = tf.reduce_mean(\n",
      "        tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits, labels=tf.ones_like(disc_fake_logits))) \\\n",
      "                  + 100.0 * mae_loss\n",
      "    t_vars = tf.trainable_variables()\n",
      "    d_vars = [var for var in t_vars if 'dis_' in var.name and 'moving_mean' not in var.name and 'moving_variance' not in var.name]\n",
      "    g_vars = [var for var in t_vars if 'gen_' in var.name and 'moving_mean' not in var.name and 'moving_variance' not in var.name]\n",
      "    d_var_names = [var.name for var in d_vars]\n",
      "    g_var_names = [var.name for var in g_vars]\n",
      "    print('\\n'.join(d_var_names))\n",
      "    print('\\n'.join(g_var_names))\n",
      "    with tf.variable_scope(name_or_scope='', reuse=tf.AUTO_REUSE):\n",
      "        d_optim = tf.train.AdamOptimizer(0.0002, beta1=0.5).minimize(d_loss, var_list=d_vars)\n",
      "        g_optim = tf.train.AdamOptimizer(0.0002, beta1=0.5).minimize(g_loss, var_list=g_vars)\n",
      "    sess.run(tf.global_variables_initializer() )\n",
      "    if load_discrim:\n",
      "        saver = tf.train.Saver()\n",
      "    else:\n",
      "        saver = tf.train.Saver(g_vars)\n",
      "    # Train model\n",
      "    #\n",
      "    if cont:\n",
      "        load_model_tf(ckpt_dir,sess, saver)\n",
      "    all_files = os.listdir(train_data_dir)\n",
      "    steps_per_epoch = 512\n",
      "\n",
      "    rgb_gen_tf(sess, g_in, real_images, gen_img, 10000, do_blur=do_blur)\n",
      "    # for var in tf.trainable_variables():\n",
      "    #     tf.summary.histogram(var.name, var)\n",
      "    if trainit:\n",
      "        imgs, _ = load_test(img_size, data_dir=test_data_dir)\n",
      "        color_me, imgs, batch_edge, base_colors = get_rgb_XY(imgs, do_blur, return_edge=True)\n",
      "        size = int(np.ceil(np.sqrt(len(imgs))))\n",
      "        ri = utils.merge_color(imgs, (size, size)) * 255.0\n",
      "        edge = utils.merge_color( batch_edge, (size, size))*255.0\n",
      "        color = utils.merge_color( base_colors, (size, size))*255.0\n",
      "        cv2.imwrite(result_dir + \"base.png\", color)\n",
      "        cv2.imwrite(result_dir + \"base_line.jpg\", edge)\n",
      "        cv2.imwrite(result_dir + \"real_img.jpg\", ri)\n",
      "        # merged = tf.summary.merge_all()\n",
      "        # train_writer = tf.summary.FileWriter('logs',\n",
      "        #                                      sess.graph)\n",
      "        all_batches = image_rgb_gen_batches(all_files, batch_size, img_size, do_blur=do_blur,\n",
      "                                            train_data_dir=train_data_dir)\n",
      "        for epoch in range( 20000 ):\n",
      "            # Xtest = get_Xtrainlimit(img_size, data_dir=test_data_dir,limit=64)\n",
      "            progbar = keras_generic_utils.Progbar( 100*batch_size )#len(all_files)\n",
      "            batch_epoch = 100#int(len(all_files)/batch_size)\n",
      "            batch_counter = 0\n",
      "            for batch_counter in range( batch_epoch ):\n",
      "                batch = next(all_batches)\n",
      "                disc_loss, gen_mae, _ = sess.run([d_loss, mae_loss, d_optim],\n",
      "                                          feed_dict={real_images: batch[1], g_in: batch[0],K.learning_phase():1 })\n",
      "\n",
      "                gen_loss, _ = sess.run([g_loss, g_optim],\n",
      "                                          feed_dict={real_images: batch[1], g_in: batch[0],K.learning_phase():1 })\n",
      "\n",
      "                gen_total_loss = min(gen_loss+gen_mae, 10000)\n",
      "                gen_mae = min(gen_mae,10000)\n",
      "                gen_log_loss = min(gen_loss, 10000)\n",
      "                progbar.add(batch_size, values=[(\"D_l\", disc_loss),\n",
      "                                                (\"G_lt\", gen_total_loss),\n",
      "                                                (\"G_mae\", gen_mae),\n",
      "                                                (\"G_l\", gen_log_loss)])\n",
      "                if batch_counter == batch_epoch-1:\n",
      "                    r_i = utils.merge_color(batch[1], (size, size)) * 255.0\n",
      "                    output = sess.run(gen_img,\n",
      "                                      feed_dict={real_images: batch[1], g_in: batch[0], K.learning_phase(): 0})\n",
      "                    o_i = utils.merge_color(output, (size, size)) * 255.0\n",
      "                    cv2.imwrite(result_dir + \"real_img_{}.png\".format(epoch), r_i)\n",
      "                    cv2.imwrite(result_dir + \"rec_img_{}.png\".format(epoch), o_i)\n",
      "            # train_writer.add_summary(summary1, epoch * 2)\n",
      "            # train_writer.add_summary(summary2, epoch * 2 + 1)\n",
      "\n",
      "            print()\n",
      "            save_model_tf( ckpt_dir, sess, saver, epoch)\n",
      "            rgb_gen_tf(sess, g_in, real_images, gen_img , epoch, do_blur=do_blur)\n",
      "    else:\n",
      "        if not cont:\n",
      "            load_model_tf(ckpt_dir, sess, saver)\n",
      "        rgb_gen_tf(sess, g_in, real_images, gen_img , 0, do_blur=do_blur)\n",
      "\n",
      "\n",
      "def get_disc_batch(X_in, X_out, generator_model, batch_counter):\n",
      "    label_flipping = 0\n",
      "    # Create X_disc: alternatively only generated or real images\n",
      "    # generate fake image\n",
      "    X_disc1 = generator_model.predict(X_in)\n",
      "    y_disc1 = np.zeros((X_disc1.shape[0], 1), dtype=np.float)\n",
      "    y_disc1[:, 0] = 0\n",
      "    # generate real image\n",
      "    X_disc2 = X_out\n",
      "    y_disc2 = np.zeros((X_disc2.shape[0], 1), dtype=np.float)\n",
      "    y_disc2[:, 0] = 1\n",
      "    X_disc1 = np.concatenate([X_disc1, X_in], axis=3)\n",
      "    X_disc2 = np.concatenate([X_disc2, X_in], axis=3)\n",
      "    X_disc = np.concatenate([X_disc1, X_disc2], axis=0)\n",
      "    y_disc = np.concatenate([y_disc1, y_disc2], axis=0)\n",
      "    if label_flipping > 0:\n",
      "        p = np.random.binomial(1, label_flipping)\n",
      "        if p > 0:\n",
      "            y_disc[:,0] = 1- y_disc[:,0]\n",
      "    return X_disc, y_disc\n",
      "\n",
      "\n",
      "def load_img_test():\n",
      "    do_blur = True\n",
      "    imgs, _ = load_test(img_size, data_dir=test_data_dir)\n",
      "    color_me, imgs, batch_edge, base_colors = get_rgb_XY(imgs, do_blur, return_edge=True)\n",
      "    import utils\n",
      "    size = int(np.ceil(np.sqrt(len(imgs))))\n",
      "    real_img = utils.merge_color(imgs, (size, size)) * 255.0\n",
      "    edge = utils.merge_color(batch_edge, (size, size)) * 255.0\n",
      "    color = utils.merge_color(base_colors, (size, size)) * 255.0\n",
      "    cv2.imwrite(result_dir + \"base.png\", color)\n",
      "    cv2.imwrite(result_dir + \"base_line.jpg\", edge)\n",
      "    cv2.imwrite(result_dir + \"real_img.jpg\", real_img)\n",
      "    all_files = os.listdir(train_data_dir)\n",
      "    bc = 0\n",
      "    for batch in image_rgb_gen_batches(all_files, batch_size, img_size, do_blur=do_blur,\n",
      "                                       train_data_dir=train_data_dir):\n",
      "        # real_img = utils.merge_color(batch[1], (size, size)) * 255.0\n",
      "\n",
      "        cv2.imwrite(result_dir + \"real_{}.png\".format(bc), batch[1][0]*255.0)\n",
      "        bc+=1\n",
      "        if bc>10:\n",
      "            break\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    if len(sys.argv)>=2:\n",
      "        cmd = sys.argv[1]\n",
      "        if cmd == 'gan_tf':\n",
      "            rgb_gan_main(trainit=True, cont=False)\n",
      "        else:\n",
      "            set_keras_session()\n",
      "            if cmd == 'ab':\n",
      "                ab_main( trainit=True, cont=False )\n",
      "            elif cmd == 'trans':\n",
      "                ab_trans_main( train_it=True, cont=False )\n",
      "            elif cmd == 'rgb':\n",
      "                rgb_main( trainit=True, cont=False)\n",
      "    else:\n",
      "        rgb_gan_main( trainit= True, cont = False)\n",
      "        # rgb_gan_main_keras_tf( trainit= True, cont = False)\n",
      "    print('done.')\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hackcha_deepcolor\\baselines.py\n",
      "[]\n",
      "found files: []\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import os\n",
      "from glob import glob\n",
      "import sys\n",
      "import math\n",
      "from random import randint\n",
      "\n",
      "from utils import *\n",
      "\n",
      "upsplash = False\n",
      "if upsplash:\n",
      "    model_dir = \"tr_unsplash\"\n",
      "    test_data_dir = \"data/images/Test\"\n",
      "    train_data_dir = \"data/images/Train\"\n",
      "    result_dir = \"data/result/\"\n",
      "else:#comic\n",
      "    model_dir = \"tr_re\"\n",
      "    test_data_dir = \"imgs\"\n",
      "    train_data_dir = \"imgs\"\n",
      "    result_dir = \"results/\"\n",
      "\n",
      "class Color():\n",
      "    def __init__(self, imgsize=256, batchsize=4):\n",
      "        self.batch_size = batchsize\n",
      "        self.batch_size_sqrt = int(math.sqrt(self.batch_size))\n",
      "        self.image_size = imgsize\n",
      "        self.output_size = imgsize\n",
      "\n",
      "        self.gf_dim = 64\n",
      "        self.df_dim = 64\n",
      "\n",
      "        self.input_colors = 1\n",
      "        self.input_colors2 = 3\n",
      "        self.output_colors = 3\n",
      "\n",
      "        self.l1_scaling = 100\n",
      "\n",
      "        self.d_bn1 = batch_norm(name='d_bn1')\n",
      "        self.d_bn2 = batch_norm(name='d_bn2')\n",
      "        self.d_bn3 = batch_norm(name='d_bn3')\n",
      "\n",
      "        self.line_images = tf.placeholder(tf.float32, [self.batch_size, self.image_size, self.image_size, self.input_colors])\n",
      "        self.color_images = tf.placeholder(tf.float32, [self.batch_size, self.image_size, self.image_size, self.input_colors2])\n",
      "        self.real_images = tf.placeholder(tf.float32, [self.batch_size, self.image_size, self.image_size, self.output_colors])\n",
      "\n",
      "        combined_preimage = tf.concat([self.line_images, self.color_images], 3)\n",
      "        # combined_preimage = self.line_images\n",
      "\n",
      "        self.generated_images = self.generator(combined_preimage)\n",
      "\n",
      "        self.real_AB = tf.concat([combined_preimage, self.real_images],3)\n",
      "        self.fake_AB = tf.concat([combined_preimage, self.generated_images],3)\n",
      "\n",
      "        self.disc_true, disc_true_logits = self.discriminator(self.real_AB, reuse=False)\n",
      "        self.disc_fake, disc_fake_logits = self.discriminator(self.fake_AB, reuse=True)\n",
      "\n",
      "        self.d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_true_logits, labels=tf.ones_like(disc_true_logits)))\n",
      "        self.d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits, labels=tf.zeros_like(disc_fake_logits)))\n",
      "        self.d_loss = self.d_loss_real + self.d_loss_fake\n",
      "        self.mae_loss = tf.reduce_mean(tf.abs(self.real_images - self.generated_images))\n",
      "        self.g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_fake_logits, labels=tf.ones_like(disc_fake_logits))) \\\n",
      "                        + self.l1_scaling * self.mae_loss\n",
      "\n",
      "        t_vars = tf.trainable_variables()\n",
      "        self.d_vars = [var for var in t_vars if 'd_' in var.name]\n",
      "        self.g_vars = [var for var in t_vars if 'g_' in var.name]\n",
      "\n",
      "        with tf.variable_scope(name_or_scope='', reuse=tf.AUTO_REUSE):\n",
      "            self.d_optim = tf.train.AdamOptimizer(0.0002, beta1=0.5).minimize(self.d_loss, var_list=self.d_vars)\n",
      "            self.g_optim = tf.train.AdamOptimizer(0.0002, beta1=0.5).minimize(self.g_loss, var_list=self.g_vars)\n",
      "\n",
      "\n",
      "    def discriminator(self, image, y=None, reuse=False):\n",
      "        # image is 256 x 256 x (input_c_dim + output_c_dim)\n",
      "        if reuse:\n",
      "            tf.get_variable_scope().reuse_variables()\n",
      "        else:\n",
      "            assert tf.get_variable_scope().reuse == False\n",
      "\n",
      "        h0 = lrelu(conv2d(image, self.df_dim, name='d_h0_conv')) # h0 is (128 x 128 x self.df_dim)\n",
      "        h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim*2, name='d_h1_conv'))) # h1 is (64 x 64 x self.df_dim*2)\n",
      "        h2 = lrelu(self.d_bn2(conv2d(h1, self.df_dim*4, name='d_h2_conv'))) # h2 is (32 x 32 x self.df_dim*4)\n",
      "        h3 = lrelu(self.d_bn3(conv2d(h2, self.df_dim*8, d_h=1, d_w=1, name='d_h3_conv'))) # h3 is (16 x 16 x self.df_dim*8)\n",
      "        h4 = linear(tf.reshape(h3, [self.batch_size, -1]), 1, 'd_h3_lin')\n",
      "        return tf.nn.sigmoid(h4), h4\n",
      "\n",
      "    def generator(self, img_in):\n",
      "        s = self.output_size\n",
      "        s2, s4, s8, s16, s32, s64, s128 = int(s/2), int(s/4), int(s/8), int(s/16), int(s/32), int(s/64), int(s/128)\n",
      "        # image is (256 x 256 x input_c_dim)\n",
      "        e1 = conv2d(img_in, self.gf_dim, name='g_e1_conv') # e1 is (128 x 128 x self.gf_dim)\n",
      "        e2 = bn(conv2d(lrelu(e1), self.gf_dim*2, name='g_e2_conv')) # e2 is (64 x 64 x self.gf_dim*2)\n",
      "        e3 = bn(conv2d(lrelu(e2), self.gf_dim*4, name='g_e3_conv')) # e3 is (32 x 32 x self.gf_dim*4)\n",
      "        e4 = bn(conv2d(lrelu(e3), self.gf_dim*8, name='g_e4_conv')) # e4 is (16 x 16 x self.gf_dim*8)\n",
      "        e5 = bn(conv2d(lrelu(e4), self.gf_dim*8, name='g_e5_conv')) # e5 is (8 x 8 x self.gf_dim*8)\n",
      "\n",
      "\n",
      "        self.d4, self.d4_w, self.d4_b = deconv2d(tf.nn.relu(e5), [self.batch_size, s16, s16, self.gf_dim*8], name='g_d4', with_w=True)\n",
      "        d4 = bn(self.d4)\n",
      "        d4 = tf.concat([d4, e4],3)\n",
      "        # d4 is (16 x 16 x self.gf_dim*8*2)\n",
      "\n",
      "        self.d5, self.d5_w, self.d5_b = deconv2d(tf.nn.relu(d4), [self.batch_size, s8, s8, self.gf_dim*4], name='g_d5', with_w=True)\n",
      "        d5 = bn(self.d5)\n",
      "        d5 = tf.concat([d5, e3],3)\n",
      "        # d5 is (32 x 32 x self.gf_dim*4*2)\n",
      "\n",
      "        self.d6, self.d6_w, self.d6_b = deconv2d(tf.nn.relu(d5), [self.batch_size, s4, s4, self.gf_dim*2], name='g_d6', with_w=True)\n",
      "        d6 = bn(self.d6)\n",
      "        d6 = tf.concat([d6, e2],3)\n",
      "        # d6 is (64 x 64 x self.gf_dim*2*2)\n",
      "\n",
      "        self.d7, self.d7_w, self.d7_b = deconv2d(tf.nn.relu(d6), [self.batch_size, s2, s2, self.gf_dim], name='g_d7', with_w=True)\n",
      "        d7 = bn(self.d7)\n",
      "        d7 = tf.concat([d7, e1],3)\n",
      "        # d7 is (128 x 128 x self.gf_dim*1*2)\n",
      "\n",
      "        self.d8, self.d8_w, self.d8_b = deconv2d(tf.nn.relu(d7), [self.batch_size, s, s, self.output_colors], name='g_d8', with_w=True)\n",
      "        # d8 is (256 x 256 x output_c_dim)\n",
      "\n",
      "        return tf.nn.tanh(self.d8)\n",
      "\n",
      "\n",
      "    def imageblur(self, cimg, sampling=False):\n",
      "        if sampling:\n",
      "            cimg = cimg * 0.3 + np.ones_like(cimg) * 0.7 * 255\n",
      "        else:\n",
      "            for i in range(30):\n",
      "                randx = randint(0,205)\n",
      "                randy = randint(0,205)\n",
      "                cimg[randx:randx+50, randy:randy+50] = 255\n",
      "        return cv2.blur(cimg,(100,100))\n",
      "\n",
      "    def train(self):\n",
      "        self.loadmodel()\n",
      "\n",
      "        data = glob(os.path.join(train_data_dir, \"*\"))\n",
      "        print(data[0])\n",
      "        base = np.array([get_image(sample_file) for sample_file in data[0:self.batch_size]])\n",
      "        base_normalized = base/255.0\n",
      "\n",
      "        base_edge = np.array([cv2.adaptiveThreshold(cv2.cvtColor(ba, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=9, C=2) for ba in base]) / 255.0\n",
      "        base_edge = np.expand_dims(base_edge, 3)\n",
      "\n",
      "        base_colors = np.array([self.imageblur(ba) for ba in base]) / 255.0\n",
      "\n",
      "        ims(result_dir+\"base.png\",merge_color(base_normalized, [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "        ims(result_dir+\"base_line.jpg\",merge(base_edge, [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "        ims(result_dir+\"base_colors.jpg\",merge_color(base_colors, [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "\n",
      "        datalen = len(data)\n",
      "\n",
      "        for e in range(20000):\n",
      "            for i in range(int(datalen / self.batch_size) ):\n",
      "                batch_files = data[i*self.batch_size:(i+1)*self.batch_size]\n",
      "                batch = np.array([get_image(batch_file) for batch_file in batch_files])\n",
      "                batch_normalized = batch/255.0\n",
      "\n",
      "                batch_edge = np.array([cv2.adaptiveThreshold(cv2.cvtColor(ba, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=9, C=2) for ba in batch]) / 255.0\n",
      "                batch_edge = np.expand_dims(batch_edge, 3)\n",
      "\n",
      "                batch_colors = np.array([self.imageblur(ba) for ba in batch]) / 255.0\n",
      "\n",
      "                d_loss, _ = self.sess.run([self.d_loss, self.d_optim], feed_dict={self.real_images: batch_normalized, self.line_images: batch_edge, self.color_images: batch_colors})\n",
      "                g_loss, mae_loss, _ = self.sess.run([self.g_loss,self.mae_loss, self.g_optim], feed_dict={self.real_images: batch_normalized, self.line_images: batch_edge, self.color_images: batch_colors})\n",
      "\n",
      "                print(\"%d: [%d / %d] d_loss %f, mae_loss %f g_loss %f\" % (e, i, (datalen/self.batch_size), d_loss, mae_loss, g_loss))\n",
      "\n",
      "                if i % 100 == 0:\n",
      "                    recreation = self.sess.run(self.generated_images, feed_dict={self.real_images: base_normalized, self.line_images: base_edge, self.color_images: base_colors})\n",
      "                    ims(result_dir+str(e*100000 + i)+\".jpg\",merge_color(recreation, [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "\n",
      "                if i % 500 == 0:\n",
      "                    self.save(\"./checkpoint\", e*100000 + i)\n",
      "\n",
      "    def loadmodel(self, load_discrim=True):\n",
      "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
      "        self.sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
      "        # self.sess = tf.Session()\n",
      "        self.sess.run(tf.initialize_all_variables())\n",
      "\n",
      "        if load_discrim:\n",
      "            self.saver = tf.train.Saver()\n",
      "        else:\n",
      "            self.saver = tf.train.Saver(self.g_vars)\n",
      "\n",
      "        if self.load(\"./checkpoint\"):\n",
      "            print(\"Loaded\")\n",
      "        else:\n",
      "            print(\"Load failed\")\n",
      "\n",
      "    def sample(self):\n",
      "        self.loadmodel(False)\n",
      "\n",
      "        data = glob(os.path.join(test_data_dir, \"*\"))\n",
      "\n",
      "        datalen = len(data)\n",
      "\n",
      "        for i in range(min(100,datalen / self.batch_size)):\n",
      "            batch_files = data[i*self.batch_size:(i+1)*self.batch_size]\n",
      "            batch = np.array([cv2.resize(imread(batch_file), (512,512)) for batch_file in batch_files])\n",
      "            batch_normalized = batch/255.0\n",
      "\n",
      "            batch_edge = np.array([cv2.adaptiveThreshold(cv2.cvtColor(ba, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=9, C=2) for ba in batch]) / 255.0\n",
      "            batch_edge = np.expand_dims(batch_edge, 3)\n",
      "\n",
      "            batch_colors = np.array([self.imageblur(ba,True) for ba in batch]) / 255.0\n",
      "\n",
      "            recreation = self.sess.run(self.generated_images, feed_dict={self.real_images: batch_normalized, self.line_images: batch_edge, self.color_images: batch_colors})\n",
      "            ims(result_dir+\"img_\"+str(i)+\".jpg\",merge_color(recreation, [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "            ims(result_dir+\"img_\"+str(i)+\"_origin.jpg\",merge_color(batch_normalized, [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "            ims(result_dir+\"img_\"+str(i)+\"_line.jpg\",merge_color(batch_edge, [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "            ims(result_dir+\"img_\"+str(i)+\"_color.jpg\",merge_color(batch_colors, [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "\n",
      "    def save(self, checkpoint_dir, step):\n",
      "        model_name = \"model\"\n",
      "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
      "\n",
      "        if not os.path.exists(checkpoint_dir):\n",
      "            os.makedirs(checkpoint_dir)\n",
      "\n",
      "        self.saver.save(self.sess,\n",
      "                        os.path.join(checkpoint_dir, model_name),\n",
      "                        global_step=step)\n",
      "\n",
      "    def load(self, checkpoint_dir):\n",
      "        print(\" [*] Reading checkpoint...\")\n",
      "\n",
      "\n",
      "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
      "\n",
      "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
      "        if ckpt and ckpt.model_checkpoint_path:\n",
      "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
      "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    # import train_utils\n",
      "    # train_utils.set_keras_session( )\n",
      "    if len(sys.argv) < 2:\n",
      "        print(\"Usage: python dc_main.py [train, sample]\")\n",
      "    else:\n",
      "        cmd = sys.argv[1]\n",
      "        if cmd == \"train\":\n",
      "            c = Color()\n",
      "            c.train()\n",
      "        elif cmd == \"sample\":\n",
      "            c = Color(512,1)\n",
      "            c.sample()\n",
      "        else:\n",
      "            print(\"Usage: python dc_main.py [train, sample]\")\n",
      "\n",
      "Output: {'dc_main': ['dc_main.Color.sample', '<builtin>.print', 'dc_main.Color.__init__', '<builtin>.len', 'dc_main.Color.train'], 'dc_main.Color.__init__': ['tensorflow.abs', 'tensorflow.placeholder', 'tensorflow.zeros_like', 'utils.batch_norm.__init__', 'dc_main.Color.generator', 'tensorflow.variable_scope', 'tensorflow.train.AdamOptimizer', 'tensorflow.concat', 'tensorflow.nn.sigmoid_cross_entropy_with_logits', '<builtin>.int', 'tensorflow.reduce_mean', 'math.sqrt', 'dc_main.Color.discriminator', 'tensorflow.trainable_variables', 'tensorflow.ones_like'], 'math.sqrt': [], '<builtin>.int': [], 'utils.batch_norm.__init__': [], 'tensorflow.placeholder': [], 'tensorflow.concat': [], 'dc_main.Color.generator': ['tensorflow.nn.tanh', 'tensorflow.concat', '<builtin>.int', 'utils.conv2d', 'utils.deconv2d', 'utils.bn', 'tensorflow.nn.relu', 'utils.lrelu'], 'dc_main.Color.discriminator': ['tensorflow.reshape', 'utils.batch_norm.__init__', 'tensorflow.get_variable_scope', 'utils.conv2d', 'utils.linear', 'tensorflow.nn.sigmoid', 'utils.lrelu'], 'tensorflow.ones_like': [], 'tensorflow.nn.sigmoid_cross_entropy_with_logits': [], 'tensorflow.reduce_mean': [], 'tensorflow.zeros_like': [], 'tensorflow.abs': [], 'tensorflow.trainable_variables': [], 'tensorflow.variable_scope': [], 'tensorflow.train.AdamOptimizer': [], 'tensorflow.get_variable_scope': [], 'utils.conv2d': ['tensorflow.reshape', 'tensorflow.truncated_normal_initializer', 'tensorflow.variable_scope', 'tensorflow.get_variable', 'tensorflow.constant_initializer', 'tensorflow.nn.conv2d', 'tensorflow.nn.bias_add'], 'utils.lrelu': ['tensorflow.maximum'], 'tensorflow.reshape': [], 'utils.linear': ['tensorflow.matmul', 'tensorflow.variable_scope', 'tensorflow.random_normal_initializer', 'tensorflow.get_variable', 'tensorflow.constant_initializer'], 'tensorflow.nn.sigmoid': [], 'utils.bn': ['utils.batch_norm.__init__', '<builtin>.str'], 'tensorflow.nn.relu': [], 'utils.deconv2d': ['tensorflow.reshape', 'tensorflow.variable_scope', 'tensorflow.random_normal_initializer', 'tensorflow.get_variable', 'tensorflow.constant_initializer', 'tensorflow.nn.conv2d_transpose', 'tensorflow.nn.bias_add'], 'tensorflow.nn.tanh': [], 'dc_main.Color.imageblur': ['<builtin>.range', 'random.randint', 'cv2.blur', 'numpy.ones_like'], 'numpy.ones_like': [], '<builtin>.range': [], 'random.randint': [], 'cv2.blur': [], 'dc_main.Color.train': ['<builtin>.range', '<builtin>.print', 'utils.get_image', 'dc_main.Color.imageblur', 'dc_main.Color.loadmodel', 'dc_main.Color.save', 'utils.merge_color', '<builtin>.int', '<builtin>.str', '<builtin>.len', 'numpy.array', 'os.path.join', 'utils.ims', 'glob.glob', 'numpy.expand_dims', 'utils.merge', 'cv2.adaptiveThreshold', 'cv2.cvtColor'], 'dc_main.Color.loadmodel': ['dc_main.Color.load', '<builtin>.print', 'tensorflow.Session', 'tensorflow.ConfigProto', 'tensorflow.train.Saver', 'tensorflow.initialize_all_variables', 'tensorflow.GPUOptions'], 'os.path.join': [], 'glob.glob': [], '<builtin>.print': [], 'utils.get_image': ['utils.transform', 'utils.imread'], 'numpy.array': [], 'cv2.cvtColor': [], 'cv2.adaptiveThreshold': [], 'numpy.expand_dims': [], 'utils.merge_color': ['numpy.zeros', '<builtin>.enumerate', '<builtin>.int'], 'utils.ims': ['<builtin>.print', 'cv2.imwrite'], 'utils.merge': ['numpy.zeros', '<builtin>.enumerate', '<builtin>.int'], '<builtin>.len': [], '<builtin>.str': [], 'dc_main.Color.save': ['os.path.exists', 'os.path.join', 'os.makedirs'], 'tensorflow.GPUOptions': [], 'tensorflow.ConfigProto': [], 'tensorflow.Session': [], 'tensorflow.initialize_all_variables': [], 'tensorflow.train.Saver': [], 'dc_main.Color.load': ['os.path.join', '<builtin>.print', 'os.path.basename', 'tensorflow.train.get_checkpoint_state'], 'dc_main.Color.sample': ['<builtin>.min', '<builtin>.range', 'dc_main.Color.imageblur', 'dc_main.Color.loadmodel', 'utils.imread', 'utils.merge_color', '<builtin>.str', '<builtin>.len', 'numpy.array', 'os.path.join', 'utils.ims', 'glob.glob', 'numpy.expand_dims', 'cv2.resize', 'cv2.adaptiveThreshold', 'cv2.cvtColor'], '<builtin>.min': [], 'utils.imread': ['cv2.imread'], 'cv2.resize': [], 'os.path.exists': [], 'os.makedirs': [], 'tensorflow.train.get_checkpoint_state': [], 'os.path.basename': [], 'utils': [], 'utils.batch_norm.__call__': ['tensorflow.contrib.layers.batch_norm'], 'tensorflow.contrib.layers.batch_norm': [], 'utils.bnreset': [], 'tensorflow.truncated_normal_initializer': [], 'tensorflow.get_variable': [], 'tensorflow.nn.conv2d': [], 'tensorflow.constant_initializer': [], 'tensorflow.nn.bias_add': [], 'tensorflow.random_normal_initializer': [], 'tensorflow.nn.conv2d_transpose': [], 'tensorflow.maximum': [], 'tensorflow.matmul': [], 'utils.transform': ['numpy.array', 'cv2.resize'], 'cv2.imread': [], 'numpy.zeros': [], '<builtin>.enumerate': [], 'cv2.imwrite': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hackcha_deepcolor\\dc_main.py\n",
      "[('dc_main', 'dc_main Color sample'), ('dc_main', 'dc_main Color __init__'), ('dc_main', 'dc_main Color train'), ('dc_main Color __init__', 'tensorflow abs'), ('dc_main Color __init__', 'tensorflow placeholder'), ('dc_main Color __init__', 'tensorflow zeros_like'), ('dc_main Color __init__', 'utils batch_norm __init__'), ('dc_main Color __init__', 'dc_main Color generator'), ('dc_main Color __init__', 'tensorflow variable_scope'), ('dc_main Color __init__', 'tensorflow train AdamOptimizer'), ('dc_main Color __init__', 'tensorflow concat'), ('dc_main Color __init__', 'tensorflow nn sigmoid_cross_entropy_with_logits'), ('dc_main Color __init__', 'tensorflow reduce_mean'), ('dc_main Color __init__', 'math sqrt'), ('dc_main Color __init__', 'dc_main Color discriminator'), ('dc_main Color __init__', 'tensorflow trainable_variables'), ('dc_main Color __init__', 'tensorflow ones_like'), ('dc_main Color generator', 'tensorflow nn tanh'), ('dc_main Color generator', 'tensorflow concat'), ('dc_main Color generator', 'utils conv2d'), ('dc_main Color generator', 'utils deconv2d'), ('dc_main Color generator', 'utils bn'), ('dc_main Color generator', 'tensorflow nn relu'), ('dc_main Color generator', 'utils lrelu'), ('dc_main Color discriminator', 'tensorflow reshape'), ('dc_main Color discriminator', 'utils batch_norm __init__'), ('dc_main Color discriminator', 'tensorflow get_variable_scope'), ('dc_main Color discriminator', 'utils conv2d'), ('dc_main Color discriminator', 'utils linear'), ('dc_main Color discriminator', 'tensorflow nn sigmoid')]\n",
      "0\n",
      "found files: []\n",
      "from dc_main import *\n",
      "\n",
      "\n",
      "def merge_it(c, files1, files2, index, img_size = 512):\n",
      "    batch = np.array([cv2.resize(imread(batch_file), (img_size, img_size)) for batch_file in files1])\n",
      "    batch_c = np.array([cv2.resize(imread(batch_file), (img_size, img_size)) for batch_file in files2])\n",
      "    batch_normalized = batch / 255.0\n",
      "    batch_edge = np.array([cv2.adaptiveThreshold(cv2.cvtColor(ba, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
      "                                                 cv2.THRESH_BINARY, blockSize=9, C=2) for ba in batch]) / 255.0\n",
      "    batch_edge = np.expand_dims(batch_edge, 3)\n",
      "    batch_colors = np.array([c.imageblur(ba, True) for ba in batch_c]) / 255.0\n",
      "\n",
      "    recreation = c.sess.run(c.generated_images,\n",
      "                            feed_dict={c.real_images: batch_normalized, c.line_images: batch_edge,\n",
      "                                       c.color_images: batch_colors})\n",
      "    out_file = 'data/lmerge_{}.jpg'.format(index)\n",
      "    edge_file = 'data/ledge_{}.jpg'.format(index)\n",
      "    ims(edge_file, merge_color(batch_edge, [c.batch_size_sqrt, c.batch_size_sqrt]))\n",
      "    ims(out_file, merge_color(recreation, [c.batch_size_sqrt, c.batch_size_sqrt]))\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    img_size= 256\n",
      "    c = Color(img_size, 1)\n",
      "    c.loadmodel( False )\n",
      "    print('load model done.')\n",
      "    # files1 = ['data/1.jpg','data/2.jpg','data/3.jpg','data/4.jpg','data/1.jpg','data/2.jpg','data/3.jpg','data/4.jpg']\n",
      "    # # files2 = ['data/lm.jpg','data/lm.jpg','data/lm.jpg','data/lm.jpg','data/cm.jpg','data/cm.jpg','data/cm.jpg','data/cm.jpg']\n",
      "    # files2 = ['data/m_m.jpg', 'data/m_m.jpg', 'data/m_m.jpg', 'data/m_m.jpg', 'data/wm_m.jpg', 'data/wm_m.jpg', 'data/wm_m.jpg',\n",
      "    #           'data/wm_m.jpg']\n",
      "    # files1 = ['data/h1.jpg','data/1.jpg']\n",
      "    # files2 = ['data/h2.jpg', 'data/h2.jpg']\n",
      "    files1 = ['data/timg_.jpg', 'data/lyf1.jpg']\n",
      "    files2 = ['data/timg.jpg', 'data/lyf2.jpg']\n",
      "    for i, (file1, file2) in enumerate( zip(files1, files2)):\n",
      "        merge_it(c,[file1], [file2], i, img_size=img_size)\n",
      "    print('done.')\n",
      "\n",
      "Output: {'merge_image_main': ['<builtin>.zip', 'dc_main.Color.loadmodel', '<builtin>.enumerate', 'dc_main.Color.__init__', 'merge_image_main.merge_it', '<builtin>.print'], 'merge_image_main.merge_it': ['cv2.adaptiveThreshold', 'utils.imread', 'numpy.expand_dims', 'dc_main.Color.imageblur', 'utils.ims', 'cv2.resize', 'numpy.array', 'utils.merge_color', 'cv2.cvtColor'], 'utils.imread': ['cv2.imread'], 'cv2.resize': [], 'numpy.array': [], 'cv2.cvtColor': [], 'cv2.adaptiveThreshold': [], 'numpy.expand_dims': [], 'dc_main.Color.imageblur': ['random.randint', 'numpy.ones_like', 'cv2.blur', '<builtin>.range'], 'utils.merge_color': ['<builtin>.enumerate', 'numpy.zeros', '<builtin>.int'], 'utils.ims': ['cv2.imwrite', '<builtin>.print'], 'dc_main.Color.__init__': ['tensorflow.abs', 'math.sqrt', '<builtin>.int', 'dc_main.Color.generator', 'tensorflow.placeholder', 'dc_main.Color.discriminator', 'tensorflow.concat', 'tensorflow.nn.sigmoid_cross_entropy_with_logits', 'tensorflow.reduce_mean', 'utils.batch_norm.__init__', 'tensorflow.trainable_variables', 'tensorflow.variable_scope', 'tensorflow.train.AdamOptimizer', 'tensorflow.zeros_like', 'tensorflow.ones_like'], 'dc_main.Color.loadmodel': ['tensorflow.ConfigProto', 'tensorflow.Session', 'tensorflow.train.Saver', 'tensorflow.GPUOptions', 'dc_main.Color.load', 'tensorflow.initialize_all_variables', '<builtin>.print'], '<builtin>.print': [], '<builtin>.zip': [], '<builtin>.enumerate': [], 'dc_main': ['dc_main.Color.train', 'dc_main.Color.__init__', '<builtin>.len', 'dc_main.Color.sample', '<builtin>.print'], 'math.sqrt': [], '<builtin>.int': [], 'utils.batch_norm.__init__': [], 'tensorflow.placeholder': [], 'tensorflow.concat': [], 'dc_main.Color.generator': ['tensorflow.nn.tanh', 'utils.bn', '<builtin>.int', 'utils.lrelu', 'tensorflow.concat', 'utils.deconv2d', 'utils.conv2d', 'tensorflow.nn.relu'], 'dc_main.Color.discriminator': ['tensorflow.reshape', 'tensorflow.nn.sigmoid', 'utils.lrelu', 'tensorflow.get_variable_scope', 'utils.batch_norm.__init__', 'utils.conv2d', 'utils.linear'], 'tensorflow.ones_like': [], 'tensorflow.nn.sigmoid_cross_entropy_with_logits': [], 'tensorflow.reduce_mean': [], 'tensorflow.zeros_like': [], 'tensorflow.abs': [], 'tensorflow.trainable_variables': [], 'tensorflow.variable_scope': [], 'tensorflow.train.AdamOptimizer': [], 'tensorflow.get_variable_scope': [], 'utils.conv2d': ['tensorflow.reshape', 'tensorflow.truncated_normal_initializer', 'tensorflow.get_variable', 'tensorflow.variable_scope', 'tensorflow.nn.conv2d', 'tensorflow.constant_initializer', 'tensorflow.nn.bias_add'], 'utils.lrelu': ['tensorflow.maximum'], 'tensorflow.reshape': [], 'utils.linear': ['tensorflow.get_variable', 'tensorflow.variable_scope', 'tensorflow.constant_initializer', 'tensorflow.random_normal_initializer', 'tensorflow.matmul'], 'tensorflow.nn.sigmoid': [], 'utils.bn': ['<builtin>.str', 'utils.batch_norm.__init__'], 'tensorflow.nn.relu': [], 'utils.deconv2d': ['tensorflow.reshape', 'tensorflow.nn.conv2d_transpose', 'tensorflow.get_variable', 'tensorflow.variable_scope', 'tensorflow.constant_initializer', 'tensorflow.random_normal_initializer', 'tensorflow.nn.bias_add'], 'tensorflow.nn.tanh': [], 'numpy.ones_like': [], '<builtin>.range': [], 'random.randint': [], 'cv2.blur': [], 'dc_main.Color.train': ['dc_main.Color.save', 'utils.get_image', 'dc_main.Color.loadmodel', 'cv2.adaptiveThreshold', 'numpy.expand_dims', 'dc_main.Color.imageblur', 'utils.ims', '<builtin>.range', '<builtin>.int', 'numpy.array', 'cv2.cvtColor', 'utils.merge_color', 'utils.merge', '<builtin>.len', '<builtin>.str', 'glob.glob', 'os.path.join', '<builtin>.print'], 'os.path.join': [], 'glob.glob': [], 'utils.get_image': ['utils.transform', 'utils.imread'], 'utils.merge': ['<builtin>.enumerate', 'numpy.zeros', '<builtin>.int'], '<builtin>.len': [], '<builtin>.str': [], 'dc_main.Color.save': ['os.path.join', 'os.path.exists', 'os.makedirs'], 'tensorflow.GPUOptions': [], 'tensorflow.ConfigProto': [], 'tensorflow.Session': [], 'tensorflow.initialize_all_variables': [], 'tensorflow.train.Saver': [], 'dc_main.Color.load': ['os.path.join', 'tensorflow.train.get_checkpoint_state', 'os.path.basename', '<builtin>.print'], 'dc_main.Color.sample': ['cv2.adaptiveThreshold', 'dc_main.Color.loadmodel', '<builtin>.range', 'utils.imread', 'numpy.expand_dims', 'dc_main.Color.imageblur', 'cv2.resize', 'utils.ims', '<builtin>.min', 'numpy.array', 'utils.merge_color', 'os.path.join', '<builtin>.str', 'glob.glob', '<builtin>.len', 'cv2.cvtColor'], '<builtin>.min': [], 'os.path.exists': [], 'os.makedirs': [], 'tensorflow.train.get_checkpoint_state': [], 'os.path.basename': [], 'utils': [], 'utils.batch_norm.__call__': ['tensorflow.contrib.layers.batch_norm'], 'tensorflow.contrib.layers.batch_norm': [], 'utils.bnreset': [], 'tensorflow.truncated_normal_initializer': [], 'tensorflow.get_variable': [], 'tensorflow.nn.conv2d': [], 'tensorflow.constant_initializer': [], 'tensorflow.nn.bias_add': [], 'tensorflow.random_normal_initializer': [], 'tensorflow.nn.conv2d_transpose': [], 'tensorflow.maximum': [], 'tensorflow.matmul': [], 'utils.transform': ['numpy.array', 'cv2.resize'], 'cv2.imread': [], 'numpy.zeros': [], 'cv2.imwrite': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hackcha_deepcolor\\merge_image_main.py\n",
      "[('merge_image_main', 'dc_main Color loadmodel'), ('merge_image_main', 'dc_main Color __init__'), ('merge_image_main', 'merge_image_main merge_it'), ('merge_image_main merge_it', 'cv2 adaptiveThreshold'), ('merge_image_main merge_it', 'utils imread'), ('merge_image_main merge_it', 'numpy expand_dims'), ('merge_image_main merge_it', 'dc_main Color imageblur'), ('merge_image_main merge_it', 'utils ims'), ('merge_image_main merge_it', 'cv2 resize'), ('merge_image_main merge_it', 'numpy array'), ('merge_image_main merge_it', 'utils merge_color'), ('merge_image_main merge_it', 'cv2 cvtColor'), ('utils imread', 'cv2 imread'), ('dc_main Color imageblur', 'random randint'), ('dc_main Color imageblur', 'numpy ones_like'), ('dc_main Color imageblur', 'cv2 blur'), ('utils merge_color', 'numpy zeros'), ('utils ims', 'cv2 imwrite'), ('dc_main Color __init__', 'tensorflow abs'), ('dc_main Color __init__', 'math sqrt'), ('dc_main Color __init__', 'dc_main Color generator'), ('dc_main Color __init__', 'tensorflow placeholder'), ('dc_main Color __init__', 'dc_main Color discriminator'), ('dc_main Color __init__', 'tensorflow concat'), ('dc_main Color __init__', 'tensorflow nn sigmoid_cross_entropy_with_logits'), ('dc_main Color __init__', 'tensorflow reduce_mean'), ('dc_main Color __init__', 'utils batch_norm __init__'), ('dc_main Color __init__', 'tensorflow trainable_variables'), ('dc_main Color __init__', 'tensorflow variable_scope'), ('dc_main Color __init__', 'tensorflow train AdamOptimizer')]\n",
      "0\n",
      "found files: []\n",
      "import keras\n",
      "from keras.applications.inception_v3 import InceptionV3\n",
      "from keras.applications.inception_v3 import preprocess_input\n",
      "# from keras.applications.vgg16 import VGG16, preprocess_input\n",
      "from keras.preprocessing import image\n",
      "from keras.engine import Layer\n",
      "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate, Activation, Dense, Dropout, Flatten\n",
      "from keras.layers.normalization import BatchNormalization\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.models import Sequential, Model\n",
      "from keras.layers.core import RepeatVector, Permute\n",
      "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
      "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "from keras.optimizers import SGD, Adam\n",
      "from skimage.transform import resize\n",
      "import keras.activations\n",
      "# from skimage.io import imsave\n",
      "from matplotlib import pyplot\n",
      "import numpy as np\n",
      "import os\n",
      "import random\n",
      "import cv2\n",
      "from random import randint\n",
      "from keras.backend.tensorflow_backend import set_session\n",
      "import tensorflow as tf\n",
      "import utils\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "img_to_array \n",
      "load_img \n",
      "\"\"\"\n",
      "\n",
      "\n",
      "def set_keras_session():\n",
      "    config = tf.ConfigProto()\n",
      "    config.gpu_options.allow_growth = True\n",
      "    config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
      "    sess = tf.Session(config=config)\n",
      "    set_session(sess)\n",
      "\n",
      "def create_inception_embedding( grayscaled_rgb, inception):\n",
      "    grayscaled_rgb_resized = []\n",
      "    for i in grayscaled_rgb:\n",
      "        #299 for inception, 224 for vgg\n",
      "        i = resize(i, (299, 299, 3), mode='constant', preserve_range=True)\n",
      "        grayscaled_rgb_resized.append(i)\n",
      "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
      "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
      "    with inception.graph.as_default():\n",
      "        embed = inception.predict(grayscaled_rgb_resized)\n",
      "    return embed\n",
      "\n",
      "def load_inception():\n",
      "    inception = InceptionV3(weights='imagenet', include_top=True)\n",
      "    inception.graph = tf.get_default_graph()\n",
      "    return inception\n",
      "\n",
      "def get_Xtrain():\n",
      "    X = []\n",
      "    for filename in os.listdir('data/images/Train/'):\n",
      "        X.append(img_to_array(load_img('data/images/Train/' + filename)))\n",
      "    X = np.array(X, dtype=float)\n",
      "    Xtrain = 1.0 / 255 * X\n",
      "    print('load data done.')\n",
      "    return Xtrain\n",
      "\n",
      "def get_Xtrainlimit(img_size, data_dir='data/images/Train/', limit=512):\n",
      "    X = []\n",
      "    files = os.listdir(data_dir)\n",
      "    for filename in files[:limit]:\n",
      "        X.append(utils.get_image(data_dir + filename, target_size=(img_size, img_size)))\n",
      "    Xtrain = np.array(X)\n",
      "    return Xtrain\n",
      "\n",
      "def image_ab_gen_trans(inception, datagen, Xtrain, batch_size):\n",
      "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
      "        grayscaled_rgb = gray2rgb(my_rgb_to_gray(batch))\n",
      "        embed = create_inception_embedding(inception, grayscaled_rgb)\n",
      "        lab_batch = rgb2lab(batch)\n",
      "        X_batch = lab_batch[:,:,:,0]\n",
      "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
      "        Y_batch = lab_batch[:,:,:,1:] / 128.0\n",
      "        yield ([X_batch, embed], Y_batch)\n",
      "\n",
      "def image_a_b_gen_batches(all_files, batch_size, img_size, trans=False, inception=None, data_dir ='data/images/Train/' ):\n",
      "    datagen = ImageDataGenerator(\n",
      "        shear_range=0.2,\n",
      "        zoom_range=0.2,\n",
      "        rotation_range=20,\n",
      "        horizontal_flip=True)\n",
      "    #Get images\n",
      "    while True:\n",
      "        np.random.shuffle( all_files )\n",
      "        for bi in range( int(len(all_files)/batch_size) ):\n",
      "            files = all_files[bi*batch_size:(bi+1)*batch_size]\n",
      "            X = []\n",
      "            for filename in files:\n",
      "                X.append(img_to_array(load_img( data_dir+ filename,\n",
      "                                               target_size=(img_size, img_size))))\n",
      "            Xtrain = np.array(X, dtype=float)\n",
      "            batch_index = 0\n",
      "            for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
      "                batch_index = batch_index + 1\n",
      "                if batch_index > 1:\n",
      "                    break\n",
      "                # for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
      "                lab_batch = rgb2lab(batch / 255.0)\n",
      "                X_batch = lab_batch[:, :, :, 0]\n",
      "                X_batch = X_batch.reshape(X_batch.shape + (1,))\n",
      "                Y_batch = lab_batch[:, :, :, 1:] / 128.0\n",
      "                if trans:\n",
      "                    gray_imgs = my_rgb_to_gray(batch)\n",
      "                    grayscaled_rgb = gray2rgb(gray_imgs)\n",
      "                    embed = create_inception_embedding(grayscaled_rgb, inception)\n",
      "                    yield ([X_batch, embed], Y_batch)\n",
      "                else:\n",
      "                    yield (X_batch, Y_batch)\n",
      "\n",
      "def image_ab_gen(datagen, Xtrain, batch_size, trans= False, inception = None):\n",
      "    # Get images\n",
      "    # X = []\n",
      "    # for filename in files:\n",
      "    #     X.append(img_to_array(load_img('data/images/Train/' + filename, target_size=(img_size, img_size))))\n",
      "    # Xtrain = np.array(X, dtype=float)\n",
      "    ii = 0\n",
      "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
      "        ii += 1\n",
      "        lab_batch = rgb2lab( batch/255.0 )\n",
      "        X_batch = lab_batch[:,:,:,0]\n",
      "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
      "        Y_batch = lab_batch[:,:,:,1:] / 128.0\n",
      "        #\n",
      "        # img_size = 256\n",
      "        # cur = np.zeros((img_size, img_size, 3), dtype=np.float64)\n",
      "        # Y = Y_batch *128\n",
      "        # re = Y[0]\n",
      "        # cur[:, :, 0] = X_batch[0][:, :, 0]\n",
      "        # cur[:, :, 1:] = re\n",
      "        # img = lab2rgb(cur) * 255.0\n",
      "        # pyplot.imsave(\"data/result/imgflow_\" + str(ii) + \".jpg\", img.astype('uint8'))\n",
      "        if trans:\n",
      "            gray_imgs = my_rgb_to_gray(batch)\n",
      "            grayscaled_rgb = gray2rgb(gray_imgs)\n",
      "            embed = create_inception_embedding(grayscaled_rgb, inception)\n",
      "            yield ([X_batch, embed], Y_batch)\n",
      "        else:\n",
      "            yield (X_batch, Y_batch)\n",
      "\n",
      "def image_ab_valid(datagen, Xtrain, batch_size, trans= False, inception = None):\n",
      "    ii = 0\n",
      "    ii += 1\n",
      "    lab_batch = rgb2lab( Xtrain/255.0 )\n",
      "    X_batch = lab_batch[:,:,:,0]\n",
      "    X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
      "    Y_batch = lab_batch[:,:,:,1:] / 128.0\n",
      "    # Y_batch = Xtrain/255.0\n",
      "    if trans:\n",
      "        gray_imgs = my_rgb_to_gray(Xtrain)\n",
      "        grayscaled_rgb = gray2rgb(gray_imgs)\n",
      "        embed = create_inception_embedding(grayscaled_rgb, inception)\n",
      "        return ([X_batch, embed], Y_batch)\n",
      "    return (X_batch, Y_batch)\n",
      "\n",
      "\n",
      "\n",
      "def image_rgb_gen(datagen, Xtrain, batch_size):\n",
      "    ii = 0\n",
      "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
      "        ii += 1\n",
      "        lab_batch = rgb2lab( batch/255.0 )\n",
      "        X_batch = lab_batch[:,:,:,0]\n",
      "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
      "        # Y_batch = lab_batch[:,:,:,1:] / 128.0\n",
      "        Y_batch = batch/255.0\n",
      "        yield (X_batch, Y_batch)\n",
      "\n",
      "def image_rgb_valid(datagen, Xtrain, batch_size, do_blur=False):\n",
      "    return  get_rgb_XY( Xtrain, do_blur)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def imageblur( cimg, sampling=False):\n",
      "    \"\"\"\n",
      "    #\n",
      "    :param cimg:\n",
      "    :param sampling:\n",
      "    :return:\n",
      "    \"\"\"\n",
      "    if sampling:\n",
      "        cimg = cimg * 0.3 + np.ones_like(cimg) * 0.7 * 255\n",
      "    else:\n",
      "        for i in range(30):\n",
      "            randx = randint(0,205)\n",
      "            randy = randint(0,205)\n",
      "            cimg[randx:randx+50, randy:randy+50] = 255\n",
      "    return cv2.blur(cimg,(100,100))\n",
      "\n",
      "def get_rgb_XY( batch, do_blur, return_edge = False ):\n",
      "    Y_batch = batch / 255.0\n",
      "    if do_blur:\n",
      "        add_edge = True\n",
      "        if add_edge:\n",
      "            batch_edge = np.array([cv2.adaptiveThreshold(cv2.cvtColor(ba, cv2.COLOR_BGR2GRAY), 255,\n",
      "                                                         cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,\n",
      "                                                         blockSize=9,\n",
      "                                                         C=2) for ba in batch]) / 255.0\n",
      "            batch_edge = np.expand_dims(batch_edge, 3)\n",
      "            base_colors = np.array([imageblur(ba) for ba in batch]) / 255.0\n",
      "            X_batch = np.concatenate([ base_colors, batch_edge], axis=3)#X_batch\n",
      "        else:\n",
      "            lab_batch = rgb2lab(batch / 255.0)\n",
      "            X_batch = lab_batch[:, :, :, 0] / 100.0\n",
      "            X_batch = X_batch.reshape(X_batch.shape + (1,))\n",
      "            base_colors = np.array([imageblur(ba) for ba in batch]) / 255.0\n",
      "            X_batch = np.concatenate([X_batch, base_colors], axis=3)\n",
      "    else:\n",
      "        lab_batch = rgb2lab(batch / 255.0)\n",
      "        X_batch = lab_batch[:, :, :, 0] / 100.0\n",
      "        X_batch = X_batch.reshape(X_batch.shape + (1,))\n",
      "    if return_edge:\n",
      "        return X_batch, Y_batch, batch_edge, base_colors\n",
      "    return (X_batch, Y_batch)\n",
      "\n",
      "def image_rgb_gen_batches(all_files, batch_size, img_size, do_blur=False, train_data_dir='data/images/Train/'):\n",
      "    #Get images\n",
      "    # datagen = ImageDataGenerator(\n",
      "    #     shear_range=0.2,\n",
      "    #     zoom_range=0.2,\n",
      "    #     rotation_range=20,\n",
      "    #     horizontal_flip=True)\n",
      "    while True:\n",
      "        np.random.shuffle( all_files )\n",
      "        for bi in range( int(len(all_files)/batch_size) ):\n",
      "            files = all_files[bi*batch_size:(bi+1)*batch_size]\n",
      "            X = []\n",
      "            for filename in files:\n",
      "                X.append(utils.get_image( train_data_dir+ filename,\n",
      "                                               target_size=(img_size, img_size)))\n",
      "            Xtrain = np.array(X)\n",
      "            yield  get_rgb_XY(Xtrain, do_blur)\n",
      "\n",
      "\n",
      "\n",
      "def my_rgb_to_gray(rgb):\n",
      "    gray = 0.2125 * rgb[..., 0]\n",
      "    gray[:] += 0.7154 * rgb[..., 1]\n",
      "    gray[:] += 0.0721 * rgb[..., 2]\n",
      "    # gray = 0.299 * rgb[..., 0]\n",
      "    # gray[:] += 0.587 * rgb[..., 1]\n",
      "    # gray[:] += 0.114 * rgb[..., 2]\n",
      "    return gray\n",
      "\n",
      "def load_test( img_size, data_dir='data/Test/' ):\n",
      "    imgs = []\n",
      "    for filename in os.listdir(data_dir)[-4:]:\n",
      "        imgs.append(utils.get_image(data_dir + filename, target_size=(img_size, img_size)))\n",
      "    imgs = np.array(imgs)\n",
      "    gray_me = gray2rgb(my_rgb_to_gray(imgs))\n",
      "    # TODO \n",
      "    # color_me = 1.0/255*color_me\n",
      "    # color_me_embed = create_inception_embedding(gray_me)\n",
      "    color_me = rgb2lab(1.0 / 255 * gray_me)[:, :, :, 0]/100.0\n",
      "    color_me = color_me.reshape(color_me.shape + (1,))\n",
      "    return imgs, color_me\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hackcha_deepcolor\\train_utils.py\n",
      "[]\n",
      "found files: []\n",
      "import cv2\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt\n",
      "from glob import glob\n",
      "from random import randint\n",
      "\n",
      "data = glob(\"imgs/*.jpg\")\n",
      "for imname in data:\n",
      "\n",
      "    cimg = cv2.imread(imname,1)\n",
      "    cimg = np.fliplr(cimg.reshape(-1,3)).reshape(cimg.shape)\n",
      "    cimg = cv2.resize(cimg, (256,256))\n",
      "\n",
      "    img = cv2.imread(imname,0)\n",
      "\n",
      "    # kernel = np.ones((5,5),np.float32)/25\n",
      "    seg = np.ones_like(cimg)\n",
      "\n",
      "    num_segs = 8\n",
      "    seg_len = 256/num_segs\n",
      "\n",
      "    for x in xrange(num_segs):\n",
      "        for y in xrange(num_segs):\n",
      "            seg[x*seg_len:(x+1)*seg_len, y*seg_len:(y+1)*seg_len, 0] = np.average(cimg[x*seg_len:(x+1)*seg_len, y*seg_len:(y+1)*seg_len, 0])\n",
      "            seg[x*seg_len:(x+1)*seg_len, y*seg_len:(y+1)*seg_len, 1] = np.average(cimg[x*seg_len:(x+1)*seg_len, y*seg_len:(y+1)*seg_len, 1])\n",
      "            seg[x*seg_len:(x+1)*seg_len, y*seg_len:(y+1)*seg_len, 2] = np.average(cimg[x*seg_len:(x+1)*seg_len, y*seg_len:(y+1)*seg_len, 2])\n",
      "\n",
      "\n",
      "    # img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
      "    img_edge = cv2.adaptiveThreshold(img, 255,\n",
      "                                     cv2.ADAPTIVE_THRESH_MEAN_C,\n",
      "                                     cv2.THRESH_BINARY,\n",
      "                                     blockSize=9,\n",
      "                                     C=2)\n",
      "    # img_edge = cv2.cvtColor(img_edge, cv2.COLOR_GRAY2RGB)\n",
      "    # img_cartoon = cv2.bitwise_and(img, img_edge)\n",
      "\n",
      "    plt.subplot(131),plt.imshow(cimg)\n",
      "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
      "\n",
      "    plt.subplot(132),plt.imshow(seg)\n",
      "    plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
      "\n",
      "    plt.subplot(133),plt.imshow(img_edge,cmap = 'gray')\n",
      "    plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
      "\n",
      "    plt.show()\n",
      "\n",
      "Output: {'test_processing': ['cv2.resize', 'numpy.average', 'matplotlib.pyplot.imshow', 'matplotlib.pyplot.xticks', 'cv2.imread', 'matplotlib.pyplot.title', 'matplotlib.pyplot.yticks', 'cv2.adaptiveThreshold', 'numpy.fliplr', 'glob.glob', 'matplotlib.pyplot.show', 'matplotlib.pyplot.subplot', 'numpy.ones_like'], 'glob.glob': [], 'cv2.imread': [], 'numpy.fliplr': [], 'cv2.resize': [], 'numpy.ones_like': [], 'numpy.average': [], 'cv2.adaptiveThreshold': [], 'matplotlib.pyplot.subplot': [], 'matplotlib.pyplot.imshow': [], 'matplotlib.pyplot.title': [], 'matplotlib.pyplot.xticks': [], 'matplotlib.pyplot.yticks': [], 'matplotlib.pyplot.show': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hackcha_deepcolor\\test_processing.py\n",
      "[('test_processing', 'cv2 resize'), ('test_processing', 'numpy average'), ('test_processing', 'matplotlib pyplot imshow'), ('test_processing', 'matplotlib pyplot xticks'), ('test_processing', 'cv2 imread'), ('test_processing', 'matplotlib pyplot title'), ('test_processing', 'matplotlib pyplot yticks'), ('test_processing', 'cv2 adaptiveThreshold'), ('test_processing', 'numpy fliplr'), ('test_processing', 'glob glob'), ('test_processing', 'matplotlib pyplot show'), ('test_processing', 'matplotlib pyplot subplot'), ('test_processing', 'numpy ones_like')]\n",
      "0\n",
      "found files: []\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import os\n",
      "from glob import glob\n",
      "import sys\n",
      "import math\n",
      "from random import randint\n",
      "\n",
      "from utils import *\n",
      "import utils\n",
      "\n",
      "class Palette():\n",
      "    def __init__(self, imgsize=256, batchsize=4):\n",
      "\n",
      "        print(\"Loading Palatte\")\n",
      "\n",
      "        self.batch_size = batchsize\n",
      "        self.batch_size_sqrt = int(math.sqrt(self.batch_size))\n",
      "        self.image_size = imgsize\n",
      "        self.output_size = imgsize\n",
      "\n",
      "        self.gf_dim = 64\n",
      "        self.df_dim = 64\n",
      "        self.z_dim = 64\n",
      "\n",
      "        self.input_colors = 1\n",
      "        self.input_colors2 = 3\n",
      "        self.output_colors = 3\n",
      "\n",
      "        bnreset()\n",
      "\n",
      "        self.line_images = tf.placeholder(tf.float32, [self.batch_size, self.image_size, self.image_size, self.input_colors])\n",
      "        self.real_images = tf.placeholder(tf.float32, [self.batch_size, self.image_size/16, self.image_size/16, self.output_colors])\n",
      "\n",
      "        with tf.variable_scope(\"col\"):\n",
      "            z_mean, z_stddev = self.encoder(self.real_images)\n",
      "            samples = tf.random_normal([self.batch_size, self.z_dim], 0, 1, dtype=tf.float32)\n",
      "            self.guessed_z = z_mean + (z_stddev * samples)\n",
      "\n",
      "            # references: line_images,\n",
      "            self.generated_images = self.generator(self.line_images, self.guessed_z)\n",
      "\n",
      "        self.g_loss = tf.reduce_mean(tf.abs(self.real_images - self.generated_images)) * 100\n",
      "        self.l_loss = tf.reduce_mean(0.5 * tf.reduce_sum(tf.square(z_mean) + tf.square(z_stddev) - tf.log(tf.square(z_stddev)) - 1, axis=1))\n",
      "        self.cost = tf.reduce_mean(self.g_loss + self.l_loss)\n",
      "\n",
      "        t_vars = tf.trainable_variables()\n",
      "        self.g_vars = [var for var in t_vars if ('col' in var.name)]\n",
      "        self.g_optim = tf.train.AdamOptimizer(0.0002, beta1=0.5).minimize(self.cost, var_list=self.g_vars)\n",
      "\n",
      "    def encoder(self, real_imgs):\n",
      "        with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n",
      "            h0 = lrelu(conv2d(real_imgs, self.df_dim, name=\"e_h0_col\")) #128 x 128 x 64\n",
      "            h1 = lrelu(bn(conv2d(h0, self.df_dim, name=\"e_h1_col\"))) #64 x 64 x 64\n",
      "            h2 = lrelu(bn(conv2d(h1, self.df_dim, name=\"e_h2_col\"))) #32\n",
      "            h3 = lrelu(bn(conv2d(h2, self.df_dim, name=\"e_h3_col\"))) #16\n",
      "            h4 = lrelu(bn(conv2d(h3, self.df_dim, name=\"e_h4_col\"))) #8\n",
      "            h5 = lrelu(bn(conv2d(h4, self.df_dim, name=\"e_h5_col\"))) #4\n",
      "            mean = linear(tf.reshape(h5, [self.batch_size, -1]), self.z_dim, \"e_mean_col\") #(4*4*64) -> 64\n",
      "            stddev = linear(tf.reshape(h5, [self.batch_size, -1]), self.z_dim, \"e_stddev_col\") #(4*4*64) -> 64\n",
      "        return mean, stddev\n",
      "\n",
      "\n",
      "    def generator(self, img_in, z):\n",
      "        with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n",
      "            s = self.output_size\n",
      "            s2, s4, s8, s16, s32, s64, s128 = int(s/2), int(s/4), int(s/8), int(s/16), int(s/32), int(s/64), int(s/128)\n",
      "\n",
      "            z0 = linear(z, (self.image_size/64)*(self.image_size/64)*self.df_dim, \"g_z0_col\") # 4 x 4 x 64\n",
      "            z1 = tf.reshape(z0, [self.batch_size, self.image_size/64, self.image_size/64, self.df_dim])\n",
      "\n",
      "            # image is (256 x 256 x input_c_dim)\n",
      "            e1 = conv2d(img_in, self.gf_dim, name='g_e1_conv_col') # e1 is (128 x 128 x self.gf_dim)\n",
      "            e2 = bn(conv2d(lrelu(e1), self.gf_dim*2, name='g_e2_conv_col')) # e2 is (64 x 64 x self.gf_dim*2)\n",
      "            e3 = bn(conv2d(lrelu(e2), self.gf_dim*2, name='g_e3_conv_col')) # e3 is (32 x 32 x self.gf_dim*2)\n",
      "            e4 = bn(conv2d(lrelu(e3), self.gf_dim*2, name='g_e4_conv_col')) # e4 is (16 x 16 x self.gf_dim*2)\n",
      "            e5 = bn(conv2d(lrelu(e4), self.gf_dim*2, name='g_e5_conv_col')) # e4 is (8 x 8 x self.gf_dim*2)\n",
      "            e6 = bn(conv2d(lrelu(e5), self.gf_dim*4, name='g_e6_conv_col')) # e4 is (4 x 4 x self.gf_dim*2)\n",
      "            combined = tf.concat(3, [z1, e6])\n",
      "            e7 = bn(deconv2d(combined, [self.batch_size, self.image_size/32, self.image_size/32, self.gf_dim*4], name='g_e7_conv_col')) # e4 is (8 x 8 x self.gf_dim*2)\n",
      "            e8 = deconv2d(lrelu(e7), [self.batch_size, self.image_size/16, self.image_size/16, 3], name='g_e8_conv_col') # e5 is (16 x 16 x 3)\n",
      "\n",
      "        return tf.nn.tanh(e8)\n",
      "\n",
      "\n",
      "    def imgprocess(self, cimg, sampling=False):\n",
      "        num_segs = 16\n",
      "        seg_len = 256/num_segs\n",
      "\n",
      "        seg = np.ones((num_segs, num_segs, 3))\n",
      "        for x in range(num_segs):\n",
      "            for y in range(num_segs):\n",
      "                seg[x:(x+1), y:(y+1), 0] = np.average(cimg[x*seg_len:(x+1)*seg_len, y*seg_len:(y+1)*seg_len, 0])\n",
      "                seg[x:(x+1), y:(y+1), 1] = np.average(cimg[x*seg_len:(x+1)*seg_len, y*seg_len:(y+1)*seg_len, 1])\n",
      "                seg[x:(x+1), y:(y+1), 2] = np.average(cimg[x*seg_len:(x+1)*seg_len, y*seg_len:(y+1)*seg_len, 2])\n",
      "        return seg\n",
      "\n",
      "    def train(self):\n",
      "        s = tf.Session()\n",
      "        s.run(tf.initialize_all_variables())\n",
      "        self.loadmodel(s)\n",
      "\n",
      "        data = glob(os.path.join(\"imgs\", \"*.jpg\"))\n",
      "        print(data[0])\n",
      "        base = np.array([get_image(sample_file) for sample_file in data[0:self.batch_size]])\n",
      "\n",
      "        base_edge = np.array([cv2.adaptiveThreshold(cv2.cvtColor(ba, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=9, C=2) for ba in base]) / 255.0\n",
      "        base_edge = np.expand_dims(base_edge, 3)\n",
      "\n",
      "        base_colors = np.array([self.imgprocess(ba) for ba in base]) / 255.0\n",
      "\n",
      "        ims(\"results/base_line.jpg\",merge(base_edge, [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "        ims(\"results/base_colors.jpg\",merge_color(np.array([cv2.resize(x, (256,256), interpolation=cv2.INTER_NEAREST) for x in base_colors]), [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "\n",
      "        datalen = len(data)\n",
      "\n",
      "        for e in range(20000):\n",
      "            for i in range(datalen / self.batch_size):\n",
      "                batch_files = data[i*self.batch_size:(i+1)*self.batch_size]\n",
      "                batch = np.array([get_image(batch_file) for batch_file in batch_files])\n",
      "\n",
      "                batch_edge = np.array([cv2.adaptiveThreshold(cv2.cvtColor(ba, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=9, C=2) for ba in batch]) / 255.0\n",
      "                batch_edge = np.expand_dims(batch_edge, 3)\n",
      "\n",
      "                batch_colors = np.array([self.imgprocess(ba) for ba in batch]) / 255.0\n",
      "\n",
      "                g_loss, l_loss, _ = self.sess.run([self.g_loss, self.l_loss, self.g_optim], feed_dict={self.real_images: batch_colors, self.line_images: batch_edge})\n",
      "\n",
      "                print(\"%d: [%d / %d] l_loss %f, g_loss %f\" % (e, i, (datalen/self.batch_size), l_loss, g_loss))\n",
      "\n",
      "                if i % 100 == 0:\n",
      "                    recreation = self.sess.run(self.generated_images, feed_dict={self.real_images: base_colors, self.line_images: base_edge})\n",
      "                    print(recreation.shape)\n",
      "                    ims(\"results/\"+str(e*100000 + i)+\"_base.jpg\",merge_color(np.array([cv2.resize(x, (256,256), interpolation=cv2.INTER_NEAREST) for x in recreation]), [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "\n",
      "                    recreation = self.sess.run(self.generated_images, feed_dict={self.real_images: batch_colors, self.line_images: batch_edge})\n",
      "                    ims(\"results/\"+str(e*100000 + i)+\".jpg\",merge_color(np.array([cv2.resize(x, (256,256), interpolation=cv2.INTER_NEAREST) for x in recreation]), [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "                    ims(\"results/\"+str(e*100000 + i)+\"_line.jpg\",merge(batch_edge, [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "                    ims(\"results/\"+str(e*100000 + i)+\"_original.jpg\",merge_color(np.array([cv2.resize(x, (256,256), interpolation=cv2.INTER_NEAREST) for x in batch_colors]), [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "\n",
      "                if i % 1000 == 0:\n",
      "                    self.save(\"./checkpoint\", e*100000 + i)\n",
      "\n",
      "    def loadmodel(self, sess, load_discrim=True):\n",
      "        self.sess = sess\n",
      "        # self.sess.run(tf.initialize_all_variables())\n",
      "\n",
      "        if load_discrim:\n",
      "            self.saver = tf.train.Saver()\n",
      "        else:\n",
      "            self.saver = tf.train.Saver(self.g_vars)\n",
      "            print([v.name for v in self.g_vars])\n",
      "\n",
      "        if self.load(\"./checkpoint\"):\n",
      "            print(\"Loaded\")\n",
      "        else:\n",
      "            print(\"Load failed\")\n",
      "\n",
      "    def sample(self):\n",
      "        s = tf.Session()\n",
      "        s.run(tf.initialize_all_variables())\n",
      "        self.loadmodel(s, False)\n",
      "\n",
      "        data = glob(os.path.join(\"imgs\", \"*.jpg\"))\n",
      "\n",
      "        datalen = len(data)\n",
      "\n",
      "        for i in range(min(100,datalen / self.batch_size)):\n",
      "            batch_files = data[i*self.batch_size:(i+1)*self.batch_size]\n",
      "            batch = np.array([cv2.resize(imread(batch_file), (256,256)) for batch_file in batch_files])\n",
      "            batch_normalized = batch/255.0\n",
      "\n",
      "            random_z = np.random.normal(0, 1, [self.batch_size, self.z_dim])\n",
      "\n",
      "            batch_edge = np.array([cv2.adaptiveThreshold(cv2.cvtColor(ba, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=9, C=2) for ba in batch]) / 255.0\n",
      "            batch_edge = np.expand_dims(batch_edge, 3)\n",
      "\n",
      "            recreation = self.sess.run(self.generated_images, feed_dict={self.line_images: batch_edge, self.guessed_z: random_z})\n",
      "            ims(\"results/sample_\"+str(i)+\".jpg\",merge_color(np.array([cv2.resize(x, (256,256), interpolation=cv2.INTER_NEAREST) for x in recreation]), [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "            ims(\"results/sample_\"+str(i)+\"_origin.jpg\",merge_color(batch_normalized, [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "            ims(\"results/sample_\"+str(i)+\"_line.jpg\",merge_color(batch_edge, [self.batch_size_sqrt, self.batch_size_sqrt]))\n",
      "\n",
      "\n",
      "    def save(self, checkpoint_dir, step):\n",
      "        model_name = \"model\"\n",
      "        model_dir = \"tr_colors\"\n",
      "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
      "\n",
      "        if not os.path.exists(checkpoint_dir):\n",
      "            os.makedirs(checkpoint_dir)\n",
      "\n",
      "        self.saver.save(self.sess,\n",
      "                        os.path.join(checkpoint_dir, model_name),\n",
      "                        global_step=step)\n",
      "\n",
      "    def load(self, checkpoint_dir):\n",
      "        print(\" [*] Reading checkpoint...\")\n",
      "\n",
      "        model_dir = \"tr_colors\"\n",
      "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
      "\n",
      "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
      "        if ckpt and ckpt.model_checkpoint_path:\n",
      "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
      "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    if len(sys.argv) < 2:\n",
      "        print(\"Usage: python dc_main.py [train, sample]\")\n",
      "    else:\n",
      "        cmd = sys.argv[1]\n",
      "        if cmd == \"train\":\n",
      "            c = Palette()\n",
      "            c.train()\n",
      "        elif cmd == \"sample\":\n",
      "            c = Palette(256,1)\n",
      "            c.sample()\n",
      "        else:\n",
      "            print(\"Usage: python dc_main.py [train, sample]\")\n",
      "\n",
      "Output: {'guess_colors': ['guess_colors.Palette.__init__', 'guess_colors.Palette.train', 'guess_colors.Palette.sample', '<builtin>.print', '<builtin>.len'], 'guess_colors.Palette.__init__': ['tensorflow.trainable_variables', 'tensorflow.abs', 'tensorflow.placeholder', 'guess_colors.Palette.generator', 'tensorflow.square', 'tensorflow.reduce_sum', 'tensorflow.reduce_mean', 'tensorflow.random_normal', 'tensorflow.variable_scope', '<builtin>.int', 'utils.bnreset', 'guess_colors.Palette.encoder', '<builtin>.print', 'tensorflow.train.AdamOptimizer', 'math.sqrt', 'tensorflow.log'], '<builtin>.print': [], 'math.sqrt': [], '<builtin>.int': [], 'utils.bnreset': [], 'tensorflow.placeholder': [], 'tensorflow.variable_scope': [], 'guess_colors.Palette.encoder': ['tensorflow.reshape', 'utils.lrelu', 'utils.conv2d', 'tensorflow.variable_scope', 'utils.bn', 'tensorflow.get_variable_scope', 'utils.linear'], 'tensorflow.random_normal': [], 'guess_colors.Palette.generator': ['utils.deconv2d', 'tensorflow.nn.tanh', 'utils.lrelu', 'utils.conv2d', 'tensorflow.variable_scope', 'tensorflow.concat', '<builtin>.int', 'tensorflow.reshape', 'utils.bn', 'tensorflow.get_variable_scope', 'utils.linear'], 'tensorflow.abs': [], 'tensorflow.reduce_mean': [], 'tensorflow.square': [], 'tensorflow.log': [], 'tensorflow.reduce_sum': [], 'tensorflow.trainable_variables': [], 'tensorflow.train.AdamOptimizer': [], 'tensorflow.get_variable_scope': [], 'utils.conv2d': ['tensorflow.reshape', 'tensorflow.nn.bias_add', 'tensorflow.nn.conv2d', 'tensorflow.get_variable', 'tensorflow.constant_initializer', 'tensorflow.variable_scope', 'tensorflow.truncated_normal_initializer'], 'utils.lrelu': ['tensorflow.maximum'], 'utils.bn': ['<builtin>.str', 'utils.batch_norm.__init__'], 'tensorflow.reshape': [], 'utils.linear': ['tensorflow.random_normal_initializer', 'tensorflow.get_variable', 'tensorflow.constant_initializer', 'tensorflow.variable_scope', 'tensorflow.matmul'], 'tensorflow.concat': [], 'utils.deconv2d': ['tensorflow.reshape', 'tensorflow.random_normal_initializer', 'tensorflow.nn.bias_add', 'tensorflow.get_variable', 'tensorflow.nn.conv2d_transpose', 'tensorflow.constant_initializer', 'tensorflow.variable_scope'], 'tensorflow.nn.tanh': [], 'guess_colors.Palette.imgprocess': ['<builtin>.range', 'numpy.ones', 'numpy.average'], 'numpy.ones': [], '<builtin>.range': [], 'numpy.average': [], 'guess_colors.Palette.train': ['<builtin>.range', 'numpy.expand_dims', 'guess_colors.Palette.imgprocess', 'cv2.adaptiveThreshold', 'utils.merge', '<builtin>.len', 'cv2.cvtColor', '<builtin>.str', 'utils.merge_color', 'tensorflow.initialize_all_variables', 'tensorflow.Session', 'os.path.join', 'guess_colors.Palette.loadmodel', 'glob.glob', 'guess_colors.Palette.save', 'numpy.array', 'cv2.resize', 'utils.ims', '<builtin>.print', 'utils.get_image'], 'tensorflow.Session': [], 'tensorflow.initialize_all_variables': [], 'guess_colors.Palette.loadmodel': ['guess_colors.Palette.load', '<builtin>.print', 'tensorflow.train.Saver'], 'os.path.join': [], 'glob.glob': [], 'utils.get_image': ['utils.transform', 'utils.imread'], 'numpy.array': [], 'cv2.cvtColor': [], 'cv2.adaptiveThreshold': [], 'numpy.expand_dims': [], 'utils.merge': ['numpy.zeros', '<builtin>.enumerate', '<builtin>.int'], 'utils.ims': ['<builtin>.print', 'cv2.imwrite'], 'cv2.resize': [], 'utils.merge_color': ['numpy.zeros', '<builtin>.enumerate', '<builtin>.int'], '<builtin>.len': [], '<builtin>.str': [], 'guess_colors.Palette.save': ['os.path.join', 'os.path.exists', 'os.makedirs'], 'tensorflow.train.Saver': [], 'guess_colors.Palette.load': ['tensorflow.train.get_checkpoint_state', 'os.path.join', '<builtin>.print', 'os.path.basename'], 'guess_colors.Palette.sample': ['os.path.join', '<builtin>.range', '<builtin>.min', 'numpy.array', 'numpy.expand_dims', 'guess_colors.Palette.loadmodel', '<builtin>.len', 'glob.glob', 'cv2.resize', '<builtin>.str', 'utils.ims', 'utils.merge_color', 'cv2.adaptiveThreshold', 'numpy.random.normal', 'tensorflow.initialize_all_variables', 'utils.imread', 'tensorflow.Session', 'cv2.cvtColor'], '<builtin>.min': [], 'utils.imread': ['cv2.imread'], 'numpy.random.normal': [], 'os.path.exists': [], 'os.makedirs': [], 'tensorflow.train.get_checkpoint_state': [], 'os.path.basename': [], 'utils': [], 'utils.batch_norm.__init__': [], 'utils.batch_norm.__call__': ['tensorflow.contrib.layers.batch_norm'], 'tensorflow.contrib.layers.batch_norm': [], 'tensorflow.truncated_normal_initializer': [], 'tensorflow.get_variable': [], 'tensorflow.nn.conv2d': [], 'tensorflow.constant_initializer': [], 'tensorflow.nn.bias_add': [], 'tensorflow.random_normal_initializer': [], 'tensorflow.nn.conv2d_transpose': [], 'tensorflow.maximum': [], 'tensorflow.matmul': [], 'utils.transform': ['cv2.resize', 'numpy.array'], 'cv2.imread': [], 'numpy.zeros': [], '<builtin>.enumerate': [], 'cv2.imwrite': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hackcha_deepcolor\\guess_colors.py\n",
      "[('guess_colors', 'guess_colors Palette __init__'), ('guess_colors', 'guess_colors Palette train'), ('guess_colors', 'guess_colors Palette sample'), ('guess_colors Palette __init__', 'tensorflow trainable_variables'), ('guess_colors Palette __init__', 'tensorflow abs'), ('guess_colors Palette __init__', 'tensorflow placeholder'), ('guess_colors Palette __init__', 'guess_colors Palette generator'), ('guess_colors Palette __init__', 'tensorflow square'), ('guess_colors Palette __init__', 'tensorflow reduce_sum'), ('guess_colors Palette __init__', 'tensorflow reduce_mean'), ('guess_colors Palette __init__', 'tensorflow random_normal'), ('guess_colors Palette __init__', 'tensorflow variable_scope'), ('guess_colors Palette __init__', 'utils bnreset'), ('guess_colors Palette __init__', 'guess_colors Palette encoder'), ('guess_colors Palette __init__', 'tensorflow train AdamOptimizer'), ('guess_colors Palette __init__', 'math sqrt'), ('guess_colors Palette __init__', 'tensorflow log'), ('guess_colors Palette encoder', 'tensorflow reshape'), ('guess_colors Palette encoder', 'utils lrelu'), ('guess_colors Palette encoder', 'utils conv2d'), ('guess_colors Palette encoder', 'tensorflow variable_scope'), ('guess_colors Palette encoder', 'utils bn'), ('guess_colors Palette encoder', 'tensorflow get_variable_scope'), ('guess_colors Palette encoder', 'utils linear'), ('guess_colors Palette generator', 'utils deconv2d'), ('guess_colors Palette generator', 'tensorflow nn tanh'), ('guess_colors Palette generator', 'utils lrelu'), ('guess_colors Palette generator', 'utils conv2d'), ('guess_colors Palette generator', 'tensorflow variable_scope'), ('guess_colors Palette generator', 'tensorflow concat')]\n",
      "0\n",
      "found files: []\n",
      "from bottle import route, run, template, static_file, get, post, request, BaseRequest\n",
      "import urllib.request, urllib.error, urllib.parse\n",
      "import cv2\n",
      "import numpy as np\n",
      "import re\n",
      "import base64\n",
      "import tensorflow as tf\n",
      "\n",
      "import dc_main\n",
      "from dc_main import *\n",
      "import guess_colors\n",
      "from guess_colors import *\n",
      "\n",
      "BaseRequest.MEMFILE_MAX = 1000 * 1000\n",
      "\n",
      "c = Color(512, 1)\n",
      "p = Palette(256, 1)\n",
      "\n",
      "c.loadmodel(load_discrim=False)\n",
      "p.loadmodel(c.sess, False)\n",
      "\n",
      "\n",
      "@route('/<filename:path>')\n",
      "def send_static(filename):\n",
      "    return static_file(filename, root='web/')\n",
      "\n",
      "@route('/draw')\n",
      "def send_static():\n",
      "    return static_file(\"draw.html\", root='web/')\n",
      "\n",
      "@route('/')\n",
      "def send_static():\n",
      "    return static_file(\"index.html\", root='web/')\n",
      "\n",
      "def imageblur(cimg, sampling=False):\n",
      "    if sampling:\n",
      "        cimg = cimg * 0.3 + np.ones_like(cimg) * 0.7 * 255\n",
      "    else:\n",
      "        for i in range(30):\n",
      "            randx = randint(0,205)\n",
      "            randy = randint(0,205)\n",
      "            cimg[randx:randx+50, randy:randy+50] = 255\n",
      "    return cv2.blur(cimg,(100,100))\n",
      "\n",
      "@route(\"/standard_sanae\", method=\"POST\")\n",
      "def do_uploadtl():\n",
      "    lines_img = cv2.imread(\"web/image_examples/sanae.png\", 1)\n",
      "    lines_img = np.array(cv2.resize(lines_img, (512,512)))\n",
      "    lines_img = cv2.adaptiveThreshold(cv2.cvtColor(lines_img, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=9, C=2)\n",
      "    lines_img = cv2.merge((lines_img,lines_img,lines_img,255 - lines_img))\n",
      "    cnt = cv2.imencode(\".png\",lines_img)[1]\n",
      "    return base64.b64encode(cnt)\n",
      "\n",
      "@route(\"/standard_armscross\", method=\"POST\")\n",
      "def do_uploadtl():\n",
      "    lines_img = cv2.imread(\"web/image_examples/armscross.png\", 1)\n",
      "    lines_img = np.array(cv2.resize(lines_img, (512,512)))\n",
      "    lines_img = cv2.adaptiveThreshold(cv2.cvtColor(lines_img, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=9, C=2)\n",
      "    lines_img = cv2.merge((lines_img,lines_img,lines_img,255 - lines_img))\n",
      "    cnt = cv2.imencode(\".png\",lines_img)[1]\n",
      "    return base64.b64encode(cnt)\n",
      "\n",
      "@route(\"/standard_picasso\", method=\"POST\")\n",
      "def do_uploadtl():\n",
      "    lines_img = cv2.imread(\"web/image_examples/picasso.png\", 1)\n",
      "    lines_img = np.array(cv2.resize(lines_img, (512,512)))\n",
      "    lines_img = cv2.adaptiveThreshold(cv2.cvtColor(lines_img, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=9, C=2)\n",
      "    lines_img = cv2.merge((lines_img,lines_img,lines_img,255 - lines_img))\n",
      "    cnt = cv2.imencode(\".png\",lines_img)[1]\n",
      "    return base64.b64encode(cnt)\n",
      "\n",
      "@route(\"/upload_toline\", method=\"POST\")\n",
      "def do_uploadtl():\n",
      "    print(\"Parsing line\")\n",
      "    img = request.files.get('img')\n",
      "    lines_img = cv2.imdecode(np.fromstring(img.file.read(), np.uint8), cv2.CV_LOAD_IMAGE_UNCHANGED)\n",
      "    lines_img = np.array(cv2.resize(lines_img, (512,512)))\n",
      "    lines_img = cv2.adaptiveThreshold(cv2.cvtColor(lines_img, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize=9, C=2)\n",
      "    lines_img = cv2.merge((lines_img,lines_img,lines_img,255 - lines_img))\n",
      "    cnt = cv2.imencode(\".png\",lines_img)[1]\n",
      "    return base64.b64encode(cnt)\n",
      "\n",
      "def imageblur(cimg, sampling=False):\n",
      "    if sampling:\n",
      "        cimg = cimg * 0.3 + np.ones_like(cimg) * 0.7 * 255\n",
      "    else:\n",
      "        for i in range(30):\n",
      "            randx = randint(0,205)\n",
      "            randy = randint(0,205)\n",
      "            cimg[randx:randx+50, randy:randy+50] = 255\n",
      "    return cv2.blur(cimg,(100,100))\n",
      "\n",
      "@route('/upload_canvas', method='POST')\n",
      "def do_uploadc():\n",
      "    print(\"Got it\")\n",
      "    # lines = request.files.get('lines')\n",
      "    # colors = request.files.get('colors')\n",
      "    line_data = request.forms.get(\"lines\")\n",
      "    line_data = re.sub('^data:image/.+;base64,', '', line_data)\n",
      "    line_s = base64.b64decode(line_data)\n",
      "    line_img = np.fromstring(line_s, dtype=np.uint8)\n",
      "    line_img = cv2.imdecode(line_img, -1)\n",
      "\n",
      "    color_data = request.forms.get(\"colors\")\n",
      "    color_data = re.sub('^data:image/.+;base64,', '', color_data)\n",
      "    color_s = base64.b64decode(color_data)\n",
      "    color_img = np.fromstring(color_s, dtype=np.uint8)\n",
      "    color_img = cv2.imdecode(color_img, -1)\n",
      "\n",
      "    lines_img = np.array(cv2.resize(line_img, (512,512)))\n",
      "    lines_img = np.array([lines_img]) / 255.0\n",
      "    lines_img = lines_img[:,:,:,0]\n",
      "    lines_img = np.expand_dims(lines_img, 3)\n",
      "\n",
      "    color_img = color_img[:,:,:] * lines_img[0,:,:,:]\n",
      "    colors_img = imageblur(color_img, True)\n",
      "    colors_img = np.array([colors_img]) / 255.0\n",
      "    colors_img = colors_img[:,:,:,0:3]\n",
      "    generated = c.sess.run(c.generated_images, feed_dict={c.line_images: lines_img, c.color_images: colors_img})\n",
      "    cnt = cv2.imencode(\".png\",generated[0]*255)[1]\n",
      "    return base64.b64encode(cnt)\n",
      "\n",
      "@route('/upload_lineonly', method='POST')\n",
      "def do_uploadc():\n",
      "    print(\"Got it\")\n",
      "    # lines = request.files.get('lines')\n",
      "    # colors = request.files.get('colors')\n",
      "    line_data = request.forms.get(\"lines\")\n",
      "    line_data = re.sub('^data:image/.+;base64,', '', line_data)\n",
      "    line_s = base64.b64decode(line_data)\n",
      "    line_img = np.fromstring(line_s, dtype=np.uint8)\n",
      "    line_img = cv2.imdecode(line_img, -1)\n",
      "\n",
      "    lines_img = np.array(cv2.resize(line_img, (512,512)))\n",
      "    lines_img = np.array([lines_img]) / 255.0\n",
      "    lines_img = lines_img[:,:,:,0]\n",
      "    lines_img = np.expand_dims(lines_img, 3)\n",
      "\n",
      "    lines_img_sm = np.array(cv2.resize(line_img, (256,256)))\n",
      "    lines_img_sm = np.array([lines_img_sm]) / 255.0\n",
      "    lines_img_sm = lines_img_sm[:,:,:,0]\n",
      "    lines_img_sm = np.expand_dims(lines_img_sm, 3)\n",
      "\n",
      "    random_z = np.random.normal(0, 1, [p.batch_size, p.z_dim])\n",
      "\n",
      "    color_img = p.sess.run(p.generated_images, feed_dict={p.line_images: lines_img_sm, p.guessed_z: random_z})\n",
      "    color_img = np.array([cv2.resize(x, (512,512),  interpolation=cv2.INTER_NEAREST) for x in color_img])[0]\n",
      "\n",
      "    color_img = color_img * 255.0\n",
      "    colors_img = imageblur(color_img, True)\n",
      "    colors_img = np.array([colors_img]) / 255.0\n",
      "    colors_img = colors_img[:,:,:,0:3]\n",
      "    generated = c.sess.run(c.generated_images, feed_dict={c.line_images: lines_img, c.color_images: colors_img})\n",
      "    cnt = cv2.imencode(\".png\",generated[0]*255)[1]\n",
      "    return base64.b64encode(cnt)\n",
      "\n",
      "run(host=\"0.0.0.0\", port=8000)\n",
      "\n",
      "Output: {'server': ['bottle.run', 'guess_colors.Palette.__init__', 'dc_main.Color.__init__', 'dc_main.Color.loadmodel', 'bottle.route', 'guess_colors.Palette.loadmodel'], 'dc_main.Color.__init__': ['tensorflow.variable_scope', 'dc_main.Color.generator', 'tensorflow.concat', 'tensorflow.reduce_mean', 'utils.batch_norm.__init__', 'tensorflow.trainable_variables', '<builtin>.int', 'tensorflow.placeholder', 'tensorflow.nn.sigmoid_cross_entropy_with_logits', 'tensorflow.zeros_like', 'tensorflow.train.AdamOptimizer', 'dc_main.Color.discriminator', 'math.sqrt', 'tensorflow.abs', 'tensorflow.ones_like'], 'guess_colors.Palette.__init__': ['tensorflow.random_normal', 'tensorflow.variable_scope', 'tensorflow.reduce_mean', 'tensorflow.trainable_variables', '<builtin>.int', 'tensorflow.square', 'tensorflow.placeholder', 'tensorflow.reduce_sum', 'tensorflow.train.AdamOptimizer', 'guess_colors.Palette.encoder', '<builtin>.print', 'utils.bnreset', 'guess_colors.Palette.generator', 'math.sqrt', 'tensorflow.abs', 'tensorflow.log'], 'dc_main.Color.loadmodel': ['tensorflow.train.Saver', 'tensorflow.initialize_all_variables', 'tensorflow.GPUOptions', '<builtin>.print', 'tensorflow.ConfigProto', 'tensorflow.Session', 'dc_main.Color.load'], 'guess_colors.Palette.loadmodel': ['<builtin>.print', 'guess_colors.Palette.load', 'tensorflow.train.Saver'], 'bottle.route': [], 'server.send_static': ['bottle.static_file'], 'bottle.static_file': [], 'server.imageblur': ['<builtin>.range', 'random.randint', 'cv2.blur', 'numpy.ones_like'], 'numpy.ones_like': [], '<builtin>.range': [], 'random.randint': [], 'cv2.blur': [], 'server.do_uploadtl': ['cv2.imdecode', 'cv2.imread', 'cv2.cvtColor', 'cv2.adaptiveThreshold', 'numpy.fromstring', 'bottle.request.files.get', 'cv2.resize', 'numpy.array', 'cv2.imencode', '<builtin>.print', 'base64.b64encode', 'cv2.merge'], 'cv2.imread': [], 'cv2.resize': [], 'numpy.array': [], 'cv2.cvtColor': [], 'cv2.adaptiveThreshold': [], 'cv2.merge': [], 'cv2.imencode': [], 'base64.b64encode': [], '<builtin>.print': [], 'bottle.request.files.get': [], 'numpy.fromstring': [], 'cv2.imdecode': [], 'server.do_uploadc': ['cv2.imdecode', 'numpy.fromstring', 'numpy.random.normal', 're.sub', 'cv2.resize', 'numpy.array', 'cv2.imencode', 'bottle.request.forms.get', 'base64.b64decode', '<builtin>.print', 'base64.b64encode', 'server.imageblur', 'numpy.expand_dims'], 'bottle.request.forms.get': [], 're.sub': [], 'base64.b64decode': [], 'numpy.expand_dims': [], 'numpy.random.normal': [], 'bottle.run': [], 'guess_colors': ['guess_colors.Palette.sample', 'guess_colors.Palette.__init__', 'guess_colors.Palette.train', '<builtin>.print', '<builtin>.len'], 'math.sqrt': [], '<builtin>.int': [], 'utils.bnreset': [], 'tensorflow.placeholder': [], 'tensorflow.variable_scope': [], 'guess_colors.Palette.encoder': ['tensorflow.variable_scope', 'tensorflow.reshape', 'tensorflow.get_variable_scope', 'utils.conv2d', 'utils.bn', 'utils.linear', 'utils.lrelu'], 'tensorflow.random_normal': [], 'guess_colors.Palette.generator': ['tensorflow.variable_scope', 'tensorflow.reshape', 'tensorflow.concat', 'tensorflow.get_variable_scope', '<builtin>.int', 'utils.conv2d', 'utils.bn', 'tensorflow.nn.tanh', 'utils.linear', 'utils.deconv2d', 'utils.lrelu'], 'tensorflow.abs': [], 'tensorflow.reduce_mean': [], 'tensorflow.square': [], 'tensorflow.log': [], 'tensorflow.reduce_sum': [], 'tensorflow.trainable_variables': [], 'tensorflow.train.AdamOptimizer': [], 'tensorflow.get_variable_scope': [], 'utils.conv2d': ['tensorflow.variable_scope', 'tensorflow.reshape', 'tensorflow.nn.bias_add', 'tensorflow.get_variable', 'tensorflow.nn.conv2d', 'tensorflow.truncated_normal_initializer', 'tensorflow.constant_initializer'], 'utils.lrelu': ['tensorflow.maximum'], 'utils.bn': ['utils.batch_norm.__init__', '<builtin>.str'], 'tensorflow.reshape': [], 'utils.linear': ['tensorflow.variable_scope', 'tensorflow.get_variable', 'tensorflow.matmul', 'tensorflow.random_normal_initializer', 'tensorflow.constant_initializer'], 'tensorflow.concat': [], 'utils.deconv2d': ['tensorflow.variable_scope', 'tensorflow.reshape', 'tensorflow.nn.bias_add', 'tensorflow.get_variable', 'tensorflow.nn.conv2d_transpose', 'tensorflow.random_normal_initializer', 'tensorflow.constant_initializer'], 'tensorflow.nn.tanh': [], 'guess_colors.Palette.imgprocess': ['<builtin>.range', 'numpy.ones', 'numpy.average'], 'numpy.ones': [], 'numpy.average': [], 'guess_colors.Palette.train': ['guess_colors.Palette.imgprocess', '<builtin>.str', 'utils.merge', 'cv2.resize', 'guess_colors.Palette.loadmodel', 'guess_colors.Palette.save', 'numpy.expand_dims', 'utils.ims', 'numpy.array', 'utils.merge_color', '<builtin>.print', 'cv2.cvtColor', 'tensorflow.initialize_all_variables', 'glob.glob', 'tensorflow.Session', 'os.path.join', '<builtin>.range', 'cv2.adaptiveThreshold', '<builtin>.len', 'utils.get_image'], 'tensorflow.Session': [], 'tensorflow.initialize_all_variables': [], 'os.path.join': [], 'glob.glob': [], 'utils.get_image': ['utils.imread', 'utils.transform'], 'utils.merge': ['<builtin>.int', 'numpy.zeros', '<builtin>.enumerate'], 'utils.ims': ['<builtin>.print', 'cv2.imwrite'], 'utils.merge_color': ['<builtin>.int', 'numpy.zeros', '<builtin>.enumerate'], '<builtin>.len': [], '<builtin>.str': [], 'guess_colors.Palette.save': ['os.makedirs', 'os.path.exists', 'os.path.join'], 'tensorflow.train.Saver': [], 'guess_colors.Palette.load': ['<builtin>.print', 'tensorflow.train.get_checkpoint_state', 'os.path.basename', 'os.path.join'], 'guess_colors.Palette.sample': ['<builtin>.range', 'numpy.expand_dims', '<builtin>.str', 'cv2.cvtColor', 'numpy.random.normal', 'cv2.adaptiveThreshold', 'utils.ims', '<builtin>.min', 'utils.imread', 'cv2.resize', 'guess_colors.Palette.loadmodel', 'tensorflow.initialize_all_variables', 'glob.glob', 'numpy.array', 'utils.merge_color', 'tensorflow.Session', '<builtin>.len', 'os.path.join'], '<builtin>.min': [], 'utils.imread': ['cv2.imread'], 'os.path.exists': [], 'os.makedirs': [], 'tensorflow.train.get_checkpoint_state': [], 'os.path.basename': [], 'utils': [], 'utils.batch_norm.__init__': [], 'utils.batch_norm.__call__': ['tensorflow.contrib.layers.batch_norm'], 'tensorflow.contrib.layers.batch_norm': [], 'tensorflow.truncated_normal_initializer': [], 'tensorflow.get_variable': [], 'tensorflow.nn.conv2d': [], 'tensorflow.constant_initializer': [], 'tensorflow.nn.bias_add': [], 'tensorflow.random_normal_initializer': [], 'tensorflow.nn.conv2d_transpose': [], 'tensorflow.maximum': [], 'tensorflow.matmul': [], 'utils.transform': ['cv2.resize', 'numpy.array'], 'numpy.zeros': [], '<builtin>.enumerate': [], 'cv2.imwrite': [], 'dc_main': ['dc_main.Color.sample', 'dc_main.Color.train', 'dc_main.Color.__init__', '<builtin>.print', '<builtin>.len'], 'dc_main.Color.generator': ['tensorflow.concat', 'utils.conv2d', '<builtin>.int', 'utils.bn', 'tensorflow.nn.tanh', 'utils.deconv2d', 'tensorflow.nn.relu', 'utils.lrelu'], 'dc_main.Color.discriminator': ['tensorflow.nn.sigmoid', 'tensorflow.reshape', 'utils.batch_norm.__init__', 'tensorflow.get_variable_scope', 'utils.conv2d', 'utils.linear', 'utils.lrelu'], 'tensorflow.ones_like': [], 'tensorflow.nn.sigmoid_cross_entropy_with_logits': [], 'tensorflow.zeros_like': [], 'tensorflow.nn.sigmoid': [], 'tensorflow.nn.relu': [], 'dc_main.Color.imageblur': ['<builtin>.range', 'random.randint', 'cv2.blur', 'numpy.ones_like'], 'dc_main.Color.train': ['<builtin>.range', 'dc_main.Color.imageblur', '<builtin>.str', 'cv2.cvtColor', '<builtin>.len', 'cv2.adaptiveThreshold', 'utils.ims', 'os.path.join', 'utils.merge', '<builtin>.int', 'dc_main.Color.save', 'dc_main.Color.loadmodel', 'glob.glob', 'numpy.array', 'utils.merge_color', '<builtin>.print', 'numpy.expand_dims', 'utils.get_image'], 'dc_main.Color.save': ['os.makedirs', 'os.path.exists', 'os.path.join'], 'tensorflow.GPUOptions': [], 'tensorflow.ConfigProto': [], 'dc_main.Color.load': ['<builtin>.print', 'tensorflow.train.get_checkpoint_state', 'os.path.basename', 'os.path.join'], 'dc_main.Color.sample': ['<builtin>.range', 'numpy.expand_dims', 'dc_main.Color.imageblur', 'cv2.cvtColor', '<builtin>.str', 'cv2.adaptiveThreshold', 'utils.ims', '<builtin>.min', 'utils.imread', 'dc_main.Color.loadmodel', 'cv2.resize', 'glob.glob', 'numpy.array', 'utils.merge_color', '<builtin>.len', 'os.path.join']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hackcha_deepcolor\\server.py\n",
      "[('server', 'bottle run'), ('server', 'guess_colors Palette __init__'), ('server', 'dc_main Color __init__'), ('server', 'dc_main Color loadmodel'), ('server', 'bottle route'), ('server', 'guess_colors Palette loadmodel'), ('dc_main Color __init__', 'tensorflow variable_scope'), ('dc_main Color __init__', 'dc_main Color generator'), ('dc_main Color __init__', 'tensorflow concat'), ('dc_main Color __init__', 'tensorflow reduce_mean'), ('dc_main Color __init__', 'utils batch_norm __init__'), ('dc_main Color __init__', 'tensorflow trainable_variables'), ('dc_main Color __init__', 'tensorflow placeholder'), ('dc_main Color __init__', 'tensorflow nn sigmoid_cross_entropy_with_logits'), ('dc_main Color __init__', 'tensorflow zeros_like'), ('dc_main Color __init__', 'tensorflow train AdamOptimizer'), ('dc_main Color __init__', 'dc_main Color discriminator'), ('dc_main Color __init__', 'math sqrt'), ('dc_main Color __init__', 'tensorflow abs'), ('dc_main Color __init__', 'tensorflow ones_like'), ('guess_colors Palette __init__', 'tensorflow random_normal'), ('guess_colors Palette __init__', 'tensorflow variable_scope'), ('guess_colors Palette __init__', 'tensorflow reduce_mean'), ('guess_colors Palette __init__', 'tensorflow trainable_variables'), ('guess_colors Palette __init__', 'tensorflow square'), ('guess_colors Palette __init__', 'tensorflow placeholder'), ('guess_colors Palette __init__', 'tensorflow reduce_sum'), ('guess_colors Palette __init__', 'tensorflow train AdamOptimizer'), ('guess_colors Palette __init__', 'guess_colors Palette encoder'), ('guess_colors Palette __init__', 'utils bnreset')]\n",
      "0\n",
      "found files: []\n",
      "import keras\n",
      "from keras.applications.inception_v3 import InceptionV3\n",
      "from keras.applications.inception_v3 import preprocess_input\n",
      "# from keras.applications.vgg16 import VGG16, preprocess_input\n",
      "from keras.preprocessing import image\n",
      "from keras.engine import Layer\n",
      "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate, Activation, Dense, Dropout, Flatten\n",
      "from keras.layers.normalization import BatchNormalization\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.models import Sequential, Model\n",
      "from keras.layers.core import RepeatVector, Permute\n",
      "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
      "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "from keras.optimizers import SGD, Adam\n",
      "from skimage.transform import resize\n",
      "import keras.activations\n",
      "# from skimage.io import imsave\n",
      "from matplotlib import pyplot\n",
      "import numpy as np\n",
      "import os\n",
      "import random\n",
      "import tensorflow as tf\n",
      "\n",
      "r = np.loads( 'tmp.npz' )\n",
      "curs, imgs = r['cur'], r['img']\n",
      "\n",
      "Output: {'test_real': ['numpy.loads'], 'numpy.loads': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hackcha_deepcolor\\test_real.py\n",
      "[('test_real', 'numpy loads')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('comic_main', 'dc_main Color __init__'), ('comic_main', 'dc_main Color loadmodel'), ('comic_main', 'comic_main comic_it'), ('comic_main comic_it', 'utils merge_color'), ('comic_main comic_it', 'numpy expand_dims'), ('comic_main comic_it', 'cv2 cvtColor'), ('comic_main comic_it', 'cv2 adaptiveThreshold'), ('comic_main comic_it', 'utils imread'), ('comic_main comic_it', 'numpy array'), ('comic_main comic_it', 'utils ims'), ('comic_main comic_it', 'dc_main Color imageblur'), ('comic_main comic_it', 'cv2 resize'), ('utils imread', 'cv2 imread'), ('dc_main Color imageblur', 'numpy ones_like'), ('dc_main Color imageblur', 'random randint'), ('dc_main Color imageblur', 'cv2 blur'), ('utils merge_color', 'numpy zeros'), ('utils ims', 'cv2 imwrite'), ('dc_main Color __init__', 'utils batch_norm __init__'), ('dc_main Color __init__', 'tensorflow train AdamOptimizer'), ('dc_main Color __init__', 'tensorflow placeholder'), ('dc_main Color __init__', 'tensorflow abs'), ('dc_main Color __init__', 'tensorflow zeros_like'), ('dc_main Color __init__', 'tensorflow trainable_variables'), ('dc_main Color __init__', 'tensorflow nn sigmoid_cross_entropy_with_logits'), ('dc_main Color __init__', 'tensorflow concat'), ('dc_main Color __init__', 'math sqrt'), ('dc_main Color __init__', 'dc_main Color generator'), ('dc_main Color __init__', 'tensorflow ones_like'), ('dc_main Color __init__', 'dc_main Color discriminator')], [('utils batch_norm __call__', 'tensorflow contrib layers batch_norm'), ('utils bn', 'utils batch_norm __init__'), ('utils conv2d', 'tensorflow get_variable'), ('utils conv2d', 'tensorflow nn bias_add'), ('utils conv2d', 'tensorflow reshape'), ('utils conv2d', 'tensorflow constant_initializer'), ('utils conv2d', 'tensorflow truncated_normal_initializer'), ('utils conv2d', 'tensorflow nn conv2d'), ('utils conv2d', 'tensorflow variable_scope'), ('utils deconv2d', 'tensorflow random_normal_initializer'), ('utils deconv2d', 'tensorflow get_variable'), ('utils deconv2d', 'tensorflow nn conv2d_transpose'), ('utils deconv2d', 'tensorflow nn bias_add'), ('utils deconv2d', 'tensorflow reshape'), ('utils deconv2d', 'tensorflow constant_initializer'), ('utils deconv2d', 'tensorflow variable_scope'), ('utils lrelu', 'tensorflow maximum'), ('utils linear', 'tensorflow random_normal_initializer'), ('utils linear', 'tensorflow get_variable'), ('utils linear', 'tensorflow constant_initializer'), ('utils linear', 'tensorflow matmul'), ('utils linear', 'tensorflow variable_scope'), ('utils get_image', 'utils transform'), ('utils get_image', 'utils imread'), ('utils imread', 'cv2 imread'), ('utils transform', 'numpy array'), ('utils transform', 'cv2 resize'), ('utils merge_color', 'numpy zeros'), ('utils merge', 'numpy zeros'), ('utils ims', 'cv2 imwrite')], [('download_images', 'cv2 imwrite'), ('download_images', 'untangle parse'), ('download_images', 'numpy asarray'), ('download_images', 'cv2 imdecode'), ('download_images', 'cv2 resize')], [('dc_main', 'dc_main Color sample'), ('dc_main', 'dc_main Color __init__'), ('dc_main', 'dc_main Color train'), ('dc_main Color __init__', 'tensorflow abs'), ('dc_main Color __init__', 'tensorflow placeholder'), ('dc_main Color __init__', 'tensorflow zeros_like'), ('dc_main Color __init__', 'utils batch_norm __init__'), ('dc_main Color __init__', 'dc_main Color generator'), ('dc_main Color __init__', 'tensorflow variable_scope'), ('dc_main Color __init__', 'tensorflow train AdamOptimizer'), ('dc_main Color __init__', 'tensorflow concat'), ('dc_main Color __init__', 'tensorflow nn sigmoid_cross_entropy_with_logits'), ('dc_main Color __init__', 'tensorflow reduce_mean'), ('dc_main Color __init__', 'math sqrt'), ('dc_main Color __init__', 'dc_main Color discriminator'), ('dc_main Color __init__', 'tensorflow trainable_variables'), ('dc_main Color __init__', 'tensorflow ones_like'), ('dc_main Color generator', 'tensorflow nn tanh'), ('dc_main Color generator', 'tensorflow concat'), ('dc_main Color generator', 'utils conv2d'), ('dc_main Color generator', 'utils deconv2d'), ('dc_main Color generator', 'utils bn'), ('dc_main Color generator', 'tensorflow nn relu'), ('dc_main Color generator', 'utils lrelu'), ('dc_main Color discriminator', 'tensorflow reshape'), ('dc_main Color discriminator', 'utils batch_norm __init__'), ('dc_main Color discriminator', 'tensorflow get_variable_scope'), ('dc_main Color discriminator', 'utils conv2d'), ('dc_main Color discriminator', 'utils linear'), ('dc_main Color discriminator', 'tensorflow nn sigmoid')], [('merge_image_main', 'dc_main Color loadmodel'), ('merge_image_main', 'dc_main Color __init__'), ('merge_image_main', 'merge_image_main merge_it'), ('merge_image_main merge_it', 'cv2 adaptiveThreshold'), ('merge_image_main merge_it', 'utils imread'), ('merge_image_main merge_it', 'numpy expand_dims'), ('merge_image_main merge_it', 'dc_main Color imageblur'), ('merge_image_main merge_it', 'utils ims'), ('merge_image_main merge_it', 'cv2 resize'), ('merge_image_main merge_it', 'numpy array'), ('merge_image_main merge_it', 'utils merge_color'), ('merge_image_main merge_it', 'cv2 cvtColor'), ('utils imread', 'cv2 imread'), ('dc_main Color imageblur', 'random randint'), ('dc_main Color imageblur', 'numpy ones_like'), ('dc_main Color imageblur', 'cv2 blur'), ('utils merge_color', 'numpy zeros'), ('utils ims', 'cv2 imwrite'), ('dc_main Color __init__', 'tensorflow abs'), ('dc_main Color __init__', 'math sqrt'), ('dc_main Color __init__', 'dc_main Color generator'), ('dc_main Color __init__', 'tensorflow placeholder'), ('dc_main Color __init__', 'dc_main Color discriminator'), ('dc_main Color __init__', 'tensorflow concat'), ('dc_main Color __init__', 'tensorflow nn sigmoid_cross_entropy_with_logits'), ('dc_main Color __init__', 'tensorflow reduce_mean'), ('dc_main Color __init__', 'utils batch_norm __init__'), ('dc_main Color __init__', 'tensorflow trainable_variables'), ('dc_main Color __init__', 'tensorflow variable_scope'), ('dc_main Color __init__', 'tensorflow train AdamOptimizer')], [('test_processing', 'cv2 resize'), ('test_processing', 'numpy average'), ('test_processing', 'matplotlib pyplot imshow'), ('test_processing', 'matplotlib pyplot xticks'), ('test_processing', 'cv2 imread'), ('test_processing', 'matplotlib pyplot title'), ('test_processing', 'matplotlib pyplot yticks'), ('test_processing', 'cv2 adaptiveThreshold'), ('test_processing', 'numpy fliplr'), ('test_processing', 'glob glob'), ('test_processing', 'matplotlib pyplot show'), ('test_processing', 'matplotlib pyplot subplot'), ('test_processing', 'numpy ones_like')], [('guess_colors', 'guess_colors Palette __init__'), ('guess_colors', 'guess_colors Palette train'), ('guess_colors', 'guess_colors Palette sample'), ('guess_colors Palette __init__', 'tensorflow trainable_variables'), ('guess_colors Palette __init__', 'tensorflow abs'), ('guess_colors Palette __init__', 'tensorflow placeholder'), ('guess_colors Palette __init__', 'guess_colors Palette generator'), ('guess_colors Palette __init__', 'tensorflow square'), ('guess_colors Palette __init__', 'tensorflow reduce_sum'), ('guess_colors Palette __init__', 'tensorflow reduce_mean'), ('guess_colors Palette __init__', 'tensorflow random_normal'), ('guess_colors Palette __init__', 'tensorflow variable_scope'), ('guess_colors Palette __init__', 'utils bnreset'), ('guess_colors Palette __init__', 'guess_colors Palette encoder'), ('guess_colors Palette __init__', 'tensorflow train AdamOptimizer'), ('guess_colors Palette __init__', 'math sqrt'), ('guess_colors Palette __init__', 'tensorflow log'), ('guess_colors Palette encoder', 'tensorflow reshape'), ('guess_colors Palette encoder', 'utils lrelu'), ('guess_colors Palette encoder', 'utils conv2d'), ('guess_colors Palette encoder', 'tensorflow variable_scope'), ('guess_colors Palette encoder', 'utils bn'), ('guess_colors Palette encoder', 'tensorflow get_variable_scope'), ('guess_colors Palette encoder', 'utils linear'), ('guess_colors Palette generator', 'utils deconv2d'), ('guess_colors Palette generator', 'tensorflow nn tanh'), ('guess_colors Palette generator', 'utils lrelu'), ('guess_colors Palette generator', 'utils conv2d'), ('guess_colors Palette generator', 'tensorflow variable_scope'), ('guess_colors Palette generator', 'tensorflow concat')], [('server', 'bottle run'), ('server', 'guess_colors Palette __init__'), ('server', 'dc_main Color __init__'), ('server', 'dc_main Color loadmodel'), ('server', 'bottle route'), ('server', 'guess_colors Palette loadmodel'), ('dc_main Color __init__', 'tensorflow variable_scope'), ('dc_main Color __init__', 'dc_main Color generator'), ('dc_main Color __init__', 'tensorflow concat'), ('dc_main Color __init__', 'tensorflow reduce_mean'), ('dc_main Color __init__', 'utils batch_norm __init__'), ('dc_main Color __init__', 'tensorflow trainable_variables'), ('dc_main Color __init__', 'tensorflow placeholder'), ('dc_main Color __init__', 'tensorflow nn sigmoid_cross_entropy_with_logits'), ('dc_main Color __init__', 'tensorflow zeros_like'), ('dc_main Color __init__', 'tensorflow train AdamOptimizer'), ('dc_main Color __init__', 'dc_main Color discriminator'), ('dc_main Color __init__', 'math sqrt'), ('dc_main Color __init__', 'tensorflow abs'), ('dc_main Color __init__', 'tensorflow ones_like'), ('guess_colors Palette __init__', 'tensorflow random_normal'), ('guess_colors Palette __init__', 'tensorflow variable_scope'), ('guess_colors Palette __init__', 'tensorflow reduce_mean'), ('guess_colors Palette __init__', 'tensorflow trainable_variables'), ('guess_colors Palette __init__', 'tensorflow square'), ('guess_colors Palette __init__', 'tensorflow placeholder'), ('guess_colors Palette __init__', 'tensorflow reduce_sum'), ('guess_colors Palette __init__', 'tensorflow train AdamOptimizer'), ('guess_colors Palette __init__', 'guess_colors Palette encoder'), ('guess_colors Palette __init__', 'utils bnreset')], [('test_real', 'numpy loads')]]\n",
      "********************doctrings*************************\n",
      "['comic it', 'bnreset bn conv2d deconv2d lrelu linear get image transform imread merge color merge ims', '', '', 'merge it', '', '', 'send static send static send static imageblur do uploadtl do uploadtl do uploadtl do uploadtl imageblur do uploadc do uploadc', '']\n",
      "embed index dataset: 12\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\bb_stitcher\\\\helpers.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\tests\\\\test_point_pick.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\tests\\\\conftest.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\bb_stitcher\\\\prep.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\tests\\\\test_prep.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\bb_stitcher\\\\visualisation.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\bb_stitcher\\\\picking\\\\picker.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\setup.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\bb_stitcher\\\\scripts\\\\bb_stitcher.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\bb_stitcher\\\\core.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\tests\\\\test_script_bb_stitcher.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\tests\\\\test_visualisation.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\tests\\\\test_helpers.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\bb_stitcher\\\\stitcher.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\bb_stitcher\\\\picking\\\\draggables.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\tests\\\\test_stitcher.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\docs\\\\conf.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\bb_stitcher\\\\measure.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\bb_stitcher\\\\io_utils.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\tests\\\\test_core.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\gitmirgut_bb_stitcher\\\\tests\\\\test_measure.py']\n",
      "#  Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n",
      "#  not use this file except in compliance with the License. You may obtain\n",
      "#  a copy of the License at\n",
      "#\n",
      "#       http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "#  Unless required by applicable law or agreed to in writing, software\n",
      "#  distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
      "#  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
      "#  License for the specific language governing permissions and limitations\n",
      "#  under the License.\n",
      "\"\"\"This module provides various helper functions.\"\"\"\n",
      "import collections\n",
      "import configparser\n",
      "from logging import getLogger\n",
      "import os\n",
      "\n",
      "import cv2\n",
      "from numba import njit\n",
      "import numpy as np\n",
      "\n",
      "log = getLogger(__name__)\n",
      "\n",
      "\n",
      "def get_default_config():\n",
      "    \"\"\"Return the default config.\"\"\"\n",
      "    default_config = configparser.ConfigParser()\n",
      "    path_config = os.path.join(os.path.dirname(__file__), 'default_config.ini')\n",
      "    default_config.read(path_config)\n",
      "    return default_config\n",
      "\n",
      "\n",
      "def get_default_debug_config():\n",
      "    \"\"\"Return the default logging config file.\"\"\"\n",
      "    default_config = configparser.ConfigParser()\n",
      "    path_config = os.path.join(os.path.dirname(__file__), 'logging_config.ini')\n",
      "    default_config.read(path_config)\n",
      "    return default_config\n",
      "\n",
      "\n",
      "def get_boundaries(size_left, size_right, homo_left, homo_right):\n",
      "    \"\"\"Determine the boundaries of two transformed images.\n",
      "\n",
      "    When two images have been transformed by homographies to a 'shared space' (which holds both\n",
      "    images), it's possible that this 'shared space' is not aligned with the displayed area.\n",
      "    Its possible that various points are outside of the display area.\n",
      "    This function determines the max/min values of x and y of the both images in shared space\n",
      "    in relation to the origin of the display area.\n",
      "\n",
      "    Example:\n",
      "        .. code::\n",
      "\n",
      "                         *--------*    *--------*\n",
      "                         |        |    |        |\n",
      "                         |  left  |    | right  |\n",
      "                         |        |    |        |\n",
      "                         *--------*    *--------*\n",
      "                             \\            /\n",
      "                   homo_left  \\          / homo_right\n",
      "                               \\        /\n",
      "                                v      v\n",
      "\n",
      "            shared space:      *--------*\n",
      "                  +~~~~~~~~~~~~|        |~~~~+\n",
      "                  ;  *--------*| right  |    ;\n",
      "                  ;  |        ||        |    ;\n",
      "                  ;  |  left  |*--------*    ;\n",
      "                  ;  |        |              ;\n",
      "                  ;  *--------* display_area ;\n",
      "                  +~~~~~~~~~~~~~~~~~~~~~~~~~~+\n",
      "\n",
      "    (In this example ``xmin`` would be the x value of the left border from the left image and\n",
      "    ``ymin`` would be the y value of the top border from the right image)\n",
      "\n",
      "    Args:\n",
      "        size_left (tuple): Size *(width, height)* of the left image.\n",
      "        size_right (tuple): Size *(width, height)* of the right image.\n",
      "        homo_left (ndarray): An homography *(3,3)* which is used to transform the left image.\n",
      "        homo_right (ndarray): An homography *(3,3)* which is used to transform the right image.\n",
      "\n",
      "    Returns:\n",
      "        -- **xmin** (float) -- Minimal x value of both images after transformation.\n",
      "        -- **ymin** (float) -- Minimal y value of both images after transformation.\n",
      "        -- **xmax** (float) -- Maximal x value of both images after transformation.\n",
      "        -- **ymax** (float) -- Maximal x value of both images after transformation.\n",
      "    \"\"\"\n",
      "    h_l, w_l = size_left\n",
      "    h_r, w_r = size_right\n",
      "\n",
      "    corners_l = np.float32([\n",
      "        [0, 0],\n",
      "        [0, w_l],\n",
      "        [h_l, w_l],\n",
      "        [h_l, 0]\n",
      "    ]).reshape(-1, 1, 2)\n",
      "    corners_r = np.float32([\n",
      "        [0, 0],\n",
      "        [0, w_r],\n",
      "        [h_r, w_r],\n",
      "        [h_r, 0]\n",
      "    ]).reshape(-1, 1, 2)\n",
      "\n",
      "    # transform the corners of the images, to get the dimension of the\n",
      "    # transformed images and stitched image\n",
      "    corners_tr_l = cv2.perspectiveTransform(corners_l, homo_left)\n",
      "    corners_tr_r = cv2.perspectiveTransform(corners_r, homo_right)\n",
      "\n",
      "    pts = np.concatenate((corners_tr_l, corners_tr_r), axis=0)\n",
      "    # measure the max values in x and y direction to get the translation vector\n",
      "    # so that whole image will be shown\n",
      "    [xmin, ymin] = np.float32(pts.min(axis=0).ravel())\n",
      "    [xmax, ymax] = np.float32(pts.max(axis=0).ravel())\n",
      "\n",
      "    Bounderies = collections.namedtuple('Bounderies', ['xmin', 'ymin', 'xmax', 'ymax'])\n",
      "    return Bounderies(xmin, ymin, xmax, ymax)\n",
      "\n",
      "\n",
      "def get_transform_to_origin_mat(xmin, ymin):\n",
      "    \"\"\"Determine homography matrix to align 'shared_space' to display area origin.\n",
      "\n",
      "    Example:\n",
      "        .. code::\n",
      "\n",
      "            shared space:      *--------*\n",
      "                  +~~~~~~~~~~~~|        |~~~~+\n",
      "                  ;  *--------*| right  |    ;\n",
      "                  ;  |        ||        |    ;\n",
      "                  ;  |  left  |*--------*    ;\n",
      "                  ;  |        |              ;\n",
      "                  ;  *--------* display_area ;\n",
      "                  +~~~~~~~~~~~~~~~~~~~~~~~~~~+\n",
      "\n",
      "                                |\n",
      "                                | transformation to origin\n",
      "                                V\n",
      "\n",
      "                  +~~~~~~~~~*--------*~~~~~~+\n",
      "                  ;         |        |      ;\n",
      "                  *--------*| right  |      ;\n",
      "                  |        ||        |      ;\n",
      "                  |  left  |*--------*      ;\n",
      "                  |        |                ;\n",
      "                  *--------* display_area   ;\n",
      "                  ;                         ;\n",
      "                  +~~~~~~~~~~~~~~~~~~~~~~~~~+\n",
      "    Args:\n",
      "        xmin (float): Minimal x value of images in 'shared space'.\n",
      "        ymin (float): Minimal y value of images in 'shared space'.\n",
      "\n",
      "    Returns:\n",
      "        ndarray: *(3,3)* homography to align 'shared space' the to the origin of display area.\n",
      "\n",
      "    See Also:\n",
      "        - :meth:`get_boundaries`\n",
      "    \"\"\"\n",
      "    t = [-xmin, -ymin]\n",
      "\n",
      "    # define translation matrix\n",
      "    homo_trans = np.array([[1, 0, t[0]], [0, 1, t[1]], [0, 0, 1]], dtype=np.float32)  # translate\n",
      "    return homo_trans\n",
      "\n",
      "\n",
      "def add_alpha_channel(image):\n",
      "    \"\"\"Add alpha channel to image for transparent areas.\n",
      "\n",
      "    Args:\n",
      "        image (ndarray): Image of shape *(M,N)* (black/white), *(M,N,3)* (BGR)\n",
      "                        or *(M,N,4)* already with alpha channel.\n",
      "\n",
      "    Returns:\n",
      "        ndarray: ``image`` extended with alpha channel\n",
      "\n",
      "    \"\"\"\n",
      "    if len(image.shape) == 2:\n",
      "        return cv2.cvtColor(image, cv2.COLOR_GRAY2BGRA)\n",
      "    elif len(image.shape) == 3:\n",
      "        if image.shape[2] == 3:\n",
      "            return cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
      "        elif image.shape[2] == 4:\n",
      "            return image\n",
      "        else:\n",
      "            raise Exception('Shape {} of image is unknown cannot add alpha channel. Valid image'\n",
      "                            'shapes are (N,M), (N,M,3), (N,M,4).'.format(str(image.shape)))\n",
      "    else:\n",
      "        raise Exception('Shape {} of image is unknown cannot add alpha channel. Valid image shapes'\n",
      "                        'are (N,M), (N,M,3), (N,M,4).'.format(str(image.shape)))\n",
      "\n",
      "\n",
      "def form_rectangle(width, height):\n",
      "    \"\"\"Return a rectangle represented by 4 points ndarray *(4,2)*.\n",
      "\n",
      "    The starting point is the Origin and the points are sorted in clockwise order.\n",
      "\n",
      "    Args:\n",
      "        width (float): Width of the rectangle.\n",
      "        height (float): Height of the rectangle.\n",
      "\n",
      "    Returns:\n",
      "        ndarray: Rectangle represented by 4 points as ndarray *(4,2)*.\n",
      "    \"\"\"\n",
      "    rect = np.zeros((4, 2), dtype=np.float32)\n",
      "    rect[0] = 0, 0\n",
      "    rect[1] = width, 0\n",
      "    rect[2] = width, height\n",
      "    rect[3] = 0, height\n",
      "\n",
      "    return rect\n",
      "\n",
      "\n",
      "def sort_pts(points):\n",
      "    r\"\"\"Sort points as convex quadrilateral.\n",
      "\n",
      "    Sort points in clockwise order, so that they form a convex quadrilateral.\n",
      "\n",
      "    Example:\n",
      "        .. code::\n",
      "\n",
      "            pts:                sorted_pts:\n",
      "                 x   x                      A---B\n",
      "                              --->         /     \\\n",
      "               x       x                  D-------C\n",
      "\n",
      "    Args:\n",
      "        points (ndarray): Array of points *(N,2)*.\n",
      "\n",
      "    Returns:\n",
      "        ndarray: Clockwise ordered ``points`` *(N,2)*, where the most up left point is the \\\n",
      "        starting point.\n",
      "    \"\"\"\n",
      "    assert (len(points) == 4)\n",
      "\n",
      "    # calculate the barycentre / centre of gravity\n",
      "    barycentre = points.sum(axis=0) / 4\n",
      "\n",
      "    # var for saving the points in relation to the barycentre\n",
      "    bary_vectors = np.zeros((4, 2), np.float32)\n",
      "\n",
      "    # var for saving the A point of the origin\n",
      "    A = None\n",
      "    min_dist = None\n",
      "\n",
      "    for i, point in enumerate(points):\n",
      "\n",
      "        # determine the distance to the origin\n",
      "        cur_dist_origin = np.linalg.norm(point)\n",
      "\n",
      "        # save the A point of the origin\n",
      "        if A is None or cur_dist_origin < min_dist:\n",
      "            min_dist = cur_dist_origin\n",
      "            A = i\n",
      "\n",
      "        # determine point in relation to the barycentre\n",
      "        bary_vectors[i] = point - barycentre\n",
      "\n",
      "    angles = np.zeros(4, np.float32)\n",
      "    # determine the angles of the different points in relation to the line\n",
      "    # between closest point of origin (A) and barycentre\n",
      "    for i, bary_vector in enumerate(bary_vectors):\n",
      "        if i != A:\n",
      "            cur_angle = np.arctan2(\n",
      "                (np.linalg.det((bary_vectors[A], bary_vector))), np.dot(\n",
      "                    bary_vectors[A], bary_vector))\n",
      "            if cur_angle < 0:\n",
      "                cur_angle += 2 * np.pi\n",
      "            angles[i] = cur_angle\n",
      "    index_sorted = np.argsort(angles)\n",
      "    sorted_pts = np.zeros((len(points), 2), np.float32)\n",
      "    for i in range(len(points)):\n",
      "        sorted_pts[i] = points[index_sorted[i]]\n",
      "    return sorted_pts\n",
      "\n",
      "\n",
      "def raw_estimate_rect(points):\n",
      "    \"\"\"Abstract an rectangle from an convex quadrilateral.\n",
      "\n",
      "    The convex quadrilateral is defined by ``Points``. The points must be sorted in clockwise order\n",
      "    where the most up left point is the starting point. (see sort_pts)\n",
      "\n",
      "    Example:\n",
      "        .. code::\n",
      "\n",
      "            points:             rectangled points:\n",
      "                 A---B                    A'------B'\n",
      "                /     \\       --->        |       |\n",
      "               D-------C                  D'------C'\n",
      "\n",
      "    The dimension of the rectangle is estimated in the following manner:\n",
      "    ``|A'B'|=|D'C'|=max(|AB|,|DC|)`` and ``|A'D'|=|B'C'|=max(|AD|,|BC|)``\n",
      "\n",
      "    Args:\n",
      "        points (ndarray): Array of clockwise ordered points *(4,2)*, where most up left point is\\\n",
      "        the starting point.\n",
      "\n",
      "    Returns:\n",
      "        ndarray: 'Rectangled' points (the rectangle is aligned to the origin).\n",
      "    \"\"\"\n",
      "    # TODO(gitmirgut) add link to sort_pts\n",
      "    A = points[0]\n",
      "    B = points[1]\n",
      "    C = points[2]\n",
      "    D = points[3]\n",
      "\n",
      "    AB = np.linalg.norm(B - A)\n",
      "    BC = np.linalg.norm(C - B)\n",
      "    CD = np.linalg.norm(D - C)\n",
      "    DA = np.linalg.norm(D - A)\n",
      "\n",
      "    hori_len = max(AB, CD)\n",
      "    vert_len = max(BC, DA)\n",
      "\n",
      "    dest_rect = form_rectangle(hori_len, vert_len)\n",
      "\n",
      "    return dest_rect\n",
      "\n",
      "\n",
      "def harmonize_rects(rect_a, rect_b):\n",
      "    \"\"\"Harmonize two rectangles in their vertical dimension.\n",
      "\n",
      "    Example:\n",
      "        .. code::\n",
      "\n",
      "           rect_a:    rect_b:        harm_rect_a:       harm_rect_b:\n",
      "\n",
      "                        W-----X         A'--------------B'    W'----X'\n",
      "            A-----B     |     |         |               |     |     |\n",
      "            |     |     |     |   -->   |               |     |     |\n",
      "            D-----C     |     |         |               |     |     |\n",
      "                        Z-----Y         D'--------------C'    Z'----Y'\n",
      "\n",
      "    Args:\n",
      "        rect_a (ndarray): Array of clockwise ordered points *(4,2)*, where most up left point is\\\n",
      "        the starting point.\n",
      "        rect_b (ndarray): Same as ``rect_a``\n",
      "\n",
      "    Returns:\n",
      "        - **harm_rect_a** (ndarray) -- Harmonized version of ``rect_a``\n",
      "        - **harm_rect_b** (ndarray) -- Harmonized version of ``rect_b``\n",
      "    \"\"\"\n",
      "    A = rect_a[0]\n",
      "    B = rect_a[1]\n",
      "    C = rect_a[2]\n",
      "    D = rect_a[3]\n",
      "\n",
      "    W = rect_b[0]\n",
      "    X = rect_b[1]\n",
      "    Y = rect_b[2]\n",
      "    Z = rect_b[3]\n",
      "\n",
      "    AB = np.linalg.norm(B - A)\n",
      "    BC = np.linalg.norm(C - B)\n",
      "    CD = np.linalg.norm(D - C)\n",
      "    DA = np.linalg.norm(D - A)\n",
      "\n",
      "    assert AB == CD and BC == DA\n",
      "\n",
      "    WX = np.linalg.norm(X - W)\n",
      "    XY = np.linalg.norm(Y - X)\n",
      "    YZ = np.linalg.norm(Z - Y)\n",
      "    ZW = np.linalg.norm(W - Z)\n",
      "\n",
      "    assert WX == YZ and XY == ZW\n",
      "\n",
      "    hori_a = AB\n",
      "    vert_a = BC\n",
      "\n",
      "    hori_b = WX\n",
      "    vert_b = XY\n",
      "\n",
      "    if vert_a > vert_b:\n",
      "        harm_vert_b = vert_a\n",
      "        ratio = vert_a / vert_b\n",
      "        harm_hori_b = ratio * hori_b\n",
      "        harm_rect_b = form_rectangle(harm_hori_b, harm_vert_b)\n",
      "        return rect_a, harm_rect_b\n",
      "    else:\n",
      "        harm_vert_a = vert_b\n",
      "        ratio = vert_b / vert_a\n",
      "        harm_hori_a = ratio * hori_a\n",
      "        harm_rect_a = form_rectangle(harm_hori_a, harm_vert_a)\n",
      "        return harm_rect_a, rect_b\n",
      "\n",
      "\n",
      "@njit\n",
      "def angles_to_points(angle_centers, angles, distance=22):\n",
      "    r\"\"\"Calculate point representations of angles.\n",
      "\n",
      "    The angle point representations ``points_reprs`` are calculated in  dependency of the\n",
      "    ``angle_center`` and the ray starting from this center, which is perpendicular to the right\n",
      "    border. Positive angles will be interpreted as clockwise rotation.\n",
      "\n",
      "    Example:\n",
      "        .. code::\n",
      "\n",
      "            angle_center\n",
      "                  *--------x-Axis------>\n",
      "                   \\         |\n",
      "                    \\ angle /\n",
      "                     \\     /\n",
      "                      \\ --\n",
      "                       \\\n",
      "            points_repr *\n",
      "                         \\\n",
      "                          v\n",
      "\n",
      "    Args:\n",
      "        angle_centers (ndarray): The centers of the ``angles``. *(N,2)*\n",
      "        angles (ndarray): Angles in rad (length *(N,)*).\n",
      "        distance (int): The distance between the ``angle_centers`` and the point representations.\n",
      "\n",
      "    Returns:\n",
      "        - **points_repr** (ndarray) -- Angles represented by points. *(N,2)*\n",
      "\n",
      "    See Also:\n",
      "        - :meth:`points_to_angles`\n",
      "    \"\"\"\n",
      "    assert len(angle_centers) == len(angles)\n",
      "    points_repr = np.zeros((len(angle_centers), 2), dtype=np.float32)\n",
      "    for i in range(angle_centers.shape[0]):\n",
      "        center = angle_centers[i, :]\n",
      "        z_rotation = np.array(angles[i])\n",
      "        # remove round\n",
      "        points_repr[i, 0] = center[0] + distance * np.cos(z_rotation)\n",
      "        points_repr[i, 1] = center[1] + distance * np.sin(z_rotation)\n",
      "    return points_repr\n",
      "\n",
      "\n",
      "@njit\n",
      "def _process_points_to_angles(angle_centers, points_repr):\n",
      "    angles = np.zeros(len(angle_centers), dtype=np.float32)\n",
      "\n",
      "    for i in range(angle_centers.shape[0]):\n",
      "        angle_center = angle_centers[i, :]\n",
      "        point_repr = points_repr[i]\n",
      "        angle_center_x, angle_center_y = angle_center\n",
      "        point_repr_x, point_repr_y = point_repr\n",
      "\n",
      "        # the 0-angle has to be a ray from the center, which is perpendicular to the right border\n",
      "        # we abstract this ray as a point ``ray_pt`` which always lies on the right side of the\n",
      "        # center, so ``ray_pt_dis`` has to be just greater 0, we take 80\n",
      "        ray_pt_dis = np.float64(80.)\n",
      "        ray_pt = np.array([angle_center_x + ray_pt_dis, angle_center_y])\n",
      "\n",
      "        \"\"\"\n",
      "        angle_center      p       ray_pt\n",
      "                  *---------------*\n",
      "                   \\         |   /\n",
      "                    \\ angle /   /\n",
      "                 r   \\     /   /  d\n",
      "                      \\ --   /\n",
      "                       \\     /\n",
      "                        \\   /\n",
      "                         \\ /\n",
      "               point_repr *\n",
      "        \"\"\"\n",
      "\n",
      "        d = np.linalg.norm(ray_pt - point_repr)\n",
      "        p = ray_pt_dis\n",
      "        r = np.linalg.norm(angle_center - point_repr)\n",
      "        if r == 0:\n",
      "            return None\n",
      "        cos_angle = (p ** 2 + r ** 2 - d ** 2) / (2 * r * p)\n",
      "\n",
      "        # this is due to some arithmetic problems, where cos_angle is something like\n",
      "        # cos_angle = 1.000000000000008 which leads to an error.\n",
      "        if cos_angle > 1 and cos_angle < 1 + 1e-9:\n",
      "            cos_angle = 1\n",
      "        elif cos_angle < -1 and cos_angle > -1 - 1e-9:\n",
      "            cos_angle = -1\n",
      "\n",
      "        angle = np.arccos(cos_angle)\n",
      "\n",
      "        if angle_center_y > point_repr_y:\n",
      "            angle = -angle\n",
      "\n",
      "        angles[i] = angle\n",
      "\n",
      "    return angles\n",
      "\n",
      "\n",
      "def points_to_angles(angle_centers, points_repr):\n",
      "    \"\"\"Convert angle point representation back to normal angle.\n",
      "\n",
      "    This function is the inverted version of :meth:`angles_to_points`.\n",
      "\n",
      "    Args:\n",
      "        angle_centers (ndarray): The centers of the ``angles``. *(N,2)*\n",
      "        points_repr (ndarray): Angles represented by points. *(N,2)*\n",
      "\n",
      "    Returns:\n",
      "        ndarray: Angles in rad *(N,)*\n",
      "\n",
      "    See Also:\n",
      "        - :meth:`angles_to_points`\n",
      "    \"\"\"\n",
      "    \"\"\"Calculate angle between vertical line passing through angle_centers and line AB.\"\"\"\n",
      "    # https://de.wikipedia.org/wiki/Roll-Nick-Gier-Winkel#/media/File:RPY_angles_of_spaceships_(local_frame).png\n",
      "    # TODO(zeor_angle) variablen Nullwinkel einbauen, momentan ist entspricht dieser der x-Achse\n",
      "    assert len(angle_centers) == len(points_repr)\n",
      "\n",
      "    angles = _process_points_to_angles(angle_centers, points_repr)\n",
      "    if angles is None:\n",
      "        raise Exception('Angle center point {} and angle point representation {}'\n",
      "                        ' seams to be the same.'.format(angle_centers, points_repr))\n",
      "\n",
      "    return angles\n",
      "\n",
      "\n",
      "def get_ratio_px_to_mm(start_point, end_point, distance_mm):\n",
      "    \"\"\"Return ratio between pixel and millimetre.\n",
      "\n",
      "    The function calculates the distance of two points (``start_point``, ``end_point``) in pixels\n",
      "    and then calculates ratio using the distance in pixels and the distance in mm ``distance_mm``.\n",
      "\n",
      "    Args:\n",
      "        start_point (ndarray): Start point of the reference Line Segment *(2,)*\n",
      "        end_point (ndarray): End point of the reference Line Segment *(2,)*\n",
      "        distance_mm (float): The distance between the ``start_point`` and ``end_point`` of the \\\n",
      "        line segment in real world in mm.\n",
      "\n",
      "    Returns:\n",
      "        float: The ratio between px and mm (the length of 1px in mm).\n",
      "\n",
      "    \"\"\"\n",
      "    distance_px = np.linalg.norm(end_point - start_point)\n",
      "    return distance_mm / distance_px\n",
      "\n",
      "Output: {'helpers': ['logging.getLogger', 'numba.njit'], 'logging.getLogger': [], 'helpers.get_default_config': ['configparser.ConfigParser', 'os.path.join', 'os.path.dirname'], 'configparser.ConfigParser': [], 'os.path.dirname': [], 'os.path.join': [], 'helpers.get_default_debug_config': ['configparser.ConfigParser', 'os.path.join', 'os.path.dirname'], 'helpers.get_boundaries': ['numpy.concatenate', 'numpy.float32', 'collections.namedtuple', 'cv2.perspectiveTransform'], 'numpy.float32': [], 'cv2.perspectiveTransform': [], 'numpy.concatenate': [], 'collections.namedtuple': [], 'helpers.get_transform_to_origin_mat': ['numpy.array'], 'numpy.array': [], 'helpers.add_alpha_channel': ['<builtin>.str', '<builtin>.len', 'cv2.cvtColor', '<builtin>.Exception'], '<builtin>.len': [], 'cv2.cvtColor': [], '<builtin>.str': [], '<builtin>.Exception': [], 'helpers.form_rectangle': ['numpy.zeros'], 'numpy.zeros': [], 'helpers.sort_pts': ['numpy.linalg.norm', 'numpy.zeros', 'numpy.dot', '<builtin>.range', '<builtin>.len', 'numpy.linalg.det', '<builtin>.enumerate', 'numpy.argsort', 'numpy.arctan2'], '<builtin>.enumerate': [], 'numpy.linalg.norm': [], 'numpy.linalg.det': [], 'numpy.dot': [], 'numpy.arctan2': [], 'numpy.argsort': [], '<builtin>.range': [], 'helpers.raw_estimate_rect': ['numpy.linalg.norm', '<builtin>.max', 'helpers.form_rectangle'], '<builtin>.max': [], 'helpers.harmonize_rects': ['numpy.linalg.norm', 'helpers.form_rectangle'], 'numba.njit': [], 'helpers.angles_to_points': ['numpy.cos', 'numpy.sin', 'numpy.zeros', '<builtin>.range', '<builtin>.len', 'numpy.array'], 'numpy.cos': [], 'numpy.sin': [], 'helpers._process_points_to_angles': ['numpy.linalg.norm', 'numpy.float64', 'numpy.zeros', '<builtin>.range', '<builtin>.len', 'numpy.arccos', 'numpy.array'], 'numpy.float64': [], 'numpy.arccos': [], 'helpers.points_to_angles': ['helpers._process_points_to_angles', '<builtin>.len', '<builtin>.Exception'], 'helpers.get_ratio_px_to_mm': ['numpy.linalg.norm']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\bb_stitcher\\helpers.py\n",
      "[('helpers', 'logging getLogger'), ('helpers', 'numba njit'), ('helpers get_default_config', 'configparser ConfigParser'), ('helpers get_default_config', 'os path join'), ('helpers get_default_config', 'os path dirname'), ('helpers get_default_debug_config', 'configparser ConfigParser'), ('helpers get_default_debug_config', 'os path join'), ('helpers get_default_debug_config', 'os path dirname'), ('helpers get_boundaries', 'numpy concatenate'), ('helpers get_boundaries', 'numpy float32'), ('helpers get_boundaries', 'collections namedtuple'), ('helpers get_boundaries', 'cv2 perspectiveTransform'), ('helpers get_transform_to_origin_mat', 'numpy array'), ('helpers add_alpha_channel', 'cv2 cvtColor'), ('helpers form_rectangle', 'numpy zeros'), ('helpers sort_pts', 'numpy linalg norm'), ('helpers sort_pts', 'numpy zeros'), ('helpers sort_pts', 'numpy dot'), ('helpers sort_pts', 'numpy linalg det'), ('helpers sort_pts', 'numpy argsort'), ('helpers sort_pts', 'numpy arctan2'), ('helpers raw_estimate_rect', 'numpy linalg norm'), ('helpers raw_estimate_rect', 'helpers form_rectangle'), ('helpers harmonize_rects', 'numpy linalg norm'), ('helpers harmonize_rects', 'helpers form_rectangle'), ('helpers angles_to_points', 'numpy cos'), ('helpers angles_to_points', 'numpy sin'), ('helpers angles_to_points', 'numpy zeros'), ('helpers angles_to_points', 'numpy array'), ('helpers _process_points_to_angles', 'numpy linalg norm')]\n",
      "1076\n",
      "found files: []\n",
      "import numpy as np\n",
      "import pytest\n",
      "\n",
      "import bb_stitcher.helpers as helpers\n",
      "import bb_stitcher.prep as prep\n",
      "import bb_stitcher.picking.picker as picker\n",
      "\n",
      "\n",
      "def create_prepared_image_dict(img, angle, config):\n",
      "    img_alpha = helpers.add_alpha_channel(img['img'])\n",
      "    rectificator = prep.Rectificator(config)\n",
      "    rect_img = rectificator.rectify_image(img_alpha)\n",
      "    rect_detections = rectificator.rectify_points(img['detections'], img['size'])\n",
      "    rect_img_w_detections = rectificator.rectify_image(img['img_w_detections'])\n",
      "\n",
      "    rot_img, rot_mat = prep.rotate_image(rect_img, angle)\n",
      "    rot_detections = prep.rotate_points(rect_detections, angle, img['size'])\n",
      "    rot_img_w_detections, rot_mat = prep.rotate_image(rect_img_w_detections, angle)\n",
      "\n",
      "    d = dict()\n",
      "    d['img'] = rot_img\n",
      "    d['detections'] = rot_detections\n",
      "    d['img_w_detections'] = rot_img_w_detections\n",
      "    return d\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def left_img_prep(left_img, config):\n",
      "    return create_prepared_image_dict(left_img, 90, config)\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def right_img_prep(right_img, config):\n",
      "    return create_prepared_image_dict(right_img, -90, config)\n",
      "\n",
      "\n",
      "@pytest.mark.slow\n",
      "def test_gui(left_img_prep, right_img_prep):\n",
      "    # TODO(gitmirgut): better gui test...\n",
      "    pt = picker.PointPicker()\n",
      "    print(pt)\n",
      "    # points = pt.pick([left_img_prep['img'], right_img_prep['img']])\n",
      "    # print(points)\n",
      "\n",
      "\n",
      "def test_pick_length(panorama, monkeypatch):\n",
      "    def mockreturn(myself, image_list, all):\n",
      "        points = np.array([\n",
      "            [94.43035126, 471.89889526],\n",
      "            [5494.71777344, 471.83984375]], dtype=np.float32)\n",
      "        return points\n",
      "    monkeypatch.setattr(picker.PointPicker, 'pick', mockreturn)\n",
      "    pt = picker.PointPicker()\n",
      "    points = pt.pick([panorama], False)\n",
      "    assert len(points) == 2\n",
      "    start_point, end_point = points\n",
      "    print(start_point.shape)\n",
      "    distance_px = np.linalg.norm(end_point - start_point)\n",
      "    distance_mm = 344\n",
      "    px_to_mm = distance_mm / distance_px\n",
      "    print(distance_px * px_to_mm)\n",
      "\n",
      "Output: {'test_point_pick': ['pytest.mark.slow', 'pytest.fixture'], 'test_point_pick.create_prepared_image_dict': ['bb_stitcher.helpers.add_alpha_channel', 'bb_stitcher.prep.rotate_image', 'bb_stitcher.prep.Rectificator', 'bb_stitcher.prep.rotate_points', '<builtin>.dict'], 'bb_stitcher.helpers.add_alpha_channel': [], 'bb_stitcher.prep.Rectificator': [], 'bb_stitcher.prep.rotate_image': [], 'bb_stitcher.prep.rotate_points': [], '<builtin>.dict': [], 'pytest.fixture': [], 'test_point_pick.left_img_prep': ['test_point_pick.create_prepared_image_dict'], 'test_point_pick.right_img_prep': ['test_point_pick.create_prepared_image_dict'], 'pytest.mark.slow': [], 'test_point_pick.test_gui': ['<builtin>.print', 'bb_stitcher.picking.picker.PointPicker'], 'bb_stitcher.picking.picker.PointPicker': [], '<builtin>.print': [], 'test_point_pick.test_pick_length': ['<builtin>.print', 'numpy.linalg.norm', 'bb_stitcher.picking.picker.PointPicker', '<builtin>.len'], 'test_point_pick.test_pick_length.mockreturn': ['numpy.array'], 'numpy.array': [], '<builtin>.len': [], 'numpy.linalg.norm': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\tests\\test_point_pick.py\n",
      "[('test_point_pick', 'pytest mark slow'), ('test_point_pick', 'pytest fixture'), ('test_point_pick create_prepared_image_dict', 'bb_stitcher helpers add_alpha_channel'), ('test_point_pick create_prepared_image_dict', 'bb_stitcher prep rotate_image'), ('test_point_pick create_prepared_image_dict', 'bb_stitcher prep Rectificator'), ('test_point_pick create_prepared_image_dict', 'bb_stitcher prep rotate_points'), ('test_point_pick left_img_prep', 'test_point_pick create_prepared_image_dict'), ('test_point_pick right_img_prep', 'test_point_pick create_prepared_image_dict'), ('test_point_pick test_gui', 'bb_stitcher picking picker PointPicker'), ('test_point_pick test_pick_length', 'numpy linalg norm'), ('test_point_pick test_pick_length', 'bb_stitcher picking picker PointPicker'), ('test_point_pick test_pick_length mockreturn', 'numpy array')]\n",
      "0\n",
      "found files: []\n",
      "import os\n",
      "import os.path\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "import pytest\n",
      "\n",
      "import bb_stitcher.helpers as helpers\n",
      "\n",
      "\n",
      "# add marker for incremental testing\n",
      "# http://doc.pytest.org/en/latest/example/simple.html#incremental-testing-test-steps\n",
      "\n",
      "\n",
      "def pytest_runtest_makereport(item, call):\n",
      "    if \"incremental\" in item.keywords:\n",
      "        if call.excinfo is not None:\n",
      "            parent = item.parent\n",
      "            parent._previousfailed = item\n",
      "\n",
      "\n",
      "def pytest_runtest_setup(item):\n",
      "    if \"incremental\" in item.keywords:\n",
      "        previousfailed = getattr(item.parent, \"_previousfailed\", None)\n",
      "        if previousfailed is not None:\n",
      "            pytest.xfail(\"previous test failed (%s)\" % previousfailed.name)\n",
      "\n",
      "\n",
      "test_dir = os.path.dirname(__file__)\n",
      "\n",
      "\n",
      "def get_test_fname(name):\n",
      "    test_dir = os.path.dirname(__file__)\n",
      "    return os.path.join(test_dir, name)\n",
      "\n",
      "\n",
      "def fname(path):\n",
      "    return os.path.basename(os.path.splitext(path)[0])\n",
      "\n",
      "\n",
      "def create_image_dict(img_path, img_with_detections, detections_path, cam_id, angle):\n",
      "    d = dict()\n",
      "    d['path'] = get_test_fname(img_path)\n",
      "    d['name'] = os.path.basename(os.path.splitext(d['path'])[0])\n",
      "    d['img'] = cv2.imread(d['path'], -1)\n",
      "    d['bw'] = cv2.imread(d['path'], 0)\n",
      "    d['color'] = cv2.imread(d['path'], 1)\n",
      "    d['height'], d['width'] = d['img'].shape[:2]\n",
      "    d['size'] = d['width'], d['height']\n",
      "    d['detections'] = np.load(get_test_fname(detections_path))['detections']\n",
      "    d['yaw_angles'] = np.load(get_test_fname(detections_path))['yaw_angles']\n",
      "    d['img_w_detections'] = cv2.imread(get_test_fname(img_with_detections), -1)\n",
      "    d['cam_id'] = cam_id\n",
      "    d['angle'] = angle\n",
      "    return d\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def left_img():\n",
      "    img_path = 'data/Cam_0_2016-09-01T12:56:50.801920Z.jpg'\n",
      "    img_with_detections = 'data/Cam_0_2016-09-01T12:56:50.801920Z_det_yaws.jpg'\n",
      "    detections_path = 'data/Cam_0_2016-09-01T12:56:50.801920Z_det_yaws.npz'\n",
      "    cam_id = 0\n",
      "    angle = 90\n",
      "    return create_image_dict(img_path, img_with_detections, detections_path, cam_id, angle)\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def right_img():\n",
      "    img_path = 'data/Cam_1_2016-09-01T12:56:50.801926Z.jpg'\n",
      "    img_with_detections = 'data/Cam_1_2016-09-01T12:56:50.801926Z_det_yaws.jpg'\n",
      "    detections_path = 'data/Cam_1_2016-09-01T12:56:50.801926Z_det_yaws.npz'\n",
      "    cam_id = 1\n",
      "    angle = -90\n",
      "    return create_image_dict(img_path, img_with_detections, detections_path, cam_id, angle)\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def not_to_bee():\n",
      "    img_path = get_test_fname('data/not_to_bee.jpg')\n",
      "    img = cv2.imread(img_path, -1)\n",
      "    return img\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def surveyor_csv_path():\n",
      "    return get_test_fname('data/Surveyor_data.csv')\n",
      "\n",
      "\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def config():\n",
      "    return helpers.get_default_config()\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def main_outdir():\n",
      "    out_path = os.path.join(test_dir, 'out')\n",
      "    if not os.path.exists(out_path):\n",
      "        os.makedirs(out_path)\n",
      "    return out_path\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def panorama():\n",
      "    img_path = get_test_fname('data/panorama.jpg')\n",
      "    img = cv2.imread(img_path, -1)\n",
      "    return img\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def error_params():\n",
      "    error_parameters = np.load(get_test_fname('data/error_points_to_angles.npz'))\n",
      "    return error_parameters['arr_0'], error_parameters['arr_1']\n",
      "\n",
      "Output: {'conftest': ['pytest.fixture', 'os.path.dirname'], 'conftest.pytest_runtest_makereport': [], 'conftest.pytest_runtest_setup': ['<builtin>.getattr', 'pytest.xfail'], '<builtin>.getattr': [], 'pytest.xfail': [], 'os.path.dirname': [], 'conftest.get_test_fname': ['os.path.dirname', 'os.path.join'], 'os.path.join': [], 'conftest.fname': ['os.path.splitext', 'os.path.basename'], 'os.path.splitext': [], 'os.path.basename': [], 'conftest.create_image_dict': ['<builtin>.dict', 'conftest.get_test_fname', 'os.path.splitext', 'cv2.imread', 'numpy.load', 'os.path.basename'], '<builtin>.dict': [], 'cv2.imread': [], 'numpy.load': [], 'pytest.fixture': [], 'conftest.left_img': ['conftest.create_image_dict'], 'conftest.right_img': ['conftest.create_image_dict'], 'conftest.not_to_bee': ['conftest.get_test_fname', 'cv2.imread'], 'conftest.surveyor_csv_path': ['conftest.get_test_fname'], 'conftest.config': ['bb_stitcher.helpers.get_default_config'], 'bb_stitcher.helpers.get_default_config': [], 'conftest.main_outdir': ['os.makedirs', 'os.path.join', 'os.path.exists'], 'os.path.exists': [], 'os.makedirs': [], 'conftest.panorama': ['conftest.get_test_fname', 'cv2.imread'], 'conftest.error_params': ['conftest.get_test_fname', 'numpy.load']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\tests\\conftest.py\n",
      "[('conftest', 'pytest fixture'), ('conftest', 'os path dirname'), ('conftest pytest_runtest_setup', 'pytest xfail'), ('conftest get_test_fname', 'os path dirname'), ('conftest get_test_fname', 'os path join'), ('conftest fname', 'os path splitext'), ('conftest fname', 'os path basename'), ('conftest create_image_dict', 'conftest get_test_fname'), ('conftest create_image_dict', 'os path splitext'), ('conftest create_image_dict', 'cv2 imread'), ('conftest create_image_dict', 'numpy load'), ('conftest create_image_dict', 'os path basename'), ('conftest left_img', 'conftest create_image_dict'), ('conftest right_img', 'conftest create_image_dict'), ('conftest not_to_bee', 'conftest get_test_fname'), ('conftest not_to_bee', 'cv2 imread'), ('conftest surveyor_csv_path', 'conftest get_test_fname'), ('conftest config', 'bb_stitcher helpers get_default_config'), ('conftest main_outdir', 'os makedirs'), ('conftest main_outdir', 'os path join'), ('conftest main_outdir', 'os path exists'), ('conftest panorama', 'conftest get_test_fname'), ('conftest panorama', 'cv2 imread'), ('conftest error_params', 'conftest get_test_fname'), ('conftest error_params', 'numpy load')]\n",
      "0\n",
      "found files: []\n",
      "#  Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n",
      "#  not use this file except in compliance with the License. You may obtain\n",
      "#  a copy of the License at\n",
      "#\n",
      "#       http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "#  Unless required by applicable law or agreed to in writing, software\n",
      "#  distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
      "#  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
      "#  License for the specific language governing permissions and limitations\n",
      "#  under the License.\n",
      "\"\"\"This module provides functions to prepare an image or points for stitching.\"\"\"\n",
      "import ast\n",
      "import functools\n",
      "from logging import getLogger\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "import bb_stitcher.helpers as helpers\n",
      "\n",
      "log = getLogger(__name__)\n",
      "\n",
      "\n",
      "class Rectificator(object):\n",
      "    \"\"\"Class to rectify images and points.\n",
      "\n",
      "    Remove lens distortion from images and points.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, config):\n",
      "        \"\"\"Initialize a rectificator with camera parameters.\n",
      "\n",
      "        Args:\n",
      "            config: config file which holds the camera parameters.\n",
      "        \"\"\"\n",
      "        # TODO(gitmirgut) add link to description for loading auto configuration.\n",
      "        # TODO(gitmirgut) add action when config is none.\n",
      "\n",
      "        self.intr_m = np.array(ast.literal_eval(config['Rectificator']['INTR_M']))\n",
      "        self.dist_c = np.array(ast.literal_eval(config['Rectificator']['DIST_C']))\n",
      "        self.cached_new_cam_mat = None\n",
      "        self.cached_dim = None\n",
      "        self.cached_size = None\n",
      "\n",
      "    def rectify_image(self, image):\n",
      "        \"\"\"Remove lens distortion from an image.\n",
      "\n",
      "        Args:\n",
      "            image (ndarray): Input (distorted) image.\n",
      "\n",
      "        Returns:\n",
      "            ndarray: Output (corrected) image with same size and type as ``image``.\n",
      "        \"\"\"\n",
      "        log.info('Start rectification of image with shape {}.'.format(image.shape))\n",
      "        h, w = image.shape[:2]\n",
      "        cached_new_cam_mat, __ = cv2.getOptimalNewCameraMatrix(\n",
      "            self.intr_m, self.dist_c, (w, h), 1, (w, h), 0)\n",
      "        log.debug('new_camera_mat = \\n{}'.format(cached_new_cam_mat))\n",
      "        return cv2.undistort(image, self.intr_m, self.dist_c, None, cached_new_cam_mat)\n",
      "\n",
      "    def rectify_points(self, points, size):\n",
      "        \"\"\"Remove lens distortion from points.\n",
      "\n",
      "        Map points determined from distorted image to its position in an undistorted image.\n",
      "\n",
      "        Args:\n",
      "            points (ndarray): List of (distorted) points *(N,2)*.\n",
      "            size (tuple): Size *(width, height)* of the image, which was used to determine the\n",
      "                                points.\n",
      "\n",
      "        Returns:\n",
      "            ndarray: List of corrected ``points``.\n",
      "        \"\"\"\n",
      "        points = np.array([points])\n",
      "        # size = (img_width, img_height)\n",
      "        log.info(size)\n",
      "\n",
      "        # size and camera matrix will be cached to speed up rectification if multiple images\n",
      "        # with same size will be rectified.\n",
      "        if self.cached_size != size or self.cached_new_cam_mat is None:\n",
      "            self.cached_size = size\n",
      "            self.cached_new_cam_mat, __ = cv2.getOptimalNewCameraMatrix(self.intr_m,\n",
      "                                                                        self.dist_c,\n",
      "                                                                        self.cached_size, 1,\n",
      "                                                                        self.cached_size, 0)\n",
      "            log.debug('new_camera_mat = \\n{}'.format(self.cached_new_cam_mat))\n",
      "        return cv2.undistortPoints(\n",
      "            points, self.intr_m, self.dist_c, None, self.cached_new_cam_mat)[0]\n",
      "\n",
      "    def rectify_points_angles(self, points, angles, size):\n",
      "        \"\"\"Remove lens distortion from angles.\n",
      "\n",
      "        Map angles determined from distorted image to its angles in an undistorted image.\n",
      "\n",
      "        Args:\n",
      "            points(ndarray): List of (distorted) points *(N,2)*.\n",
      "            angles (ndarray): List of Angles in rad (length *(N,)*).\n",
      "            size (tuple): Size *(width, height)* of the image, which was used to determine the\n",
      "                                points.\n",
      "\n",
      "        Returns:\n",
      "            - **rect_points** (ndarray) -- List of corrected ``points``\n",
      "            - **rect_angles** (ndarray) -- List of corrected ``angles``\n",
      "        \"\"\"\n",
      "        angle_pt_repr = helpers.angles_to_points(points, angles)\n",
      "\n",
      "        rect_points = self.rectify_points(points, size)\n",
      "        rect_angle_pt_reprs = self.rectify_points(angle_pt_repr, size)\n",
      "\n",
      "        rect_angles = helpers.points_to_angles(rect_points, rect_angle_pt_reprs)\n",
      "\n",
      "        return rect_points, rect_angles\n",
      "\n",
      "\n",
      "@functools.lru_cache(maxsize=16)\n",
      "def __get_affine_mat_and_new_size(angle, size=(4000, 3000)):\n",
      "    \"\"\"Calculate the affine transformation to rotate image by given angle.\n",
      "\n",
      "    Args:\n",
      "        angle (int): Rotation angle in degree. Positive values mean counter-clockwise rotation.\n",
      "        size (tuple): Size *(width, height)* of the potential image, which was used for determine\n",
      "                    the points.\n",
      "    Returns:\n",
      "        - **affine_mat** (ndarray) -- An affine *(3,3)*--matrix  which rotates and translate image.\n",
      "        - **new_size** (tuple)  --  Size *(width, height)* of the future image after rotation.\n",
      "    \"\"\"\n",
      "    import math\n",
      "\n",
      "    # determine the center.\n",
      "    (width_half, height_half) = tuple(np.array(size) / 2.0)\n",
      "    center = (width_half - 0.5, height_half - 0.5)\n",
      "\n",
      "    log.debug('center of the rotation: {}'.format(center))\n",
      "\n",
      "    # Convert the 3x2 rotation matrix to 3x3 homography.\n",
      "    rotation_mat = np.vstack([cv2.getRotationMatrix2D(center, angle, 1.0), [0, 0, 1]])\n",
      "\n",
      "    # To get just the rotation.\n",
      "    rot_matrix_2x2 = rotation_mat[:2, :2]\n",
      "\n",
      "    # Declare the corners of the image in relation to the center\n",
      "    corners = np.array([\n",
      "        [-width_half, height_half],\n",
      "        [width_half, height_half],\n",
      "        [-width_half, -height_half],\n",
      "        [width_half, -height_half]\n",
      "    ])\n",
      "    log.debug('corners of the rectangle: {}'.format(corners))\n",
      "    # get the rotated corners\n",
      "    corners_rotated = corners.dot(rot_matrix_2x2)\n",
      "    corners_rotated = np.array(corners_rotated, np.float32)\n",
      "\n",
      "    # calculate the new dimension of the potential image.\n",
      "    x_cor = corners_rotated[:, [0][0]]\n",
      "    right_bound = max(x_cor)\n",
      "    left_bound = min(x_cor)\n",
      "    w = math.ceil(abs(right_bound - left_bound))\n",
      "\n",
      "    y_cor = corners_rotated[:, [1][0]]\n",
      "    top_bound = max(y_cor)\n",
      "    bot_bound = min(y_cor)\n",
      "    h = math.ceil(abs(top_bound - bot_bound))\n",
      "\n",
      "    size_new = (w, h)\n",
      "    log.debug('size_new = {}'.format(size_new))\n",
      "\n",
      "    # matrix to center the rotated image\n",
      "    translation_matrix = np.array([\n",
      "        [1, 0, math.ceil(w / 2.0 - width_half)],\n",
      "        [0, 1, math.ceil(h / 2.0 - height_half)],\n",
      "        [0, 0, 1]\n",
      "    ])\n",
      "\n",
      "    # get the affine Matrix\n",
      "    affine_mat = translation_matrix.dot(rotation_mat)\n",
      "    log.debug('affine_mat = \\n{}'.format(affine_mat))\n",
      "\n",
      "    return affine_mat, size_new\n",
      "\n",
      "\n",
      "def rotate_image(image, angle):\n",
      "    \"\"\"Rotate image by given angle.\n",
      "\n",
      "    Args:\n",
      "        image (ndarray): Input image.\n",
      "        angle (int): Rotation angle in degree. Positive value means counter-clockwise rotation.\n",
      "\n",
      "    Returns:\n",
      "        - **rot_image** (ndarray) -- Rotated ``image``.\n",
      "        - **affine_mat** (ndarray) -- An affine *(3,3)*--matrix for rotation of image or points.\n",
      "    \"\"\"\n",
      "    img_size = image.shape[:2][::-1]\n",
      "    affine_mat, size_new = __get_affine_mat_and_new_size(angle, img_size)\n",
      "    log.debug(\"The affine matrix = {} and the new size = {}\".format(affine_mat, size_new))\n",
      "    rot_image = cv2.warpPerspective(image, affine_mat, size_new)\n",
      "    return rot_image, affine_mat\n",
      "\n",
      "\n",
      "def rotate_points(points, angle, size):\n",
      "    \"\"\"Rotate points by given angle and in relation to the size of an image.\n",
      "\n",
      "    Args:\n",
      "        points (ndarray): List of points *(N, 2)*.\n",
      "        angle (int): Rotation angle in degree. Positive values mean counter-clockwise rotation.\n",
      "        size (tuple): Size *(width, height)* of the image, which was used to determine the\n",
      "                    ``points``.\n",
      "\n",
      "    Returns:\n",
      "        ndarray: Rotated ``points`` *(N, 2)*.\n",
      "    \"\"\"\n",
      "    points = np.array([points])\n",
      "    log.debug('Start rotate points.')\n",
      "    affine_mat, __ = __get_affine_mat_and_new_size(angle, size)\n",
      "    return cv2.transform(points, affine_mat[0:2])[0]\n",
      "\n",
      "Output: {'prep': ['functools.lru_cache', 'logging.getLogger'], 'logging.getLogger': [], 'prep.Rectificator.__init__': ['numpy.array', 'ast.literal_eval'], 'ast.literal_eval': [], 'numpy.array': [], 'prep.Rectificator.rectify_image': ['cv2.getOptimalNewCameraMatrix', 'cv2.undistort'], 'cv2.getOptimalNewCameraMatrix': [], 'cv2.undistort': [], 'prep.Rectificator.rectify_points': ['cv2.getOptimalNewCameraMatrix', 'numpy.array', 'cv2.undistortPoints'], 'cv2.undistortPoints': [], 'prep.Rectificator.rectify_points_angles': ['prep.Rectificator.rectify_points', 'bb_stitcher.helpers.angles_to_points', 'bb_stitcher.helpers.points_to_angles'], 'bb_stitcher.helpers.angles_to_points': [], 'bb_stitcher.helpers.points_to_angles': [], 'functools.lru_cache': [], 'prep.__get_affine_mat_and_new_size': ['math.ceil', '<builtin>.tuple', 'numpy.array', 'numpy.vstack', '<builtin>.min', '<builtin>.max', '<builtin>.abs', 'cv2.getRotationMatrix2D'], '<builtin>.tuple': [], 'cv2.getRotationMatrix2D': [], 'numpy.vstack': [], '<builtin>.max': [], '<builtin>.min': [], '<builtin>.abs': [], 'math.ceil': [], 'prep.rotate_image': ['cv2.warpPerspective', 'prep.__get_affine_mat_and_new_size'], 'cv2.warpPerspective': [], 'prep.rotate_points': ['numpy.array', 'prep.__get_affine_mat_and_new_size', 'cv2.transform'], 'cv2.transform': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\bb_stitcher\\prep.py\n",
      "[('prep', 'functools lru_cache'), ('prep', 'logging getLogger'), ('prep Rectificator __init__', 'numpy array'), ('prep Rectificator __init__', 'ast literal_eval'), ('prep Rectificator rectify_image', 'cv2 getOptimalNewCameraMatrix'), ('prep Rectificator rectify_image', 'cv2 undistort'), ('prep Rectificator rectify_points', 'cv2 getOptimalNewCameraMatrix'), ('prep Rectificator rectify_points', 'numpy array'), ('prep Rectificator rectify_points', 'cv2 undistortPoints'), ('prep Rectificator rectify_points_angles', 'prep Rectificator rectify_points'), ('prep Rectificator rectify_points_angles', 'bb_stitcher helpers angles_to_points'), ('prep Rectificator rectify_points_angles', 'bb_stitcher helpers points_to_angles'), ('prep __get_affine_mat_and_new_size', 'math ceil'), ('prep __get_affine_mat_and_new_size', 'numpy array'), ('prep __get_affine_mat_and_new_size', 'numpy vstack'), ('prep __get_affine_mat_and_new_size', 'cv2 getRotationMatrix2D'), ('prep rotate_image', 'cv2 warpPerspective'), ('prep rotate_image', 'prep __get_affine_mat_and_new_size'), ('prep rotate_points', 'numpy array'), ('prep rotate_points', 'prep __get_affine_mat_and_new_size'), ('prep rotate_points', 'cv2 transform')]\n",
      "302\n",
      "found files: []\n",
      "import os.path\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "import numpy.testing as npt\n",
      "import pytest\n",
      "\n",
      "import bb_stitcher.prep as prep\n",
      "import bb_stitcher.visualisation as vis\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def outdir(main_outdir):\n",
      "    out_path = os.path.join(main_outdir, str(__name__))\n",
      "    if not os.path.exists(out_path):\n",
      "        os.makedirs(out_path)\n",
      "    return out_path\n",
      "\n",
      "\n",
      "def draw_marks(img, pts, color=(0, 0, 255), marker_types=cv2.MARKER_TILTED_CROSS):\n",
      "    img_m = np.copy(img)\n",
      "    if len(img_m.shape) == 2:\n",
      "        img_m = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
      "    pts = pts.astype(int)\n",
      "    for pt in pts:\n",
      "        cv2.drawMarker(img_m, tuple(pt), color, markerType=marker_types,\n",
      "                       markerSize=40, thickness=5)\n",
      "    return img_m\n",
      "\n",
      "\n",
      "def test_Rectificator(left_img, right_img, config, outdir):\n",
      "\n",
      "    # left image\n",
      "    rectificator = prep.Rectificator(config)\n",
      "    corrected_image = rectificator.rectify_image(left_img['img'])\n",
      "    assert corrected_image.shape == left_img['img'].shape\n",
      "\n",
      "    # for visual see /out\n",
      "    name_img_rect = ''.join([left_img['name'], '_rectified.jpg'])\n",
      "    out = os.path.join(outdir, name_img_rect)\n",
      "    cv2.imwrite(out, corrected_image)\n",
      "\n",
      "    corrected_detections = rectificator.rectify_points(\n",
      "        left_img['detections'], left_img['size'])\n",
      "    assert len(corrected_detections) == len(left_img['detections'])\n",
      "\n",
      "    # for visual see /out\n",
      "    rect_img = rectificator.rectify_image(left_img['img_w_detections'])\n",
      "    marked_img = draw_marks(rect_img, corrected_detections)\n",
      "    name_out = ''.join([left_img['name'], '_detections_rectified.jpg'])\n",
      "    out = os.path.join(outdir, name_out)\n",
      "    cv2.imwrite(out, marked_img)\n",
      "\n",
      "    # right image\n",
      "    corrected_image = rectificator.rectify_image(right_img['img'])\n",
      "    assert corrected_image.shape == right_img['img'].shape\n",
      "\n",
      "    # for visual see /out\n",
      "    name_img_rect = ''.join([right_img['name'], '_rectified.jpg'])\n",
      "    out = os.path.join(outdir, name_img_rect)\n",
      "    cv2.imwrite(out, corrected_image)\n",
      "\n",
      "    corrected_detections = rectificator.rectify_points(\n",
      "        right_img['detections'], right_img['size'])\n",
      "    assert len(corrected_detections) == len(right_img['detections'])\n",
      "\n",
      "    # for visual see /out\n",
      "    rect_img = rectificator.rectify_image(right_img['img_w_detections'])\n",
      "    marked_img = draw_marks(rect_img, corrected_detections)\n",
      "    name_out = ''.join([right_img['name'], '_detections_rectified.jpg'])\n",
      "    out = os.path.join(outdir, name_out)\n",
      "    cv2.imwrite(out, marked_img)\n",
      "\n",
      "    corr_detect, corr_angles = rectificator.rectify_points_angles(\n",
      "        left_img['detections'], left_img['yaw_angles'], left_img['size'])\n",
      "    assert len(corr_angles) == len(left_img['yaw_angles'])\n",
      "\n",
      "    # for visual see /out\n",
      "    rect_img = rectificator.rectify_image(left_img['img_w_detections'])\n",
      "    vis.draw_complex_marks(rect_img, corr_detect, corr_angles)\n",
      "    name_out = ''.join([left_img['name'], '_detect_angles_rectified.jpg'])\n",
      "    out = os.path.join(outdir, name_out)\n",
      "    cv2.imwrite(out, rect_img)\n",
      "\n",
      "\n",
      "def test_rotate_image():\n",
      "    img = np.zeros((30, 40), np.uint8)\n",
      "    border = 1\n",
      "    img[-border:, :] = 100  # bottom\n",
      "    img[:, -border:] = 150  # right\n",
      "    img[:border, :] = 200   # top\n",
      "    img[:, :border] = 250   # left\n",
      "\n",
      "    rot_img, mat = prep.rotate_image(img, 90)\n",
      "\n",
      "    assert img.shape[0] == rot_img.shape[1] and img.shape[1] == rot_img.shape[0]\n",
      "\n",
      "    assert rot_img[-1][15] == 250\n",
      "    assert rot_img[20][-1] == 100\n",
      "    assert rot_img[0][15] == 150\n",
      "    assert rot_img[20][0] == 200\n",
      "\n",
      "    rot_img, mat = prep.rotate_image(img, -90)\n",
      "    assert img.shape[0] == rot_img.shape[1] and img.shape[1] == rot_img.shape[0]\n",
      "    assert rot_img[-1][15] == 150\n",
      "    assert rot_img[20][-1] == 200\n",
      "    assert rot_img[0][15] == 250\n",
      "    assert rot_img[20][0] == 100\n",
      "\n",
      "\n",
      "def test_rotate_image_specifc(left_img, outdir):\n",
      "    img, mat = prep.rotate_image(left_img['img'], 90)\n",
      "    name_img_rot = ''.join([left_img['name'], '_rotated.jpg'])\n",
      "    out = os.path.join(outdir, name_img_rot)\n",
      "    cv2.imwrite(out, img)\n",
      "\n",
      "\n",
      "def test_rotate_points():\n",
      "    size = (4000, 3000)\n",
      "    pts = np.array([\n",
      "        [0, 0],\n",
      "        [0, 2999],\n",
      "        [3999, 2999],\n",
      "        [3999, 0]\n",
      "    ])\n",
      "\n",
      "    rot_pts_pos90 = prep.rotate_points(pts, 90, size)\n",
      "    target_points_pos90 = np.array([\n",
      "        [0, 3999],\n",
      "        [2999, 3999],\n",
      "        [2999, 0],\n",
      "        [0, 0]\n",
      "    ])\n",
      "    npt.assert_equal(rot_pts_pos90, target_points_pos90)\n",
      "\n",
      "    rot_pts_neg90 = prep.rotate_points(pts, -90, size)\n",
      "    target_points_neg90 = np.array([\n",
      "        [2999, 0],\n",
      "        [0, 0],\n",
      "        [0, 3999],\n",
      "        [2999, 3999]\n",
      "    ])\n",
      "    npt.assert_equal(rot_pts_neg90, target_points_neg90)\n",
      "\n",
      "\n",
      "def test_rectify_and_rotate_image(left_img, config, outdir):\n",
      "    rectificator = prep.Rectificator(config)\n",
      "    rect_img = rectificator.rectify_image(left_img['img_w_detections'])\n",
      "    rect_detections = rectificator.rectify_points(left_img['detections'], left_img['size'])\n",
      "\n",
      "    angle = 90\n",
      "    rot_img, rot_mat = prep.rotate_image(rect_img, angle)\n",
      "    rot_detections = prep.rotate_points(rect_detections, angle, left_img['size'])\n",
      "\n",
      "    marked_img = draw_marks(rot_img, rot_detections)\n",
      "    name_out = ''.join([left_img['name'], '_detections_rectified_rot.jpg'])\n",
      "    out = os.path.join(outdir, name_out)\n",
      "    cv2.imwrite(out, marked_img)\n",
      "\n",
      "Output: {'test_prep': ['pytest.fixture'], 'pytest.fixture': [], 'test_prep.outdir': ['<builtin>.str'], '<builtin>.str': [], 'test_prep.draw_marks': ['cv2.drawMarker', 'numpy.copy', '<builtin>.len', '<builtin>.tuple', 'cv2.cvtColor'], 'numpy.copy': [], '<builtin>.len': [], 'cv2.cvtColor': [], '<builtin>.tuple': [], 'cv2.drawMarker': [], 'test_prep.test_Rectificator': ['cv2.imwrite', 'test_prep.draw_marks', 'bb_stitcher.visualisation.draw_complex_marks', 'bb_stitcher.prep.Rectificator', '<builtin>.len'], 'bb_stitcher.prep.Rectificator': [], 'cv2.imwrite': [], 'bb_stitcher.visualisation.draw_complex_marks': [], 'test_prep.test_rotate_image': ['numpy.zeros', 'bb_stitcher.prep.rotate_image'], 'numpy.zeros': [], 'bb_stitcher.prep.rotate_image': [], 'test_prep.test_rotate_image_specifc': ['cv2.imwrite', 'bb_stitcher.prep.rotate_image'], 'test_prep.test_rotate_points': ['numpy.array', 'numpy.testing.assert_equal', 'bb_stitcher.prep.rotate_points'], 'numpy.array': [], 'bb_stitcher.prep.rotate_points': [], 'numpy.testing.assert_equal': [], 'test_prep.test_rectify_and_rotate_image': ['cv2.imwrite', 'test_prep.draw_marks', 'bb_stitcher.prep.rotate_image', 'bb_stitcher.prep.Rectificator', 'bb_stitcher.prep.rotate_points']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\tests\\test_prep.py\n",
      "[('test_prep', 'pytest fixture'), ('test_prep draw_marks', 'cv2 drawMarker'), ('test_prep draw_marks', 'numpy copy'), ('test_prep draw_marks', 'cv2 cvtColor'), ('test_prep test_Rectificator', 'cv2 imwrite'), ('test_prep test_Rectificator', 'test_prep draw_marks'), ('test_prep test_Rectificator', 'bb_stitcher visualisation draw_complex_marks'), ('test_prep test_Rectificator', 'bb_stitcher prep Rectificator'), ('test_prep test_rotate_image', 'numpy zeros'), ('test_prep test_rotate_image', 'bb_stitcher prep rotate_image'), ('test_prep test_rotate_image_specifc', 'cv2 imwrite'), ('test_prep test_rotate_image_specifc', 'bb_stitcher prep rotate_image'), ('test_prep test_rotate_points', 'numpy array'), ('test_prep test_rotate_points', 'numpy testing assert_equal'), ('test_prep test_rotate_points', 'bb_stitcher prep rotate_points'), ('test_prep test_rectify_and_rotate_image', 'cv2 imwrite'), ('test_prep test_rectify_and_rotate_image', 'test_prep draw_marks'), ('test_prep test_rectify_and_rotate_image', 'bb_stitcher prep rotate_image'), ('test_prep test_rectify_and_rotate_image', 'bb_stitcher prep Rectificator'), ('test_prep test_rectify_and_rotate_image', 'bb_stitcher prep rotate_points')]\n",
      "0\n",
      "found files: []\n",
      "#  Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n",
      "#  not use this file except in compliance with the License. You may obtain\n",
      "#  a copy of the License at\n",
      "#\n",
      "#       http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "#  Unless required by applicable law or agreed to in writing, software\n",
      "#  distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
      "#  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
      "#  License for the specific language governing permissions and limitations\n",
      "#  under the License.\n",
      "\"\"\"This module contains different functions to draw coordinates and orientations on images.\"\"\"\n",
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "# adapted from:\n",
      "# https://github.com/BioroboticsLab/bb_pipeline/blob/master/pipeline/stages/visualization.py\n",
      "def draw_arrows(img, positions, angles, color=(0, 0, 255), line_width=6, arrow_length=150):\n",
      "    u\"\"\"Draw arrows from positions in angle direction (clockwise).\n",
      "\n",
      "    (The 0-Angle is the x-Axis.)\n",
      "\n",
      "    Args:\n",
      "        img (ndarray): Image (min. 3 channel) to draw on.\n",
      "        positions (ndarray): The points the arrows starts from. *(N,2)*\n",
      "        angles (ndarray):  Angles in rad (length *(N,)*).\n",
      "    \"\"\"\n",
      "    assert len(positions) == len(angles)\n",
      "    for i, position in enumerate(positions):\n",
      "        position = position.astype(np.int32)\n",
      "        x_to = np.round(position[0] + arrow_length * np.cos(angles[i])).astype(np.int32)\n",
      "        y_to = np.round(position[1] + arrow_length * np.sin(angles[i])).astype(np.int32)\n",
      "        cv2.arrowedLine(img, tuple(position), (x_to, y_to), color, line_width, cv2.LINE_AA)\n",
      "\n",
      "\n",
      "def draw_circles(img, centres, radius=32, color=(0, 0, 255), line_width=6):\n",
      "    \"\"\"Draw circles around positions.\n",
      "\n",
      "    Args:\n",
      "        img (ndarray): Image (min. 3 channel) to draw on.\n",
      "        centres (ndarray): The centres of the circles. *(N,2)*\n",
      "        radius: Radius of the circles.\n",
      "    \"\"\"\n",
      "    for center in centres:\n",
      "        center = center.astype(np.int32)\n",
      "        cv2.circle(img, tuple(center), radius, color, line_width)\n",
      "\n",
      "\n",
      "def draw_marks(img, positions, color=(0, 0, 255), marker_types=cv2.MARKER_CROSS):\n",
      "    \"\"\"Draw cross marks on position.\n",
      "\n",
      "    Args:\n",
      "        img (ndarray): Image (min. 3 channel) to draw on.\n",
      "        positions (ndarray): The points to mark. *(N,2)*\n",
      "    \"\"\"\n",
      "    for position in positions.astype(int):\n",
      "        cv2.drawMarker(img, tuple(position), color, markerType=marker_types,\n",
      "                       markerSize=40, thickness=5)\n",
      "\n",
      "\n",
      "def draw_complex_marks(img, centres, angles, color=(0, 0, 255), marker_types=cv2.MARKER_CROSS):\n",
      "    \"\"\"Draw more complex marks, with circles, marked centres and arrows for angles/direction.\n",
      "\n",
      "    Args:\n",
      "        img (ndarray): Image (min. 3 channel) to draw on.\n",
      "        centres (ndarray): The centres of the marks and starting points of arrows. *(N,2)*\n",
      "        angles (ndarray):  Angles in rad (length *(N,)*).\n",
      "    \"\"\"\n",
      "    arrow_length = 150\n",
      "    assert len(centres) == len(angles)\n",
      "    for i, center in enumerate(centres):\n",
      "        center = center.astype(np.int32)\n",
      "        x_to = np.round(center[0] + arrow_length * np.cos(angles[i])).astype(np.int32)\n",
      "        y_to = np.round(center[1] + arrow_length * np.sin(angles[i])).astype(np.int32)\n",
      "        cv2.arrowedLine(img, tuple(center), (x_to, y_to), color, thickness=6, line_type=cv2.LINE_AA)\n",
      "        cv2.circle(img, tuple(center), radius=32, color=color, thickness=6)\n",
      "        cv2.drawMarker(img, tuple(center), color, markerType=marker_types,\n",
      "                       markerSize=40, thickness=1)\n",
      "\n",
      "\n",
      "def draw_grid(image, origin, ratio_px_mm, step_size_mm=8):\n",
      "    \"\"\"Draw a grid with axes in mm on the image.\n",
      "\n",
      "    Args:\n",
      "        image (ndarray): Image to draw on.\n",
      "        origin (ndarray): The orgin of the grid / axes.\n",
      "        ratio_px_mm: Ratio to convert pixel to mm.\n",
      "        step_size_mm: The (step) distance between the grid lines.\n",
      "    \"\"\"\n",
      "    w, h = image.shape[:2][::-1]\n",
      "    x, y = origin\n",
      "    step_size_px = step_size_mm / ratio_px_mm\n",
      "\n",
      "    # draw vertical lines in mm\n",
      "    max_lines_vert = int((w - x) / step_size_px)\n",
      "    for i in range(max_lines_vert):\n",
      "        pt1_v = np.zeros((2,), dtype=np.uint16)\n",
      "        pt1_v[0] = x + i * step_size_px\n",
      "        pt1_v[1] = y\n",
      "        pt1_v = tuple(pt1_v)\n",
      "        pt2_v = (int(pt1_v[0]), h)\n",
      "        cv2.line(image, pt1_v, pt2_v, color=(255, 0, 0), thickness=4)\n",
      "        cv2.putText(image, str(i * step_size_mm), pt1_v, cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255),\n",
      "                    thickness=4)\n",
      "\n",
      "    # draw horizontal lines and distance in mm\n",
      "    max_lines_hori = int((h - y) / step_size_px)\n",
      "    for i in range(max_lines_hori):\n",
      "        pt1_h = np.zeros((2,), dtype=np.uint16)\n",
      "        pt1_h[0] = x\n",
      "        pt1_h[1] = y + i * step_size_px\n",
      "        pt1_h = tuple(np.uint16(pt1_h))\n",
      "        pt2_h = (w, int(pt1_h[1]))\n",
      "        cv2.line(image, pt1_h, pt2_h, color=(255, 0, 0), thickness=4)\n",
      "        cv2.putText(image, str(i * step_size_mm), pt1_h, cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255),\n",
      "                    thickness=4)\n",
      "\n",
      "Output: {'visualisation': [], 'visualisation.draw_arrows': ['<builtin>.tuple', '<builtin>.len', 'cv2.arrowedLine', 'numpy.sin', 'numpy.round', '<builtin>.enumerate', 'numpy.cos'], '<builtin>.len': [], '<builtin>.enumerate': [], 'numpy.cos': [], 'numpy.round': [], 'numpy.sin': [], '<builtin>.tuple': [], 'cv2.arrowedLine': [], 'visualisation.draw_circles': ['cv2.circle', '<builtin>.tuple'], 'cv2.circle': [], 'visualisation.draw_marks': ['cv2.drawMarker', '<builtin>.tuple'], 'cv2.drawMarker': [], 'visualisation.draw_complex_marks': ['cv2.drawMarker', '<builtin>.tuple', '<builtin>.len', 'cv2.arrowedLine', 'numpy.sin', 'numpy.round', '<builtin>.enumerate', 'numpy.cos', 'cv2.circle'], 'visualisation.draw_grid': ['<builtin>.range', '<builtin>.tuple', 'numpy.zeros', '<builtin>.str', 'numpy.uint16', 'cv2.line', 'cv2.putText', '<builtin>.int'], '<builtin>.int': [], '<builtin>.range': [], 'numpy.zeros': [], 'cv2.line': [], '<builtin>.str': [], 'cv2.putText': [], 'numpy.uint16': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\bb_stitcher\\visualisation.py\n",
      "[('visualisation draw_arrows', 'cv2 arrowedLine'), ('visualisation draw_arrows', 'numpy sin'), ('visualisation draw_arrows', 'numpy round'), ('visualisation draw_arrows', 'numpy cos'), ('visualisation draw_circles', 'cv2 circle'), ('visualisation draw_marks', 'cv2 drawMarker'), ('visualisation draw_complex_marks', 'cv2 drawMarker'), ('visualisation draw_complex_marks', 'cv2 arrowedLine'), ('visualisation draw_complex_marks', 'numpy sin'), ('visualisation draw_complex_marks', 'numpy round'), ('visualisation draw_complex_marks', 'numpy cos'), ('visualisation draw_complex_marks', 'cv2 circle'), ('visualisation draw_grid', 'numpy zeros'), ('visualisation draw_grid', 'numpy uint16'), ('visualisation draw_grid', 'cv2 line'), ('visualisation draw_grid', 'cv2 putText')]\n",
      "504\n",
      "found files: []\n",
      "#  Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n",
      "#  not use this file except in compliance with the License. You may obtain\n",
      "#  a copy of the License at\n",
      "#\n",
      "#       http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "#  Unless required by applicable law or agreed to in writing, software\n",
      "#  distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
      "#  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
      "#  License for the specific language governing permissions and limitations\n",
      "#  under the License.\n",
      "\"\"\"Initialise a GUI to pick various points on images.\n",
      "\n",
      "This Module provides a class to initialise a GUI, to pick various points\n",
      "on one or multiple images.\n",
      "\"\"\"\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "import bb_stitcher.helpers as helpers\n",
      "import bb_stitcher.picking.draggables as draggs\n",
      "\n",
      "\n",
      "class PointPicker(object):\n",
      "    \"\"\"GUI for picking points.\"\"\"\n",
      "\n",
      "    def __init__(self):\n",
      "        \"\"\"Initialise GUI to pick various point on an image.\"\"\"\n",
      "        mpl.rcParams['keymap.quit'] = ['q', 'ctrl+w', 'cmd+w']\n",
      "        mpl.rcParams['keymap.home'] = ['h', 'home']\n",
      "        mpl.rcParams['keymap.zoom'] = ['z', 'o']\n",
      "        mpl.rcParams['keymap.save'] = ['ctrl+s']\n",
      "\n",
      "    def pick(self, images, all_pts=True):\n",
      "        \"\"\"Initialise a GUI to pick points on multiple images.\n",
      "\n",
      "        A matplot GUI will be initialised, where the user can pick multiple points\n",
      "        on the **N** ``images``. Afterwards the :obj:`PointPicker` will return **N** ndarrays, which\n",
      "        holds the coordinates of the marked points. Each ndarray holds the points for one image.\n",
      "\n",
      "        Args:\n",
      "            images (list(ndarray)): List of images (ndarray)\n",
      "            all_pts (bool): If ``True`` all points will be returned and else just 'selected' \\\n",
      "            points will be returned.\n",
      "\n",
      "        Returns:\n",
      "            list(ndarray): Returns a List of length **N**, where each cell contains a ndarray \\\n",
      "            *(M,2)*, which holds the coordinates of the *M* marked points per image.\n",
      "        \"\"\"\n",
      "        imgs_a = []\n",
      "        for img in images:\n",
      "            imgs_a.append(helpers.add_alpha_channel(img))\n",
      "        count_images = len(imgs_a)\n",
      "        # creating one list per image, which will hold the draggable marks\n",
      "        # e.g. for 2 images:\n",
      "        # dms_per_image = [[<dragableMarks first image>],[<dragableMarks second image>]]\n",
      "\n",
      "        dms_per_image = []\n",
      "        for __ in range(count_images):\n",
      "            dms_per_image.append(draggs.DraggableMarkList())\n",
      "\n",
      "        def _on_click(event):\n",
      "            # double click left mouse button\n",
      "            if event.button == 1 and event.dblclick:\n",
      "                for i, ax in enumerate(axes):\n",
      "                    if event.inaxes == ax:\n",
      "                        marker, = ax.plot(\n",
      "                            event.xdata, event.ydata, 'xr', markersize=10, markeredgewidth=2)\n",
      "                        dm = draggs.DraggableMark(marker, imgs_a[i])\n",
      "                        dm.connect()\n",
      "                        dms_per_image[i].append(dm)\n",
      "                        fig.canvas.draw()\n",
      "\n",
      "        fig, axes = plt.subplots(\n",
      "            nrows=1, ncols=count_images, tight_layout=False)\n",
      "        fig.canvas.mpl_connect('button_press_event', _on_click)\n",
      "        fig.canvas.set_window_title('Point Picker | r-refine point | s-select point | z-zoom | '\n",
      "                                    'p-pan | q-quit/finish')\n",
      "\n",
      "        # if the nrows == 1 and ncols == 1 the function of plt.subplots returns a single\n",
      "        # class 'matplotlib.axes._subplots.AxesSubplot' but we want always an array\n",
      "        if count_images == 1:\n",
      "            axes = np.array([axes])\n",
      "\n",
      "        for i, image in enumerate(imgs_a):\n",
      "            # don't draw y-axis on every image, just on first image\n",
      "            if i > 0:\n",
      "                plt.setp(axes[i].get_yticklabels(), visible=False)\n",
      "            axes[i].imshow(image)\n",
      "\n",
      "        plt.show()\n",
      "        points = []\n",
      "        for i, dms in enumerate(dms_per_image):\n",
      "            points_per_image = dms.get_points(all_pts=all_pts)\n",
      "            points.append(points_per_image)\n",
      "        return points\n",
      "\n",
      "Output: {'picker': [], 'picker.PointPicker.__init__': [], 'picker.PointPicker.pick': ['matplotlib.pyplot.subplots', 'bb_stitcher.picking.draggables.DraggableMarkList', '<builtin>.len', '<builtin>.enumerate', 'bb_stitcher.helpers.add_alpha_channel', '<builtin>.range', 'numpy.array', 'matplotlib.pyplot.setp', 'matplotlib.pyplot.show'], 'bb_stitcher.helpers.add_alpha_channel': [], '<builtin>.len': [], '<builtin>.range': [], 'bb_stitcher.picking.draggables.DraggableMarkList': [], 'picker.PointPicker.pick._on_click': ['<builtin>.enumerate', 'bb_stitcher.picking.draggables.DraggableMark'], '<builtin>.enumerate': [], 'bb_stitcher.picking.draggables.DraggableMark': [], 'matplotlib.pyplot.subplots': [], 'numpy.array': [], 'matplotlib.pyplot.setp': [], 'matplotlib.pyplot.show': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\bb_stitcher\\picking\\picker.py\n",
      "[('picker PointPicker pick', 'matplotlib pyplot subplots'), ('picker PointPicker pick', 'bb_stitcher picking draggables DraggableMarkList'), ('picker PointPicker pick', 'bb_stitcher helpers add_alpha_channel'), ('picker PointPicker pick', 'numpy array'), ('picker PointPicker pick', 'matplotlib pyplot setp'), ('picker PointPicker pick', 'matplotlib pyplot show'), ('picker PointPicker pick _on_click', 'bb_stitcher picking draggables DraggableMark')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"This is the setup file to install the bb_stitcher.\"\"\"\n",
      "from pip.req import parse_requirements\n",
      "from setuptools import setup\n",
      "\n",
      "\n",
      "install_reqs = parse_requirements('requirements.txt', session=False)\n",
      "reqs = [str(ir.req) for ir in install_reqs]\n",
      "dep_links = [str(req_line.url) for req_line in install_reqs]\n",
      "\n",
      "setup(\n",
      "    name='bb_stitcher',\n",
      "    version='0.0.0.dev6',\n",
      "    description='Stitch images from different cam positions,'\n",
      "                'with an affine transformation',\n",
      "    long_description='',\n",
      "    entry_points={\n",
      "            'console_scripts': [\n",
      "                'bb_stitcher = bb_stitcher.scripts.bb_stitcher:main'\n",
      "            ]\n",
      "    },\n",
      "    url='https://github.com/gitmirgut/bb_stitcher',\n",
      "    install_requires=reqs,\n",
      "    dependency_links=dep_links,\n",
      "    author='gitmirgut',\n",
      "    author_email=\"gitmirgut@users.noreply.github.com\",\n",
      "    packages=['bb_stitcher', 'bb_stitcher.picking', 'bb_stitcher.scripts'],\n",
      "    license='Apache License 2.0',\n",
      "    classifiers=[\n",
      "        'Development Status :: 3 - Alpha',\n",
      "        'Intended Audience :: Developers',\n",
      "        'Programming Language :: Python :: 3.5'\n",
      "    ],\n",
      "    package_data={\n",
      "        'bb_stitcher': ['*.ini']\n",
      "    }\n",
      ")\n",
      "\n",
      "Output: {'setup': ['setuptools.setup', 'pip.req.parse_requirements', '<builtin>.str'], 'pip.req.parse_requirements': [], '<builtin>.str': [], 'setuptools.setup': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\setup.py\n",
      "[('setup', 'setuptools setup'), ('setup', 'pip req parse_requirements')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"This is the main script and entry point for the bb_stitcher.\"\"\"\n",
      "import argparse\n",
      "import os\n",
      "import textwrap\n",
      "\n",
      "import cv2\n",
      "\n",
      "import bb_stitcher.core as core\n",
      "import bb_stitcher.helpers as helpers\n",
      "import bb_stitcher.io_utils as io_utils\n",
      "import bb_stitcher.stitcher as stitcher\n",
      "\n",
      "\"\"\"\n",
      "Define the subcommands to work with ArgumentParser.\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "def estimate_params(args):\n",
      "    \"\"\"Execute the subcommand 'estimate' from the parser.\"\"\"\n",
      "    surveyor = core.Surveyor(helpers.get_default_config())\n",
      "    if args.type == 'fb':\n",
      "        stitch = stitcher.FeatureBasedStitcher\n",
      "    else:\n",
      "        stitch = stitcher.RectangleStitcher\n",
      "    surveyor.determine_mapping_parameters(args.left, args.right,\n",
      "                                          args.left_angle, args.right_angle,\n",
      "                                          args.left_camID, args.right_camID,\n",
      "                                          stitch)\n",
      "    surveyor.compose_panorama(args.left, args.right)\n",
      "    surveyor.save(args.out)\n",
      "\n",
      "\n",
      "def compose_params(args):\n",
      "    \"\"\"Execute the subcommand 'compose' from the parser.\"\"\"\n",
      "    surveyor = core.Surveyor(helpers.get_default_config())\n",
      "    surveyor.load(args.data)\n",
      "    img = surveyor.compose_panorama(args.left, args.right, args.grid)\n",
      "    cv2.imwrite(args.out, img)\n",
      "    pass\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Define special argument types for the argument parser.\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "def _exist_path(string):\n",
      "    \"\"\"Check if the given string is a valid file string.\"\"\"\n",
      "    if not os.path.exists(string):\n",
      "        msg = 'File \"{path}\" does not exists.'.format(path=string)\n",
      "        raise argparse.ArgumentTypeError(msg)\n",
      "    return string\n",
      "\n",
      "\n",
      "def _data_path(string):\n",
      "    \"\"\"Check if the path has a valid extension.\"\"\"\n",
      "    __, ext = os.path.splitext(string)\n",
      "    if ext not in io_utils.valid_ext:\n",
      "        msg = 'The Extension \"{ext}\" of \"{path}\" is not a valid extension, please use ' \\\n",
      "              'one of these {valid_ext} extensions.'.format(ext=ext,\n",
      "                                                            path=string,\n",
      "                                                            valid_ext=','.join(io_utils.valid_ext))\n",
      "        raise argparse.ArgumentTypeError(msg)\n",
      "    return string\n",
      "\n",
      "\n",
      "def _img_path(string):\n",
      "    \"\"\"Check if the path is a valid image.\"\"\"\n",
      "    valid_ext = ['.jpeg', '.jpg', '.png']\n",
      "    __, ext = os.path.splitext(string)\n",
      "    if ext not in valid_ext:\n",
      "        msg = 'Did not understand the image type of {path}, please use one of these {valid_ext}' \\\n",
      "              ' extensions.'.format(path=string,\n",
      "                                    valid_ext=','.join(valid_ext))\n",
      "        raise argparse.ArgumentTypeError(msg)\n",
      "    return string\n",
      "\n",
      "\n",
      "def _stitching_data(string):\n",
      "    \"\"\"Check if the path is a valid data file, which holds params.\"\"\"\n",
      "    string = _data_path(string)\n",
      "    return _exist_path(string)\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Define the main parser.\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "def _get_main_parser():\n",
      "    main_parser = argparse.ArgumentParser(\n",
      "        prog='bb_stitcher',\n",
      "        usage='%(prog)s <command> [options]',\n",
      "        description='This will stitch two images and return the needed data for reproducing the'\n",
      "                    'stitching with points and angles.',\n",
      "    )\n",
      "    subparsers = main_parser.add_subparsers(title=\"Commands\")\n",
      "    subparsers.dest = 'command'\n",
      "    subparsers.required = True\n",
      "\n",
      "    estimate_parser = subparsers.add_parser('estimate',\n",
      "                                            aliases=['est'], usage='bb_stitcher estimate',\n",
      "                                            help='Estimate stitching parameters.',\n",
      "                                            formatter_class=argparse.RawTextHelpFormatter)\n",
      "    compose_parser = subparsers.add_parser('compose',\n",
      "                                           aliases=['com'], help='Compose panorama.')\n",
      "\n",
      "    # Define estimation parser --------------------------------------------------------------------\n",
      "    estimate_parser.add_argument('type',\n",
      "                                 choices=['fb', 'rect'], type=str,\n",
      "                                 help=textwrap.dedent('''\\\n",
      "                                         Define the stitcher to use:\n",
      "                                            fb - FeatureBasedStitcher\n",
      "                                            rect - RectangleStitcher\n",
      "                                        '''))\n",
      "\n",
      "    estimate_parser.add_argument('left', help='Path of the left image.', type=_exist_path)\n",
      "    estimate_parser.add_argument('right', help='Path of the right image.', type=_exist_path)\n",
      "\n",
      "    estimate_parser.add_argument('left_angle', help='Rotation angle of the left image '\n",
      "                                                    '(counter-clockwise).', type=int)\n",
      "    estimate_parser.add_argument('right_angle', help='Rotation angle of the right image '\n",
      "                                                     '(counter-clockwise).', type=int)\n",
      "\n",
      "    estimate_parser.add_argument('left_camID',\n",
      "                                 help='Cam ID of the camera which shot the left image.', type=int)\n",
      "    estimate_parser.add_argument('right_camID',\n",
      "                                 help='Cam ID of the camera which shot the right image.', type=int)\n",
      "\n",
      "    estimate_parser.add_argument('out',\n",
      "                                 help=textwrap.dedent('''\\\n",
      "                                         Output path of the stitching data.\n",
      "                                         Supported Types: {ext}\n",
      "                                         '''.format(ext=','.join(io_utils.valid_ext))),\n",
      "                                 type=_data_path)\n",
      "    estimate_parser.set_defaults(func=estimate_params)\n",
      "\n",
      "    # Define composer parser ----------------------------------------------------------------------\n",
      "    compose_parser.add_argument('left', help='Path of the left image.', type=_exist_path)\n",
      "    compose_parser.add_argument('right', help='Path of the right image.', type=_exist_path)\n",
      "\n",
      "    compose_parser.add_argument('data', help='Path of the file which holds the stitching data.',\n",
      "                                type=_stitching_data)\n",
      "    compose_parser.add_argument('out', help='Output path of the stitchted images.', type=_img_path)\n",
      "    compose_parser.add_argument('-g', '--grid', help='Draw grid in mm on stitched images.',\n",
      "                                action='store_true')\n",
      "    compose_parser.set_defaults(func=compose_params)\n",
      "    return main_parser\n",
      "\n",
      "\n",
      "def main():\n",
      "    \"\"\"Parse the arguments of parser.\"\"\"\n",
      "    # define the main parser\n",
      "    main_parser = _get_main_parser()\n",
      "    args = main_parser.parse_args()\n",
      "    args.func(args)\n",
      "\n",
      "Output: {'bb_stitcher': [], 'bb_stitcher.estimate_params': [], 'bb_stitcher.compose_params': ['cv2.imwrite'], 'cv2.imwrite': [], 'bb_stitcher._exist_path': ['os.path.exists', 'argparse.ArgumentTypeError'], 'os.path.exists': [], 'argparse.ArgumentTypeError': [], 'bb_stitcher._data_path': ['argparse.ArgumentTypeError', 'os.path.splitext'], 'os.path.splitext': [], 'bb_stitcher._img_path': ['argparse.ArgumentTypeError', 'os.path.splitext'], 'bb_stitcher._stitching_data': ['bb_stitcher._data_path', 'bb_stitcher._exist_path'], 'bb_stitcher._get_main_parser': ['argparse.ArgumentParser', 'textwrap.dedent'], 'argparse.ArgumentParser': [], 'textwrap.dedent': [], 'bb_stitcher.main': ['bb_stitcher._get_main_parser']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\bb_stitcher\\scripts\\bb_stitcher.py\n",
      "[('bb_stitcher compose_params', 'cv2 imwrite'), ('bb_stitcher _exist_path', 'os path exists'), ('bb_stitcher _exist_path', 'argparse ArgumentTypeError'), ('bb_stitcher _data_path', 'argparse ArgumentTypeError'), ('bb_stitcher _data_path', 'os path splitext'), ('bb_stitcher _img_path', 'argparse ArgumentTypeError'), ('bb_stitcher _img_path', 'os path splitext'), ('bb_stitcher _stitching_data', 'bb_stitcher _data_path'), ('bb_stitcher _stitching_data', 'bb_stitcher _exist_path'), ('bb_stitcher _get_main_parser', 'argparse ArgumentParser'), ('bb_stitcher _get_main_parser', 'textwrap dedent'), ('bb_stitcher main', 'bb_stitcher _get_main_parser')]\n",
      "318\n",
      "found files: []\n",
      "\"\"\"Module to connect the stitching and mapping from image coordinates to world coordinates.\"\"\"\n",
      "import collections\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "import bb_stitcher.helpers as helpers\n",
      "import bb_stitcher.io_utils as io_utils\n",
      "import bb_stitcher.measure as measure\n",
      "import bb_stitcher.stitcher as stitcher\n",
      "import bb_stitcher.visualisation as visualisation\n",
      "\n",
      "\n",
      "class Surveyor(object):\n",
      "    \"\"\"Class to determine the relationship between two images of one comb side .\n",
      "\n",
      "    The :obj:`Surveyor` determines all needed data to stitch two images from different areas of one\n",
      "    comb side to a complete view of the comb. On this basis the :obj:`Surveyor` can also be used to\n",
      "    map the coordinates from these images to hive coordinates.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, config=None):\n",
      "        \"\"\"Initialize Surveyor.\"\"\"\n",
      "        if config is None:\n",
      "            self.config = helpers.get_default_config()\n",
      "        else:\n",
      "            self.config = config\n",
      "        self.homo_left = None\n",
      "        self.homo_right = None\n",
      "        self.size_left = None\n",
      "        self.size_right = None\n",
      "        self.origin = None\n",
      "        self.ratio_px_mm = None\n",
      "        self._world_homo = None\n",
      "        self.cam_id_left = None\n",
      "        self.cam_id_right = None\n",
      "\n",
      "        # these will not be exported\n",
      "        self._world_homo_left = None\n",
      "        self._world_homo_right = None\n",
      "\n",
      "        self._stitcher = None\n",
      "\n",
      "    def _acept_filehandler(self, filehandler):\n",
      "        filehandler.visit_surveyor(self)\n",
      "\n",
      "    def load(self, path):\n",
      "        \"\"\"Load saved parameters for mapping from file.\n",
      "\n",
      "        Args:\n",
      "            path (str): Path of the file, which holds the needed data.\n",
      "        \"\"\"\n",
      "        filehandler = io_utils.get_file_handler(path)\n",
      "        self._acept_filehandler(filehandler)\n",
      "        filehandler.load(path)\n",
      "\n",
      "        # modify homographies from the stitcher to map points to world coordinates\n",
      "        self._world_homo = Surveyor._determine_world_homo(self.origin, self.ratio_px_mm)\n",
      "        self._world_homo_left = self._world_homo.dot(self.homo_left)\n",
      "        self._world_homo_right = self._world_homo.dot(self.homo_right)\n",
      "\n",
      "    def save(self, path):\n",
      "        \"\"\"Save parameters of the :obj:`Surveyor` needed for later stitching to a file.\n",
      "\n",
      "        Args:\n",
      "            path (str): Path of the output file. The extension must be '.npz' or '.csv'.\n",
      "\n",
      "        See Also:\n",
      "            - :mod:`.io_utils`\n",
      "        \"\"\"\n",
      "        filehandler = io_utils.get_file_handler(path)\n",
      "        self._acept_filehandler(filehandler)\n",
      "        filehandler.save(path)\n",
      "\n",
      "    @staticmethod\n",
      "    def _determine_world_homo(origin, ratio_px_mm):\n",
      "        trans_homo = np.array([\n",
      "            [1, 0, -origin[0]],\n",
      "            [0, 1, -origin[1]],\n",
      "            [0, 0, 1]], dtype=np.float64)\n",
      "        ratio_homo = np.array([\n",
      "            [ratio_px_mm, 0, 0],\n",
      "            [0, ratio_px_mm, 0],\n",
      "            [0, 0, 1]\n",
      "        ], dtype=np.float64)\n",
      "        return ratio_homo.dot(trans_homo)\n",
      "\n",
      "    def determine_mapping_parameters(self, path_l, path_r, angl_l, angl_r,\n",
      "                                     cam_id_l, cam_id_r, stitcher_type):\n",
      "        \"\"\"Determine the parameters for mapping of images and coordinates.\n",
      "\n",
      "        This functions is used to calculate all needed data to stitch two images and to map\n",
      "        image coordinates/angels to hive coordinates/angles.\n",
      "\n",
      "        Args:\n",
      "            path_l (str): Path to the left image.\n",
      "            path_r (str): Path to the right image.\n",
      "            angl_l (int): Angle in degree to rotate left image.\n",
      "            angl_r (int): Angle in degree to rotate right image.\n",
      "            cam_id_l (int): ID of the camera, which shot the left image.\n",
      "            cam_id_r (int): ID of the camera, which shot the right image.\n",
      "            stitcher_type (Stitcher): Stitcher to use for stitching of the images.\n",
      "        \"\"\"\n",
      "        assert stitcher.Stitcher in stitcher_type.__bases__\n",
      "        img_l = cv2.imread(path_l, -1)\n",
      "        img_r = cv2.imread(path_r, -1)\n",
      "        stitch = stitcher_type(self.config)\n",
      "        stitch.estimate_transform(img_l, img_r, angl_l, angl_r)\n",
      "\n",
      "        panorama = stitch.compose_panorama(img_l, img_r)\n",
      "\n",
      "        stitching_params = stitch.get_parameters()\n",
      "        self.homo_left = stitching_params.homo_left\n",
      "        self.homo_right = stitching_params.homo_right\n",
      "        self.size_left = stitching_params.size_left\n",
      "        self.size_right = stitching_params.size_right\n",
      "        self.origin = measure.get_origin(panorama)\n",
      "        self.ratio_px_mm = measure.get_ratio(panorama)\n",
      "        self.cam_id_left = cam_id_l\n",
      "        self.cam_id_right = cam_id_r\n",
      "\n",
      "        # modify homographies from the stitcher to map points to world coordinates\n",
      "        self._world_homo = Surveyor._determine_world_homo(self.origin, self.ratio_px_mm)\n",
      "        self._world_homo_left = self._world_homo.dot(self.homo_left)\n",
      "        self._world_homo_right = self._world_homo.dot(self.homo_right)\n",
      "\n",
      "    def get_parameters(self):\n",
      "        \"\"\"Return the estimated or loaded parameters of the :obj:`Surveyor` needed for later stitching.\n",
      "\n",
      "        With this function you could save the :obj:`Surveyor` parameters and load them later for\n",
      "        further stitching of images and mapping of image coordinates/angels to hive\n",
      "        coordinates/angles in relation to hive.\n",
      "        \"\"\"\n",
      "        StitchingParams = collections.namedtuple('SurveyorParams', ['homo_left', 'homo_right',\n",
      "                                                                    'size_left', 'size_right',\n",
      "                                                                    'cam_id_left', 'cam_id_right',\n",
      "                                                                    'origin', 'ratio_px_mm'])\n",
      "        result = StitchingParams(self.homo_left, self.homo_right,\n",
      "                                 self.size_left, self.size_right,\n",
      "                                 self.cam_id_left, self.cam_id_right,\n",
      "                                 self.origin, self.ratio_px_mm)\n",
      "        return result\n",
      "\n",
      "    def set_parameters(self, homo_left, homo_right, size_left, size_right, cam_id_l, cam_id_r,\n",
      "                       origin, ratio_px_mm):\n",
      "        \"\"\"Load needed parameters for mapping image points/angles to hive coordinates/angles.\n",
      "\n",
      "        This function becomes handy if you calculated the parameters in an earlier surveying\n",
      "        process and did not want to calculate the parameters again and just want to map image\n",
      "        points/angles to hive coordinates/angles.\n",
      "\n",
      "        Args:\n",
      "            homo_left (ndarray): homography *(3,3)* for data from the left side to form a panorama.\n",
      "            homo_right (ndarray): homography *(3,3)* for data from the right side to form a \\\n",
      "            panorama.\n",
      "            size_left (tuple): Size of the left image in px, which was used to calculate \\\n",
      "            homography.\n",
      "            size_right (tuple): Size of the right image in px, which was used to calculate \\\n",
      "            homography.\n",
      "            cam_id_l (int): ID of the camera, which shot the left image.\n",
      "            cam_id_r (int): ID of the camera, which shot the right image.\n",
      "            origin (ndarray): Origin of the stitched data/image in px *(2,)*.\n",
      "            ratio_px_mm (float): Ratio to convert pixel to mm.\n",
      "            pano_size (tuple): Size of the panorama in px.\n",
      "        \"\"\"\n",
      "        self.homo_left = homo_left\n",
      "        self.homo_right = homo_right\n",
      "        self.size_left = size_left\n",
      "        self.size_right = size_right\n",
      "        self.cam_id_left = cam_id_l\n",
      "        self.cam_id_right = cam_id_r\n",
      "        self.origin = origin\n",
      "        self.ratio_px_mm = ratio_px_mm\n",
      "\n",
      "        # modify homographies from the stitcher to map points to world coordinates\n",
      "        self._world_homo = Surveyor._determine_world_homo(self.origin, self.ratio_px_mm)\n",
      "        self._world_homo_left = self._world_homo.dot(self.homo_left)\n",
      "        self._world_homo_right = self._world_homo.dot(self.homo_right)\n",
      "\n",
      "    def map_points_angles(self, points, angles, cam_id):\n",
      "        u\"\"\"Map image points/angles to points/angles in relation to world/hive.\n",
      "\n",
      "        This happens under the assumption that the mapping parameters were estimated or loaded\n",
      "        before.\n",
      "\n",
      "        Args:\n",
      "            points (ndarray): List of points from left image in px *(N,2)*.\n",
      "            angles (ndarray): Angles in rad (length *(N,)*).\n",
      "            cam_id (ndarray): ID of the camera, which shot the image.\n",
      "\n",
      "        Returns:\n",
      "            - **points_mapped** (ndarray) -- ``points`` mapped to hive in mm *(N,2)*.\n",
      "            - **angles_mapped** (ndarray) -- ``angles`` mapped to  *(N,)*.\n",
      "\n",
      "        Note:\n",
      "            For all angles in ``angles`` it is assumed that a 0-angle shows to the right border of\n",
      "            the image and that a positive angle means clockwise rotation.\n",
      "        \"\"\"\n",
      "        self._stitcher = self._stitcher or stitcher.Stitcher(self.config)\n",
      "\n",
      "        # using modified homographies to map points and angles to world coordinates\n",
      "        self._stitcher.load_parameters(self._world_homo_left, self._world_homo_right,\n",
      "                                       self.size_left, self.size_right)\n",
      "\n",
      "        if cam_id == self.cam_id_left:\n",
      "            points, angles = self._stitcher.map_left_points_angles(points, angles)\n",
      "        elif cam_id == self.cam_id_right:\n",
      "            points, angles = self._stitcher.map_right_points_angles(points, angles)\n",
      "        else:\n",
      "            raise ValueError('Got invalid cam_id {invalid_ID} cam_id must be '\n",
      "                             '{left_ID} or {right_ID}.'.format(invalid_ID=cam_id,\n",
      "                                                               left_ID=self.cam_id_left,\n",
      "                                                               right_ID=self.cam_id_right)\n",
      "                             )\n",
      "        return points, angles\n",
      "\n",
      "    def compose_panorama(self, path_l, path_r, grid=False):\n",
      "        \"\"\"Try to compose the given images into the final panorama.\n",
      "\n",
      "        This happens under the assumption that the mapping parameters were estimated or loaded\n",
      "        before.\n",
      "\n",
      "        Args:\n",
      "            path_l (str): Path to the left image.\n",
      "            path_r (str): Path to the right image.\n",
      "            grid (bool, optional): If ``True`` a grid with axes in mm will be drawn on the image.\n",
      "        \"\"\"\n",
      "        # TODO(gitmirgut): PoC draw grid in dependency of step_size\n",
      "        stitch = stitcher.Stitcher(self.config)\n",
      "        stitch.load_parameters(self.homo_left, self.homo_right,\n",
      "                               self.size_left, self.size_right)\n",
      "        image_left = cv2.imread(path_l, -1)\n",
      "        image_right = cv2.imread(path_r, -1)\n",
      "        pano = stitch.compose_panorama(image_left, image_right)\n",
      "        if grid:\n",
      "            visualisation.draw_grid(pano, self.origin, self.ratio_px_mm, step_size_mm=8)\n",
      "        return pano\n",
      "\n",
      "Output: {'core': [], 'core.Surveyor.__init__': ['bb_stitcher.helpers.get_default_config'], 'bb_stitcher.helpers.get_default_config': [], 'core.Surveyor._acept_filehandler': [], 'core.Surveyor.load': ['core.Surveyor._acept_filehandler', 'bb_stitcher.io_utils.get_file_handler', 'core.Surveyor._determine_world_homo'], 'bb_stitcher.io_utils.get_file_handler': [], 'core.Surveyor._determine_world_homo': ['numpy.array'], 'core.Surveyor.save': ['core.Surveyor._acept_filehandler', 'bb_stitcher.io_utils.get_file_handler'], 'numpy.array': [], 'core.Surveyor.determine_mapping_parameters': ['cv2.imread', 'bb_stitcher.measure.get_origin', 'bb_stitcher.measure.get_ratio', 'core.Surveyor._determine_world_homo'], 'cv2.imread': [], 'bb_stitcher.measure.get_origin': [], 'bb_stitcher.measure.get_ratio': [], 'core.Surveyor.get_parameters': ['collections.namedtuple'], 'collections.namedtuple': [], 'core.Surveyor.set_parameters': ['core.Surveyor._determine_world_homo'], 'core.Surveyor.map_points_angles': ['bb_stitcher.stitcher.Stitcher', '<builtin>.ValueError'], 'bb_stitcher.stitcher.Stitcher': [], '<builtin>.ValueError': [], 'core.Surveyor.compose_panorama': ['cv2.imread', 'bb_stitcher.visualisation.draw_grid', 'bb_stitcher.stitcher.Stitcher'], 'bb_stitcher.visualisation.draw_grid': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\bb_stitcher\\core.py\n",
      "[('core Surveyor __init__', 'bb_stitcher helpers get_default_config'), ('core Surveyor load', 'core Surveyor _acept_filehandler'), ('core Surveyor load', 'bb_stitcher io_utils get_file_handler'), ('core Surveyor load', 'core Surveyor _determine_world_homo'), ('core Surveyor _determine_world_homo', 'numpy array'), ('core Surveyor save', 'core Surveyor _acept_filehandler'), ('core Surveyor save', 'bb_stitcher io_utils get_file_handler'), ('core Surveyor determine_mapping_parameters', 'cv2 imread'), ('core Surveyor determine_mapping_parameters', 'bb_stitcher measure get_origin'), ('core Surveyor determine_mapping_parameters', 'bb_stitcher measure get_ratio'), ('core Surveyor determine_mapping_parameters', 'core Surveyor _determine_world_homo'), ('core Surveyor get_parameters', 'collections namedtuple'), ('core Surveyor set_parameters', 'core Surveyor _determine_world_homo'), ('core Surveyor map_points_angles', 'bb_stitcher stitcher Stitcher'), ('core Surveyor compose_panorama', 'cv2 imread'), ('core Surveyor compose_panorama', 'bb_stitcher visualisation draw_grid'), ('core Surveyor compose_panorama', 'bb_stitcher stitcher Stitcher')]\n",
      "0\n",
      "found files: []\n",
      "import argparse\n",
      "import os\n",
      "import sys\n",
      "\n",
      "import numpy as np\n",
      "import pytest\n",
      "\n",
      "import bb_stitcher.measure\n",
      "import bb_stitcher.picking\n",
      "import bb_stitcher.scripts.bb_stitcher as script_bb_stitcher\n",
      "import bb_stitcher.io_utils as io_utils\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def outdir(main_outdir):\n",
      "    out_path = os.path.join(main_outdir, str(__name__))\n",
      "    if not os.path.exists(out_path):\n",
      "        os.makedirs(out_path)\n",
      "    return out_path\n",
      "\n",
      "\n",
      "def test_exist_path():\n",
      "    with pytest.raises(argparse.ArgumentTypeError):\n",
      "        script_bb_stitcher._exist_path('move_along_no_file_to_see_here')\n",
      "\n",
      "    assert __file__ == script_bb_stitcher._exist_path(__file__)\n",
      "\n",
      "\n",
      "def test_data_path():\n",
      "    for ext in io_utils.valid_ext:\n",
      "        output_file = ''.join(['file', ext])\n",
      "        assert output_file == script_bb_stitcher._data_path(output_file)\n",
      "\n",
      "    with pytest.raises(argparse.ArgumentTypeError):\n",
      "        script_bb_stitcher._data_path('file_with_bad_extension.666')\n",
      "\n",
      "\n",
      "def test_img_path():\n",
      "    for ext in ['.jpeg', '.jpg', '.png']:\n",
      "        img_path = ''.join(['img', ext])\n",
      "        assert img_path == script_bb_stitcher._img_path(img_path)\n",
      "\n",
      "    with pytest.raises(argparse.ArgumentTypeError):\n",
      "        script_bb_stitcher._img_path('eps2.9_pyth0n-pt1.p7z')\n",
      "\n",
      "\n",
      "def test_get_main_parser(left_img, right_img, surveyor_csv_path):\n",
      "    # todo(gitmirgut) better test on bad values see\n",
      "    # http://stackoverflow.com/questions/18651705/argparse-unit-tests-suppress-the-help-message#18652005\n",
      "    main_parser = script_bb_stitcher._get_main_parser()\n",
      "    cmd = 'estimate fb {left_img} {right_img} 90 -90 0 1  test.csv'.format(\n",
      "        left_img=left_img['path'],\n",
      "        right_img=right_img['path']\n",
      "    )\n",
      "    main_parser.parse_args(cmd.split())\n",
      "\n",
      "    cmd = 'estimate rect {left_img} {right_img} 90 -90 0 1  test.csv'.format(\n",
      "        left_img=left_img['path'],\n",
      "        right_img=right_img['path']\n",
      "    )\n",
      "    main_parser.parse_args(cmd.split())\n",
      "\n",
      "    cmd = 'compose {left_img} {right_img} {data_path} pano.jpg'.format(\n",
      "        left_img=left_img['path'],\n",
      "        right_img=right_img['path'],\n",
      "        data_path=surveyor_csv_path\n",
      "    )\n",
      "    main_parser.parse_args(cmd.split())\n",
      "\n",
      "\n",
      "def test_overall_compose(left_img, right_img, surveyor_csv_path, outdir, monkeypatch):\n",
      "    out = os.path.join(outdir, 'panorama_compose.jpg')\n",
      "    cmd = 'bb_stitcher compose {left} {right} {data} {out} -g'.format(left=left_img['path'],\n",
      "                                                                      right=right_img['path'],\n",
      "                                                                      data=surveyor_csv_path,\n",
      "                                                                      out=out\n",
      "                                                                      )\n",
      "    monkeypatch.setattr(sys, 'argv', cmd.split())\n",
      "    script_bb_stitcher.main()\n",
      "    assert os.path.exists(out)\n",
      "\n",
      "\n",
      "def test_overall_estimate_rect(left_img, right_img, outdir, monkeypatch):\n",
      "    out = os.path.join(outdir, 'data_rect.csv')\n",
      "    cmd = 'bb_stitcher estimate rect {left} {right} {left_angle} {right_angle} ' \\\n",
      "          '{left_camId} {right_camId} {out}'.format(left=left_img['path'],\n",
      "                                                    right=right_img['path'],\n",
      "                                                    left_angle=left_img['angle'],\n",
      "                                                    right_angle=right_img['angle'],\n",
      "                                                    left_camId=left_img['cam_id'],\n",
      "                                                    right_camId=right_img['cam_id'],\n",
      "                                                    out=out)\n",
      "\n",
      "    def mock_pick(myself, image_list, all):\n",
      "        left_points = np.array([\n",
      "            [88.91666412, 3632.6015625],\n",
      "            [2760.26855469, 3636.70849609],\n",
      "            [2726.26708984, 363.4861145],\n",
      "            [93.88884735, 371.98330688]], dtype=np.float32)\n",
      "        right_points = np.array([\n",
      "            [181.49372864, 3687.71582031],\n",
      "            [2903.44042969, 3723.99926758],\n",
      "            [2921.27368164, 458.77352905],\n",
      "            [255.66642761, 431.24780273]], dtype=np.float32)\n",
      "        return left_points, right_points\n",
      "\n",
      "    def mock_get_origin(image):\n",
      "        return np.array([94.43029022, 471.89901733])\n",
      "\n",
      "    def mock_get_ratio(image):\n",
      "        return 0.0644410123918\n",
      "\n",
      "    monkeypatch.setattr(sys, 'argv', cmd.split())\n",
      "    monkeypatch.setattr(bb_stitcher.picking.picker.PointPicker, 'pick', mock_pick)\n",
      "    monkeypatch.setattr(bb_stitcher.measure, 'get_origin', mock_get_origin)\n",
      "    monkeypatch.setattr(bb_stitcher.measure, 'get_ratio', mock_get_ratio)\n",
      "    script_bb_stitcher.main()\n",
      "    assert os.path.exists(out)\n",
      "\n",
      "\n",
      "def test_overall_estimate_fb(left_img, right_img, outdir, monkeypatch):\n",
      "    out = os.path.join(outdir, 'data_fb.npz')\n",
      "    cmd = 'bb_stitcher estimate fb {left} {right} {left_angle} {right_angle} ' \\\n",
      "          '{left_camId} {right_camId} {out}'.format(left=left_img['path'],\n",
      "                                                    right=right_img['path'],\n",
      "                                                    left_angle=left_img['angle'],\n",
      "                                                    right_angle=right_img['angle'],\n",
      "                                                    left_camId=left_img['cam_id'],\n",
      "                                                    right_camId=right_img['cam_id'],\n",
      "                                                    out=out)\n",
      "\n",
      "    def mock_get_origin(image):\n",
      "        return np.array([94.43029022, 471.89901733])\n",
      "\n",
      "    def mock_get_ratio(image):\n",
      "        return 0.0644410123918\n",
      "\n",
      "    monkeypatch.setattr(sys, 'argv', cmd.split())\n",
      "    monkeypatch.setattr(bb_stitcher.measure, 'get_origin', mock_get_origin)\n",
      "    monkeypatch.setattr(bb_stitcher.measure, 'get_ratio', mock_get_ratio)\n",
      "    script_bb_stitcher.main()\n",
      "    assert os.path.exists(out)\n",
      "\n",
      "Output: {'test_script_bb_stitcher': ['pytest.fixture'], 'pytest.fixture': [], 'test_script_bb_stitcher.outdir': ['os.makedirs', 'os.path.exists', 'os.path.join', '<builtin>.str'], '<builtin>.str': [], 'os.path.join': [], 'os.path.exists': [], 'os.makedirs': [], 'test_script_bb_stitcher.test_exist_path': ['pytest.raises', 'bb_stitcher.scripts.bb_stitcher._exist_path'], 'pytest.raises': [], 'bb_stitcher.scripts.bb_stitcher._exist_path': [], 'test_script_bb_stitcher.test_data_path': ['bb_stitcher.scripts.bb_stitcher._data_path', 'pytest.raises'], 'bb_stitcher.scripts.bb_stitcher._data_path': [], 'test_script_bb_stitcher.test_img_path': ['pytest.raises', 'bb_stitcher.scripts.bb_stitcher._img_path'], 'bb_stitcher.scripts.bb_stitcher._img_path': [], 'test_script_bb_stitcher.test_get_main_parser': ['bb_stitcher.scripts.bb_stitcher._get_main_parser'], 'bb_stitcher.scripts.bb_stitcher._get_main_parser': [], 'test_script_bb_stitcher.test_overall_compose': ['bb_stitcher.scripts.bb_stitcher.main', 'os.path.exists', 'os.path.join'], 'bb_stitcher.scripts.bb_stitcher.main': [], 'test_script_bb_stitcher.test_overall_estimate_rect': ['bb_stitcher.scripts.bb_stitcher.main', 'os.path.exists', 'os.path.join'], 'test_script_bb_stitcher.test_overall_estimate_rect.mock_pick': ['numpy.array'], 'numpy.array': [], 'test_script_bb_stitcher.test_overall_estimate_rect.mock_get_origin': ['numpy.array'], 'test_script_bb_stitcher.test_overall_estimate_rect.mock_get_ratio': [], 'test_script_bb_stitcher.test_overall_estimate_fb': ['bb_stitcher.scripts.bb_stitcher.main', 'os.path.exists', 'os.path.join'], 'test_script_bb_stitcher.test_overall_estimate_fb.mock_get_origin': ['numpy.array'], 'test_script_bb_stitcher.test_overall_estimate_fb.mock_get_ratio': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\tests\\test_script_bb_stitcher.py\n",
      "[('test_script_bb_stitcher', 'pytest fixture'), ('test_script_bb_stitcher outdir', 'os makedirs'), ('test_script_bb_stitcher outdir', 'os path exists'), ('test_script_bb_stitcher outdir', 'os path join'), ('test_script_bb_stitcher test_exist_path', 'pytest raises'), ('test_script_bb_stitcher test_exist_path', 'bb_stitcher scripts bb_stitcher _exist_path'), ('test_script_bb_stitcher test_data_path', 'bb_stitcher scripts bb_stitcher _data_path'), ('test_script_bb_stitcher test_data_path', 'pytest raises'), ('test_script_bb_stitcher test_img_path', 'pytest raises'), ('test_script_bb_stitcher test_img_path', 'bb_stitcher scripts bb_stitcher _img_path'), ('test_script_bb_stitcher test_get_main_parser', 'bb_stitcher scripts bb_stitcher _get_main_parser'), ('test_script_bb_stitcher test_overall_compose', 'bb_stitcher scripts bb_stitcher main'), ('test_script_bb_stitcher test_overall_compose', 'os path exists'), ('test_script_bb_stitcher test_overall_compose', 'os path join'), ('test_script_bb_stitcher test_overall_estimate_rect', 'bb_stitcher scripts bb_stitcher main'), ('test_script_bb_stitcher test_overall_estimate_rect', 'os path exists'), ('test_script_bb_stitcher test_overall_estimate_rect', 'os path join'), ('test_script_bb_stitcher test_overall_estimate_rect mock_pick', 'numpy array'), ('test_script_bb_stitcher test_overall_estimate_rect mock_get_origin', 'numpy array'), ('test_script_bb_stitcher test_overall_estimate_fb', 'bb_stitcher scripts bb_stitcher main'), ('test_script_bb_stitcher test_overall_estimate_fb', 'os path exists'), ('test_script_bb_stitcher test_overall_estimate_fb', 'os path join'), ('test_script_bb_stitcher test_overall_estimate_fb mock_get_origin', 'numpy array')]\n",
      "0\n",
      "found files: []\n",
      "import os\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "import pytest\n",
      "\n",
      "import bb_stitcher.visualisation as visualisation\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def outdir(main_outdir):\n",
      "    out_path = os.path.join(main_outdir, str(__name__))\n",
      "    if not os.path.exists(out_path):\n",
      "        os.makedirs(out_path)\n",
      "    return out_path\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def sample():\n",
      "    return np.ones((310, 310, 3), dtype=np.uint8) * 255\n",
      "\n",
      "\n",
      "def test_draw_arrows(sample, outdir):\n",
      "    positions = np.ones((9, 2)) * 155\n",
      "    angles = np.ones((9,))\n",
      "    for i, val in enumerate(range(- 4, 5)):\n",
      "        angles[i] = val * np.pi / 4\n",
      "    visualisation.draw_arrows(sample, positions, angles)\n",
      "    out = os.path.join(outdir, 'draw_arrows.jpg')\n",
      "    cv2.imwrite(out, sample)\n",
      "\n",
      "\n",
      "def test_draw_circles(sample, outdir):\n",
      "    positions = np.array([[75, 155], [150, 155], [225, 155]])\n",
      "    visualisation.draw_circles(sample, positions)\n",
      "    out = os.path.join(outdir, 'draw_circles.jpg')\n",
      "    cv2.imwrite(out, sample)\n",
      "\n",
      "\n",
      "def test_draw_marks(sample, outdir):\n",
      "    positions = np.array([[75, 155], [150, 155], [225, 155]])\n",
      "    visualisation.draw_marks(sample, positions)\n",
      "    out = os.path.join(outdir, 'draw_marks.jpg')\n",
      "    cv2.imwrite(out, sample)\n",
      "\n",
      "\n",
      "def test_draw_complex_marks(outdir):\n",
      "    image = np.ones((900, 900, 3), dtype=np.uint8) * 255\n",
      "    positions = np.array([\n",
      "        [150, 150],\n",
      "        [450, 150],\n",
      "        [750, 150],\n",
      "        [150, 450],\n",
      "        [450, 450],\n",
      "        [750, 450],\n",
      "        [150, 750],\n",
      "        [450, 750],\n",
      "        [750, 750],\n",
      "    ])\n",
      "    angles = np.ones((9,))\n",
      "    for i, val in enumerate(range(-4, 5)):\n",
      "        angles[i] = val * np.pi / 4\n",
      "    visualisation.draw_complex_marks(image, positions, angles)\n",
      "    out = os.path.join(outdir, 'draw_complex.jpg')\n",
      "    cv2.imwrite(out, image)\n",
      "\n",
      "\n",
      "def test_draw_grid(panorama, outdir):\n",
      "    origin = np.array([94.43029022, 471.89901733], dtype=np.float32)\n",
      "    ratio = 0.0644410123918\n",
      "    visualisation.draw_grid(panorama, origin, ratio, step_size_mm=8)\n",
      "    out = os.path.join(outdir, 'draw_grid.jpg')\n",
      "    cv2.imwrite(out, panorama)\n",
      "\n",
      "Output: {'test_visualisation': ['pytest.fixture'], 'pytest.fixture': [], 'test_visualisation.outdir': ['os.makedirs', 'os.path.exists', 'os.path.join', '<builtin>.str'], '<builtin>.str': [], 'os.path.join': [], 'os.path.exists': [], 'os.makedirs': [], 'test_visualisation.sample': ['numpy.ones'], 'numpy.ones': [], 'test_visualisation.test_draw_arrows': ['<builtin>.range', 'bb_stitcher.visualisation.draw_arrows', '<builtin>.enumerate', 'cv2.imwrite', 'numpy.ones', 'os.path.join'], '<builtin>.range': [], '<builtin>.enumerate': [], 'bb_stitcher.visualisation.draw_arrows': [], 'cv2.imwrite': [], 'test_visualisation.test_draw_circles': ['numpy.array', 'cv2.imwrite', 'os.path.join', 'bb_stitcher.visualisation.draw_circles'], 'numpy.array': [], 'bb_stitcher.visualisation.draw_circles': [], 'test_visualisation.test_draw_marks': ['bb_stitcher.visualisation.draw_marks', 'numpy.array', 'os.path.join', 'cv2.imwrite'], 'bb_stitcher.visualisation.draw_marks': [], 'test_visualisation.test_draw_complex_marks': ['<builtin>.range', 'numpy.array', '<builtin>.enumerate', 'bb_stitcher.visualisation.draw_complex_marks', 'cv2.imwrite', 'numpy.ones', 'os.path.join'], 'bb_stitcher.visualisation.draw_complex_marks': [], 'test_visualisation.test_draw_grid': ['os.path.join', 'numpy.array', 'bb_stitcher.visualisation.draw_grid', 'cv2.imwrite'], 'bb_stitcher.visualisation.draw_grid': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\tests\\test_visualisation.py\n",
      "[('test_visualisation', 'pytest fixture'), ('test_visualisation outdir', 'os makedirs'), ('test_visualisation outdir', 'os path exists'), ('test_visualisation outdir', 'os path join'), ('test_visualisation sample', 'numpy ones'), ('test_visualisation test_draw_arrows', 'bb_stitcher visualisation draw_arrows'), ('test_visualisation test_draw_arrows', 'cv2 imwrite'), ('test_visualisation test_draw_arrows', 'numpy ones'), ('test_visualisation test_draw_arrows', 'os path join'), ('test_visualisation test_draw_circles', 'numpy array'), ('test_visualisation test_draw_circles', 'cv2 imwrite'), ('test_visualisation test_draw_circles', 'os path join'), ('test_visualisation test_draw_circles', 'bb_stitcher visualisation draw_circles'), ('test_visualisation test_draw_marks', 'bb_stitcher visualisation draw_marks'), ('test_visualisation test_draw_marks', 'numpy array'), ('test_visualisation test_draw_marks', 'os path join'), ('test_visualisation test_draw_marks', 'cv2 imwrite'), ('test_visualisation test_draw_complex_marks', 'numpy array'), ('test_visualisation test_draw_complex_marks', 'bb_stitcher visualisation draw_complex_marks'), ('test_visualisation test_draw_complex_marks', 'cv2 imwrite'), ('test_visualisation test_draw_complex_marks', 'numpy ones'), ('test_visualisation test_draw_complex_marks', 'os path join'), ('test_visualisation test_draw_grid', 'os path join'), ('test_visualisation test_draw_grid', 'numpy array'), ('test_visualisation test_draw_grid', 'bb_stitcher visualisation draw_grid'), ('test_visualisation test_draw_grid', 'cv2 imwrite')]\n",
      "0\n",
      "found files: []\n",
      "import numpy as np\n",
      "import numpy.testing as npt\n",
      "import pytest\n",
      "\n",
      "import bb_stitcher.helpers as helpers\n",
      "\n",
      "\n",
      "def test_get_boundaries():\n",
      "    size_left = (4, 3)\n",
      "    size_right = (5, 2)\n",
      "    homo_left = np.float32([[1, 0, -1],\n",
      "                            [0, 1, 0],\n",
      "                            [0, 0, 1]])\n",
      "    homo_right = np.float32([[1, 0, 3],\n",
      "                             [0, 1, -2],\n",
      "                             [0, 0, 1]])\n",
      "    bounds = helpers.get_boundaries(size_left, size_right, homo_left, homo_right)\n",
      "    target_bounds = (-1, -2, 8, 3)\n",
      "    assert bounds == target_bounds\n",
      "\n",
      "\n",
      "def test_get_transform_to_origin_mat():\n",
      "    homo = helpers.get_transform_to_origin_mat(-1, -3)\n",
      "    target_homo = np.float32([\n",
      "        [1, 0, 1],\n",
      "        [0, 1, 3],\n",
      "        [0, 0, 1]\n",
      "    ])\n",
      "    npt.assert_equal(homo, target_homo)\n",
      "    homo = helpers.get_transform_to_origin_mat(1.3, -3)\n",
      "    target_homo = np.float32([\n",
      "        [1, 0, -1.3],\n",
      "        [0, 1, 3],\n",
      "        [0, 0, 1]\n",
      "    ])\n",
      "    npt.assert_equal(homo, target_homo)\n",
      "    homo = helpers.get_transform_to_origin_mat(1, 3)\n",
      "    target_homo = np.float32([\n",
      "        [1, 0, -1],\n",
      "        [0, 1, -3],\n",
      "        [0, 0, 1]\n",
      "    ])\n",
      "    npt.assert_equal(homo, target_homo)\n",
      "    homo = helpers.get_transform_to_origin_mat(-1, 3)\n",
      "    target_homo = np.float32([\n",
      "        [1, 0, 1],\n",
      "        [0, 1, -3],\n",
      "        [0, 0, 1]\n",
      "    ])\n",
      "    npt.assert_equal(homo, target_homo)\n",
      "\n",
      "\n",
      "def test_add_alpha_channel(left_img):\n",
      "    color = left_img['color']\n",
      "    w, h = left_img['size']\n",
      "\n",
      "    # test color image without alpha channel\n",
      "    target = helpers.add_alpha_channel(color)\n",
      "    assert target.shape == (h, w, 4)\n",
      "\n",
      "    # test black and white image\n",
      "    img_bw = left_img['bw']\n",
      "    target = helpers.add_alpha_channel(img_bw)\n",
      "    assert target.shape == (h, w, 4)\n",
      "\n",
      "    # test already alpha\n",
      "    img_alpha = np.zeros((3000, 4000, 4), dtype=np.uint8)\n",
      "    helpers.add_alpha_channel(img_alpha)\n",
      "    assert img_alpha.shape == (h, w, 4)\n",
      "\n",
      "    # provoke exception\n",
      "    img_not = np.zeros((3000, 4000, 5), dtype=np.uint8)\n",
      "    with pytest.raises(Exception):\n",
      "        helpers.add_alpha_channel(img_not)\n",
      "\n",
      "    # provoke exception\n",
      "    img_not = np.zeros((3000, 4000, 5, 4), dtype=np.uint8)\n",
      "    with pytest.raises(Exception):\n",
      "        helpers.add_alpha_channel(img_not)\n",
      "\n",
      "\n",
      "def test_form_rectangle():\n",
      "    height = 4\n",
      "    width = 3\n",
      "    target = np.array([\n",
      "        [0, 0],\n",
      "        [3, 0],\n",
      "        [3, 4],\n",
      "        [0, 4]\n",
      "    ])\n",
      "    result = helpers.form_rectangle(width, height)\n",
      "    npt.assert_equal(result, target)\n",
      "\n",
      "\n",
      "def test_sort_pts():\n",
      "    # TODO(gitmirgut) Add more test.\n",
      "    points = np.array([\n",
      "        [2, 2],\n",
      "        [2, 1],\n",
      "        [1, 1],\n",
      "        [1, 2]])\n",
      "    target_points = np.array([\n",
      "        [1, 1],\n",
      "        [2, 1],\n",
      "        [2, 2],\n",
      "        [1, 2]], dtype=np.float32)\n",
      "    sorted_points = helpers.sort_pts(points)\n",
      "    npt.assert_equal(sorted_points, target_points)\n",
      "\n",
      "\n",
      "def test_raw_estimate_rect():\n",
      "    points = np.array([\n",
      "        [2, 2],\n",
      "        [6, 1],\n",
      "        [8, 8],\n",
      "        [1, 7]\n",
      "    ], dtype=np.float32)\n",
      "    target_points = np.array([\n",
      "        [0, 0],\n",
      "        [7.0710, 0],\n",
      "        [7.0710, 7.2801],\n",
      "        [0, 7.2801]\n",
      "    ])\n",
      "    result = helpers.raw_estimate_rect(points)\n",
      "    npt.assert_almost_equal(result, target_points, decimal=4)\n",
      "\n",
      "\n",
      "def test_harmonize_rects():\n",
      "    rect_a = np.array([\n",
      "        [0, 0],\n",
      "        [5, 0],\n",
      "        [5, 4],\n",
      "        [0, 4]\n",
      "    ], dtype=np.float32)\n",
      "\n",
      "    rect_b = np.array([\n",
      "        [0, 0],\n",
      "        [7, 0],\n",
      "        [7, 6],\n",
      "        [0, 6]\n",
      "    ], dtype=np.float32)\n",
      "\n",
      "    target_rect_a = np.array([\n",
      "        [0, 0],\n",
      "        [7.5, 0],\n",
      "        [7.5, 6],\n",
      "        [0, 6]\n",
      "    ], dtype=np.float32)\n",
      "    new_rect_a, new_rect_b = helpers.harmonize_rects(rect_a, rect_b)\n",
      "    npt.assert_equal(new_rect_a, target_rect_a)\n",
      "    npt.assert_equal(new_rect_b, rect_b)\n",
      "\n",
      "    new_rect_b, new_rect_a = helpers.harmonize_rects(rect_b, rect_a)\n",
      "    npt.assert_equal(new_rect_a, target_rect_a)\n",
      "    npt.assert_equal(new_rect_b, rect_b)\n",
      "\n",
      "\n",
      "def test_angles_to_points():\n",
      "    angles = np.ones((5,))\n",
      "    for i, val in enumerate(range(- 2, 3)):\n",
      "        angles[i] = val * np.pi / 2\n",
      "\n",
      "    points = np.zeros((5, 2), dtype=np.uint16)\n",
      "    target = np.array([\n",
      "        [-10, 0],\n",
      "        [0, -10],\n",
      "        [10, 0],\n",
      "        [0, 10],\n",
      "        [-10, 0]\n",
      "    ])\n",
      "    result = helpers.angles_to_points(points, angles, 10)\n",
      "    npt.assert_almost_equal(result, target)\n",
      "\n",
      "    points = np.ones((5, 2), dtype=np.uint16) * 10\n",
      "    target = np.array([\n",
      "        [0, 10],\n",
      "        [10, 0],\n",
      "        [20, 10],\n",
      "        [10, 20],\n",
      "        [0, 10]\n",
      "    ])\n",
      "    result = helpers.angles_to_points(points, angles, 10)\n",
      "    npt.assert_almost_equal(result, target)\n",
      "\n",
      "\n",
      "def test_points_to_angles(error_params):\n",
      "    angle_centers = np.zeros((5, 2), dtype=np.uint16)\n",
      "    points_repr = np.array([\n",
      "        [-10, - 0.00000001],  # if it would be zero it will be pi\n",
      "        [0, -10],\n",
      "        [10, 0],\n",
      "        [0, 10],\n",
      "        [-10, 0]\n",
      "    ])\n",
      "    target = np.ones((5,))\n",
      "    for i, val in enumerate(range(- 2, 3)):\n",
      "        target[i] = val * np.pi / 2\n",
      "    result = helpers.points_to_angles(angle_centers, points_repr)\n",
      "    npt.assert_almost_equal(result, target, decimal=7)\n",
      "\n",
      "    angle_centers = np.ones((1, 2))\n",
      "    points_repr = np.ones((1, 2))\n",
      "    with pytest.raises(Exception):\n",
      "        helpers.points_to_angles(angle_centers, points_repr)\n",
      "\n",
      "    # the following values are from a real bb_binary\n",
      "    # hard to reconstruct with real values.\n",
      "    angle_centers, points_repr = error_params\n",
      "\n",
      "    target = np.array([0.])\n",
      "    result = helpers.points_to_angles(angle_centers, points_repr)\n",
      "    npt.assert_equal(target, result)\n",
      "\n",
      "\n",
      "def test_get_ratio_px_to_mm():\n",
      "    start_point = np.array([0, 0])\n",
      "    end_point = np.array([30, 40])\n",
      "    distance_mm = 25\n",
      "    px_to_mm = helpers.get_ratio_px_to_mm(start_point, end_point, distance_mm)\n",
      "    assert px_to_mm == 0.5\n",
      "\n",
      "\n",
      "def test_get_default_config():\n",
      "    config = helpers.get_default_config()\n",
      "\n",
      "    config_set = {\n",
      "        'Rectificator',\n",
      "        'FeatureBasedStitcher',\n",
      "        'SURF',\n",
      "        'FeatureMatcher'}\n",
      "    assert set(config.sections()) == config_set\n",
      "\n",
      "\n",
      "def test_get_default_debug_config():\n",
      "    deb_config = helpers.get_default_debug_config()\n",
      "    assert 'loggers' in deb_config\n",
      "\n",
      "Output: {'test_helpers': [], 'test_helpers.test_get_boundaries': ['numpy.float32', 'bb_stitcher.helpers.get_boundaries'], 'numpy.float32': [], 'bb_stitcher.helpers.get_boundaries': [], 'test_helpers.test_get_transform_to_origin_mat': ['numpy.testing.assert_equal', 'numpy.float32', 'bb_stitcher.helpers.get_transform_to_origin_mat'], 'bb_stitcher.helpers.get_transform_to_origin_mat': [], 'numpy.testing.assert_equal': [], 'test_helpers.test_add_alpha_channel': ['bb_stitcher.helpers.add_alpha_channel', 'numpy.zeros', 'pytest.raises'], 'bb_stitcher.helpers.add_alpha_channel': [], 'numpy.zeros': [], 'pytest.raises': [], 'test_helpers.test_form_rectangle': ['numpy.testing.assert_equal', 'numpy.array', 'bb_stitcher.helpers.form_rectangle'], 'numpy.array': [], 'bb_stitcher.helpers.form_rectangle': [], 'test_helpers.test_sort_pts': ['numpy.testing.assert_equal', 'numpy.array', 'bb_stitcher.helpers.sort_pts'], 'bb_stitcher.helpers.sort_pts': [], 'test_helpers.test_raw_estimate_rect': ['bb_stitcher.helpers.raw_estimate_rect', 'numpy.array', 'numpy.testing.assert_almost_equal'], 'bb_stitcher.helpers.raw_estimate_rect': [], 'numpy.testing.assert_almost_equal': [], 'test_helpers.test_harmonize_rects': ['numpy.testing.assert_equal', 'numpy.array', 'bb_stitcher.helpers.harmonize_rects'], 'bb_stitcher.helpers.harmonize_rects': [], 'test_helpers.test_angles_to_points': ['numpy.array', 'bb_stitcher.helpers.angles_to_points', '<builtin>.range', 'numpy.zeros', 'numpy.ones', 'numpy.testing.assert_almost_equal', '<builtin>.enumerate'], 'numpy.ones': [], '<builtin>.range': [], '<builtin>.enumerate': [], 'bb_stitcher.helpers.angles_to_points': [], 'test_helpers.test_points_to_angles': ['numpy.array', 'pytest.raises', 'bb_stitcher.helpers.points_to_angles', '<builtin>.range', 'numpy.testing.assert_equal', 'numpy.zeros', 'numpy.ones', 'numpy.testing.assert_almost_equal', '<builtin>.enumerate'], 'bb_stitcher.helpers.points_to_angles': [], 'test_helpers.test_get_ratio_px_to_mm': ['numpy.array', 'bb_stitcher.helpers.get_ratio_px_to_mm'], 'bb_stitcher.helpers.get_ratio_px_to_mm': [], 'test_helpers.test_get_default_config': ['<builtin>.set', 'bb_stitcher.helpers.get_default_config'], 'bb_stitcher.helpers.get_default_config': [], '<builtin>.set': [], 'test_helpers.test_get_default_debug_config': ['bb_stitcher.helpers.get_default_debug_config'], 'bb_stitcher.helpers.get_default_debug_config': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\tests\\test_helpers.py\n",
      "[('test_helpers test_get_boundaries', 'numpy float32'), ('test_helpers test_get_boundaries', 'bb_stitcher helpers get_boundaries'), ('test_helpers test_get_transform_to_origin_mat', 'numpy testing assert_equal'), ('test_helpers test_get_transform_to_origin_mat', 'numpy float32'), ('test_helpers test_get_transform_to_origin_mat', 'bb_stitcher helpers get_transform_to_origin_mat'), ('test_helpers test_add_alpha_channel', 'bb_stitcher helpers add_alpha_channel'), ('test_helpers test_add_alpha_channel', 'numpy zeros'), ('test_helpers test_add_alpha_channel', 'pytest raises'), ('test_helpers test_form_rectangle', 'numpy testing assert_equal'), ('test_helpers test_form_rectangle', 'numpy array'), ('test_helpers test_form_rectangle', 'bb_stitcher helpers form_rectangle'), ('test_helpers test_sort_pts', 'numpy testing assert_equal'), ('test_helpers test_sort_pts', 'numpy array'), ('test_helpers test_sort_pts', 'bb_stitcher helpers sort_pts'), ('test_helpers test_raw_estimate_rect', 'bb_stitcher helpers raw_estimate_rect'), ('test_helpers test_raw_estimate_rect', 'numpy array'), ('test_helpers test_raw_estimate_rect', 'numpy testing assert_almost_equal'), ('test_helpers test_harmonize_rects', 'numpy testing assert_equal'), ('test_helpers test_harmonize_rects', 'numpy array'), ('test_helpers test_harmonize_rects', 'bb_stitcher helpers harmonize_rects'), ('test_helpers test_angles_to_points', 'numpy array'), ('test_helpers test_angles_to_points', 'bb_stitcher helpers angles_to_points'), ('test_helpers test_angles_to_points', 'numpy zeros'), ('test_helpers test_angles_to_points', 'numpy ones'), ('test_helpers test_angles_to_points', 'numpy testing assert_almost_equal'), ('test_helpers test_points_to_angles', 'numpy array'), ('test_helpers test_points_to_angles', 'pytest raises'), ('test_helpers test_points_to_angles', 'bb_stitcher helpers points_to_angles'), ('test_helpers test_points_to_angles', 'numpy testing assert_equal'), ('test_helpers test_points_to_angles', 'numpy zeros')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"This module contains various image stitchers especially designed for the BeesBook Project.\"\"\"\n",
      "import collections\n",
      "import math\n",
      "\n",
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "import bb_stitcher.helpers as helpers\n",
      "import bb_stitcher.picking.picker as picker\n",
      "import bb_stitcher.prep as prep\n",
      "\n",
      "\n",
      "class Stitcher(object):\n",
      "    \"\"\"Class to create a 'panorama' from two images.\n",
      "\n",
      "    Warnings:\n",
      "        This class is more like an abstract class. This :obj:`Stitcher` can not be used to estimate\n",
      "        the required parameters for stitching. But if you already estimated the parameters with an\n",
      "        other :obj:`Stitcher` you could use this on for stitching.\n",
      "\n",
      "    See Also:\n",
      "        - :obj:`FeatureBasedStitcher`\n",
      "        - :obj:`RectangleStitcher`\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, config=None, rectify=True):\n",
      "        \"\"\"\"Initialize the stitcher.\"\"\"\n",
      "        if config is None:\n",
      "            self.config = helpers.get_default_config()\n",
      "        else:\n",
      "            self.config = config\n",
      "        self.rectify = rectify\n",
      "        if rectify:\n",
      "            self.rectificator = prep.Rectificator(self.config)\n",
      "        self.homo_left = None\n",
      "        self.homo_right = None\n",
      "        self.size_left = None\n",
      "        self.size_right = None\n",
      "\n",
      "    def _prepare_image(self, image, angle=0):\n",
      "        \"\"\"Prepare image for stitching.\n",
      "\n",
      "        It rotates and rectifies the image. Ff the Stitcher is initialized with ``rectify=False``\n",
      "        the image will not be rectified.\n",
      "\n",
      "        Args:\n",
      "            image (ndarray): Image to prepare.\n",
      "            angle (int): angle in degree to rotate image.\n",
      "\n",
      "        Returns:\n",
      "            - **image** (ndarray) -- rotated (and rectified) image.\n",
      "            - **affine** (ndarray) -- An affine *(3,3)*--matrix for rotation of image or points.\n",
      "        \"\"\"\n",
      "        image = helpers.add_alpha_channel(image)\n",
      "        if self.rectify:\n",
      "            image = self.rectificator.rectify_image(image)\n",
      "        image_rot, affine = prep.rotate_image(image, angle)\n",
      "        return image_rot, affine\n",
      "\n",
      "    def load_parameters(self, homo_left=None, homo_right=None, size_left=None, size_right=None):\n",
      "        \"\"\"Load needed parameters for stitching points, angles and images.\n",
      "\n",
      "         This function becomes handy if you calculate the parameters in an earlier stitching\n",
      "         process and did not want to calculate the parameters again and just want to map points,\n",
      "         angles or images which were made under the same camera setup as the earlier stitching\n",
      "         process.\n",
      "\n",
      "        Args:\n",
      "            homo_left (ndarray): homography *(3,3)* for data from the left side to form a panorama.\n",
      "            homo_right (ndarray): homography *(3,3)* for data from the right side to form a \\\n",
      "            panorama.\n",
      "            size_left (tuple): Size of the left image, which was used to calculate homography.\n",
      "            size_right (tuple): Size of the right image, which was used to calculate homography.\n",
      "        \"\"\"\n",
      "        self.homo_left = homo_left\n",
      "        self.homo_right = homo_right\n",
      "        self.size_left = size_left\n",
      "        self.size_right = size_right\n",
      "\n",
      "    def get_parameters(self):\n",
      "        \"\"\"Return the estimated or loaded parameters of the stitcher needed for later stitching.\n",
      "\n",
      "        With this function you could save the stitching parameters and load them later for further\n",
      "        stitching of points and angles (see ``set_parameters``).\n",
      "\n",
      "        Use this function if you estimated the transform and did not want to estimate the parameters\n",
      "        again.\n",
      "        \"\"\"\n",
      "        StitchingParams = collections.namedtuple('StichingParams', ['homo_left', 'homo_right',\n",
      "                                                                    'size_left', 'size_right'])\n",
      "        result = StitchingParams(self.homo_left, self.homo_right,\n",
      "                                 self.size_left, self.size_right)\n",
      "        return result\n",
      "\n",
      "    def estimate_transform(self, image_left, image_right, angle_left=0, angle_right=0):\n",
      "        \"\"\"Estimate transformation/homography of the left and right images/data to form a panorama.\n",
      "\n",
      "        Return the transformation matrix for the left and right image.\n",
      "\n",
      "        Args:\n",
      "            image_left (ndarray): Input left image.\n",
      "            image_right (ndarray): Input right image.\n",
      "            angle_left (int): Angle in degree to rotate left image.\n",
      "            angle_right (int): Angle in degree to rotate right image.\n",
      "\n",
      "        Warning:\n",
      "            This must be overridden by a sublcass to customize stitching.\n",
      "        \"\"\"\n",
      "        raise NotImplementedError()\n",
      "\n",
      "    def compose_panorama(self, image_left, image_right):\n",
      "        \"\"\"Try to compose the given images into the final panorama.\n",
      "\n",
      "        This happens under the assumption that the image transformations were estimated or loaded\n",
      "        before.\n",
      "\n",
      "        Args:\n",
      "            image_left (ndarray): Input left image.\n",
      "            image_right (ndarray): Input right image.\n",
      "\n",
      "        Returns:\n",
      "            ndarray: panorama (stitched image)\n",
      "        \"\"\"\n",
      "        image_left = helpers.add_alpha_channel(image_left)\n",
      "        image_right = helpers.add_alpha_channel(image_right)\n",
      "\n",
      "        if self.rectify:\n",
      "            image_left = self.rectificator.rectify_image(image_left)\n",
      "            image_right = self.rectificator.rectify_image(image_right)\n",
      "\n",
      "        bounds = helpers.get_boundaries(self.size_left, self.size_right,\n",
      "                                        self.homo_left, self.homo_right)\n",
      "        pano_size = (math.ceil(bounds.xmax - bounds.xmin), math.ceil(bounds.ymax - bounds.ymin))\n",
      "\n",
      "        image_left = cv2.warpPerspective(image_left, self.homo_left, pano_size)\n",
      "        image_right = cv2.warpPerspective(image_right, self.homo_right, pano_size)\n",
      "\n",
      "        alpha = 0.5\n",
      "        cv2.addWeighted(image_left, alpha, image_right, 1 - alpha, 0, image_left)\n",
      "\n",
      "        return image_left\n",
      "\n",
      "    def map_left_points(self, points):\n",
      "        \"\"\"Map points from the left image to the panorama.\n",
      "\n",
      "        This happens under the assumption that the image transformations were estimated or loaded\n",
      "        before.\n",
      "\n",
      "        Args:\n",
      "            points (ndarray(float)): List of points from left image *(N,2)*.\n",
      "\n",
      "        Returns:\n",
      "            ndarray: ``points`` mapped to panorama *(N,2)*\n",
      "        \"\"\"\n",
      "        # TODO(gitmirgut): PoC auto convert to float\n",
      "        # TODO(gitmirgut): Add exception if size is None\n",
      "        if self.rectify:\n",
      "            points = self.rectificator.rectify_points(points, self.size_left)\n",
      "        points = np.array([points])\n",
      "        return cv2.perspectiveTransform(points, self.homo_left)[0]\n",
      "\n",
      "    def map_left_points_angles(self, points, angles):\n",
      "        \"\"\"Map points and angles from the left image to the panorama.\n",
      "\n",
      "        This happens under the assumption that the image transformations were estimated or loaded\n",
      "        before.\n",
      "\n",
      "        Args:\n",
      "            points (ndarray(float)): List of points from left image *(N,2)*.\n",
      "            angles (ndarray): Angles in rad (length *(N,)*).\n",
      "\n",
      "        Returns:\n",
      "            - **points_mapped** (ndarray) -- ``points`` mapped to panorama *(N,2)*\n",
      "            - **angles_mapped** (ndarray) -- ``angles`` mapped to panorama *(N,)*\n",
      "        \"\"\"\n",
      "        angle_pt_repr = helpers.angles_to_points(points, angles)\n",
      "        if self.rectify:\n",
      "            points = self.rectificator.rectify_points(points, self.size_left)\n",
      "            angle_pt_repr = self.rectificator.rectify_points(angle_pt_repr, self.size_left)\n",
      "        points = np.array([points])\n",
      "        angle_pt_repr = np.array([angle_pt_repr])\n",
      "        points_mapped = cv2.perspectiveTransform(points, self.homo_left)[0]\n",
      "        angle_pt_repr_mapped = cv2.perspectiveTransform(angle_pt_repr, self.homo_left)[0]\n",
      "        angles_mapped = helpers.points_to_angles(points_mapped, angle_pt_repr_mapped)\n",
      "        return points_mapped, angles_mapped\n",
      "\n",
      "    def map_right_points(self, points):\n",
      "        \"\"\"Map points from the right image to the panorama.\n",
      "\n",
      "        This happens under the assumption that the image transformations were estimated or loaded\n",
      "        before.\n",
      "\n",
      "        Args:\n",
      "            points (ndarray(float)): List of points from right image *(N,2)*.\n",
      "\n",
      "        Returns:\n",
      "            ndarray: ``points`` mapped to panorama *(N,2)*\n",
      "        \"\"\"\n",
      "        # TODO(gitmirgut): PoC auto convert to float\n",
      "        if self.rectify:\n",
      "            points = self.rectificator.rectify_points(points, self.size_right)\n",
      "        points = np.array([points])\n",
      "        return cv2.perspectiveTransform(points, self.homo_right)[0]\n",
      "\n",
      "    def map_right_points_angles(self, points, angles):\n",
      "        \"\"\"Map points and angles from the right image to the panorama.\n",
      "\n",
      "        This happens under the assumption that the image transformations were estimated or loaded\n",
      "        before.\n",
      "\n",
      "        Args:\n",
      "            points (ndarray(float)): List of points from right image *(N,2)*.\n",
      "            angles (ndarray): Angles in rad (length *(N,)*).\n",
      "\n",
      "        Returns:\n",
      "            - **points_mapped** (ndarray) -- ``points`` mapped to panorama *(N,2)*\n",
      "            - **angles_mapped** (ndarray) -- ``angles`` mapped to panorama *(N,)*\n",
      "        \"\"\"\n",
      "        angle_pt_repr = helpers.angles_to_points(points, angles)\n",
      "        if self.rectify:\n",
      "            points = self.rectificator.rectify_points(points, self.size_right)\n",
      "            angle_pt_repr = self.rectificator.rectify_points(angle_pt_repr, self.size_right)\n",
      "        points = np.array([points])\n",
      "        angle_pt_repr = np.array([angle_pt_repr])\n",
      "        points_mapped = cv2.perspectiveTransform(points, self.homo_right)[0]\n",
      "        angle_pt_repr_mapped = cv2.perspectiveTransform(angle_pt_repr, self.homo_right)[0]\n",
      "        angles_mapped = helpers.points_to_angles(points_mapped, angle_pt_repr_mapped)\n",
      "        return points_mapped, angles_mapped\n",
      "\n",
      "    @staticmethod\n",
      "    def _calc_image_to_world_mat(panorama):\n",
      "        \"\"\"Determine the matrix to convert image coordinates to world coordinates.\n",
      "\n",
      "        The user must select two points on the image. The first point will be the origin and the\n",
      "        distance between the first and the second point, will be used to determine the ratio\n",
      "        between px and mm.\n",
      "\n",
      "        Returns:\n",
      "             ndarray: homography *(3,3)* to transform image points to world points.\n",
      "        \"\"\"\n",
      "        pt_picker = picker.PointPicker()\n",
      "        points = pt_picker.pick([panorama], False)\n",
      "        start_point, end_point = points[0]\n",
      "        distance_mm = float(input('Distance in mm of the two selected points: '))\n",
      "        ratio = helpers.get_ratio_px_to_mm(start_point, end_point, distance_mm)\n",
      "\n",
      "        # define matrix to convert image coordinates to world coordinates\n",
      "        homo_to_world = np.array([\n",
      "            [ratio, 0, start_point[0]],\n",
      "            [0, ratio, end_point[1]],\n",
      "            [0, 0, 1]], dtype=np.float32)\n",
      "\n",
      "        return homo_to_world\n",
      "\n",
      "\n",
      "class FeatureBasedStitcher(Stitcher):\n",
      "    \"\"\"Class to create a feature based stitcher.\"\"\"\n",
      "\n",
      "    def __init__(self, config=None, rectify=True):\n",
      "        \"\"\"Initialize a feature based stitcher.\n",
      "\n",
      "        Args:\n",
      "            config: config file which holds the basic stitching parameters.\n",
      "        \"\"\"\n",
      "        super().__init__(config, rectify)\n",
      "        self.overlap = int(self.config['FeatureBasedStitcher']['OVERLAP'])\n",
      "        self.border_top = int(self.config['FeatureBasedStitcher']['BORDER_TOP'])\n",
      "        self.border_bottom = int(self.config['FeatureBasedStitcher']['BORDER_BOTTOM'])\n",
      "        self.transform = self.config['FeatureBasedStitcher']['TRANSFORM']\n",
      "        self.hessianThreshold = float(self.config['SURF']['HESSIANTHRESHOLD'])\n",
      "        self.nOctaves = int(self.config['SURF']['N_OCTAVES'])\n",
      "        self.max_shift_y = int(self.config['FeatureMatcher']['MAX_SCHIFT_Y'])\n",
      "\n",
      "    @staticmethod\n",
      "    def _calc_feature_mask(size_left, size_right, overlap, border_top, border_bottom):\n",
      "        \"\"\"Calculate the masks, which defines the area for feature detection.\n",
      "\n",
      "        The mask is used to shrink the area for searching features.\n",
      "\n",
      "        Args:\n",
      "            size_left (tuple): Size of the left image.\n",
      "            size_right (tuple): Size of the right image.\n",
      "            overlap (int): Estimated overlap of both images in px.\n",
      "            border_top (int): Estimated border size on top of both images in px.\n",
      "            border_bottom (int): Estimated border size on top of both images in px.\n",
      "\n",
      "        Returns:\n",
      "            - **mask_left** (ndarray) -- mask area of the left image to search for features.\n",
      "            - **mask_right** (ndarray) -- mask area of the right image to search for features.\n",
      "        \"\"\"\n",
      "        # TODO(gitmirgut): Add note, why to use border.\n",
      "        mask_left = np.zeros(size_left[:: - 1], np.uint8)\n",
      "        mask_right = np.zeros(size_right[:: - 1], np.uint8)\n",
      "        mask_left[border_top:size_left[1] - border_bottom, size_left[0] - overlap:] = 255\n",
      "        mask_right[border_top:size_left[1] - border_bottom, :overlap] = 255\n",
      "\n",
      "        return mask_left, mask_right\n",
      "\n",
      "    def estimate_transform(self, image_left, image_right, angle_left=0, angle_right=0):\n",
      "        \"\"\"Estimate transformation for stitching of images based on feature matching.\n",
      "\n",
      "        Args:\n",
      "            image_left (ndarray): Input left image.\n",
      "            image_right (ndarray): Input right image.\n",
      "            angle_left (int): Angle in degree to rotate left image.\n",
      "            angle_right (int): Angle in degree to rotate right image.\n",
      "        \"\"\"\n",
      "        self.size_left = image_left.shape[:2][::-1]\n",
      "        self.size_right = image_right.shape[:2][::-1]\n",
      "\n",
      "        # rectify and rotate images\n",
      "        image_left, affine_left = self._prepare_image(image_left, angle_left)\n",
      "        image_right, affine_right = self._prepare_image(image_right, angle_right)\n",
      "\n",
      "        rot_size_left = image_left.shape[:2][:: - 1]\n",
      "        rot_size_right = image_right.shape[:2][:: - 1]\n",
      "\n",
      "        # calculates the mask which will mark the feature searching area.\n",
      "        mask_left, mask_right = self._calc_feature_mask(\n",
      "            rot_size_left, rot_size_right, self.overlap, self.border_top, self.border_bottom)\n",
      "\n",
      "        # Initialize the feature detector and descriptor SURF\n",
      "        # http://www.vision.ee.ethz.ch/~surf/download.html\n",
      "        # is noncommercial licensed\n",
      "        surf = cv2.xfeatures2d.SURF_create(\n",
      "            hessianThreshold=self.hessianThreshold, nOctaves=self.nOctaves)\n",
      "        surf.setUpright(True)\n",
      "        surf.setExtended(128)\n",
      "\n",
      "        kps_left, ds_left = surf.detectAndCompute(image_left, mask_left)\n",
      "        kps_right, ds_right = surf.detectAndCompute(image_right, mask_right)\n",
      "\n",
      "        assert (len(kps_left) > 0 and len(kps_right) > 0)\n",
      "\n",
      "        # Start with Feature Matching\n",
      "        bf = cv2.BFMatcher()\n",
      "\n",
      "        # search the 2 best matches for each left descriptor (ds_left)\n",
      "        raw_matches = bf.knnMatch(ds_left, ds_right, k=2)\n",
      "\n",
      "        good_matches = []\n",
      "        for m in raw_matches:\n",
      "            if len(m) == 2 and m[0].distance < m[1].distance:\n",
      "                good_match = m[0]\n",
      "                keypoint_left = np.array(kps_left[good_match.queryIdx].pt)\n",
      "                keypoint_right = np.array(kps_right[good_match.trainIdx].pt)\n",
      "                dist = abs(keypoint_left - keypoint_right)\n",
      "\n",
      "                # checks if the distance in the y direction is to big\n",
      "                if dist[1] < self.max_shift_y:\n",
      "                    good_matches.append(good_match)\n",
      "\n",
      "        good_pts_left = np.float32(\n",
      "            [kps_left[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
      "        good_pts_right = np.float32(\n",
      "            [kps_right[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
      "\n",
      "        assert len(good_matches) > 2\n",
      "        homo_right = cv2.estimateRigidTransform(good_pts_left, good_pts_right, False)\n",
      "        if homo_right is None:\n",
      "            return None\n",
      "        homo_right = cv2.invertAffineTransform(homo_right)\n",
      "        homo_right = np.vstack([homo_right, [0, 0, 1]])\n",
      "\n",
      "        # include the previous rotation\n",
      "        homo_left = affine_left\n",
      "        homo_right = homo_right.dot(affine_right)\n",
      "\n",
      "        # define translation matrix\n",
      "        bounds = helpers.get_boundaries(self.size_left, self.size_right, homo_left, homo_right)\n",
      "        homo_trans = helpers.get_transform_to_origin_mat(bounds.xmin, bounds.ymin)\n",
      "\n",
      "        self.homo_left = homo_trans.dot(homo_left)\n",
      "        self.homo_right = homo_trans.dot(homo_right)\n",
      "\n",
      "\n",
      "class RectangleStitcher(Stitcher):\n",
      "    \"\"\"Class to create a rectangle stitcher.\n",
      "\n",
      "    The ``RectangleStitcher`` maps selected points to an abstracted rectangle.\n",
      "    \"\"\"\n",
      "\n",
      "    def estimate_transform(self, image_left, image_right, angle_left=0, angle_right=0):\n",
      "        \"\"\"Estimate transformation for stitching of images based on 'rectangle' Stitching.\n",
      "\n",
      "        Args:\n",
      "            image_left (ndarray): Input left image.\n",
      "            image_right (ndarray): Input right image.\n",
      "            angle_left (int): Angle in degree to rotate left image.\n",
      "            angle_right (int): Angle in degree to rotate right image.\n",
      "        \"\"\"\n",
      "        # TODO(gitmirgut) set all to False\n",
      "        self.size_left = image_left.shape[:2][::-1]\n",
      "        self.size_right = image_right.shape[:2][::-1]\n",
      "\n",
      "        image_left, affine_left = self._prepare_image(image_left, angle_left)\n",
      "        image_right, affine_right = self._prepare_image(image_right, angle_right)\n",
      "\n",
      "        pt_picker = picker.PointPicker()\n",
      "        pts_left, pts_right = pt_picker.pick([image_left, image_right], False)\n",
      "        assert len(pts_left) == 4 and len(pts_right) == 4\n",
      "        pts_left_srt = helpers.sort_pts(pts_left)\n",
      "        pts_right_srt = helpers.sort_pts(pts_right)\n",
      "\n",
      "        target_pts_left = helpers.raw_estimate_rect(pts_left_srt)\n",
      "        target_pts_right = helpers.raw_estimate_rect(pts_right_srt)\n",
      "        target_pts_left, target_pts_right = helpers.harmonize_rects(\n",
      "            target_pts_left, target_pts_right)\n",
      "\n",
      "        # declare the shift of the right points\n",
      "        shift_right = np.amax(target_pts_left[:, 0])\n",
      "        target_pts_right[:, 0] = target_pts_right[:, 0] + shift_right\n",
      "        homo_left, __ = cv2.findHomography(pts_left_srt, target_pts_left)\n",
      "        homo_right, __ = cv2.findHomography(pts_right_srt, target_pts_right)\n",
      "\n",
      "        # calculate the overall homography including the previous rotation\n",
      "        homo_left = homo_left.dot(affine_left)\n",
      "        homo_right = homo_right.dot(affine_right)\n",
      "\n",
      "        # define translation matrix\n",
      "        bounds = helpers.get_boundaries(self.size_left, self.size_right, homo_left, homo_right)\n",
      "        homo_trans = helpers.get_transform_to_origin_mat(bounds.xmin, bounds.ymin)\n",
      "\n",
      "        self.homo_left = homo_trans.dot(homo_left)\n",
      "        self.homo_right = homo_trans.dot(homo_right)\n",
      "\n",
      "Output: {'stitcher': [], 'stitcher.Stitcher.__init__': ['bb_stitcher.prep.Rectificator', 'bb_stitcher.helpers.get_default_config'], 'bb_stitcher.helpers.get_default_config': [], 'bb_stitcher.prep.Rectificator': [], 'stitcher.Stitcher._prepare_image': ['bb_stitcher.helpers.add_alpha_channel', 'bb_stitcher.prep.rotate_image'], 'bb_stitcher.helpers.add_alpha_channel': [], 'bb_stitcher.prep.rotate_image': [], 'stitcher.Stitcher.load_parameters': [], 'stitcher.Stitcher.get_parameters': ['collections.namedtuple'], 'collections.namedtuple': [], 'stitcher.Stitcher.estimate_transform': ['<builtin>.NotImplementedError'], '<builtin>.NotImplementedError': [], 'stitcher.Stitcher.compose_panorama': ['cv2.warpPerspective', 'bb_stitcher.helpers.get_boundaries', 'bb_stitcher.helpers.add_alpha_channel', 'cv2.addWeighted', 'math.ceil'], 'bb_stitcher.helpers.get_boundaries': [], 'math.ceil': [], 'cv2.warpPerspective': [], 'cv2.addWeighted': [], 'stitcher.Stitcher.map_left_points': ['cv2.perspectiveTransform', 'numpy.array'], 'numpy.array': [], 'cv2.perspectiveTransform': [], 'stitcher.Stitcher.map_left_points_angles': ['bb_stitcher.helpers.angles_to_points', 'cv2.perspectiveTransform', 'bb_stitcher.helpers.points_to_angles', 'numpy.array'], 'bb_stitcher.helpers.angles_to_points': [], 'bb_stitcher.helpers.points_to_angles': [], 'stitcher.Stitcher.map_right_points': ['cv2.perspectiveTransform', 'numpy.array'], 'stitcher.Stitcher.map_right_points_angles': ['bb_stitcher.helpers.angles_to_points', 'cv2.perspectiveTransform', 'bb_stitcher.helpers.points_to_angles', 'numpy.array'], 'stitcher.Stitcher._calc_image_to_world_mat': ['<builtin>.float', 'bb_stitcher.picking.picker.PointPicker', '<builtin>.input', 'bb_stitcher.helpers.get_ratio_px_to_mm', 'numpy.array'], 'bb_stitcher.picking.picker.PointPicker': [], '<builtin>.input': [], '<builtin>.float': [], 'bb_stitcher.helpers.get_ratio_px_to_mm': [], 'stitcher.FeatureBasedStitcher.__init__': ['<builtin>.float', '<builtin>.int', '<builtin>.super'], '<builtin>.super': [], '<builtin>.int': [], 'stitcher.FeatureBasedStitcher._calc_feature_mask': ['numpy.zeros'], 'numpy.zeros': [], 'stitcher.FeatureBasedStitcher.estimate_transform': ['stitcher.FeatureBasedStitcher._calc_feature_mask', 'bb_stitcher.helpers.get_transform_to_origin_mat', 'stitcher.Stitcher._prepare_image', '<builtin>.len', 'numpy.float32', '<builtin>.abs', 'bb_stitcher.helpers.get_boundaries', 'cv2.estimateRigidTransform', 'cv2.invertAffineTransform', 'cv2.xfeatures2d.SURF_create', 'numpy.vstack', 'cv2.BFMatcher', 'numpy.array'], 'cv2.xfeatures2d.SURF_create': [], '<builtin>.len': [], 'cv2.BFMatcher': [], '<builtin>.abs': [], 'numpy.float32': [], 'cv2.estimateRigidTransform': [], 'cv2.invertAffineTransform': [], 'numpy.vstack': [], 'bb_stitcher.helpers.get_transform_to_origin_mat': [], 'stitcher.RectangleStitcher.estimate_transform': ['cv2.findHomography', 'bb_stitcher.picking.picker.PointPicker', 'bb_stitcher.helpers.get_transform_to_origin_mat', 'stitcher.Stitcher._prepare_image', '<builtin>.len', 'numpy.amax', 'bb_stitcher.helpers.get_boundaries', 'bb_stitcher.helpers.raw_estimate_rect', 'bb_stitcher.helpers.sort_pts', 'bb_stitcher.helpers.harmonize_rects'], 'bb_stitcher.helpers.sort_pts': [], 'bb_stitcher.helpers.raw_estimate_rect': [], 'bb_stitcher.helpers.harmonize_rects': [], 'numpy.amax': [], 'cv2.findHomography': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\bb_stitcher\\stitcher.py\n",
      "[('stitcher Stitcher __init__', 'bb_stitcher prep Rectificator'), ('stitcher Stitcher __init__', 'bb_stitcher helpers get_default_config'), ('stitcher Stitcher _prepare_image', 'bb_stitcher helpers add_alpha_channel'), ('stitcher Stitcher _prepare_image', 'bb_stitcher prep rotate_image'), ('stitcher Stitcher get_parameters', 'collections namedtuple'), ('stitcher Stitcher compose_panorama', 'cv2 warpPerspective'), ('stitcher Stitcher compose_panorama', 'bb_stitcher helpers get_boundaries'), ('stitcher Stitcher compose_panorama', 'bb_stitcher helpers add_alpha_channel'), ('stitcher Stitcher compose_panorama', 'cv2 addWeighted'), ('stitcher Stitcher compose_panorama', 'math ceil'), ('stitcher Stitcher map_left_points', 'cv2 perspectiveTransform'), ('stitcher Stitcher map_left_points', 'numpy array'), ('stitcher Stitcher map_left_points_angles', 'bb_stitcher helpers angles_to_points'), ('stitcher Stitcher map_left_points_angles', 'cv2 perspectiveTransform'), ('stitcher Stitcher map_left_points_angles', 'bb_stitcher helpers points_to_angles'), ('stitcher Stitcher map_left_points_angles', 'numpy array'), ('stitcher Stitcher map_right_points', 'cv2 perspectiveTransform'), ('stitcher Stitcher map_right_points', 'numpy array'), ('stitcher Stitcher map_right_points_angles', 'bb_stitcher helpers angles_to_points'), ('stitcher Stitcher map_right_points_angles', 'cv2 perspectiveTransform'), ('stitcher Stitcher map_right_points_angles', 'bb_stitcher helpers points_to_angles'), ('stitcher Stitcher map_right_points_angles', 'numpy array'), ('stitcher Stitcher _calc_image_to_world_mat', 'bb_stitcher picking picker PointPicker'), ('stitcher Stitcher _calc_image_to_world_mat', 'bb_stitcher helpers get_ratio_px_to_mm'), ('stitcher Stitcher _calc_image_to_world_mat', 'numpy array'), ('stitcher FeatureBasedStitcher _calc_feature_mask', 'numpy zeros'), ('stitcher FeatureBasedStitcher estimate_transform', 'stitcher FeatureBasedStitcher _calc_feature_mask'), ('stitcher FeatureBasedStitcher estimate_transform', 'bb_stitcher helpers get_transform_to_origin_mat'), ('stitcher FeatureBasedStitcher estimate_transform', 'stitcher Stitcher _prepare_image'), ('stitcher FeatureBasedStitcher estimate_transform', 'numpy float32')]\n",
      "0\n",
      "found files: []\n",
      "#  Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n",
      "#  not use this file except in compliance with the License. You may obtain\n",
      "#  a copy of the License at\n",
      "#\n",
      "#       http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "#  Unless required by applicable law or agreed to in writing, software\n",
      "#  distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
      "#  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
      "#  License for the specific language governing permissions and limitations\n",
      "#  under the License.\n",
      "\"\"\"This module contains draggable objects for the matplotlib GUI.\n",
      "\n",
      "The objects are used to mark specific points on an image. The module also\n",
      "contains a special list to save these objects. This list is extended with\n",
      "special functions to get the coordinates of the marked points.\n",
      "\"\"\"\n",
      "import cv2\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "class DraggableMark(object):\n",
      "    \"\"\"Defines marks which can be dragged by mouse.\n",
      "\n",
      "    The placed mark can be dragged by simple left click and can be **refined** by pressing the\n",
      "    :const:`key_refine` specific button and they can be marked as **selected** by pressing\n",
      "    :const:`key_select`.\n",
      "    \"\"\"\n",
      "\n",
      "    _lock = None  # only one mark at at time can be animated.\n",
      "    key_refine = 'r'  # if this key is pressed the mark will be refined\n",
      "    key_select = 's'  # if this key is pressed the mark will be selected\n",
      "\n",
      "    def __init__(self, mark, img=None):\n",
      "        \"\"\"Initialize a draggable mark.\"\"\"\n",
      "        self.mark = mark\n",
      "        self.img = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)\n",
      "        self.press = None\n",
      "        self.background = None\n",
      "        self.selected = False\n",
      "\n",
      "    def get_coordinate(self):\n",
      "        \"\"\"Return the current coordinate of the mark.\n",
      "\n",
      "        Returns:\n",
      "            ndarray: center of the mark *(2,)*.\n",
      "        \"\"\"\n",
      "        return self.mark.get_xydata()[0]\n",
      "\n",
      "    def _toggle_select(self):\n",
      "        \"\"\"Toggle mark selection state.\"\"\"\n",
      "        if self.selected is False:\n",
      "            self.selected = True\n",
      "            self.mark.set_color('g')\n",
      "        else:\n",
      "            self.selected = False\n",
      "            self.mark.set_color('r')\n",
      "\n",
      "    def _select(self):\n",
      "        self.selected = True\n",
      "        self.mark.set_color('g')\n",
      "\n",
      "    def _unselect(self):\n",
      "        self.selected = False\n",
      "        self.mark.set_color('r')\n",
      "\n",
      "    def _refine(self):\n",
      "        \"\"\"Refine the location of the mark.\n",
      "\n",
      "        Use it if you want that the mark should be on a corner.\n",
      "        \"\"\"\n",
      "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
      "        new_coordinate = self.get_coordinate()\n",
      "        new_coordinate = np.array([[new_coordinate]], dtype=np.float32)\n",
      "        cv2.cornerSubPix(self.img, new_coordinate, (40, 40), (-1, -1), criteria)\n",
      "        x, y = new_coordinate[0][0]\n",
      "        self.mark.set_xdata(x)\n",
      "        self.mark.set_ydata(y)\n",
      "        self._unselect()\n",
      "        self.mark.set_color('y')\n",
      "        self.mark.figure.canvas.draw()\n",
      "\n",
      "    def connect(self):\n",
      "        \"\"\"Connect to the mark to various Events.\"\"\"\n",
      "        self.cid_press = self.mark.figure.canvas.mpl_connect(\n",
      "            'button_press_event', self._on_press)\n",
      "        self.cid_release = self.mark.figure.canvas.mpl_connect(\n",
      "            'button_release_event', self._on_release)\n",
      "        self.cid_motion = self.mark.figure.canvas.mpl_connect(\n",
      "            'motion_notify_event', self._on_motion)\n",
      "        self.cid_key = self.mark.figure.canvas.mpl_connect(\n",
      "            'key_release_event', self._on_key)\n",
      "\n",
      "    def _on_press(self, event):\n",
      "        \"\"\"Check on button press if mouse is over this DraggableMarks.\"\"\"\n",
      "        # if the event is not in the axes return\n",
      "        if event.inaxes != self.mark.axes:\n",
      "            return\n",
      "\n",
      "        # checks if an other DraggableMarks is already chosen\n",
      "        if DraggableMark._lock is not None:\n",
      "            return\n",
      "\n",
      "        # This checks if the mouse is over us (marker)\n",
      "        contains, __ = self.mark.contains(event)\n",
      "        if not contains:\n",
      "            return\n",
      "\n",
      "        # set back the color to red to mark that is not refined and remove\n",
      "        # selection flag\n",
      "        self._unselect()\n",
      "\n",
      "        # get the current coordinates of the marker\n",
      "        x, y = self.get_coordinate()\n",
      "\n",
      "        # cache the coordinates and the event coordinates\n",
      "        self.press = x, y, event.xdata, event.ydata\n",
      "\n",
      "        # Locks the dragging of other DraggableMarker\n",
      "        DraggableMark._lock = self\n",
      "\n",
      "        # draw everything but the selected marker and store the pixel buffer\n",
      "        canvas = self.mark.figure.canvas\n",
      "        axes = self.mark.axes\n",
      "        self.mark.set_animated(True)\n",
      "        canvas.draw()\n",
      "        self.background = canvas.copy_from_bbox(self.mark.axes.bbox)\n",
      "\n",
      "        # now redraw just the marker\n",
      "        axes.draw_artist(self.mark)\n",
      "\n",
      "        # and blit just the redrawn area\n",
      "        canvas.blit(axes.bbox)\n",
      "\n",
      "    def _on_motion(self, event):\n",
      "        \"\"\"On motion the mark will move if the mouse is over this marker.\"\"\"\n",
      "        if DraggableMark._lock is not self:\n",
      "            return\n",
      "        if event.inaxes != self.mark.axes:\n",
      "            return\n",
      "        x0, y0, xpress, ypress = self.press\n",
      "        dx = event.xdata - xpress\n",
      "        dy = event.ydata - ypress\n",
      "        self.mark.set_xdata(x0 + dx)\n",
      "        self.mark.set_ydata(y0 + dy)\n",
      "\n",
      "        canvas = self.mark.figure.canvas\n",
      "        axes = self.mark.axes\n",
      "\n",
      "        # restore the background region\n",
      "        canvas.restore_region(self.background)\n",
      "\n",
      "        # redraw just the current rectangle\n",
      "        axes.draw_artist(self.mark)\n",
      "\n",
      "        # blit just the redrawn area\n",
      "        canvas.blit(axes.bbox)\n",
      "\n",
      "    def _on_release(self, event):\n",
      "        \"\"\"On release the press data will be reset.\"\"\"\n",
      "        if DraggableMark._lock is not self:\n",
      "            return\n",
      "\n",
      "        self.press = None\n",
      "        DraggableMark._lock = None\n",
      "\n",
      "        # turn off the mark animation property and reset the background\n",
      "        self.mark.set_animated(False)\n",
      "        self.background = None\n",
      "\n",
      "        # redraw the full figure\n",
      "        self.mark.figure.canvas.draw()\n",
      "\n",
      "    def _on_key(self, event):\n",
      "        \"\"\"Check what key ist pressed and executes corresponding function.\"\"\"\n",
      "        if event.inaxes != self.mark.axes:\n",
      "            return\n",
      "\n",
      "        # This checks if the mouse is over us (marker)\n",
      "        contains, __ = self.mark.contains(event)\n",
      "        if not contains:\n",
      "            return\n",
      "\n",
      "        if event.key == DraggableMark.key_select:\n",
      "            self._toggle_select()\n",
      "        elif event.key == DraggableMark.key_refine:\n",
      "            self._refine()\n",
      "\n",
      "        self.mark.figure.canvas.draw()\n",
      "\n",
      "    def disconnect(self):\n",
      "        \"\"\"Disconnect all the stored connection ids.\"\"\"\n",
      "        self.mark.figure.canvas.mpl_disconnect(self.c_id_press)\n",
      "        self.mark.figure.canvas.mpl_disconnect(self.c_id_release)\n",
      "        self.mark.figure.canvas.mpl_disconnect(self.c_id_motion)\n",
      "        self.mark.figure.canvas.mpl_disconnect(self.cid_key)\n",
      "        self.mark.figure.canvas.draw()\n",
      "\n",
      "\n",
      "class DraggableMarkList(list):\n",
      "    \"\"\"Extended List with some extra functions for :obj:`DraggableMark` objects.\"\"\"\n",
      "\n",
      "    def __init__(self, *args):\n",
      "        \"\"\"Initialize a list which holds :obj:`DraggableMark` objects.\"\"\"\n",
      "        list.__init__(self, *args)\n",
      "\n",
      "    def get_points(self, all_pts=True):\n",
      "        \"\"\"Convert the list of :obj:`DraggableMark` objects to a ndarray holding just coordinates.\n",
      "\n",
      "        Args:\n",
      "            all_pts (bool): if ``True`` function returns all coordinate. If ``False`` function \\\n",
      "            return just coordinates form :obj:`DraggableMark` objects marked as selected.\n",
      "\n",
      "        Returns:\n",
      "            ndarray: array that contains just the coordinates of the :obj:`DraggableMark` objects \\\n",
      "            of the list.\n",
      "        \"\"\"\n",
      "        dms = []\n",
      "        if all_pts:\n",
      "            dms = self\n",
      "        else:\n",
      "            for i, dm in enumerate(self):\n",
      "                if dm.selected:\n",
      "                    dms.append(dm)\n",
      "        points = np.zeros((len(dms), 2), np.float32)\n",
      "        for i, dm in enumerate(dms):\n",
      "            points[i] = dm.get_coordinate()\n",
      "\n",
      "        return points\n",
      "\n",
      "Output: {'draggables': [], 'draggables.DraggableMark.__init__': ['cv2.cvtColor'], 'cv2.cvtColor': [], 'draggables.DraggableMark.get_coordinate': [], 'draggables.DraggableMark._toggle_select': [], 'draggables.DraggableMark._select': [], 'draggables.DraggableMark._unselect': [], 'draggables.DraggableMark._refine': ['cv2.cornerSubPix', 'numpy.array', 'draggables.DraggableMark._unselect', 'draggables.DraggableMark.get_coordinate'], 'numpy.array': [], 'cv2.cornerSubPix': [], 'draggables.DraggableMark.connect': [], 'draggables.DraggableMark._on_press': ['draggables.DraggableMark._unselect', 'draggables.DraggableMark.get_coordinate'], 'draggables.DraggableMark._on_motion': [], 'draggables.DraggableMark._on_release': [], 'draggables.DraggableMark._on_key': ['draggables.DraggableMark._toggle_select', 'draggables.DraggableMark._refine'], 'draggables.DraggableMark.disconnect': [], 'draggables.DraggableMarkList.__init__': [], 'draggables.DraggableMarkList.get_points': ['<builtin>.enumerate', 'numpy.zeros', '<builtin>.len'], '<builtin>.enumerate': [], '<builtin>.len': [], 'numpy.zeros': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\gitmirgut_bb_stitcher\\bb_stitcher\\picking\\draggables.py\n",
      "[('draggables DraggableMark __init__', 'cv2 cvtColor'), ('draggables DraggableMark _refine', 'cv2 cornerSubPix'), ('draggables DraggableMark _refine', 'numpy array'), ('draggables DraggableMark _refine', 'draggables DraggableMark _unselect'), ('draggables DraggableMark _refine', 'draggables DraggableMark get_coordinate'), ('draggables DraggableMark _on_press', 'draggables DraggableMark _unselect'), ('draggables DraggableMark _on_press', 'draggables DraggableMark get_coordinate'), ('draggables DraggableMark _on_key', 'draggables DraggableMark _toggle_select'), ('draggables DraggableMark _on_key', 'draggables DraggableMark _refine'), ('draggables DraggableMarkList get_points', 'numpy zeros')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('helpers', 'logging getLogger'), ('helpers', 'numba njit'), ('helpers get_default_config', 'configparser ConfigParser'), ('helpers get_default_config', 'os path join'), ('helpers get_default_config', 'os path dirname'), ('helpers get_default_debug_config', 'configparser ConfigParser'), ('helpers get_default_debug_config', 'os path join'), ('helpers get_default_debug_config', 'os path dirname'), ('helpers get_boundaries', 'numpy concatenate'), ('helpers get_boundaries', 'numpy float32'), ('helpers get_boundaries', 'collections namedtuple'), ('helpers get_boundaries', 'cv2 perspectiveTransform'), ('helpers get_transform_to_origin_mat', 'numpy array'), ('helpers add_alpha_channel', 'cv2 cvtColor'), ('helpers form_rectangle', 'numpy zeros'), ('helpers sort_pts', 'numpy linalg norm'), ('helpers sort_pts', 'numpy zeros'), ('helpers sort_pts', 'numpy dot'), ('helpers sort_pts', 'numpy linalg det'), ('helpers sort_pts', 'numpy argsort'), ('helpers sort_pts', 'numpy arctan2'), ('helpers raw_estimate_rect', 'numpy linalg norm'), ('helpers raw_estimate_rect', 'helpers form_rectangle'), ('helpers harmonize_rects', 'numpy linalg norm'), ('helpers harmonize_rects', 'helpers form_rectangle'), ('helpers angles_to_points', 'numpy cos'), ('helpers angles_to_points', 'numpy sin'), ('helpers angles_to_points', 'numpy zeros'), ('helpers angles_to_points', 'numpy array'), ('helpers _process_points_to_angles', 'numpy linalg norm')], [('test_point_pick', 'pytest mark slow'), ('test_point_pick', 'pytest fixture'), ('test_point_pick create_prepared_image_dict', 'bb_stitcher helpers add_alpha_channel'), ('test_point_pick create_prepared_image_dict', 'bb_stitcher prep rotate_image'), ('test_point_pick create_prepared_image_dict', 'bb_stitcher prep Rectificator'), ('test_point_pick create_prepared_image_dict', 'bb_stitcher prep rotate_points'), ('test_point_pick left_img_prep', 'test_point_pick create_prepared_image_dict'), ('test_point_pick right_img_prep', 'test_point_pick create_prepared_image_dict'), ('test_point_pick test_gui', 'bb_stitcher picking picker PointPicker'), ('test_point_pick test_pick_length', 'numpy linalg norm'), ('test_point_pick test_pick_length', 'bb_stitcher picking picker PointPicker'), ('test_point_pick test_pick_length mockreturn', 'numpy array')], [('conftest', 'pytest fixture'), ('conftest', 'os path dirname'), ('conftest pytest_runtest_setup', 'pytest xfail'), ('conftest get_test_fname', 'os path dirname'), ('conftest get_test_fname', 'os path join'), ('conftest fname', 'os path splitext'), ('conftest fname', 'os path basename'), ('conftest create_image_dict', 'conftest get_test_fname'), ('conftest create_image_dict', 'os path splitext'), ('conftest create_image_dict', 'cv2 imread'), ('conftest create_image_dict', 'numpy load'), ('conftest create_image_dict', 'os path basename'), ('conftest left_img', 'conftest create_image_dict'), ('conftest right_img', 'conftest create_image_dict'), ('conftest not_to_bee', 'conftest get_test_fname'), ('conftest not_to_bee', 'cv2 imread'), ('conftest surveyor_csv_path', 'conftest get_test_fname'), ('conftest config', 'bb_stitcher helpers get_default_config'), ('conftest main_outdir', 'os makedirs'), ('conftest main_outdir', 'os path join'), ('conftest main_outdir', 'os path exists'), ('conftest panorama', 'conftest get_test_fname'), ('conftest panorama', 'cv2 imread'), ('conftest error_params', 'conftest get_test_fname'), ('conftest error_params', 'numpy load')], [('prep', 'functools lru_cache'), ('prep', 'logging getLogger'), ('prep Rectificator __init__', 'numpy array'), ('prep Rectificator __init__', 'ast literal_eval'), ('prep Rectificator rectify_image', 'cv2 getOptimalNewCameraMatrix'), ('prep Rectificator rectify_image', 'cv2 undistort'), ('prep Rectificator rectify_points', 'cv2 getOptimalNewCameraMatrix'), ('prep Rectificator rectify_points', 'numpy array'), ('prep Rectificator rectify_points', 'cv2 undistortPoints'), ('prep Rectificator rectify_points_angles', 'prep Rectificator rectify_points'), ('prep Rectificator rectify_points_angles', 'bb_stitcher helpers angles_to_points'), ('prep Rectificator rectify_points_angles', 'bb_stitcher helpers points_to_angles'), ('prep __get_affine_mat_and_new_size', 'math ceil'), ('prep __get_affine_mat_and_new_size', 'numpy array'), ('prep __get_affine_mat_and_new_size', 'numpy vstack'), ('prep __get_affine_mat_and_new_size', 'cv2 getRotationMatrix2D'), ('prep rotate_image', 'cv2 warpPerspective'), ('prep rotate_image', 'prep __get_affine_mat_and_new_size'), ('prep rotate_points', 'numpy array'), ('prep rotate_points', 'prep __get_affine_mat_and_new_size'), ('prep rotate_points', 'cv2 transform')], [('test_prep', 'pytest fixture'), ('test_prep draw_marks', 'cv2 drawMarker'), ('test_prep draw_marks', 'numpy copy'), ('test_prep draw_marks', 'cv2 cvtColor'), ('test_prep test_Rectificator', 'cv2 imwrite'), ('test_prep test_Rectificator', 'test_prep draw_marks'), ('test_prep test_Rectificator', 'bb_stitcher visualisation draw_complex_marks'), ('test_prep test_Rectificator', 'bb_stitcher prep Rectificator'), ('test_prep test_rotate_image', 'numpy zeros'), ('test_prep test_rotate_image', 'bb_stitcher prep rotate_image'), ('test_prep test_rotate_image_specifc', 'cv2 imwrite'), ('test_prep test_rotate_image_specifc', 'bb_stitcher prep rotate_image'), ('test_prep test_rotate_points', 'numpy array'), ('test_prep test_rotate_points', 'numpy testing assert_equal'), ('test_prep test_rotate_points', 'bb_stitcher prep rotate_points'), ('test_prep test_rectify_and_rotate_image', 'cv2 imwrite'), ('test_prep test_rectify_and_rotate_image', 'test_prep draw_marks'), ('test_prep test_rectify_and_rotate_image', 'bb_stitcher prep rotate_image'), ('test_prep test_rectify_and_rotate_image', 'bb_stitcher prep Rectificator'), ('test_prep test_rectify_and_rotate_image', 'bb_stitcher prep rotate_points')], [('visualisation draw_arrows', 'cv2 arrowedLine'), ('visualisation draw_arrows', 'numpy sin'), ('visualisation draw_arrows', 'numpy round'), ('visualisation draw_arrows', 'numpy cos'), ('visualisation draw_circles', 'cv2 circle'), ('visualisation draw_marks', 'cv2 drawMarker'), ('visualisation draw_complex_marks', 'cv2 drawMarker'), ('visualisation draw_complex_marks', 'cv2 arrowedLine'), ('visualisation draw_complex_marks', 'numpy sin'), ('visualisation draw_complex_marks', 'numpy round'), ('visualisation draw_complex_marks', 'numpy cos'), ('visualisation draw_complex_marks', 'cv2 circle'), ('visualisation draw_grid', 'numpy zeros'), ('visualisation draw_grid', 'numpy uint16'), ('visualisation draw_grid', 'cv2 line'), ('visualisation draw_grid', 'cv2 putText')], [('picker PointPicker pick', 'matplotlib pyplot subplots'), ('picker PointPicker pick', 'bb_stitcher picking draggables DraggableMarkList'), ('picker PointPicker pick', 'bb_stitcher helpers add_alpha_channel'), ('picker PointPicker pick', 'numpy array'), ('picker PointPicker pick', 'matplotlib pyplot setp'), ('picker PointPicker pick', 'matplotlib pyplot show'), ('picker PointPicker pick _on_click', 'bb_stitcher picking draggables DraggableMark')], [('setup', 'setuptools setup'), ('setup', 'pip req parse_requirements')], [('bb_stitcher compose_params', 'cv2 imwrite'), ('bb_stitcher _exist_path', 'os path exists'), ('bb_stitcher _exist_path', 'argparse ArgumentTypeError'), ('bb_stitcher _data_path', 'argparse ArgumentTypeError'), ('bb_stitcher _data_path', 'os path splitext'), ('bb_stitcher _img_path', 'argparse ArgumentTypeError'), ('bb_stitcher _img_path', 'os path splitext'), ('bb_stitcher _stitching_data', 'bb_stitcher _data_path'), ('bb_stitcher _stitching_data', 'bb_stitcher _exist_path'), ('bb_stitcher _get_main_parser', 'argparse ArgumentParser'), ('bb_stitcher _get_main_parser', 'textwrap dedent'), ('bb_stitcher main', 'bb_stitcher _get_main_parser')], [('core Surveyor __init__', 'bb_stitcher helpers get_default_config'), ('core Surveyor load', 'core Surveyor _acept_filehandler'), ('core Surveyor load', 'bb_stitcher io_utils get_file_handler'), ('core Surveyor load', 'core Surveyor _determine_world_homo'), ('core Surveyor _determine_world_homo', 'numpy array'), ('core Surveyor save', 'core Surveyor _acept_filehandler'), ('core Surveyor save', 'bb_stitcher io_utils get_file_handler'), ('core Surveyor determine_mapping_parameters', 'cv2 imread'), ('core Surveyor determine_mapping_parameters', 'bb_stitcher measure get_origin'), ('core Surveyor determine_mapping_parameters', 'bb_stitcher measure get_ratio'), ('core Surveyor determine_mapping_parameters', 'core Surveyor _determine_world_homo'), ('core Surveyor get_parameters', 'collections namedtuple'), ('core Surveyor set_parameters', 'core Surveyor _determine_world_homo'), ('core Surveyor map_points_angles', 'bb_stitcher stitcher Stitcher'), ('core Surveyor compose_panorama', 'cv2 imread'), ('core Surveyor compose_panorama', 'bb_stitcher visualisation draw_grid'), ('core Surveyor compose_panorama', 'bb_stitcher stitcher Stitcher')], [('test_script_bb_stitcher', 'pytest fixture'), ('test_script_bb_stitcher outdir', 'os makedirs'), ('test_script_bb_stitcher outdir', 'os path exists'), ('test_script_bb_stitcher outdir', 'os path join'), ('test_script_bb_stitcher test_exist_path', 'pytest raises'), ('test_script_bb_stitcher test_exist_path', 'bb_stitcher scripts bb_stitcher _exist_path'), ('test_script_bb_stitcher test_data_path', 'bb_stitcher scripts bb_stitcher _data_path'), ('test_script_bb_stitcher test_data_path', 'pytest raises'), ('test_script_bb_stitcher test_img_path', 'pytest raises'), ('test_script_bb_stitcher test_img_path', 'bb_stitcher scripts bb_stitcher _img_path'), ('test_script_bb_stitcher test_get_main_parser', 'bb_stitcher scripts bb_stitcher _get_main_parser'), ('test_script_bb_stitcher test_overall_compose', 'bb_stitcher scripts bb_stitcher main'), ('test_script_bb_stitcher test_overall_compose', 'os path exists'), ('test_script_bb_stitcher test_overall_compose', 'os path join'), ('test_script_bb_stitcher test_overall_estimate_rect', 'bb_stitcher scripts bb_stitcher main'), ('test_script_bb_stitcher test_overall_estimate_rect', 'os path exists'), ('test_script_bb_stitcher test_overall_estimate_rect', 'os path join'), ('test_script_bb_stitcher test_overall_estimate_rect mock_pick', 'numpy array'), ('test_script_bb_stitcher test_overall_estimate_rect mock_get_origin', 'numpy array'), ('test_script_bb_stitcher test_overall_estimate_fb', 'bb_stitcher scripts bb_stitcher main'), ('test_script_bb_stitcher test_overall_estimate_fb', 'os path exists'), ('test_script_bb_stitcher test_overall_estimate_fb', 'os path join'), ('test_script_bb_stitcher test_overall_estimate_fb mock_get_origin', 'numpy array')], [('test_visualisation', 'pytest fixture'), ('test_visualisation outdir', 'os makedirs'), ('test_visualisation outdir', 'os path exists'), ('test_visualisation outdir', 'os path join'), ('test_visualisation sample', 'numpy ones'), ('test_visualisation test_draw_arrows', 'bb_stitcher visualisation draw_arrows'), ('test_visualisation test_draw_arrows', 'cv2 imwrite'), ('test_visualisation test_draw_arrows', 'numpy ones'), ('test_visualisation test_draw_arrows', 'os path join'), ('test_visualisation test_draw_circles', 'numpy array'), ('test_visualisation test_draw_circles', 'cv2 imwrite'), ('test_visualisation test_draw_circles', 'os path join'), ('test_visualisation test_draw_circles', 'bb_stitcher visualisation draw_circles'), ('test_visualisation test_draw_marks', 'bb_stitcher visualisation draw_marks'), ('test_visualisation test_draw_marks', 'numpy array'), ('test_visualisation test_draw_marks', 'os path join'), ('test_visualisation test_draw_marks', 'cv2 imwrite'), ('test_visualisation test_draw_complex_marks', 'numpy array'), ('test_visualisation test_draw_complex_marks', 'bb_stitcher visualisation draw_complex_marks'), ('test_visualisation test_draw_complex_marks', 'cv2 imwrite'), ('test_visualisation test_draw_complex_marks', 'numpy ones'), ('test_visualisation test_draw_complex_marks', 'os path join'), ('test_visualisation test_draw_grid', 'os path join'), ('test_visualisation test_draw_grid', 'numpy array'), ('test_visualisation test_draw_grid', 'bb_stitcher visualisation draw_grid'), ('test_visualisation test_draw_grid', 'cv2 imwrite')], [('test_helpers test_get_boundaries', 'numpy float32'), ('test_helpers test_get_boundaries', 'bb_stitcher helpers get_boundaries'), ('test_helpers test_get_transform_to_origin_mat', 'numpy testing assert_equal'), ('test_helpers test_get_transform_to_origin_mat', 'numpy float32'), ('test_helpers test_get_transform_to_origin_mat', 'bb_stitcher helpers get_transform_to_origin_mat'), ('test_helpers test_add_alpha_channel', 'bb_stitcher helpers add_alpha_channel'), ('test_helpers test_add_alpha_channel', 'numpy zeros'), ('test_helpers test_add_alpha_channel', 'pytest raises'), ('test_helpers test_form_rectangle', 'numpy testing assert_equal'), ('test_helpers test_form_rectangle', 'numpy array'), ('test_helpers test_form_rectangle', 'bb_stitcher helpers form_rectangle'), ('test_helpers test_sort_pts', 'numpy testing assert_equal'), ('test_helpers test_sort_pts', 'numpy array'), ('test_helpers test_sort_pts', 'bb_stitcher helpers sort_pts'), ('test_helpers test_raw_estimate_rect', 'bb_stitcher helpers raw_estimate_rect'), ('test_helpers test_raw_estimate_rect', 'numpy array'), ('test_helpers test_raw_estimate_rect', 'numpy testing assert_almost_equal'), ('test_helpers test_harmonize_rects', 'numpy testing assert_equal'), ('test_helpers test_harmonize_rects', 'numpy array'), ('test_helpers test_harmonize_rects', 'bb_stitcher helpers harmonize_rects'), ('test_helpers test_angles_to_points', 'numpy array'), ('test_helpers test_angles_to_points', 'bb_stitcher helpers angles_to_points'), ('test_helpers test_angles_to_points', 'numpy zeros'), ('test_helpers test_angles_to_points', 'numpy ones'), ('test_helpers test_angles_to_points', 'numpy testing assert_almost_equal'), ('test_helpers test_points_to_angles', 'numpy array'), ('test_helpers test_points_to_angles', 'pytest raises'), ('test_helpers test_points_to_angles', 'bb_stitcher helpers points_to_angles'), ('test_helpers test_points_to_angles', 'numpy testing assert_equal'), ('test_helpers test_points_to_angles', 'numpy zeros')], [('stitcher Stitcher __init__', 'bb_stitcher prep Rectificator'), ('stitcher Stitcher __init__', 'bb_stitcher helpers get_default_config'), ('stitcher Stitcher _prepare_image', 'bb_stitcher helpers add_alpha_channel'), ('stitcher Stitcher _prepare_image', 'bb_stitcher prep rotate_image'), ('stitcher Stitcher get_parameters', 'collections namedtuple'), ('stitcher Stitcher compose_panorama', 'cv2 warpPerspective'), ('stitcher Stitcher compose_panorama', 'bb_stitcher helpers get_boundaries'), ('stitcher Stitcher compose_panorama', 'bb_stitcher helpers add_alpha_channel'), ('stitcher Stitcher compose_panorama', 'cv2 addWeighted'), ('stitcher Stitcher compose_panorama', 'math ceil'), ('stitcher Stitcher map_left_points', 'cv2 perspectiveTransform'), ('stitcher Stitcher map_left_points', 'numpy array'), ('stitcher Stitcher map_left_points_angles', 'bb_stitcher helpers angles_to_points'), ('stitcher Stitcher map_left_points_angles', 'cv2 perspectiveTransform'), ('stitcher Stitcher map_left_points_angles', 'bb_stitcher helpers points_to_angles'), ('stitcher Stitcher map_left_points_angles', 'numpy array'), ('stitcher Stitcher map_right_points', 'cv2 perspectiveTransform'), ('stitcher Stitcher map_right_points', 'numpy array'), ('stitcher Stitcher map_right_points_angles', 'bb_stitcher helpers angles_to_points'), ('stitcher Stitcher map_right_points_angles', 'cv2 perspectiveTransform'), ('stitcher Stitcher map_right_points_angles', 'bb_stitcher helpers points_to_angles'), ('stitcher Stitcher map_right_points_angles', 'numpy array'), ('stitcher Stitcher _calc_image_to_world_mat', 'bb_stitcher picking picker PointPicker'), ('stitcher Stitcher _calc_image_to_world_mat', 'bb_stitcher helpers get_ratio_px_to_mm'), ('stitcher Stitcher _calc_image_to_world_mat', 'numpy array'), ('stitcher FeatureBasedStitcher _calc_feature_mask', 'numpy zeros'), ('stitcher FeatureBasedStitcher estimate_transform', 'stitcher FeatureBasedStitcher _calc_feature_mask'), ('stitcher FeatureBasedStitcher estimate_transform', 'bb_stitcher helpers get_transform_to_origin_mat'), ('stitcher FeatureBasedStitcher estimate_transform', 'stitcher Stitcher _prepare_image'), ('stitcher FeatureBasedStitcher estimate_transform', 'numpy float32')], [('draggables DraggableMark __init__', 'cv2 cvtColor'), ('draggables DraggableMark _refine', 'cv2 cornerSubPix'), ('draggables DraggableMark _refine', 'numpy array'), ('draggables DraggableMark _refine', 'draggables DraggableMark _unselect'), ('draggables DraggableMark _refine', 'draggables DraggableMark get_coordinate'), ('draggables DraggableMark _on_press', 'draggables DraggableMark _unselect'), ('draggables DraggableMark _on_press', 'draggables DraggableMark get_coordinate'), ('draggables DraggableMark _on_key', 'draggables DraggableMark _toggle_select'), ('draggables DraggableMark _on_key', 'draggables DraggableMark _refine'), ('draggables DraggableMarkList get_points', 'numpy zeros')]]\n",
      "********************doctrings*************************\n",
      "[\"get default config get default debug config get boundaries get transform to origin mat add alpha channel form rectangle sort pts raw estimate rect harmonize rects angles to points process points to angles points to angles get ratio px to mm [SEP] Return the default config. Return the default logging config file. Determine the boundaries of two transformed images. When two images have been transformed by homogr Determine homography matrix to align 'shared_space' to display area origin. Examp\", 'create prepared image dict left img prep right img prep test gui test pick length', 'pytest runtest makereport pytest runtest setup get test fname fname create image dict left img right img not to bee surveyor csv path config main outdir panorama error params', 'get affine mat and new size rotate image rotate points [SEP] Calculate the affine transformation to rotate image by given angle. Args:   angle (int): Rotation Rotate image by given angle. Args:   image (ndarray): Input image.   angle (int): Rotation angl Rotate points by given angle and in relation to', 'outdir draw marks test  ectificator test rotate image test rotate image specifc test rotate points test rectify and rotate image', 'draw arrows draw circles draw marks draw complex marks draw grid [SEP] Draw arrows from positions in angle direction (clockwise). (The 0-Angle is the x-Axis.) Args:   Draw circles around positions. Args:   img (ndarray): Image (min. 3 channel) to draw on.   cent Draw cross marks on position. Args:   img (nd', '', '', \"estimate params compose params exist path data path img path stitching data get main parser main [SEP] Execute the subcommand 'estimate' from the parser. Execute the subcommand 'compose' from the parser. Check if the given string is a valid file string. Check if the path has a valid extension. Check if the path is a valid image. Check if the path is a\", '', 'outdir test exist path test data path test img path test get main parser test overall compose test overall estimate rect test overall estimate fb', 'outdir sample test draw arrows test draw circles test draw marks test draw complex marks test draw grid', 'test get boundaries test get transform to origin mat test add alpha channel test form rectangle test sort pts test raw estimate rect test harmonize rects test angles to points test points to angles test get ratio px to mm test get default config test get default debug config', '', '']\n",
      "embed index dataset: 13\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hklchung_GAN-GenerativeAdversarialNetwork\\\\CycleGAN\\\\main.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hklchung_GAN-GenerativeAdversarialNetwork\\\\LSGAN\\\\main_MNIST.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hklchung_GAN-GenerativeAdversarialNetwork\\\\ACGAN\\\\main.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hklchung_GAN-GenerativeAdversarialNetwork\\\\LSGAN\\\\main_100kCeleb.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hklchung_GAN-GenerativeAdversarialNetwork\\\\CGAN\\\\main_CelebA.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hklchung_GAN-GenerativeAdversarialNetwork\\\\CGAN\\\\main_MNIST.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hklchung_GAN-GenerativeAdversarialNetwork\\\\InfoGAN\\\\main.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\hklchung_GAN-GenerativeAdversarialNetwork\\\\DCGAN\\\\main.py']\n",
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import random\n",
      "import matplotlib.pyplot as plt\n",
      "from tqdm import tqdm\n",
      "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape, LeakyReLU, AveragePooling2D, Embedding\n",
      "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, BatchNormalization, ZeroPadding2D, Concatenate, Add\n",
      "from keras.models import Sequential, load_model, Model\n",
      "from keras.optimizers import RMSprop, Adam\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
      "from keras.utils.vis_utils import plot_model\n",
      "from keras import backend, Input\n",
      "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
      "from skimage.io import imsave\n",
      "from sklearn.utils import shuffle\n",
      "from sklearn.utils import shuffle\n",
      "from PIL import Image, ImageOps\n",
      "import cv2\n",
      "import tensorflow as tf\n",
      "from tensorflow import keras\n",
      "\n",
      "#=======================Discriminator model func===============================\n",
      "# Function to create discriminator\n",
      "def discriminator(nodes_per_layer=32):\n",
      "    input_x = Input(shape=(256, 256, 3))\n",
      "\n",
      "    x = Conv2D(nodes_per_layer, (3, 3), strides=(2, 2))(input_x)\n",
      "    x = LeakyReLU(0.2)(x)\n",
      "\n",
      "    x = Conv2D(nodes_per_layer, (3, 3), strides=(2, 2))(x)\n",
      "    x = LeakyReLU(0.2)(x)\n",
      "\n",
      "    x = Conv2D(nodes_per_layer, (3, 3), strides=(2, 2))(x)\n",
      "    x = LeakyReLU(0.2)(x)\n",
      "\n",
      "    x = Conv2D(nodes_per_layer, (3, 3), strides=(2, 2))(x)\n",
      "    x = LeakyReLU(0.2)(x)\n",
      "\n",
      "    x = Dropout(0.5)(x)\n",
      "\n",
      "    x = Flatten()(x)\n",
      "    x = Dense(1)(x)\n",
      "    output_x = Activation('sigmoid')(x)\n",
      "    return Model(input_x, output_x)\n",
      "\n",
      "#=======================Generator model funcs==================================\n",
      "# Function to create full residual blocks\n",
      "def full_residual(nodes_per_layer, x):\n",
      "  res_x = Conv2D(nodes_per_layer, (3, 3), padding='same')(x)\n",
      "  res_x = Activation('relu')(res_x)\n",
      "  res_x = Conv2D(nodes_per_layer, (3, 3), padding='same')(res_x)\n",
      "  res_x = Activation('relu')(res_x)\n",
      "  x = Add()([x, res_x])\n",
      "  return(x)\n",
      "\n",
      "# Function to create half residual blocks\n",
      "def half_residual(nodes_per_layer, x_half):\n",
      "  res_x = Conv2D(nodes_per_layer * 2, (3, 3), padding='same')(x_half)\n",
      "  res_x = Activation('relu')(res_x)\n",
      "  res_x = Conv2D(nodes_per_layer * 2, (3, 3), padding='same')(res_x)\n",
      "  res_x = Activation('relu')(res_x)\n",
      "  x_half = Add()([x_half, res_x])\n",
      "  return(x_half)\n",
      "\n",
      "# Function to create quarter residual blocks\n",
      "def quarter_residual(nodes_per_layer, x_quarter):\n",
      "  res_x = Conv2D(nodes_per_layer * 4, (3, 3), padding='same')(x_quarter)\n",
      "  res_x = Activation('relu')(res_x)\n",
      "  res_x = Conv2D(nodes_per_layer * 4, (3, 3), padding='same')(res_x)\n",
      "  res_x = Activation('relu')(res_x)\n",
      "  x_quarter = Add()([x_quarter, res_x])\n",
      "  return(x_quarter)\n",
      "\n",
      "# Function to create generator\n",
      "def generator(nodes_per_layer=32):\n",
      "    input_x = Input(shape=(256, 256, 3))\n",
      "\n",
      "    x = Conv2D(nodes_per_layer, (3, 3), padding='same')(input_x)\n",
      "    x = Activation('relu')(x)\n",
      "\n",
      "    # 3 residual blocks for full\n",
      "    x = full_residual(nodes_per_layer, x)\n",
      "    x = full_residual(nodes_per_layer, x)\n",
      "    x = full_residual(nodes_per_layer, x)\n",
      "\n",
      "    # 6 residual blocks for half\n",
      "    x_half = Conv2D(nodes_per_layer * 2, (2, 2), strides=(2, 2))(input_x)\n",
      "    x_half = Activation('relu')(x_half)\n",
      "\n",
      "    x_half = half_residual(nodes_per_layer, x_half)\n",
      "    x_half = half_residual(nodes_per_layer, x_half)\n",
      "    x_half = half_residual(nodes_per_layer, x_half)\n",
      "    x_half = half_residual(nodes_per_layer, x_half)\n",
      "    x_half = half_residual(nodes_per_layer, x_half)\n",
      "    x_half = half_residual(nodes_per_layer, x_half)\n",
      "\n",
      "    x_quarter = Conv2D(nodes_per_layer * 4, (2, 2), strides=(2, 2))(x_half)\n",
      "    x_quarter = Activation('relu')(x_quarter)\n",
      "\n",
      "    # 6 residual blocks for quarter\n",
      "    x_quarter = quarter_residual(nodes_per_layer, x_quarter)\n",
      "    x_quarter = quarter_residual(nodes_per_layer, x_quarter)\n",
      "    x_quarter = quarter_residual(nodes_per_layer, x_quarter)\n",
      "    x_quarter = quarter_residual(nodes_per_layer, x_quarter)\n",
      "    x_quarter = quarter_residual(nodes_per_layer, x_quarter)\n",
      "    x_quarter = quarter_residual(nodes_per_layer, x_quarter)\n",
      "\n",
      "    x_quarter = Conv2DTranspose(nodes_per_layer * 2, (2, 2), strides=(2, 2))(x_quarter)\n",
      "    x_quarter = Activation('relu')(x_quarter)\n",
      "\n",
      "    x_half = Add()([x_quarter, x_half])\n",
      "\n",
      "    x_half = Conv2DTranspose(nodes_per_layer, (2, 2), strides=(2, 2))(x_half)\n",
      "    x_half = Activation('relu')(x_half)\n",
      "\n",
      "    x = Add()([x, x_half])\n",
      "    x = Conv2D(3, (3, 3), padding='same')(x)\n",
      "    output_x = Activation('relu')(x)\n",
      "    return Model(input_x, output_x)\n",
      "\n",
      "#===========================Compile CycleGAN===================================\n",
      "# Create generators for 2 way style transfer\n",
      "gen_a2b = generator()\n",
      "gen_b2a = generator()\n",
      "\n",
      "# Create discriminators to validate styles\n",
      "disc_a = discriminator()\n",
      "disc_b = discriminator()\n",
      "\n",
      "optimizer1 = Adam(learning_rate=0.0001)\n",
      "\n",
      "disc_a.compile(optimizer=optimizer1, loss='binary_crossentropy', metrics=['acc'])\n",
      "disc_b.compile(optimizer=optimizer1, loss='binary_crossentropy', metrics=['acc'])\n",
      "\n",
      "disc_a.trainable = False\n",
      "disc_b.trainable = False\n",
      "\n",
      "# Create the style A to B GAN architecture\n",
      "input_a = Input(shape=(256, 256, 3))\n",
      "output_image_b = gen_a2b(input_a)\n",
      "output_disc_b = disc_b(output_image_b)\n",
      "output_gen_a = gen_b2a(output_image_b)\n",
      "GAN_a2b = Model(input_a, [output_disc_b, output_gen_a, output_image_b])\n",
      "\n",
      "# Create the style B to A GAN architecture\n",
      "input_b = Input(shape=(256, 256, 3))\n",
      "output_image_a = gen_b2a(input_b)\n",
      "output_disc_a = disc_a(output_image_a)\n",
      "output_gen_b = gen_a2b(output_image_a)\n",
      "GAN_b2a = Model(input_b, [output_disc_a, output_gen_b, output_image_a])\n",
      "\n",
      "optimizer2 = Adam(learning_rate=0.0005)\n",
      "\n",
      "GAN_a2b.compile(optimizer=optimizer2, loss=['binary_crossentropy', 'mae', 'mae'], loss_weights=[0.1, 1, 0.01])\n",
      "GAN_b2a.compile(optimizer=optimizer2, loss=['binary_crossentropy', 'mae', 'mae'], loss_weights=[0.1, 1, 0.01])\n",
      "\n",
      "plot_model(gen_a2b, to_file='gen_a2b.png', show_shapes=True, show_layer_names=True)\n",
      "plot_model(gen_b2a, to_file='gen_b2a.png', show_shapes=True, show_layer_names=True)\n",
      "plot_model(disc_a, to_file='disc_a.png', show_shapes=True, show_layer_names=True)\n",
      "plot_model(disc_b, to_file='disc_b.png', show_shapes=True, show_layer_names=True)\n",
      "plot_model(GAN_a2b, to_file='GAN_a2b.png', show_shapes=True, show_layer_names=True)\n",
      "plot_model(GAN_b2a, to_file='GAN_b2a.png', show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==============================Plot image function=============================\n",
      "def plot_output(step):\n",
      "    filename = \"GANmodel_%d\" % step\n",
      "    plt.figure(figsize=(10,10))\n",
      "    for i in range(16):\n",
      "        plt.subplot(4, 4, i+1)\n",
      "        if i % 4 == 0:\n",
      "          image = cv2.imread('monet2photo/testA/' + random.choice(os.listdir('monet2photo/testA')))\n",
      "          plt.imshow(image)\n",
      "          plt.axis('off')\n",
      "        elif i % 4 == 1:\n",
      "          image = cv2.resize(image, (256, 256))\n",
      "          image = np.expand_dims(image, axis = 0)\n",
      "          image_translated = gen_a2b.predict(image)\n",
      "          plt.imshow((image_translated/255).reshape(256,256,3))\n",
      "          plt.axis('off')\n",
      "        elif i % 4 == 2:\n",
      "          image = cv2.imread('monet2photo/testB/' + random.choice(os.listdir('monet2photo/testB')))\n",
      "          plt.imshow(image)\n",
      "          plt.axis('off')\n",
      "        elif i % 4 == 3:\n",
      "          image = cv2.resize(image, (256, 256))\n",
      "          image = np.expand_dims(image, axis = 0)\n",
      "          image_translated = gen_b2a.predict(image)\n",
      "          plt.imshow((image_translated/255).reshape(256,256,3))\n",
      "          plt.axis('off')\n",
      "          plt.tight_layout()\n",
      "    plt.savefig(filename)\n",
      "    plt.close('all')\n",
      "    \n",
      "#==========================Plot loss function==================================\n",
      "def plot_loss(gan1_performance, gan2_performance, modl1, modl2, suffix='', jump=100):\n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.plot(gan1_performance[0::jump], label=modl1)\n",
      "    plt.plot(gan2_performance[0::jump], label=modl2)\n",
      "    plt.xlabel('epoch ({})'.format(jump))\n",
      "    plt.ylabel('loss')\n",
      "    plt.legend()\n",
      "    plt.savefig('loss_over_epoch{}.png'.format(suffix))\n",
      "    plt.close('all')\n",
      "\n",
      "#=============================Train CycleGAN===================================\n",
      "def train_gan(batch_size=128, epoch=100, save_interval=1):\n",
      "    \n",
      "    # simple data augmentation implicitly including resizing to 256,256\n",
      "    feature_datagen_a = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True)\n",
      "    feature_datagen_b = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True)\n",
      "    \n",
      "    # pipeline to flow images from a directory in batches\n",
      "    feature_image_generator_a = feature_datagen_a.flow_from_directory('images_a', seed=1, class_mode=None, batch_size = batch_size)\n",
      "    feature_image_generator_b = feature_datagen_b.flow_from_directory('images_b', seed=1, class_mode=None, batch_size = batch_size)\n",
      "    \n",
      "    # core training loop, loads batch of images, generators and discriminators on batch\n",
      "    gan_a2b_losses = []\n",
      "    gan_b2a_losses = []\n",
      "\n",
      "    discA_in_class_losses = []\n",
      "    discA_btw_class_losses = []\n",
      "\n",
      "    discB_in_class_losses = []\n",
      "    discB_btw_class_losses = []\n",
      "\n",
      "    batch_num_per_epoch = len(os.listdir('images_a/images'))//batch_size\n",
      "\n",
      "    for i in range(0, epoch):\n",
      "      for j in tqdm(range(0, batch_num_per_epoch)):\n",
      "        # load a batch of images of each class into memory\n",
      "        images_a_batch = next(feature_image_generator_a)\n",
      "        images_b_batch = next(feature_image_generator_b)\n",
      "        target_a_batch = np.ones([len(images_a_batch),1])\n",
      "        target_b_batch = np.ones([len(images_b_batch),1])\n",
      "      \n",
      "        # fit each generator\n",
      "        gan_a2b_loss = GAN_a2b.train_on_batch(images_a_batch, [target_a_batch, images_a_batch, images_a_batch])\n",
      "        gan_b2a_loss = GAN_b2a.train_on_batch(images_b_batch, [target_b_batch, images_b_batch, images_b_batch])\n",
      "\n",
      "        gan_a2b_losses.append(gan_a2b_loss[0])\n",
      "        gan_b2a_losses.append(gan_b2a_loss[0])\n",
      "      \n",
      "        # create a new set of false images to train discriminator\n",
      "        images_b_batch_fake = gen_a2b.predict(images_a_batch, batch_size=1)\n",
      "        images_a_batch_fake = gen_b2a.predict(images_b_batch, batch_size=1)\n",
      "        target_a_batch_fake = np.zeros([len(images_a_batch_fake),1])\n",
      "        target_b_batch_fake = np.zeros([len(images_b_batch_fake),1])\n",
      "      \n",
      "        # combine fake and real images by class\n",
      "        images_a_batch_discriminator = np.concatenate((images_a_batch, images_a_batch_fake), axis=0)\n",
      "        images_b_batch_discriminator = np.concatenate((images_b_batch, images_b_batch_fake), axis=0)\n",
      "        target_a_batch_discriminator = np.concatenate((target_a_batch, target_a_batch_fake), axis=0)\n",
      "        target_b_batch_discriminator = np.concatenate((target_b_batch, target_b_batch_fake), axis=0)\n",
      "      \n",
      "        # fit discriminator to determine real vs fake images in a class\n",
      "        discA_in_class_loss = disc_a.train_on_batch(images_a_batch_discriminator, target_a_batch_discriminator)\n",
      "        discB_in_class_loss = disc_b.train_on_batch(images_b_batch_discriminator, target_b_batch_discriminator)\n",
      "\n",
      "        discA_in_class_losses.append(discA_in_class_loss[0])\n",
      "        discB_in_class_losses.append(discB_in_class_loss[0])\n",
      "      \n",
      "        # create a second training set for the discriminators of all real images mixing the classes\n",
      "        images_a_batch_discriminator = np.concatenate((images_a_batch, images_b_batch), axis=0)\n",
      "        images_b_batch_discriminator = np.concatenate((images_b_batch, images_a_batch), axis=0)\n",
      "        target_a_batch_discriminator = np.concatenate((target_a_batch, target_a_batch_fake), axis=0)\n",
      "        target_b_batch_discriminator = np.concatenate((target_b_batch, target_b_batch_fake), axis=0)\n",
      "      \n",
      "        # train discriminators to determine real images of class a from real images of class b\n",
      "        discA_btw_class_loss = disc_a.train_on_batch(images_a_batch_discriminator, target_a_batch_discriminator)\n",
      "        discB_btw_class_loss = disc_b.train_on_batch(images_b_batch_discriminator, target_b_batch_discriminator)\n",
      "\n",
      "        discA_btw_class_losses.append(discA_btw_class_loss[0])\n",
      "        discB_btw_class_losses.append(discB_btw_class_loss[0])\n",
      "\n",
      "      log_msg = \"epoch %d: [GAN A2B loss: %f]\" % (i, gan_a2b_loss[0])\n",
      "      log_msg = \"%s  [GAN B2A loss: %f]\" % (log_msg, gan_b2a_loss[0])\n",
      "      log_msg = \"%s  [D_A in-class loss: %f]\" % (log_msg, discA_in_class_loss[0])\n",
      "      log_msg = \"%s  [D_B in-class loss: %f]\" % (log_msg, discB_in_class_loss[0])\n",
      "      log_msg = \"%s  [D_A disc class loss: %f]\" % (log_msg, discA_btw_class_loss[0])\n",
      "      log_msg = \"%s  [D_A disc class loss: %f]\" % (log_msg, discB_btw_class_loss[0])\n",
      "      print(log_msg)\n",
      "    \n",
      "      if save_interval>0 and (i+1)%save_interval==0:\n",
      "          plot_output(i+1)\n",
      "      \n",
      "    return(gan_a2b_losses, gan_b2a_losses, discA_in_class_losses, discB_in_class_losses, discA_btw_class_losses, discB_btw_class_losses)\n",
      "\n",
      "#==============================Train CycleGAN===================================\n",
      "gan_a2b_ls, gan_b2a_ls, dA_ls, dB_ls, dA_btw_class_ls, dB_btw_class_ls = train_gan(batch_size=32, epoch=20, save_interval=1)\n",
      "\n",
      "plot_loss(gan_a2b_ls, gan_b2a_ls, 'GAN_A2B', 'GAN_B2A', suffix='', 10)\n",
      "plot_loss(dA_ls, dB_ls, 'D_A', 'D_B', suffix='in_class_disc', 10)\n",
      "plot_loss(dA_btw_class_ls, dB_btw_class_ls, 'D_A', 'D_B', suffix='between_class_disc', 10)\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hklchung_GAN-GenerativeAdversarialNetwork\\CycleGAN\\main.py\n",
      "[]\n",
      "found files: []\n",
      "\"\"\"\n",
      "Copyright (c) 2020, Heung Kit Leslie Chung\n",
      "All rights reserved.\n",
      "Redistribution and use in source and binary forms, with or without\n",
      "    modification, are permitted provided that the following conditions are met:\n",
      "1. Redistributions of source code must retain the above copyright notice, this\n",
      "    list of conditions and the following disclaimer.\n",
      "2. Redistributions in binary form must reproduce the above copyright notice,\n",
      "    this list of conditions and the following disclaimer in the documentation\n",
      "    and/or other materials provided with the distribution.\n",
      "3. Neither the name of the copyright holder nor the names of its contributors\n",
      "    may be used to endorse or promote products derived from this software\n",
      "    without specific prior written permission.\n",
      "    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "    AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "    IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
      "    ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
      "    LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
      "    CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
      "    SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
      "    INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
      "    CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
      "    ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
      "    POSSIBILITY OF SUCH DAMAGE.\n",
      "\"\"\"\n",
      "\n",
      "import os\n",
      "import numpy as np\n",
      "import random\n",
      "import matplotlib.pyplot as plt\n",
      "from tqdm import tqdm\n",
      "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape, LeakyReLU, ReLU\n",
      "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, BatchNormalization, ZeroPadding2D\n",
      "from keras.models import Sequential, load_model\n",
      "from keras.optimizers import RMSprop, Adam\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
      "from keras.utils.vis_utils import plot_model\n",
      "from keras import backend\n",
      "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
      "from skimage.io import imsave\n",
      "from skimage.transform import resize\n",
      "from sklearn.utils import shuffle\n",
      "from PIL import Image, ImageOps\n",
      "import tensorflow as tf\n",
      "from imageio import imread\n",
      "from keras.datasets import mnist\n",
      "\n",
      "#=============================Load MNIST dataset===============================\n",
      "(X, _), (_, _) = mnist.load_data()\n",
      "# KEY CHANGE: RGB values normalised to range -1 to 1 as we have tanh activation in generator\n",
      "X = (X-127.5)/127.5\n",
      "X = np.array([x.reshape(28, 28, 1) for x in X])\n",
      "\n",
      "#=========================Discriminator model==================================\n",
      "# Define architecture of the discriminator (police AI)\n",
      "depth = 64\n",
      "dropout = 0.5\n",
      "D = Sequential()\n",
      "# Input layer\n",
      "D.add(Conv2D(depth*1, 5, strides=2, input_shape=X.shape[1:],padding='same', kernel_initializer='glorot_normal'))\n",
      "D.add(LeakyReLU(alpha=0.2))\n",
      "D.add(Dropout(dropout))\n",
      "D.add(BatchNormalization(momentum=0.9))\n",
      "# Second layer\n",
      "D.add(Conv2D(depth*2, 5, strides=2, padding='same', kernel_initializer='glorot_normal'))\n",
      "D.add(LeakyReLU(alpha=0.2))\n",
      "D.add(Dropout(dropout))\n",
      "D.add(BatchNormalization(momentum=0.9))\n",
      "# Third layer\n",
      "D.add(Conv2D(depth*4, 5, strides=2, padding='same', kernel_initializer='glorot_normal'))\n",
      "D.add(LeakyReLU(alpha=0.2))\n",
      "D.add(Dropout(dropout))\n",
      "D.add(BatchNormalization(momentum=0.9))\n",
      "# Forth layer\n",
      "D.add(Conv2D(depth*8, 5, strides=1, padding='same', kernel_initializer='glorot_normal'))\n",
      "D.add(LeakyReLU(alpha=0.2))\n",
      "D.add(Dropout(dropout))\n",
      "D.add(BatchNormalization(momentum=0.9))\n",
      "D.add(Flatten())\n",
      "# Output layer\n",
      "D.add(Dense(1, kernel_initializer='glorot_normal'))\n",
      "# KEY CHANGE: linear activation (rather than sigmoid like in DCGAN)\n",
      "D.add(Activation('linear'))\n",
      "\n",
      "# Print out architecture of the discriminator\n",
      "D.summary()\n",
      "# Save model architecture as .PNG\n",
      "plot_model(D, to_file='discriminator.png', show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Generator model=====================================\n",
      "# Define architecture of the generator (fraudster AI)\n",
      "# Note: with each layer, the image gets larger but with reduced depth\n",
      "dropout = 0.5\n",
      "depth = 64*4\n",
      "dim = 7\n",
      "noise_vec = 256\n",
      "G = Sequential()\n",
      "# Input layer\n",
      "# In: 100\n",
      "# Out: dim x dim x depth\n",
      "G.add(Dense(dim*dim*depth, input_dim=noise_vec, kernel_initializer='glorot_normal'))\n",
      "G.add(BatchNormalization(momentum=0.9))\n",
      "G.add(LeakyReLU(alpha=0.3))\n",
      "G.add(Reshape((dim, dim, depth)))\n",
      "G.add(Dropout(dropout))\n",
      "# Second layer\n",
      "# In: dim x dim x depth\n",
      "# Out: 2*dim x 2*dim x depth/2\n",
      "G.add(UpSampling2D())\n",
      "G.add(Conv2DTranspose(int(depth/2), 5, padding='same', kernel_initializer='glorot_normal'))\n",
      "G.add(BatchNormalization(momentum=0.8))\n",
      "G.add(LeakyReLU(alpha=0.3))\n",
      "# Third layer\n",
      "# In: 2*dim x 2*dim x depth/2\n",
      "# Out: 4*dim x 4*dim x depth/4\n",
      "G.add(UpSampling2D())\n",
      "G.add(Conv2DTranspose(int(depth/4), 5, padding='same', kernel_initializer='glorot_normal'))\n",
      "G.add(BatchNormalization(momentum=0.8))\n",
      "G.add(LeakyReLU(alpha=0.3))\n",
      "# Output layer\n",
      "# In: 4*dim x 4*dim x depth/4\n",
      "# Out: 28 x 28 x 1 RGB scale image [0.0,1.0] per pixel\n",
      "G.add(Conv2DTranspose(1, 5, padding='same', kernel_initializer='glorot_normal'))\n",
      "# KEY CHANGE: tanh activation (rather than sigmoid like in DCGAN)\n",
      "G.add(Activation('tanh'))\n",
      "\n",
      "# Print out architecture of the generator\n",
      "G.summary()\n",
      "# Save model architecture as .PNG\n",
      "plot_model(G, to_file='generator.png', show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#============================Optimiser=========================================\n",
      "# Define optimisers - optimisr1 will be used for the discriminator and generator\n",
      "optimizer1 = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
      "optimizer2 = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
      "\n",
      "# KEY CHANGE: mse loss (rather than binary_crossentropy like in DCGAN)\n",
      "D.compile(loss='mse', optimizer=optimizer1,metrics=['accuracy'])\n",
      "G.compile(loss='mse', optimizer=optimizer1,metrics=['accuracy'])\n",
      "\n",
      "# Define architecture of GAN\n",
      "GAN = Sequential()\n",
      "GAN.add(G)  # Adding the generator\n",
      "GAN.add(D)  # Adding the discriminator \n",
      "GAN.compile(loss='mse', optimizer=optimizer2, metrics=['accuracy'])\n",
      "\n",
      "# Print out architecture of GAN\n",
      "GAN.summary()\n",
      "# Save model architecture as .PNG\n",
      "plot_model(GAN, to_file='LSGAN.png', show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Plot image function=================================\n",
      "def plot_output(noise, step):\n",
      "    filename = \"GANmodel_%d.png\" % step\n",
      "    \n",
      "    images = G.predict(noise)\n",
      "\n",
      "    plt.figure(figsize=(10,10))\n",
      "    for i in range(images.shape[0]):\n",
      "        plt.subplot(4, 4, i+1)\n",
      "        image = images[i, :, :, :]\n",
      "        image = image.reshape(X.shape[1], X.shape[2])\n",
      "        plt.imshow(image, cmap='gray')\n",
      "        plt.axis('off')\n",
      "    plt.tight_layout()\n",
      "    plt.savefig(filename)\n",
      "    plt.close('all')\n",
      "    \n",
      "#==========================Plot loss function==================================\n",
      "def plot_loss(d_performance, gan_performance, jump=100):\n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.plot(d_performance[0::jump], label='discriminator')\n",
      "    plt.plot(gan_performance[0::jump], label='GAN')\n",
      "    plt.xlabel('epoch ({})'.format(jump))\n",
      "    plt.ylabel('loss')\n",
      "    plt.legend()\n",
      "    plt.savefig('loss_over_epoch.png')\n",
      "    plt.close('all')\n",
      "    \n",
      "#========================Plot accuracy function================================\n",
      "def plot_accuracy(d_performance, gan_performance, jump=100):\n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.plot(d_performance[0::jump], label='discriminator')\n",
      "    plt.plot(gan_performance[0::jump], label='GAN')\n",
      "    plt.xlabel('epoch ({})'.format(jump))\n",
      "    plt.ylabel('accuracy')\n",
      "    plt.legend()\n",
      "    plt.savefig('accuracy_over_epoch.png')\n",
      "    plt.close('all')\n",
      "\n",
      "#=========================Train GAN function===================================\n",
      "def train_gan(X, model, batch_size, epoch, save_interval, pretrain=False, pretrain_num=100, noise_len=100):\n",
      "    if pretrain == True:\n",
      "        if pretrain_num > X.shape[0]:\n",
      "            pretrain_num = X.shape[0]\n",
      "        else:\n",
      "            # Randomly select n (pretrain_num) number of images from X\n",
      "            images_real = X[np.random.randint(0,X.shape[0], size=pretrain_num), :, :, :]\n",
      "            # Generate n number of 100D noise vectors\n",
      "            noise = np.random.normal(0.0, 1.0, size=[pretrain_num, noise_len])\n",
      "            # Produce n number of fake images with generator\n",
      "            images_fake = G.predict(noise)\n",
      "            # Concat real and fake images\n",
      "            x = np.concatenate((images_real, images_fake))\n",
      "            # Create labels\n",
      "            y = np.ones([2*pretrain_num, 1])\n",
      "            y[pretrain_num:, :] = 0\n",
      "            # Shuffle the real and fake images\n",
      "            x,y = shuffle(x,y)\n",
      "            # Make discriminator trainable\n",
      "            D.trainable = True\n",
      "            # Train discriminator on the sampled data\n",
      "            D.fit(x, y, batch_size=batch_size, epochs=1, validation_split=0.15)\n",
      "    else:\n",
      "        None\n",
      "    \n",
      "    d_performance = []\n",
      "    gan_performance = []\n",
      "    d_accuracy = []\n",
      "    gan_accuracy = []\n",
      "    \n",
      "    batch_per_epoch = int(round(X.shape[0]/batch_size))\n",
      "    \n",
      "    for i in range(epoch):\n",
      "        for j in tqdm(range(batch_per_epoch)):\n",
      "            #====================Train discriminator===========================\n",
      "            half_batch = int(batch_size/2)\n",
      "            # Randomly select n (batch_size) number of images from X\n",
      "            images_real = X[np.random.randint(0,X.shape[0], size=half_batch), :, :, :]\n",
      "            # Generate n number of 100D noise vectors\n",
      "            noise = np.random.normal(0.0, 1.0, size=[half_batch, noise_len])\n",
      "            # Produce n number of fake images with generator\n",
      "            images_fake = G.predict(noise)\n",
      "            # Concat real and fake images\n",
      "            x = np.concatenate((images_real, images_fake))\n",
      "            # Create labels\n",
      "            y = np.ones([batch_size, 1]) \n",
      "            y[half_batch:, :] = 0\n",
      "            # Shuffle the real and fake images\n",
      "            x,y = shuffle(x,y)\n",
      "            # Make discriminator trainable\n",
      "            D.trainable = True\n",
      "            # Train discriminator on the sampled data\n",
      "            d_loss = D.train_on_batch(x, y)\n",
      "            \n",
      "            #========================Train GAN=================================\n",
      "            # Create labels\n",
      "            y = np.ones([batch_size, 1])\n",
      "            # Generate n number of 100D noise vectors\n",
      "            noise = np.random.normal(0.0, 1.0, size=[batch_size, noise_len])\n",
      "            # Freeze weights in discriminator\n",
      "            D.trainable = False\n",
      "            # Train GAN on the generated data\n",
      "            gan_loss = GAN.train_on_batch(noise, y)\n",
      "            \n",
      "        # Print loss and accuracy values \n",
      "        log_msg = \"epoch %d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
      "        log_msg = \"%s  [GAN loss: %f, acc: %f]\" % (log_msg, gan_loss[0], gan_loss[1])\n",
      "        print(log_msg)\n",
      "        \n",
      "        d_performance.append(np.array(d_loss[0], dtype=float))\n",
      "        gan_performance.append(np.array(gan_loss[0], dtype=float))\n",
      "        \n",
      "        d_accuracy.append(np.array(d_loss[1], dtype=float))\n",
      "        gan_accuracy.append(np.array(gan_loss[1], dtype=float))\n",
      "        \n",
      "        # Save ouputs\n",
      "        if save_interval>0 and (i+1)%save_interval==0:\n",
      "            noise_input = np.random.normal(0.0, 1.0, size=[16, noise_len])\n",
      "            plot_output(noise=noise_input, step=(i+1))\n",
      "    \n",
      "    d_loss_ls = [float(x) for x in d_performance]\n",
      "    gan_loss_ls = [float(x) for x in gan_performance]\n",
      "    d_acc_ls = [float(x) for x in d_accuracy]\n",
      "    gan_acc_ls = [float(x) for x in gan_accuracy]\n",
      "    return(d_loss_ls, gan_loss_ls, d_acc_ls, gan_acc_ls)\n",
      "\n",
      "#=================================Train GAN====================================\n",
      "# Hints:\n",
      "# Input noise - longer noise vector produce better results (100, 128, 256)\n",
      "# --- to change noise_len, make sure to also change generator input size\n",
      "# Batch size - pick smaller batch size like 8, 16, 32, 64\n",
      "# Pre-training may hurt performance\n",
      "d_loss_ls, gan_loss_ls, d_acc_ls, gan_acc_ls = train_gan(X=X, model=GAN, batch_size=16, epoch=2000, \n",
      "                                                         save_interval=100, pretrain=False, pretrain_num=20000,\n",
      "                                                         noise_len=256)\n",
      "plot_loss(d_loss_ls, gan_loss_ls)\n",
      "plot_accuracy(d_acc_ls, gan_acc_ls)\n",
      "\n",
      "#================================Save model====================================\n",
      "model_json = GAN.to_json()\n",
      "with open(\"LSGAN_MNIST_model.json\", \"w\") as json_file:\n",
      "    json_file.write(model_json)\n",
      "GAN.save_weights(\"LSGAN_MNIST_model.h5\")\n",
      "\n",
      "#================================Result GIF====================================\n",
      "import imageio\n",
      "result_pwd = 'Result/MNIST/'\n",
      "output_pwd = os.path.abspath(os.getcwd())\n",
      "images = []\n",
      "for filename in tqdm(os.listdir(result_pwd)):\n",
      "    images.append(imageio.imread(result_pwd + '/' + filename))\n",
      "imageio.mimsave(output_pwd + '/' + result_pwd + '/' + 'LSGAN_MNIST.gif', images)\n",
      "Output: {'main_MNIST': ['tqdm.tqdm', 'keras.layers.Flatten', 'keras.layers.Dropout', 'keras.datasets.mnist.load_data', 'main_MNIST.train_gan', 'keras.layers.Activation', 'imageio.mimsave', 'os.getcwd', 'keras.layers.Conv2D', 'main_MNIST.plot_loss', 'os.listdir', 'keras.optimizers.RMSprop', 'keras.utils.vis_utils.plot_model', '<builtin>.int', 'keras.layers.LeakyReLU', 'keras.layers.Conv2DTranspose', 'keras.layers.Dense', 'main_MNIST.plot_accuracy', '<builtin>.open', 'numpy.array', 'keras.layers.Reshape', 'imageio.imread', 'keras.layers.UpSampling2D', 'os.path.abspath', 'keras.layers.BatchNormalization', 'keras.models.Sequential'], 'keras.datasets.mnist.load_data': [], 'numpy.array': [], 'keras.models.Sequential': [], 'keras.layers.Conv2D': [], 'keras.layers.LeakyReLU': [], 'keras.layers.Dropout': [], 'keras.layers.BatchNormalization': [], 'keras.layers.Flatten': [], 'keras.layers.Dense': [], 'keras.layers.Activation': [], 'keras.utils.vis_utils.plot_model': [], 'keras.layers.Reshape': [], 'keras.layers.UpSampling2D': [], '<builtin>.int': [], 'keras.layers.Conv2DTranspose': [], 'keras.optimizers.RMSprop': [], 'main_MNIST.plot_output': ['matplotlib.pyplot.savefig', 'matplotlib.pyplot.subplot', 'matplotlib.pyplot.close', 'matplotlib.pyplot.axis', 'matplotlib.pyplot.figure', 'matplotlib.pyplot.tight_layout', '<builtin>.range', 'matplotlib.pyplot.imshow'], 'matplotlib.pyplot.figure': [], '<builtin>.range': [], 'matplotlib.pyplot.subplot': [], 'matplotlib.pyplot.imshow': [], 'matplotlib.pyplot.axis': [], 'matplotlib.pyplot.tight_layout': [], 'matplotlib.pyplot.savefig': [], 'matplotlib.pyplot.close': [], 'main_MNIST.plot_loss': ['matplotlib.pyplot.savefig', 'matplotlib.pyplot.xlabel', 'matplotlib.pyplot.close', 'matplotlib.pyplot.plot', 'matplotlib.pyplot.ylabel', 'matplotlib.pyplot.figure', 'matplotlib.pyplot.legend'], 'matplotlib.pyplot.plot': [], 'matplotlib.pyplot.xlabel': [], 'matplotlib.pyplot.ylabel': [], 'matplotlib.pyplot.legend': [], 'main_MNIST.plot_accuracy': ['matplotlib.pyplot.savefig', 'matplotlib.pyplot.xlabel', 'matplotlib.pyplot.close', 'matplotlib.pyplot.plot', 'matplotlib.pyplot.ylabel', 'matplotlib.pyplot.figure', 'matplotlib.pyplot.legend'], 'main_MNIST.train_gan': ['<builtin>.print', 'numpy.ones', 'tqdm.tqdm', 'numpy.array', 'numpy.random.normal', 'main_MNIST.plot_output', 'numpy.concatenate', 'numpy.random.randint', '<builtin>.round', 'sklearn.utils.shuffle', '<builtin>.range', '<builtin>.float', '<builtin>.int'], 'numpy.random.randint': [], 'numpy.random.normal': [], 'numpy.concatenate': [], 'numpy.ones': [], 'sklearn.utils.shuffle': [], '<builtin>.round': [], 'tqdm.tqdm': [], '<builtin>.print': [], '<builtin>.float': [], '<builtin>.open': [], 'os.getcwd': [], 'os.path.abspath': [], 'os.listdir': [], 'imageio.imread': [], 'imageio.mimsave': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hklchung_GAN-GenerativeAdversarialNetwork\\LSGAN\\main_MNIST.py\n",
      "[('main_MNIST', 'tqdm tqdm'), ('main_MNIST', 'keras layers Flatten'), ('main_MNIST', 'keras layers Dropout'), ('main_MNIST', 'keras datasets mnist load_data'), ('main_MNIST', 'main_MNIST train_gan'), ('main_MNIST', 'keras layers Activation'), ('main_MNIST', 'imageio mimsave'), ('main_MNIST', 'os getcwd'), ('main_MNIST', 'keras layers Conv2D'), ('main_MNIST', 'main_MNIST plot_loss'), ('main_MNIST', 'os listdir'), ('main_MNIST', 'keras optimizers RMSprop'), ('main_MNIST', 'keras utils vis_utils plot_model'), ('main_MNIST', 'keras layers LeakyReLU'), ('main_MNIST', 'keras layers Conv2DTranspose'), ('main_MNIST', 'keras layers Dense'), ('main_MNIST', 'main_MNIST plot_accuracy'), ('main_MNIST', 'numpy array'), ('main_MNIST', 'keras layers Reshape'), ('main_MNIST', 'imageio imread'), ('main_MNIST', 'keras layers UpSampling2D'), ('main_MNIST', 'os path abspath'), ('main_MNIST', 'keras layers BatchNormalization'), ('main_MNIST', 'keras models Sequential'), ('main_MNIST plot_output', 'matplotlib pyplot savefig'), ('main_MNIST plot_output', 'matplotlib pyplot subplot'), ('main_MNIST plot_output', 'matplotlib pyplot close'), ('main_MNIST plot_output', 'matplotlib pyplot axis'), ('main_MNIST plot_output', 'matplotlib pyplot figure'), ('main_MNIST plot_output', 'matplotlib pyplot tight_layout')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"\n",
      "Copyright (c) 2020, Heung Kit Leslie Chung\n",
      "All rights reserved.\n",
      "Redistribution and use in source and binary forms, with or without\n",
      "    modification, are permitted provided that the following conditions are met:\n",
      "1. Redistributions of source code must retain the above copyright notice, this\n",
      "    list of conditions and the following disclaimer.\n",
      "2. Redistributions in binary form must reproduce the above copyright notice,\n",
      "    this list of conditions and the following disclaimer in the documentation\n",
      "    and/or other materials provided with the distribution.\n",
      "3. Neither the name of the copyright holder nor the names of its contributors\n",
      "    may be used to endorse or promote products derived from this software\n",
      "    without specific prior written permission.\n",
      "    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "    AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "    IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
      "    ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
      "    LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
      "    CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
      "    SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
      "    INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
      "    CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
      "    ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
      "    POSSIBILITY OF SUCH DAMAGE.\n",
      "\"\"\"\n",
      "\n",
      "import os\n",
      "import numpy as np\n",
      "import random\n",
      "import matplotlib.pyplot as plt\n",
      "from tqdm import tqdm\n",
      "from keras.layers import Input, Dense, Activation, Dropout, Flatten, Reshape, LeakyReLU, ReLU, AveragePooling2D, Embedding\n",
      "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, BatchNormalization, ZeroPadding2D, Concatenate\n",
      "from keras.models import Sequential, load_model, Model\n",
      "from keras.optimizers import RMSprop, Adam\n",
      "from keras.utils.vis_utils import plot_model\n",
      "from keras.utils import to_categorical\n",
      "from sklearn.utils import shuffle\n",
      "from keras.datasets import mnist, fashion_mnist\n",
      "\n",
      "#=============================Load MNIST dataset===============================\n",
      "# Load our image dataset\n",
      "(X, Y), (_, _) = mnist.load_data()\n",
      "#(X, Y), (_, _) = fashion_mnist.load_data()\n",
      "\n",
      "X = 1.0/255*X\n",
      "X = np.array([x.reshape(28, 28, 1) for x in X])\n",
      "Y = to_categorical(Y, 10)\n",
      "\n",
      "# Our input vector for generator = 32D noise + 10D category info\n",
      "latent_dim = 42\n",
      "\n",
      "#=============================Discriminator model==============================\n",
      "# Define input shape of our MNIST images\n",
      "img_shape = (28,28,1)\n",
      "img = Input(shape=img_shape)\n",
      "\n",
      "# Shared network\n",
      "depth = 64\n",
      "dropout = 0.25\n",
      "D = Sequential()\n",
      "D.add(Conv2D(depth, kernel_size=3, strides=2, input_shape=X.shape[1:], padding=\"same\"))\n",
      "D.add(LeakyReLU(alpha=0.2))\n",
      "D.add(Dropout(dropout))\n",
      "D.add(Conv2D(depth*2, kernel_size=3, strides=2, padding=\"same\"))\n",
      "D.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
      "D.add(LeakyReLU(alpha=0.2))\n",
      "D.add(Dropout(dropout))\n",
      "D.add(BatchNormalization(momentum=0.8))\n",
      "D.add(Conv2D(depth*4, kernel_size=3, strides=2, padding=\"same\"))\n",
      "D.add(LeakyReLU(alpha=0.2))\n",
      "D.add(Dropout(dropout))\n",
      "D.add(BatchNormalization(momentum=0.8))\n",
      "D.add(Flatten())\n",
      "\n",
      "# Real/Fake output\n",
      "img_embedding = D(img)\n",
      "out1 = Dense(1, activation='sigmoid', kernel_initializer='glorot_normal')(img_embedding)\n",
      "# Class label output\n",
      "out2 = Dense(10, activation='softmax')(img_embedding)\n",
      "\n",
      "# Define the model\n",
      "disc_model = Model(img, [out1, out2])\n",
      "# Print out architecture of the discriminator    \n",
      "disc_model.summary()\n",
      "\n",
      "# Save model architecture as .PNG \n",
      "plot_model(disc_model, to_file='disciminator.png', expand_nested=True, show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Generator model=====================================\n",
      "# Define architecture of the generator (fraudster AI)\n",
      "# Note: with each layer, the image gets larger but with reduced depth\n",
      "depth = 64*2\n",
      "dim = 7\n",
      "noise_vec = 42\n",
      "\n",
      "gen_model = Sequential()\n",
      "\n",
      "gen_model.add(Dense(depth*dim*dim, activation=\"relu\", input_dim=noise_vec))\n",
      "gen_model.add(Reshape((7, 7, 128)))\n",
      "gen_model.add(BatchNormalization(momentum=0.8))\n",
      "gen_model.add(UpSampling2D())\n",
      "gen_model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
      "gen_model.add(Activation(\"relu\"))\n",
      "gen_model.add(BatchNormalization(momentum=0.8))\n",
      "gen_model.add(UpSampling2D())\n",
      "gen_model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
      "gen_model.add(Activation(\"relu\"))\n",
      "gen_model.add(BatchNormalization(momentum=0.8))\n",
      "gen_model.add(Conv2D(1, kernel_size=3, padding='same'))\n",
      "gen_model.add(Activation(\"sigmoid\"))\n",
      "\n",
      "# Print out architecture of the generator\n",
      "gen_model.summary()\n",
      "# Save model architecture as .PNG\n",
      "plot_model(gen_model, to_file='generator.png', expand_nested=True, show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#===============Combine Discriminator and Generator models=====================\n",
      "# Define optimisers - optimisr1 will be used for all component networks\n",
      "optimizer1 = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
      "optimizer2 = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
      "\n",
      "disc_model.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=optimizer1, metrics=['accuracy'])\n",
      "\n",
      "# Define architecture of ACGAN\n",
      "# Starts with generator input = 42D vector\n",
      "inputs = Input(shape = (latent_dim,)) \n",
      "# Generator output\n",
      "gen_img = gen_model(inputs)\n",
      "\n",
      "disc_model.trainable = False\n",
      "\n",
      "# Generator output is the input for discriminator\n",
      "[disc_outs, class_outs] = disc_model(gen_img)\n",
      "\n",
      "# Define ACGAN inout and output\n",
      "comb_model = Model(inputs, [disc_outs, class_outs])\n",
      "comb_model.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=optimizer2)\n",
      "\n",
      "# Print out architecture of GAN\n",
      "comb_model.summary()\n",
      "# Save model architecture as .PNG \n",
      "plot_model(comb_model, to_file='acgan.png', show_shapes=True, show_layer_names=True)\n",
      "plot_model(comb_model, to_file='acgan_expand.png', expand_nested=True, show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Plot image function=================================\n",
      "def plot_output(input_42, step):\n",
      "    filename = \"GANmodel_%d\" % step\n",
      "    \n",
      "    images = gen_model.predict(input_42)\n",
      "\n",
      "    plt.figure(figsize=(10,10))\n",
      "    for i in range(images.shape[0]):\n",
      "        plt.subplot(10, 10, i+1)\n",
      "        image = images[i, :, :, :]\n",
      "        image = image.reshape(X.shape[1], X.shape[2])\n",
      "        plt.imshow(image, cmap='gray')\n",
      "        plt.axis('off')\n",
      "    plt.tight_layout()\n",
      "    plt.savefig(filename)\n",
      "    plt.close('all')\n",
      "\n",
      "#==========================Plot loss function==================================\n",
      "def plot_loss(d_performance, gan_performance, q_performance, jump=100):\n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.plot(d_performance[0::jump], label='discriminator validity')\n",
      "    plt.plot(q_performance[0::jump], label='discriminator classification')\n",
      "    plt.plot(gan_performance[0::jump], label='GAN')\n",
      "    plt.xlabel('epoch ({})'.format(jump))\n",
      "    plt.ylabel('loss')\n",
      "    plt.legend()\n",
      "    plt.savefig('loss_over_epoch.png')\n",
      "    plt.close('all')\n",
      "    \n",
      "#==============================Train InfoGAN===================================\n",
      "def train_gan(X, batch_size, epoch, save_interval):\n",
      "    batch_per_epoch = int(round(X.shape[0]/batch_size))\n",
      "    d_loss_hist = []\n",
      "    q_loss_hist = []\n",
      "    gan_loss_hist = []\n",
      "    for i in range(epoch):\n",
      "        for j in tqdm(range(batch_per_epoch)):\n",
      "            #=============Train discriminator and auxiliary models=============\n",
      "            half_batch = int(batch_size/2)\n",
      "            \n",
      "            images_index = np.random.randint(0, X.shape[0], size = (half_batch))\n",
      "            images_real = X[images_index]\n",
      "            images_label = Y[images_index]\n",
      "            \n",
      "            random_label = to_categorical(np.random.randint(0,10,half_batch), 10)\n",
      "            noise = np.random.normal(0, 1, size=(half_batch, 32))\n",
      "            images_fake = gen_model.predict(np.hstack((noise, random_label)))\n",
      "            \n",
      "            d_loss_real = disc_model.train_on_batch(images_real, [np.ones([half_batch, 1]), images_label])\n",
      "            d_loss_fake = disc_model.train_on_batch(images_fake, [np.zeros([half_batch, 1]), random_label])\n",
      "            \n",
      "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
      "            \n",
      "            #========================Train InfoGAN=============================            \n",
      "            gen_input1 = np.concatenate((noise, random_label), axis=1)\n",
      "            \n",
      "            random_label2 = to_categorical(np.random.randint(0,10,half_batch), 10)\n",
      "            noise2 = np.random.normal(0, 1, size=(half_batch, 32))\n",
      "            gen_input2 = np.concatenate((noise2, random_label2), axis=1)\n",
      "            \n",
      "            gen_input = np.concatenate((gen_input1, gen_input2), axis=0)\n",
      "            gan_loss = comb_model.train_on_batch(gen_input, [np.ones([batch_size, 1]), np.concatenate((random_label, random_label2), axis=0)])\n",
      "        \n",
      "        log_msg = \"epoch %d: [D loss: %f]\" % (i, d_loss[1])\n",
      "        log_msg = \"%s  [Q loss: %f]\" % (log_msg, d_loss[2])\n",
      "        log_msg = \"%s  [GAN loss: %f]\" % (log_msg, gan_loss[0])\n",
      "        print(log_msg)\n",
      "        \n",
      "        d_loss_hist.append(np.array(d_loss[1], dtype=float))\n",
      "        q_loss_hist.append(np.array(d_loss[2], dtype=float))\n",
      "        gan_loss_hist.append(np.array(gan_loss[0], dtype=float))\n",
      "        \n",
      "        # Save ouputs\n",
      "        if save_interval>0 and (i+1)%save_interval==0:\n",
      "            test_label = np.concatenate(([np.concatenate(np.full((10, 1), x)) for x in range(0, 10)]))\n",
      "            test_label = to_categorical(test_label)\n",
      "            noise = np.random.normal(0, 1, size=(100, 32))\n",
      "            test_input = np.hstack((noise, test_label))\n",
      "            plot_output(input_42=test_input, step=(i+1))\n",
      "            \n",
      "    d_loss_hist = [float(x) for x in d_loss_hist]\n",
      "    gan_loss_hist = [float(x) for x in gan_loss_hist]\n",
      "    \n",
      "    return(d_loss_hist, q_loss_hist, gan_loss_hist)\n",
      "\n",
      "#===============================Train InfoGAN==================================\n",
      "d_loss_ls, q_loss_ls, gan_loss_ls = train_gan(X, 16, 100, 10)\n",
      "\n",
      "plot_loss(d_loss_ls, gan_loss_ls, q_loss_ls, jump = 1)\n",
      "Output: {'main': ['main.plot_loss', 'keras.layers.Dense', 'keras.layers.Reshape', 'keras.layers.Activation', 'main.train_gan', 'numpy.array', 'keras.datasets.mnist.load_data', 'keras.layers.ZeroPadding2D', 'keras.models.Model', 'keras.layers.BatchNormalization', 'keras.models.Sequential', 'keras.layers.Input', 'keras.layers.LeakyReLU', 'keras.layers.Dropout', 'keras.layers.UpSampling2D', 'keras.utils.vis_utils.plot_model', 'keras.optimizers.RMSprop', 'keras.layers.Flatten', 'keras.layers.Conv2D', 'keras.utils.to_categorical'], 'keras.datasets.mnist.load_data': [], 'numpy.array': [], 'keras.utils.to_categorical': [], 'keras.layers.Input': [], 'keras.models.Sequential': [], 'keras.layers.Conv2D': [], 'keras.layers.LeakyReLU': [], 'keras.layers.Dropout': [], 'keras.layers.ZeroPadding2D': [], 'keras.layers.BatchNormalization': [], 'keras.layers.Flatten': [], 'keras.layers.Dense': [], 'keras.models.Model': [], 'keras.utils.vis_utils.plot_model': [], 'keras.layers.Reshape': [], 'keras.layers.UpSampling2D': [], 'keras.layers.Activation': [], 'keras.optimizers.RMSprop': [], 'main.plot_output': ['<builtin>.range', 'matplotlib.pyplot.figure', 'matplotlib.pyplot.subplot', 'matplotlib.pyplot.imshow', 'matplotlib.pyplot.axis', 'matplotlib.pyplot.close', 'matplotlib.pyplot.savefig', 'matplotlib.pyplot.tight_layout'], 'matplotlib.pyplot.figure': [], '<builtin>.range': [], 'matplotlib.pyplot.subplot': [], 'matplotlib.pyplot.imshow': [], 'matplotlib.pyplot.axis': [], 'matplotlib.pyplot.tight_layout': [], 'matplotlib.pyplot.savefig': [], 'matplotlib.pyplot.close': [], 'main.plot_loss': ['matplotlib.pyplot.figure', 'matplotlib.pyplot.close', 'matplotlib.pyplot.xlabel', 'matplotlib.pyplot.legend', 'matplotlib.pyplot.savefig', 'matplotlib.pyplot.plot', 'matplotlib.pyplot.ylabel'], 'matplotlib.pyplot.plot': [], 'matplotlib.pyplot.xlabel': [], 'matplotlib.pyplot.ylabel': [], 'matplotlib.pyplot.legend': [], 'main.train_gan': ['<builtin>.range', 'numpy.hstack', 'numpy.concatenate', 'main.plot_output', 'numpy.full', 'numpy.random.randint', '<builtin>.int', '<builtin>.float', 'numpy.random.normal', 'tqdm.tqdm', '<builtin>.print', 'numpy.add', 'keras.utils.to_categorical', '<builtin>.round', 'numpy.array'], '<builtin>.round': [], '<builtin>.int': [], 'tqdm.tqdm': [], 'numpy.random.randint': [], 'numpy.random.normal': [], 'numpy.hstack': [], 'numpy.add': [], 'numpy.concatenate': [], '<builtin>.print': [], 'numpy.full': [], '<builtin>.float': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hklchung_GAN-GenerativeAdversarialNetwork\\ACGAN\\main.py\n",
      "[('main', 'main plot_loss'), ('main', 'keras layers Dense'), ('main', 'keras layers Reshape'), ('main', 'keras layers Activation'), ('main', 'main train_gan'), ('main', 'numpy array'), ('main', 'keras datasets mnist load_data'), ('main', 'keras layers ZeroPadding2D'), ('main', 'keras models Model'), ('main', 'keras layers BatchNormalization'), ('main', 'keras models Sequential'), ('main', 'keras layers Input'), ('main', 'keras layers LeakyReLU'), ('main', 'keras layers Dropout'), ('main', 'keras layers UpSampling2D'), ('main', 'keras utils vis_utils plot_model'), ('main', 'keras optimizers RMSprop'), ('main', 'keras layers Flatten'), ('main', 'keras layers Conv2D'), ('main', 'keras utils to_categorical'), ('main plot_output', 'matplotlib pyplot figure'), ('main plot_output', 'matplotlib pyplot subplot'), ('main plot_output', 'matplotlib pyplot imshow'), ('main plot_output', 'matplotlib pyplot axis'), ('main plot_output', 'matplotlib pyplot close'), ('main plot_output', 'matplotlib pyplot savefig'), ('main plot_output', 'matplotlib pyplot tight_layout'), ('main plot_loss', 'matplotlib pyplot figure'), ('main plot_loss', 'matplotlib pyplot close'), ('main plot_loss', 'matplotlib pyplot xlabel')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"\n",
      "Copyright (c) 2020, Heung Kit Leslie Chung\n",
      "All rights reserved.\n",
      "Redistribution and use in source and binary forms, with or without\n",
      "    modification, are permitted provided that the following conditions are met:\n",
      "1. Redistributions of source code must retain the above copyright notice, this\n",
      "    list of conditions and the following disclaimer.\n",
      "2. Redistributions in binary form must reproduce the above copyright notice,\n",
      "    this list of conditions and the following disclaimer in the documentation\n",
      "    and/or other materials provided with the distribution.\n",
      "3. Neither the name of the copyright holder nor the names of its contributors\n",
      "    may be used to endorse or promote products derived from this software\n",
      "    without specific prior written permission.\n",
      "    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "    AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "    IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
      "    ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
      "    LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
      "    CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
      "    SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
      "    INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
      "    CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
      "    ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
      "    POSSIBILITY OF SUCH DAMAGE.\n",
      "\"\"\"\n",
      "\n",
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import random\n",
      "import matplotlib.pyplot as plt\n",
      "from tqdm import tqdm\n",
      "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape, LeakyReLU, AveragePooling2D, Embedding\n",
      "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, BatchNormalization, ZeroPadding2D, Concatenate\n",
      "from keras.models import Sequential, load_model, Model\n",
      "from keras.optimizers import RMSprop, Adam\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
      "from keras.utils.vis_utils import plot_model\n",
      "from keras import backend, Input\n",
      "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
      "from skimage.io import imsave\n",
      "from sklearn.utils import shuffle\n",
      "from sklearn.utils import shuffle\n",
      "from PIL import Image, ImageOps\n",
      "import tensorflow as tf\n",
      "\n",
      "#===========================Resize images======================================\n",
      "img_path = \"../Image/Train/tenk_celebs/100k\"\n",
      "out_path = \"../Image/Resized2\"\n",
      "for filename in tqdm(sorted(os.listdir(img_path))):\n",
      "    temp = Image.open(img_path + '/' + filename)\n",
      "    size = 64, 64\n",
      "    temp.thumbnail(size, Image.ANTIALIAS)\n",
      "    temp.save(out_path + '/' + filename, \"JPEG\")\n",
      "\n",
      "#============================Get images========================================\n",
      "out_path = \"/content/Resized\"\n",
      "images = []\n",
      "# Grab images from folder\n",
      "for filename in tqdm(sorted(os.listdir(out_path))):\n",
      "    if np.random.normal(0, 1, 1) > 0.89:\n",
      "        temp = np.array(img_to_array(load_img(out_path + '/' + filename)), dtype=float)\n",
      "        hor = 64 - temp.shape[0]\n",
      "        ver = 64 - temp.shape[1]\n",
      "        if hor%2 != 0:\n",
      "            temp = np.pad(temp, ((hor//2 + 1, hor//2), (ver//2, ver//2), (0, 0)),\n",
      "                  mode='constant', constant_values=0)\n",
      "        elif ver%2 != 0:\n",
      "            temp = np.pad(temp, ((hor//2, hor//2), (ver//2 + 1, ver//2), (0, 0)),\n",
      "                  mode='constant', constant_values=0)\n",
      "        else:\n",
      "        # Pad resized images with zeros such that they are all 64x64x3\n",
      "            temp = np.pad(temp, ((hor//2, hor//2), (ver//2, ver//2), (0, 0)),\n",
      "                  mode='constant', constant_values=0)\n",
      "        # Store images into a list\n",
      "        images.append(np.array(temp, dtype=float))\n",
      "\n",
      "# Normalise RGB intensities, reshape and forced into array\n",
      "X = [1.0/255*x for x in images]\n",
      "X = [x.reshape(64, 64, 3) for x in X]\n",
      "X = np.array(X)\n",
      "\n",
      "# We need only 10k images to train\n",
      "del(images)\n",
      "X = X[:10000]\n",
      "\n",
      "#=========================Discriminator model==================================\n",
      "# Define architecture of the discriminator (police AI)\n",
      "noise = 32\n",
      "depth = 256\n",
      "\n",
      "D = Sequential()\n",
      "# Input + First layer\n",
      "D.add(Conv2D(depth, 3, strides=1, input_shape=X.shape[1:]))\n",
      "D.add(LeakyReLU())\n",
      "# Second layer\n",
      "D.add(Conv2D(depth, 4, strides=2))\n",
      "D.add(LeakyReLU())\n",
      "# Third layer\n",
      "D.add(Conv2D(depth, 4, strides=2))\n",
      "D.add(LeakyReLU())\n",
      "# Forth layer\n",
      "D.add(Conv2D(depth, 4, strides=2))\n",
      "D.add(LeakyReLU())\n",
      "# Fifth layer\n",
      "D.add(Conv2D(depth, 4, strides=2))\n",
      "D.add(LeakyReLU())\n",
      "# Output\n",
      "D.add(Flatten())\n",
      "D.add(Dropout(0.4))\n",
      "D.add(Dense(1))\n",
      "D.add(Activation('linear'))\n",
      "\n",
      "# Print out architecture of the discriminator\n",
      "D.summary()\n",
      "# Save model architecture as .PNG\n",
      "plot_model(D, to_file='discriminator.png', show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Generator model=====================================\n",
      "# Define architecture of the generator (fraudster AI)\n",
      "depth = 128\n",
      "dim = 8\n",
      "noise_vec = 32\n",
      "\n",
      "G = Sequential()\n",
      "# Input + First layer\n",
      "G.add(Dense(dim*dim*depth, input_dim=noise_vec))\n",
      "G.add(LeakyReLU())\n",
      "G.add(Reshape((dim, dim, depth)))\n",
      "# Second layer\n",
      "G.add(Conv2D(depth*2, 5, padding = 'same'))\n",
      "G.add(LeakyReLU())\n",
      "# Third layer\n",
      "G.add(Conv2DTranspose(depth*2, 4, strides=2, padding = 'same'))\n",
      "G.add(LeakyReLU())\n",
      "# Forth layer\n",
      "G.add(Conv2DTranspose(depth*2, 4, strides=2, padding = 'same'))\n",
      "G.add(LeakyReLU())\n",
      "# Fifth layer\n",
      "G.add(Conv2DTranspose(depth*2, 4, strides=2, padding = 'same'))\n",
      "G.add(LeakyReLU())\n",
      "# Sixth layer\n",
      "G.add(Conv2DTranspose(depth*4, 5, strides=1, padding = 'same'))\n",
      "G.add(LeakyReLU())\n",
      "# Seventh layer\n",
      "G.add(Conv2DTranspose(depth*4, 5, strides=1, padding = 'same'))\n",
      "G.add(LeakyReLU())\n",
      "# Output\n",
      "G.add(Conv2DTranspose(3, 7, strides=1, activation = 'tanh', padding = 'same'))\n",
      "\n",
      "# Print out architecture of the generator\n",
      "G.summary()\n",
      "# Save model architecture as .PNG\n",
      "plot_model(G, to_file='generator.png', show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#============================Optimiser=========================================\n",
      "# Define optimisers - optimisr1 will be used for the discriminator and generator\n",
      "optimizer1 = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
      "optimizer2 = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
      "\n",
      "D.compile(loss='mse', optimizer=optimizer1,metrics=['accuracy'])\n",
      "\n",
      "# Define architecture of GAN\n",
      "GAN = Sequential()\n",
      "GAN.add(G)  # Adding the generator\n",
      "GAN.add(D)  # Adding the discriminator \n",
      "GAN.compile(loss='mse', optimizer=optimizer2, metrics=['accuracy'])\n",
      "\n",
      "# Print out architecture of GAN\n",
      "GAN.summary()\n",
      "# Save model architecture as .PNG\n",
      "plot_model(GAN, to_file='LSGAN.png', show_shapes=True, show_layer_names=True)\n",
      "plot_model(GAN, to_file='LSGAN_expand.png', expand_nested=True, show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Plot image function=================================\n",
      "def plot_output(noise, step):\n",
      "    filename = \"GANmodel_%d.png\" % step\n",
      "    \n",
      "    images = G.predict(noise)\n",
      "\n",
      "    plt.figure(figsize=(10,10))\n",
      "    for i in range(images.shape[0]):\n",
      "        plt.subplot(4, 4, i+1)\n",
      "        image = images[i, :, :, :]\n",
      "        image = image.reshape(images.shape[1], images.shape[2], images.shape[3])\n",
      "        plt.imshow(image)\n",
      "        plt.axis('off')\n",
      "    plt.tight_layout()\n",
      "    plt.savefig(filename)\n",
      "    plt.close('all')\n",
      "    \n",
      "#==========================Plot loss function==================================\n",
      "def plot_loss(d_performance, gan_performance, jump=100):\n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.plot(d_performance[0::jump], label='discriminator')\n",
      "    plt.plot(gan_performance[0::jump], label='GAN')\n",
      "    plt.xlabel('iteration (Skipping every {}its)'.format(jump))\n",
      "    plt.ylabel('loss')\n",
      "    plt.legend()\n",
      "    plt.savefig('loss_over_epoch.png')\n",
      "    plt.close('all')\n",
      "    \n",
      "#=========================Train GAN function===================================\n",
      "def train_gan(X, model, batch_size, epoch, save_interval, noise_len=32):    \n",
      "    d_losses = []\n",
      "    gan_losses = []\n",
      "    \n",
      "    batch_per_epoch = int(round(X.shape[0]/batch_size))\n",
      "    \n",
      "    for i in range(epoch):\n",
      "        start = 0\n",
      "        for j in tqdm(range(batch_per_epoch)):\n",
      "            #=====================Train discriminator==========================\n",
      "            noise_vec = np.random.normal(size=(batch_size, noise))\n",
      "            images_fake = G.predict(noise_vec)\n",
      "\n",
      "            images_real = X[start:start + batch_size]\n",
      "            x = np.concatenate([images_fake, images_real])\n",
      "\n",
      "            y = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
      "            y += .05 * np.random.random(y.shape)\n",
      "\n",
      "            d_loss = D.train_on_batch(x, y)\n",
      "            d_losses.append(d_loss[0])\n",
      "            \n",
      "            #=========================Train GAN================================\n",
      "            noise_vec = np.random.normal(size=(batch_size, noise))\n",
      "            y = np.zeros((batch_size, 1))\n",
      "\n",
      "            gan_loss = GAN.train_on_batch(noise_vec, y)\n",
      "            gan_losses.append(gan_loss)\n",
      "\n",
      "            start += batch_size\n",
      "            if start > X.shape[0] - batch_size:\n",
      "                start = 0\n",
      "        # Print loss and accuracy values \n",
      "        log_msg = \"epoch %d: [D loss: %f]\" % (i, d_loss[0])\n",
      "        log_msg = \"%s  [GAN loss: %f]\" % (log_msg, gan_loss)\n",
      "        print(log_msg)\n",
      "        \n",
      "        # Save ouputs\n",
      "        if save_interval>0 and (i+1)%save_interval==0:\n",
      "            noise_input = np.random.normal(0.0, 1.0, size=[16, noise_len])\n",
      "            plot_output(noise=noise_input, step=(i+1))\n",
      "    \n",
      "    d_losses = [float(x) for x in d_losses]\n",
      "    gan_losses = [float(x) for x in gan_losses]\n",
      "    return(d_losses, gan_losses)\n",
      "    \n",
      "#================================Train LSGAN===================================\n",
      "d_loss_ls, gan_loss_ls = train_gan(X=X, model=GAN, batch_size=16, epoch=30, \n",
      "                                                         save_interval=1,\n",
      "                                                         noise_len=32)\n",
      "plot_loss(d_loss_ls, gan_loss_ls, 1)\n",
      "\n",
      "#================================Save model====================================\n",
      "model_json = GAN.to_json()\n",
      "with open(\"LSGAN_100kCelebs_model.json\", \"w\") as json_file:\n",
      "    json_file.write(model_json)\n",
      "GAN.save_weights(\"LSGAN_100kCelebs_model.h5\")\n",
      "\n",
      "GAN.save('LSGAN_full_model.h5')\n",
      "D.save('LSGAN_discriminator.h5')\n",
      "G.save('LSGAN_generator.h5')\n",
      "\n",
      "#================================Result GIF====================================\n",
      "import imageio\n",
      "result_pwd = 'Result/100kCelebs/'\n",
      "output_pwd = os.path.abspath(os.getcwd())\n",
      "images = []\n",
      "for filename in tqdm(os.listdir(result_pwd)):\n",
      "    images.append(imageio.imread(result_pwd + '/' + filename))\n",
      "imageio.mimsave(output_pwd + '/' + result_pwd + '/' + 'LSGAN_100kCelebs.gif', images)\n",
      "Output: {'main_100kCeleb': ['keras.utils.vis_utils.plot_model', 'keras.layers.Reshape', 'main_100kCeleb.plot_loss', 'imageio.mimsave', 'keras.layers.Conv2D', 'tqdm.tqdm', 'numpy.random.normal', 'keras.models.Sequential', '<builtin>.open', 'imageio.imread', 'keras.layers.LeakyReLU', 'keras.layers.Activation', 'os.listdir', 'numpy.pad', 'os.getcwd', 'numpy.array', 'keras.optimizers.RMSprop', 'keras.preprocessing.image.img_to_array', 'keras.layers.Conv2DTranspose', '<builtin>.sorted', 'PIL.Image.open', 'keras.layers.Flatten', 'keras.preprocessing.image.load_img', 'keras.layers.Dense', 'main_100kCeleb.train_gan', 'os.path.abspath', 'keras.layers.Dropout'], 'os.listdir': [], '<builtin>.sorted': [], 'tqdm.tqdm': [], 'PIL.Image.open': [], 'numpy.random.normal': [], 'keras.preprocessing.image.load_img': [], 'keras.preprocessing.image.img_to_array': [], 'numpy.array': [], 'numpy.pad': [], 'keras.models.Sequential': [], 'keras.layers.Conv2D': [], 'keras.layers.LeakyReLU': [], 'keras.layers.Flatten': [], 'keras.layers.Dropout': [], 'keras.layers.Dense': [], 'keras.layers.Activation': [], 'keras.utils.vis_utils.plot_model': [], 'keras.layers.Reshape': [], 'keras.layers.Conv2DTranspose': [], 'keras.optimizers.RMSprop': [], 'main_100kCeleb.plot_output': ['<builtin>.range', 'matplotlib.pyplot.close', 'matplotlib.pyplot.axis', 'matplotlib.pyplot.imshow', 'matplotlib.pyplot.tight_layout', 'matplotlib.pyplot.savefig', 'matplotlib.pyplot.subplot', 'matplotlib.pyplot.figure'], 'matplotlib.pyplot.figure': [], '<builtin>.range': [], 'matplotlib.pyplot.subplot': [], 'matplotlib.pyplot.imshow': [], 'matplotlib.pyplot.axis': [], 'matplotlib.pyplot.tight_layout': [], 'matplotlib.pyplot.savefig': [], 'matplotlib.pyplot.close': [], 'main_100kCeleb.plot_loss': ['matplotlib.pyplot.legend', 'matplotlib.pyplot.close', 'matplotlib.pyplot.plot', 'matplotlib.pyplot.savefig', 'matplotlib.pyplot.ylabel', 'matplotlib.pyplot.xlabel', 'matplotlib.pyplot.figure'], 'matplotlib.pyplot.plot': [], 'matplotlib.pyplot.xlabel': [], 'matplotlib.pyplot.ylabel': [], 'matplotlib.pyplot.legend': [], 'main_100kCeleb.train_gan': ['numpy.random.normal', '<builtin>.int', '<builtin>.range', '<builtin>.round', 'numpy.ones', 'main_100kCeleb.plot_output', 'numpy.zeros', 'numpy.random.random', 'numpy.concatenate', '<builtin>.float', '<builtin>.print', 'tqdm.tqdm'], '<builtin>.round': [], '<builtin>.int': [], 'numpy.concatenate': [], 'numpy.ones': [], 'numpy.zeros': [], 'numpy.random.random': [], '<builtin>.print': [], '<builtin>.float': [], '<builtin>.open': [], 'os.getcwd': [], 'os.path.abspath': [], 'imageio.imread': [], 'imageio.mimsave': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hklchung_GAN-GenerativeAdversarialNetwork\\LSGAN\\main_100kCeleb.py\n",
      "[('main_100kCeleb', 'keras utils vis_utils plot_model'), ('main_100kCeleb', 'keras layers Reshape'), ('main_100kCeleb', 'main_100kCeleb plot_loss'), ('main_100kCeleb', 'imageio mimsave'), ('main_100kCeleb', 'keras layers Conv2D'), ('main_100kCeleb', 'tqdm tqdm'), ('main_100kCeleb', 'numpy random normal'), ('main_100kCeleb', 'keras models Sequential'), ('main_100kCeleb', 'imageio imread'), ('main_100kCeleb', 'keras layers LeakyReLU'), ('main_100kCeleb', 'keras layers Activation'), ('main_100kCeleb', 'os listdir'), ('main_100kCeleb', 'numpy pad'), ('main_100kCeleb', 'os getcwd'), ('main_100kCeleb', 'numpy array'), ('main_100kCeleb', 'keras optimizers RMSprop'), ('main_100kCeleb', 'keras preprocessing image img_to_array'), ('main_100kCeleb', 'keras layers Conv2DTranspose'), ('main_100kCeleb', 'PIL Image open'), ('main_100kCeleb', 'keras layers Flatten'), ('main_100kCeleb', 'keras preprocessing image load_img'), ('main_100kCeleb', 'keras layers Dense'), ('main_100kCeleb', 'main_100kCeleb train_gan'), ('main_100kCeleb', 'os path abspath'), ('main_100kCeleb', 'keras layers Dropout'), ('main_100kCeleb plot_output', 'matplotlib pyplot close'), ('main_100kCeleb plot_output', 'matplotlib pyplot axis'), ('main_100kCeleb plot_output', 'matplotlib pyplot imshow'), ('main_100kCeleb plot_output', 'matplotlib pyplot tight_layout'), ('main_100kCeleb plot_output', 'matplotlib pyplot savefig')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"\n",
      "Copyright (c) 2020, Heung Kit Leslie Chung\n",
      "All rights reserved.\n",
      "Redistribution and use in source and binary forms, with or without\n",
      "    modification, are permitted provided that the following conditions are met:\n",
      "1. Redistributions of source code must retain the above copyright notice, this\n",
      "    list of conditions and the following disclaimer.\n",
      "2. Redistributions in binary form must reproduce the above copyright notice,\n",
      "    this list of conditions and the following disclaimer in the documentation\n",
      "    and/or other materials provided with the distribution.\n",
      "3. Neither the name of the copyright holder nor the names of its contributors\n",
      "    may be used to endorse or promote products derived from this software\n",
      "    without specific prior written permission.\n",
      "    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "    AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "    IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
      "    ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
      "    LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
      "    CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
      "    SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
      "    INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
      "    CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
      "    ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
      "    POSSIBILITY OF SUCH DAMAGE.\n",
      "\"\"\"\n",
      "\n",
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import random\n",
      "import matplotlib.pyplot as plt\n",
      "from tqdm import tqdm\n",
      "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape, LeakyReLU, AveragePooling2D, Embedding\n",
      "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, BatchNormalization, ZeroPadding2D, Concatenate\n",
      "from keras.models import Sequential, load_model, Model\n",
      "from keras.optimizers import RMSprop, Adam\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
      "from keras.utils.vis_utils import plot_model\n",
      "from keras import backend, Input\n",
      "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
      "from skimage.io import imsave\n",
      "from sklearn.utils import shuffle\n",
      "from sklearn.utils import shuffle\n",
      "from PIL import Image, ImageOps\n",
      "import tensorflow as tf\n",
      "\n",
      "#===========================Get resized images=================================\n",
      "folder_path = '../Image/Train/CelebA/img_align_celeba/img_align_celeba/'\n",
      "len(os.listdir(folder_path))\n",
      "\n",
      "total = 10000\n",
      "\n",
      "width = 178\n",
      "height = 208\n",
      "diff = (height - width) // 2\n",
      "\n",
      "new_width = 64\n",
      "new_height = 64\n",
      "\n",
      "crop_rect = (0, diff, width, height - diff)\n",
      "\n",
      "X = []\n",
      "for filename in tqdm(sorted(os.listdir(folder_path))[:total]):\n",
      "    pic = Image.open(folder_path + filename).crop(crop_rect)\n",
      "    pic.thumbnail((new_width, new_height), Image.ANTIALIAS)\n",
      "    X.append(np.uint8(pic))\n",
      "\n",
      "X = np.array(X) / 255\n",
      "X.shape\n",
      "\n",
      "#===========================Get attribute labels===============================\n",
      "Y = pd.read_csv('../Image/Train/CelebA/list_attr_celeba.csv')\n",
      "Y = Y[['Black_Hair','Blond_Hair','Eyeglasses','Male','Smiling']]\n",
      "Y = np.array(Y[:total])\n",
      "Y = np.array([(x+1)/2.0 for x in Y])\n",
      "\n",
      "#=========================Discriminator model==================================\n",
      "# Define architecture of the discriminator (police AI)\n",
      "class_input = Input(shape=Y.shape[1:])\n",
      "embedding1 = Embedding(5, 25)(class_input)\n",
      "dense1 = Dense(64*64)(embedding1)\n",
      "reshape1 = Reshape((64, 64, 5))(dense1)\n",
      "dense2 = Dense(3)(reshape1)\n",
      "\n",
      "image_input = Input(shape=X.shape[1:])\n",
      "concatenate1 = Concatenate()([image_input, dense2])\n",
      "\n",
      "noise = 32\n",
      "depth = 256\n",
      "\n",
      "D = Sequential()\n",
      "# Input + First layer\n",
      "D.add(Conv2D(depth, 3, strides=1, input_shape=X.shape[1:]))\n",
      "D.add(LeakyReLU())\n",
      "# Second layer\n",
      "D.add(Conv2D(depth, 4, strides=2))\n",
      "D.add(LeakyReLU())\n",
      "# Third layer\n",
      "D.add(Conv2D(depth, 4, strides=2))\n",
      "D.add(LeakyReLU())\n",
      "# Forth layer\n",
      "D.add(Conv2D(depth, 4, strides=2))\n",
      "D.add(LeakyReLU())\n",
      "# Fifth layer\n",
      "D.add(Conv2D(depth, 4, strides=2))\n",
      "D.add(LeakyReLU())\n",
      "# Output\n",
      "D.add(Flatten())\n",
      "D.add(Dropout(0.4))\n",
      "D.add(Dense(1))\n",
      "D.add(Activation('sigmoid'))\n",
      "\n",
      "disc_out = D(concatenate1)\n",
      "\n",
      "disc_model = Model([class_input, image_input], disc_out)\n",
      "\n",
      "# Save model architecture as .PNG\n",
      "plot_model(disc_model, to_file='discriminator.png', expand_nested=True, show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Generator model=====================================\n",
      "# Define architecture of the generator (fraudster AI)\n",
      "# Note: with each layer, the image gets larger but with reduced depth\n",
      "depth = 128\n",
      "dim = 8\n",
      "noise_vec = 32 + 5\n",
      "\n",
      "gen_model = Sequential()\n",
      "# Input + First layer\n",
      "gen_model.add(Dense(dim*dim*depth, input_dim=noise_vec))\n",
      "gen_model.add(LeakyReLU())\n",
      "gen_model.add(Reshape((dim, dim, depth)))\n",
      "# Second layer\n",
      "gen_model.add(Conv2D(depth*2, 5, padding = 'same'))\n",
      "gen_model.add(LeakyReLU())\n",
      "# Third layer\n",
      "gen_model.add(Conv2DTranspose(depth*2, 4, strides=2, padding = 'same'))\n",
      "gen_model.add(LeakyReLU())\n",
      "# Forth layer\n",
      "gen_model.add(Conv2DTranspose(depth*2, 4, strides=2, padding = 'same'))\n",
      "gen_model.add(LeakyReLU())\n",
      "# Fifth layer\n",
      "gen_model.add(Conv2DTranspose(depth*2, 4, strides=2, padding = 'same'))\n",
      "gen_model.add(LeakyReLU())\n",
      "# Sixth layer\n",
      "gen_model.add(Conv2DTranspose(depth*4, 5, strides=1, padding = 'same'))\n",
      "gen_model.add(LeakyReLU())\n",
      "# Seventh layer\n",
      "gen_model.add(Conv2DTranspose(depth*4, 5, strides=1, padding = 'same'))\n",
      "gen_model.add(LeakyReLU())\n",
      "# Output\n",
      "gen_model.add(Conv2DTranspose(3, 7, strides=1, activation = 'tanh', padding = 'same'))\n",
      "\n",
      "# Save model architecture as .PNG\n",
      "plot_model(gen_model, to_file='generator.png', expand_nested=True, show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==================================CGAN========================================\n",
      "# Define optimisers\n",
      "optimizer = RMSprop(lr=.0001, clipvalue=1.0, decay=1e-8)\n",
      "disc_model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
      "disc_model.trainable = False\n",
      "\n",
      "# Define architecture of CGAN\n",
      "inputs = Input(shape = (37,))\n",
      "gen_img = gen_model(inputs)\n",
      "disc_class_inputs = Input(shape = (5,))\n",
      "disc_outs = disc_model([disc_class_inputs, gen_img])\n",
      "\n",
      "# Define CGAN input and output\n",
      "GAN = Model([inputs, disc_class_inputs], disc_outs)\n",
      "\n",
      "# Compile CGAN\n",
      "GAN.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
      "\n",
      "# Save model architecture as .PNG\n",
      "plot_model(GAN, show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Plot image function=================================\n",
      "def plot_output(input_37, step):\n",
      "    filename = \"GANmodel_%d\" % step\n",
      "    \n",
      "    images = gen_model.predict(input_37)\n",
      "\n",
      "    plt.figure(figsize=(10,10))\n",
      "    for i in range(images.shape[0]):\n",
      "        plt.subplot(4, 4, i+1)\n",
      "        image = images[i, :, :, :]\n",
      "        image = image.reshape(X.shape[1], X.shape[2], X.shape[3])\n",
      "        plt.imshow(image)\n",
      "        plt.axis('off')\n",
      "    plt.tight_layout()\n",
      "    plt.savefig(filename)\n",
      "    plt.close('all')\n",
      "    \n",
      "#==========================Plot loss function==================================\n",
      "def plot_loss(d_performance, gan_performance, jump=100):\n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.plot(d_performance[0::jump], label='discriminator')\n",
      "    plt.plot(gan_performance[0::jump], label='GAN')\n",
      "    plt.xlabel('epoch ({})'.format(jump))\n",
      "    plt.ylabel('loss')\n",
      "    plt.legend()\n",
      "    plt.savefig('loss_over_epoch.png')\n",
      "    plt.close('all')\n",
      "    \n",
      "#=========================Random label generator===============================\n",
      "def random_flip():\n",
      "    return [0,1][random.randrange(2)]\n",
      "\n",
      "#================================Train CGAN====================================\n",
      "batch_size = 8\n",
      "latent_dim = 32 + 5\n",
      "epoch = 10\n",
      "save_interval = 1\n",
      "def train_gan(X, batch_size, epoch, save_interval):\n",
      "    batch_per_epoch = int(round(X.shape[0]/batch_size))\n",
      "    d_losses = []\n",
      "    gan_losses = []\n",
      "    for i in range(epoch):\n",
      "        start = 0\n",
      "        for j in tqdm(range(batch_per_epoch)):\n",
      "            #=============Train discriminator and auxiliary models=============            \n",
      "            images_real = X[start:start + batch_size]\n",
      "            images_label = Y[start:start + batch_size]\n",
      "            \n",
      "            random_index = np.random.randint(0, Y.shape[0], size = (batch_size))\n",
      "            random_label = Y[random_index]\n",
      "            noise = np.random.normal(0, 1, size=(batch_size, 32))\n",
      "            images_fake = gen_model.predict(np.hstack((noise, random_label)))\n",
      "            \n",
      "            x = np.concatenate([images_real, images_fake])\n",
      "            label = np.concatenate([images_label, random_label])\n",
      "            y = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
      "            y += .05 * np.random.random(y.shape)\n",
      "            \n",
      "            d_loss = disc_model.train_on_batch([label, x], y)\n",
      "            d_losses.append(d_loss[0])\n",
      "            \n",
      "            #========================Train CGAN================================\n",
      "            random_index = np.random.randint(0, Y.shape[0], size = (batch_size))\n",
      "            random_label = Y[random_index]\n",
      "            noise = np.random.normal(0, 1, size=(batch_size, 32))\n",
      "            gen_input = np.concatenate((noise, random_label), axis=1)\n",
      "            y = np.ones((batch_size, 1))\n",
      "            \n",
      "            gan_loss = GAN.train_on_batch([gen_input, random_label], y)\n",
      "            gan_losses.append(gan_loss)\n",
      "\n",
      "            start += batch_size\n",
      "            if start > X.shape[0] - batch_size:\n",
      "                start = 0\n",
      "        \n",
      "        log_msg = \"epoch %d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
      "        log_msg = \"%s  [CGAN loss: %f]\" % (log_msg, gan_loss)\n",
      "        print(log_msg)\n",
      "        \n",
      "        d_losses.append(np.array(d_loss[0], dtype=float))\n",
      "        gan_losses.append(np.array(gan_loss, dtype=float))\n",
      "        \n",
      "        # Save ouputs\n",
      "        if save_interval>0 and (i+1)%save_interval==0:\n",
      "            blonde_women = np.array([np.array([0, 1, 0, 0, 0]) for i in range(4)])\n",
      "            darkhair_men = np.array([np.array([1, 0, 0, 1, 0]) for i in range(4)])\n",
      "            darkhair_women_glasses = np.array([np.array([1, 0, 1, 0, 1]) for i in range(4)])\n",
      "            blonde_men_glasses_smiling = np.array([np.array([0, 1, 1, 1, 1]) for i in range(4)])\n",
      "            labels = np.concatenate([blonde_women, darkhair_men, darkhair_women_glasses, blonde_men_glasses_smiling])\n",
      "            noise = np.random.normal(0, 1, size=(16, 32))\n",
      "            test_input = np.concatenate((noise, labels), axis=1)\n",
      "            plot_output(input_37=test_input, step=(i+1))\n",
      "    \n",
      "    d_losses = [float(x) for x in d_losses]\n",
      "    gan_losses = [float(x) for x in gan_losses]\n",
      "    \n",
      "    return(d_losses, gan_losses)\n",
      "\n",
      "#================================Train CGAN====================================\n",
      "d_loss_hist, gan_loss_hist = train_gan(X=X, batch_size=16, epoch=20, save_interval=1)\n",
      "\n",
      "plot_loss(d_loss_ls, gan_loss_ls, 1)\n",
      "\n",
      "#================================Save model====================================\n",
      "model_json = GAN.to_json()\n",
      "with open(\"GAN_model.json\", \"w\") as json_file:\n",
      "    json_file.write(model_json)\n",
      "GAN.save_weights(\"GAN_model.h5\", overwrite=True)\n",
      "\n",
      "GAN.save('CGAN_full_model.h5')\n",
      "gen_model.save('CGAN_generator.h5')\n",
      "disc_model.save('CGAN_discriminator.h5')\n",
      "Output: {'main_CelebA': ['keras.utils.vis_utils.plot_model', '<builtin>.sorted', 'keras.layers.Dense', 'keras.layers.Embedding', 'keras.layers.Flatten', 'keras.Input', 'keras.layers.Conv2D', 'keras.models.Model', 'keras.layers.Conv2DTranspose', 'main_CelebA.train_gan', 'PIL.Image.open', 'keras.layers.Activation', 'keras.optimizers.RMSprop', 'main_CelebA.plot_loss', 'numpy.array', 'keras.models.Sequential', 'numpy.uint8', 'keras.layers.LeakyReLU', '<builtin>.open', 'os.listdir', 'pandas.read_csv', '<builtin>.len', 'keras.layers.Dropout', 'keras.layers.Concatenate', 'tqdm.tqdm', 'keras.layers.Reshape'], 'os.listdir': [], '<builtin>.len': [], '<builtin>.sorted': [], 'tqdm.tqdm': [], 'PIL.Image.open': [], 'numpy.uint8': [], 'numpy.array': [], 'pandas.read_csv': [], 'keras.Input': [], 'keras.layers.Embedding': [], 'keras.layers.Dense': [], 'keras.layers.Reshape': [], 'keras.layers.Concatenate': [], 'keras.models.Sequential': [], 'keras.layers.Conv2D': [], 'keras.layers.LeakyReLU': [], 'keras.layers.Flatten': [], 'keras.layers.Dropout': [], 'keras.layers.Activation': [], 'keras.models.Model': [], 'keras.utils.vis_utils.plot_model': [], 'keras.layers.Conv2DTranspose': [], 'keras.optimizers.RMSprop': [], 'main_CelebA.plot_output': ['matplotlib.pyplot.close', '<builtin>.range', 'matplotlib.pyplot.savefig', 'matplotlib.pyplot.subplot', 'matplotlib.pyplot.axis', 'matplotlib.pyplot.imshow', 'matplotlib.pyplot.figure', 'matplotlib.pyplot.tight_layout'], 'matplotlib.pyplot.figure': [], '<builtin>.range': [], 'matplotlib.pyplot.subplot': [], 'matplotlib.pyplot.imshow': [], 'matplotlib.pyplot.axis': [], 'matplotlib.pyplot.tight_layout': [], 'matplotlib.pyplot.savefig': [], 'matplotlib.pyplot.close': [], 'main_CelebA.plot_loss': ['matplotlib.pyplot.close', 'matplotlib.pyplot.savefig', 'matplotlib.pyplot.plot', 'matplotlib.pyplot.xlabel', 'matplotlib.pyplot.figure', 'matplotlib.pyplot.legend', 'matplotlib.pyplot.ylabel'], 'matplotlib.pyplot.plot': [], 'matplotlib.pyplot.xlabel': [], 'matplotlib.pyplot.ylabel': [], 'matplotlib.pyplot.legend': [], 'main_CelebA.random_flip': ['random.randrange'], 'random.randrange': [], 'main_CelebA.train_gan': ['numpy.zeros', '<builtin>.range', 'numpy.random.randint', 'numpy.ones', '<builtin>.round', '<builtin>.int', 'numpy.random.normal', '<builtin>.print', 'main_CelebA.plot_output', 'numpy.random.random', 'numpy.array', 'numpy.hstack', 'tqdm.tqdm', 'numpy.concatenate', '<builtin>.float'], '<builtin>.round': [], '<builtin>.int': [], 'numpy.random.randint': [], 'numpy.random.normal': [], 'numpy.hstack': [], 'numpy.concatenate': [], 'numpy.ones': [], 'numpy.zeros': [], 'numpy.random.random': [], '<builtin>.print': [], '<builtin>.float': [], '<builtin>.open': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hklchung_GAN-GenerativeAdversarialNetwork\\CGAN\\main_CelebA.py\n",
      "[('main_CelebA', 'keras utils vis_utils plot_model'), ('main_CelebA', 'keras layers Dense'), ('main_CelebA', 'keras layers Embedding'), ('main_CelebA', 'keras layers Flatten'), ('main_CelebA', 'keras Input'), ('main_CelebA', 'keras layers Conv2D'), ('main_CelebA', 'keras models Model'), ('main_CelebA', 'keras layers Conv2DTranspose'), ('main_CelebA', 'main_CelebA train_gan'), ('main_CelebA', 'PIL Image open'), ('main_CelebA', 'keras layers Activation'), ('main_CelebA', 'keras optimizers RMSprop'), ('main_CelebA', 'main_CelebA plot_loss'), ('main_CelebA', 'numpy array'), ('main_CelebA', 'keras models Sequential'), ('main_CelebA', 'numpy uint8'), ('main_CelebA', 'keras layers LeakyReLU'), ('main_CelebA', 'os listdir'), ('main_CelebA', 'pandas read_csv'), ('main_CelebA', 'keras layers Dropout'), ('main_CelebA', 'keras layers Concatenate'), ('main_CelebA', 'tqdm tqdm'), ('main_CelebA', 'keras layers Reshape'), ('main_CelebA plot_output', 'matplotlib pyplot close'), ('main_CelebA plot_output', 'matplotlib pyplot savefig'), ('main_CelebA plot_output', 'matplotlib pyplot subplot'), ('main_CelebA plot_output', 'matplotlib pyplot axis'), ('main_CelebA plot_output', 'matplotlib pyplot imshow'), ('main_CelebA plot_output', 'matplotlib pyplot figure'), ('main_CelebA plot_output', 'matplotlib pyplot tight_layout')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"\n",
      "Copyright (c) 2020, Heung Kit Leslie Chung\n",
      "All rights reserved.\n",
      "Redistribution and use in source and binary forms, with or without\n",
      "    modification, are permitted provided that the following conditions are met:\n",
      "1. Redistributions of source code must retain the above copyright notice, this\n",
      "    list of conditions and the following disclaimer.\n",
      "2. Redistributions in binary form must reproduce the above copyright notice,\n",
      "    this list of conditions and the following disclaimer in the documentation\n",
      "    and/or other materials provided with the distribution.\n",
      "3. Neither the name of the copyright holder nor the names of its contributors\n",
      "    may be used to endorse or promote products derived from this software\n",
      "    without specific prior written permission.\n",
      "    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "    AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "    IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
      "    ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
      "    LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
      "    CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
      "    SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
      "    INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
      "    CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
      "    ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
      "    POSSIBILITY OF SUCH DAMAGE.\n",
      "\"\"\"\n",
      "import os\n",
      "import numpy as np\n",
      "import random\n",
      "import matplotlib.pyplot as plt\n",
      "from tqdm import tqdm\n",
      "from keras.layers import Input, Dense, Activation, Dropout, Flatten, Reshape, LeakyReLU, ReLU, AveragePooling2D, Embedding\n",
      "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, BatchNormalization, ZeroPadding2D, Concatenate\n",
      "from keras.models import Sequential, load_model, Model\n",
      "from keras.optimizers import RMSprop, Adam\n",
      "from keras.utils.vis_utils import plot_model\n",
      "from keras.utils import to_categorical\n",
      "from sklearn.utils import shuffle\n",
      "from keras.datasets import mnist, fashion_mnist\n",
      "\n",
      "#=============================Load MNIST dataset===============================\n",
      "(X, Y), (_, _) = mnist.load_data()\n",
      "#(X, Y), (_, _) = fashion_mnist.load_data()\n",
      "\n",
      "X = 1.0/255*X\n",
      "X = np.array([x.reshape(28, 28, 1) for x in X])\n",
      "Y = to_categorical(Y, 10)\n",
      "\n",
      "#=========================Discriminator model==================================\n",
      "# Define architecture of the discriminator (police AI)\n",
      "class_input = Input(shape=Y.shape[1:])\n",
      "embedding1 = Embedding(10, 50)(class_input)\n",
      "dense1 = Dense(28*28)(embedding1)\n",
      "reshape1 = Reshape((28, 28, 10))(dense1)\n",
      "dense2 = Dense(1)(reshape1)\n",
      "\n",
      "image_input = Input(shape=X.shape[1:])\n",
      "concatenate1 = Concatenate()([image_input, dense2])\n",
      "\n",
      "depth = 64\n",
      "dropout = 0.25\n",
      "D = Sequential()\n",
      "D.add(Conv2D(depth, kernel_size=3, strides=2, input_shape=X.shape[1:], padding=\"same\"))\n",
      "D.add(LeakyReLU(alpha=0.2))\n",
      "D.add(Dropout(dropout))\n",
      "D.add(Conv2D(depth*2, kernel_size=3, strides=2, padding=\"same\"))\n",
      "D.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
      "D.add(LeakyReLU(alpha=0.2))\n",
      "D.add(Dropout(dropout))\n",
      "D.add(BatchNormalization(momentum=0.8))\n",
      "D.add(Conv2D(depth*4, kernel_size=3, strides=2, padding=\"same\"))\n",
      "D.add(LeakyReLU(alpha=0.2))\n",
      "D.add(Dropout(dropout))\n",
      "D.add(BatchNormalization(momentum=0.8))\n",
      "D.add(Flatten())\n",
      "# Output layer\n",
      "D.add(Dense(1, kernel_initializer='glorot_normal'))\n",
      "D.add(Activation('sigmoid'))\n",
      "\n",
      "disc_out = D(concatenate1)\n",
      "\n",
      "disc_model = Model([class_input, image_input], disc_out)\n",
      "\n",
      "# Print out architecture of the discriminator\n",
      "disc_model.summary()\n",
      "# Save model architecture as .PNG\n",
      "plot_model(disc_model, to_file='discriminator.png', show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Generator model=====================================\n",
      "# Define architecture of the generator (fraudster AI)\n",
      "# Note: with each layer, the image gets larger but with reduced depth\n",
      "depth = 64*2\n",
      "dim = 7\n",
      "noise_vec = 266\n",
      "\n",
      "gen_model = Sequential()\n",
      "\n",
      "gen_model.add(Dense(depth*dim*dim, activation=\"relu\", input_dim=noise_vec))\n",
      "gen_model.add(Reshape((7, 7, 128)))\n",
      "gen_model.add(BatchNormalization(momentum=0.8))\n",
      "gen_model.add(UpSampling2D())\n",
      "gen_model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
      "gen_model.add(Activation(\"relu\"))\n",
      "gen_model.add(BatchNormalization(momentum=0.8))\n",
      "gen_model.add(UpSampling2D())\n",
      "gen_model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
      "gen_model.add(Activation(\"relu\"))\n",
      "gen_model.add(BatchNormalization(momentum=0.8))\n",
      "gen_model.add(Conv2D(1, kernel_size=3, padding='same'))\n",
      "gen_model.add(Activation(\"sigmoid\"))\n",
      "\n",
      "# Print out architecture of the generator\n",
      "gen_model.summary()\n",
      "# Save model architecture as .PNG\n",
      "plot_model(gen_model, to_file='generator.png', show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#===============Combine Discriminator and Generator models=====================\n",
      "# Define optimisers - optimisr1 will be used for the discriminator and generator\n",
      "optimizer1 = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
      "optimizer2 = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
      "\n",
      "disc_model.compile(loss='binary_crossentropy', optimizer=optimizer1,metrics=['accuracy'])\n",
      "gen_model.compile(loss='binary_crossentropy', optimizer=optimizer1,metrics=['accuracy'])\n",
      "\n",
      "inputs = Input(shape = (266,))\n",
      "gen_img = gen_model(inputs)\n",
      "disc_class_inputs = Input(shape = (10,))\n",
      "disc_outs = disc_model([disc_class_inputs, gen_img])\n",
      "\n",
      "# Define CGAN inout and output\n",
      "comb_model = Model([inputs, disc_class_inputs], disc_outs)\n",
      "comb_model.compile(loss=['binary_crossentropy'], optimizer=optimizer2, metrics=['accuracy'])\n",
      "\n",
      "# Print out architecture of GAN\n",
      "comb_model.summary()\n",
      "# Save model architecture as .PNG \n",
      "plot_model(comb_model, to_file='CGAN.png', show_shapes=True, show_layer_names=True)\n",
      "plot_model(comb_model, to_file='CGAN_expand.png', expand_nested=True, show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Plot image function=================================\n",
      "def plot_output(input_266, step):\n",
      "    filename = \"GANmodel_%d\" % step\n",
      "    \n",
      "    images = gen_model.predict(input_266)\n",
      "\n",
      "    plt.figure(figsize=(10,10))\n",
      "    for i in range(images.shape[0]):\n",
      "        plt.subplot(10, 10, i+1)\n",
      "        image = images[i, :, :, :]\n",
      "        image = image.reshape(X.shape[1], X.shape[2])\n",
      "        plt.imshow(image, cmap='gray')\n",
      "        plt.axis('off')\n",
      "    plt.tight_layout()\n",
      "    plt.savefig(filename)\n",
      "    plt.close('all')\n",
      "    \n",
      "#==========================Plot loss function==================================\n",
      "def plot_loss(d_performance, gan_performance, jump=100):\n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.plot(d_performance[0::jump], label='discriminator')\n",
      "    plt.plot(gan_performance[0::jump], label='GAN')\n",
      "    plt.xlabel('epoch ({})'.format(jump))\n",
      "    plt.ylabel('loss')\n",
      "    plt.legend()\n",
      "    plt.savefig('loss_over_epoch.png')\n",
      "    plt.close('all')\n",
      "    \n",
      "#================================Train CGAN====================================\n",
      "batch_size = 16\n",
      "latent_dim = 256 + 10\n",
      "epoch = 1000\n",
      "save_interval = 100\n",
      "def train_gan(X, batch_size, epoch, save_interval):\n",
      "    batch_per_epoch = int(round(X.shape[0]/batch_size))\n",
      "    d_loss_hist = []\n",
      "    gan_loss_hist = []\n",
      "    for i in range(epoch):\n",
      "        for j in tqdm(range(batch_per_epoch)):\n",
      "            #=============Train discriminator and auxiliary models=============\n",
      "            disc_model.trainable = True\n",
      "            \n",
      "            images_index = np.random.randint(0, X.shape[0], size = (batch_size))\n",
      "            images_real = X[images_index]\n",
      "            images_label = Y[images_index]\n",
      "            \n",
      "            random_label = to_categorical(np.random.randint(0,10,batch_size), 10)\n",
      "            noise = np.random.normal(0, 1, size=(batch_size, 256))\n",
      "            images_fake = gen_model.predict(np.hstack((noise, random_label)))\n",
      "            \n",
      "            d_loss_real = disc_model.train_on_batch([images_label, images_real], np.ones([batch_size, 1]))\n",
      "            d_loss_fake = disc_model.train_on_batch([random_label, images_fake], np.zeros([batch_size, 1]))\n",
      "            \n",
      "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
      "            \n",
      "            #========================Train CGAN================================\n",
      "            disc_model.trainable = False\n",
      "            \n",
      "            gen_input = np.concatenate((noise, random_label), axis=1)\n",
      "            gan_loss = comb_model.train_on_batch([gen_input, random_label], np.ones([batch_size, 1]))\n",
      "        \n",
      "        log_msg = \"epoch %d: [D loss (real): %f, acc: %f]\" % (i, d_loss_real[0], d_loss_real[1])\n",
      "        log_msg = \"%s  [D loss (fake): %f, acc: %f]\" % (log_msg, d_loss_fake[0], d_loss_fake[1])\n",
      "        log_msg = \"%s  [CGAN loss: %f, acc: %f]\" % (log_msg, gan_loss[0], gan_loss[1])\n",
      "        print(log_msg)\n",
      "        \n",
      "        d_loss_hist.append(np.array(d_loss[0], dtype=float))\n",
      "        gan_loss_hist.append(np.array(gan_loss[0], dtype=float))\n",
      "        \n",
      "        # Save ouputs\n",
      "        if save_interval>0 and (i+1)%save_interval==0:\n",
      "            test_label = np.concatenate(([np.concatenate(np.full((10, 1), x)) for x in range(0, 10)]))\n",
      "            test_label = to_categorical(test_label)\n",
      "            noise = np.random.normal(0, 1, size=(100, 256))\n",
      "            test_input = np.hstack((noise, test_label))\n",
      "            plot_output(input_266=test_input, step=(i+1))\n",
      "    \n",
      "    d_loss_hist = [float(x) for x in d_loss_hist]\n",
      "    gan_loss_hist = [float(x) for x in gan_loss_hist]\n",
      "    \n",
      "    return(d_loss_hist, gan_loss_hist)\n",
      "\n",
      "#===============================Train CGAN=====================================\n",
      "d_loss_hist, gan_loss_hist = train_gan(X=X, batch_size=16, epoch=5, save_interval=1)\n",
      "\n",
      "plot_loss(d_loss_hist, gan_loss_hist, jump = 1)\n",
      "Output: {'main_MNIST': ['main_MNIST.train_gan', 'keras.utils.to_categorical', 'keras.models.Sequential', 'numpy.array', 'keras.utils.vis_utils.plot_model', 'keras.layers.Embedding', 'keras.layers.BatchNormalization', 'keras.layers.Concatenate', 'keras.layers.Conv2D', 'keras.optimizers.RMSprop', 'keras.layers.ZeroPadding2D', 'keras.layers.Flatten', 'keras.layers.LeakyReLU', 'main_MNIST.plot_loss', 'keras.models.Model', 'keras.layers.Input', 'keras.layers.Dropout', 'keras.layers.Activation', 'keras.datasets.mnist.load_data', 'keras.layers.Dense', 'keras.layers.UpSampling2D', 'keras.layers.Reshape'], 'keras.datasets.mnist.load_data': [], 'numpy.array': [], 'keras.utils.to_categorical': [], 'keras.layers.Input': [], 'keras.layers.Embedding': [], 'keras.layers.Dense': [], 'keras.layers.Reshape': [], 'keras.layers.Concatenate': [], 'keras.models.Sequential': [], 'keras.layers.Conv2D': [], 'keras.layers.LeakyReLU': [], 'keras.layers.Dropout': [], 'keras.layers.ZeroPadding2D': [], 'keras.layers.BatchNormalization': [], 'keras.layers.Flatten': [], 'keras.layers.Activation': [], 'keras.models.Model': [], 'keras.utils.vis_utils.plot_model': [], 'keras.layers.UpSampling2D': [], 'keras.optimizers.RMSprop': [], 'main_MNIST.plot_output': ['matplotlib.pyplot.imshow', '<builtin>.range', 'matplotlib.pyplot.subplot', 'matplotlib.pyplot.tight_layout', 'matplotlib.pyplot.axis', 'matplotlib.pyplot.close', 'matplotlib.pyplot.savefig', 'matplotlib.pyplot.figure'], 'matplotlib.pyplot.figure': [], '<builtin>.range': [], 'matplotlib.pyplot.subplot': [], 'matplotlib.pyplot.imshow': [], 'matplotlib.pyplot.axis': [], 'matplotlib.pyplot.tight_layout': [], 'matplotlib.pyplot.savefig': [], 'matplotlib.pyplot.close': [], 'main_MNIST.plot_loss': ['matplotlib.pyplot.xlabel', 'matplotlib.pyplot.ylabel', 'matplotlib.pyplot.legend', 'matplotlib.pyplot.plot', 'matplotlib.pyplot.close', 'matplotlib.pyplot.savefig', 'matplotlib.pyplot.figure'], 'matplotlib.pyplot.plot': [], 'matplotlib.pyplot.xlabel': [], 'matplotlib.pyplot.ylabel': [], 'matplotlib.pyplot.legend': [], 'main_MNIST.train_gan': ['numpy.hstack', '<builtin>.range', 'numpy.random.randint', '<builtin>.int', 'main_MNIST.plot_output', 'keras.utils.to_categorical', 'numpy.full', 'numpy.zeros', '<builtin>.float', 'numpy.array', '<builtin>.round', 'numpy.concatenate', '<builtin>.print', 'numpy.add', 'numpy.random.normal', 'numpy.ones', 'tqdm.tqdm'], '<builtin>.round': [], '<builtin>.int': [], 'tqdm.tqdm': [], 'numpy.random.randint': [], 'numpy.random.normal': [], 'numpy.hstack': [], 'numpy.ones': [], 'numpy.zeros': [], 'numpy.add': [], 'numpy.concatenate': [], '<builtin>.print': [], 'numpy.full': [], '<builtin>.float': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hklchung_GAN-GenerativeAdversarialNetwork\\CGAN\\main_MNIST.py\n",
      "[('main_MNIST', 'main_MNIST train_gan'), ('main_MNIST', 'keras utils to_categorical'), ('main_MNIST', 'keras models Sequential'), ('main_MNIST', 'numpy array'), ('main_MNIST', 'keras utils vis_utils plot_model'), ('main_MNIST', 'keras layers Embedding'), ('main_MNIST', 'keras layers BatchNormalization'), ('main_MNIST', 'keras layers Concatenate'), ('main_MNIST', 'keras layers Conv2D'), ('main_MNIST', 'keras optimizers RMSprop'), ('main_MNIST', 'keras layers ZeroPadding2D'), ('main_MNIST', 'keras layers Flatten'), ('main_MNIST', 'keras layers LeakyReLU'), ('main_MNIST', 'main_MNIST plot_loss'), ('main_MNIST', 'keras models Model'), ('main_MNIST', 'keras layers Input'), ('main_MNIST', 'keras layers Dropout'), ('main_MNIST', 'keras layers Activation'), ('main_MNIST', 'keras datasets mnist load_data'), ('main_MNIST', 'keras layers Dense'), ('main_MNIST', 'keras layers UpSampling2D'), ('main_MNIST', 'keras layers Reshape'), ('main_MNIST plot_output', 'matplotlib pyplot imshow'), ('main_MNIST plot_output', 'matplotlib pyplot subplot'), ('main_MNIST plot_output', 'matplotlib pyplot tight_layout'), ('main_MNIST plot_output', 'matplotlib pyplot axis'), ('main_MNIST plot_output', 'matplotlib pyplot close'), ('main_MNIST plot_output', 'matplotlib pyplot savefig'), ('main_MNIST plot_output', 'matplotlib pyplot figure'), ('main_MNIST plot_loss', 'matplotlib pyplot xlabel')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"\n",
      "Copyright (c) 2020, Heung Kit Leslie Chung\n",
      "All rights reserved.\n",
      "Redistribution and use in source and binary forms, with or without\n",
      "    modification, are permitted provided that the following conditions are met:\n",
      "1. Redistributions of source code must retain the above copyright notice, this\n",
      "    list of conditions and the following disclaimer.\n",
      "2. Redistributions in binary form must reproduce the above copyright notice,\n",
      "    this list of conditions and the following disclaimer in the documentation\n",
      "    and/or other materials provided with the distribution.\n",
      "3. Neither the name of the copyright holder nor the names of its contributors\n",
      "    may be used to endorse or promote products derived from this software\n",
      "    without specific prior written permission.\n",
      "    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "    AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "    IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
      "    ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
      "    LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
      "    CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
      "    SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
      "    INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
      "    CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
      "    ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
      "    POSSIBILITY OF SUCH DAMAGE.\n",
      "\"\"\"\n",
      "import os\n",
      "import numpy as np\n",
      "import random\n",
      "import matplotlib.pyplot as plt\n",
      "from tqdm import tqdm\n",
      "from keras.layers import Input, Dense, Activation, Dropout, Flatten, Reshape, LeakyReLU, ReLU, AveragePooling2D, Embedding\n",
      "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, BatchNormalization, ZeroPadding2D, Concatenate\n",
      "from keras.models import Sequential, load_model, Model\n",
      "from keras.optimizers import RMSprop, Adam\n",
      "from keras.utils.vis_utils import plot_model\n",
      "from keras.utils import to_categorical\n",
      "from sklearn.utils import shuffle\n",
      "from keras.datasets import mnist, fashion_mnist\n",
      "\n",
      "#=============================Load MNIST dataset===============================\n",
      "# Load our image dataset\n",
      "(X, Y), (_, _) = mnist.load_data()\n",
      "#(X, Y), (_, _) = fashion_mnist.load_data()\n",
      "\n",
      "X = 1.0/255*X\n",
      "X = np.array([x.reshape(28, 28, 1) for x in X])\n",
      "Y = to_categorical(Y, 10)\n",
      "\n",
      "# Our input vector for generator = 256D noise + 10D category info\n",
      "latent_dim = 266\n",
      "\n",
      "#====================Discriminator and Auxiliary model=========================\n",
      "# Define input shape of our MNIST images\n",
      "img_shape = (28,28,1)\n",
      "img = Input(shape=img_shape)\n",
      "\n",
      "# Shared network\n",
      "depth = 64\n",
      "dropout = 0.25\n",
      "D = Sequential()\n",
      "D.add(Conv2D(depth, kernel_size=3, strides=2, input_shape=X.shape[1:], padding=\"same\"))\n",
      "D.add(LeakyReLU(alpha=0.2))\n",
      "D.add(Dropout(dropout))\n",
      "D.add(Conv2D(depth*2, kernel_size=3, strides=2, padding=\"same\"))\n",
      "D.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
      "D.add(LeakyReLU(alpha=0.2))\n",
      "D.add(Dropout(dropout))\n",
      "D.add(BatchNormalization(momentum=0.8))\n",
      "D.add(Conv2D(depth*4, kernel_size=3, strides=2, padding=\"same\"))\n",
      "D.add(LeakyReLU(alpha=0.2))\n",
      "D.add(Dropout(dropout))\n",
      "D.add(BatchNormalization(momentum=0.8))\n",
      "D.add(Flatten())\n",
      "\n",
      "# Discriminator output\n",
      "img_embedding = D(img)\n",
      "disc = Dense(1, activation='sigmoid', kernel_initializer='glorot_normal')(img_embedding)\n",
      "disc_model = Model(img, disc)\n",
      "\n",
      "# Auxiliary output\n",
      "aux = Dense(128, activation='relu')(img_embedding)\n",
      "label = Dense(10, activation='softmax')(aux)\n",
      "q_model = Model(img, label)\n",
      "\n",
      "# Note that these two models are one and the same with different output layers\n",
      "# Print out architecture of the discriminator    \n",
      "disc_model.summary()\n",
      "# Print out architecture of the auxiliary model\n",
      "q_model.summary()\n",
      "\n",
      "# Save model architecture as .PNG \n",
      "plot_model(disc_model, to_file='disciminator.png', expand_nested=True, show_shapes=True, show_layer_names=True)\n",
      "plot_model(q_model, to_file='auxiliary.png', expand_nested=True, show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Generator model=====================================\n",
      "# Define architecture of the generator (fraudster AI)\n",
      "# Note: with each layer, the image gets larger but with reduced depth\n",
      "depth = 64*2\n",
      "dim = 7\n",
      "noise_vec = 266\n",
      "\n",
      "gen_model = Sequential()\n",
      "\n",
      "gen_model.add(Dense(depth*dim*dim, activation=\"relu\", input_dim=noise_vec))\n",
      "gen_model.add(Reshape((7, 7, 128)))\n",
      "gen_model.add(BatchNormalization(momentum=0.8))\n",
      "gen_model.add(UpSampling2D())\n",
      "gen_model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
      "gen_model.add(Activation(\"relu\"))\n",
      "gen_model.add(BatchNormalization(momentum=0.8))\n",
      "gen_model.add(UpSampling2D())\n",
      "gen_model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
      "gen_model.add(Activation(\"relu\"))\n",
      "gen_model.add(BatchNormalization(momentum=0.8))\n",
      "gen_model.add(Conv2D(1, kernel_size=3, padding='same'))\n",
      "gen_model.add(Activation(\"sigmoid\"))\n",
      "\n",
      "# Print out architecture of the generator\n",
      "gen_model.summary()\n",
      "# Save model architecture as .PNG\n",
      "plot_model(gen_model, to_file='generator.png', expand_nested=True, show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#===============Combine Discriminator and Generator models=====================\n",
      "# Define optimisers - optimisr1 will be used for all component networks\n",
      "optimizer1 = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
      "optimizer2 = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
      "\n",
      "disc_model.compile(loss='binary_crossentropy', optimizer=optimizer1, metrics=['accuracy'])\n",
      "q_model.compile(loss='categorical_crossentropy', optimizer=optimizer1, metrics=['accuracy'])\n",
      "gen_model.compile(loss='binary_crossentropy', optimizer=optimizer1)\n",
      "\n",
      "# Define architecture of InfoGAN\n",
      "# Starts with generator input = 266D vector\n",
      "inputs = Input(shape = (latent_dim,)) \n",
      "# Generator output\n",
      "gen_img = gen_model(inputs)\n",
      "\n",
      "disc_model.trainable = False\n",
      "\n",
      "# Generator output is the input for both discriminator and auxiliary models\n",
      "disc_outs = disc_model(gen_img)\n",
      "q_outs = q_model(gen_img)\n",
      "\n",
      "# Define InfoGAN inout and output\n",
      "comb_model = Model(inputs, [disc_outs, q_outs])\n",
      "comb_model.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=optimizer2, metrics=['accuracy'])\n",
      "\n",
      "# Print out architecture of GAN\n",
      "comb_model.summary()\n",
      "# Save model architecture as .PNG \n",
      "plot_model(comb_model, to_file='infogan.png', show_shapes=True, show_layer_names=True)\n",
      "plot_model(comb_model, to_file='infogan_expand.png', expand_nested=True, show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Plot image function=================================\n",
      "def plot_output(input_266, step):\n",
      "    filename = \"GANmodel_%d\" % step\n",
      "    \n",
      "    images = gen_model.predict(input_266)\n",
      "\n",
      "    plt.figure(figsize=(10,10))\n",
      "    for i in range(images.shape[0]):\n",
      "        plt.subplot(10, 10, i+1)\n",
      "        image = images[i, :, :, :]\n",
      "        image = image.reshape(X.shape[1], X.shape[2])\n",
      "        plt.imshow(image, cmap='gray')\n",
      "        plt.axis('off')\n",
      "    plt.tight_layout()\n",
      "    plt.savefig(filename)\n",
      "    plt.close('all')\n",
      "\n",
      "#==========================Plot loss function==================================\n",
      "def plot_loss(d_performance, gan_performance, q_performance, jump=100):\n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.plot(d_performance[0::jump], label='discriminator')\n",
      "    plt.plot(q_performance[0::jump], label='q')\n",
      "    plt.plot(gan_performance[0::jump], label='GAN')\n",
      "    plt.xlabel('epoch ({})'.format(jump))\n",
      "    plt.ylabel('loss')\n",
      "    plt.legend()\n",
      "    plt.savefig('loss_over_epoch.png')\n",
      "    plt.close('all')\n",
      "    \n",
      "#==============================Train InfoGAN===================================\n",
      "def train_gan(X, batch_size, epoch, save_interval):\n",
      "    batch_per_epoch = int(round(X.shape[0]/batch_size))\n",
      "    d_loss_hist = []\n",
      "    q_loss_hist = []\n",
      "    gan_loss_hist = []\n",
      "    for i in range(epoch):\n",
      "        for j in tqdm(range(batch_per_epoch)):\n",
      "            #=============Train discriminator and auxiliary models=============\n",
      "            disc_model.trainable = True\n",
      "            half_batch = int(batch_size/2)\n",
      "            \n",
      "            images_index = np.random.randint(0, X.shape[0], size = (half_batch))\n",
      "            images_real = X[images_index]\n",
      "            images_label = Y[images_index]\n",
      "            \n",
      "            random_label = to_categorical(np.random.randint(0,10,half_batch), 10)\n",
      "            noise = np.random.normal(0, 1, size=(half_batch, 256))\n",
      "            images_fake = gen_model.predict(np.hstack((noise, random_label)))\n",
      "            \n",
      "            d_loss_real = disc_model.train_on_batch(images_real, np.ones([half_batch, 1]))\n",
      "            d_loss_fake = disc_model.train_on_batch(images_fake, np.zeros([half_batch, 1]))\n",
      "            \n",
      "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
      "            \n",
      "            q_loss_real = q_model.train_on_batch(images_real, images_label)\n",
      "            q_loss_fake = q_model.train_on_batch(images_fake, random_label)\n",
      "            \n",
      "            q_loss = 0.5 * np.add(q_loss_real, q_loss_fake)\n",
      "            \n",
      "            #========================Train InfoGAN=============================\n",
      "            disc_model.trainable = False\n",
      "            \n",
      "            gen_input1 = np.concatenate((noise, random_label), axis=1)\n",
      "            \n",
      "            random_label2 = to_categorical(np.random.randint(0,10,half_batch), 10)\n",
      "            noise2 = np.random.normal(0, 1, size=(half_batch, 256))\n",
      "            gen_input2 = np.concatenate((noise2, random_label2), axis=1)\n",
      "            \n",
      "            gen_input = np.concatenate((gen_input1, gen_input2), axis=0)\n",
      "            gan_loss = comb_model.train_on_batch(gen_input, [np.ones([batch_size, 1]), np.concatenate((random_label, random_label2), axis=0)])\n",
      "        \n",
      "        log_msg = \"epoch %d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
      "        log_msg = \"%s  [Q loss: %f]\" % (log_msg, q_loss[0])\n",
      "        log_msg = \"%s  [GAN loss: %f]\" % (log_msg, gan_loss[0])\n",
      "        print(log_msg)\n",
      "        \n",
      "        d_loss_hist.append(np.array(d_loss[0], dtype=float))\n",
      "        q_loss_hist.append(np.array(q_loss[0], dtype=float))\n",
      "        gan_loss_hist.append(np.array(gan_loss[0], dtype=float))\n",
      "        \n",
      "        # Save ouputs\n",
      "        if save_interval>0 and (i+1)%save_interval==0:\n",
      "            test_label = np.concatenate(([np.concatenate(np.full((10, 1), x)) for x in range(0, 10)]))\n",
      "            test_label = to_categorical(test_label)\n",
      "            noise = np.random.normal(0, 1, size=(100, 256))\n",
      "            test_input = np.hstack((noise, test_label))\n",
      "            plot_output(input_266=test_input, step=(i+1))\n",
      "            \n",
      "    d_loss_hist = [float(x) for x in d_loss_hist]\n",
      "    gan_loss_hist = [float(x) for x in gan_loss_hist]\n",
      "    \n",
      "    return(d_loss_hist, q_loss_hist, gan_loss_hist)\n",
      "\n",
      "#===============================Train InfoGAN==================================\n",
      "d_loss_hist, q_loss_hist, gan_loss_hist = train_gan(X=X, batch_size=32, epoch=10, save_interval=1)\n",
      "\n",
      "plot_loss(d_loss_hist, gan_loss_hist, q_loss_hist, jump = 1)\n",
      "Output: {'main': ['keras.layers.BatchNormalization', 'keras.layers.Input', 'keras.datasets.mnist.load_data', 'main.plot_loss', 'keras.models.Model', 'keras.layers.Activation', 'keras.layers.Conv2D', 'keras.layers.Dropout', 'keras.layers.Reshape', 'keras.utils.to_categorical', 'keras.utils.vis_utils.plot_model', 'keras.layers.ZeroPadding2D', 'keras.layers.LeakyReLU', 'numpy.array', 'keras.layers.Flatten', 'keras.layers.Dense', 'main.train_gan', 'keras.layers.UpSampling2D', 'keras.models.Sequential', 'keras.optimizers.RMSprop'], 'keras.datasets.mnist.load_data': [], 'numpy.array': [], 'keras.utils.to_categorical': [], 'keras.layers.Input': [], 'keras.models.Sequential': [], 'keras.layers.Conv2D': [], 'keras.layers.LeakyReLU': [], 'keras.layers.Dropout': [], 'keras.layers.ZeroPadding2D': [], 'keras.layers.BatchNormalization': [], 'keras.layers.Flatten': [], 'keras.layers.Dense': [], 'keras.models.Model': [], 'keras.utils.vis_utils.plot_model': [], 'keras.layers.Reshape': [], 'keras.layers.UpSampling2D': [], 'keras.layers.Activation': [], 'keras.optimizers.RMSprop': [], 'main.plot_output': ['matplotlib.pyplot.savefig', '<builtin>.range', 'matplotlib.pyplot.subplot', 'matplotlib.pyplot.axis', 'matplotlib.pyplot.imshow', 'matplotlib.pyplot.tight_layout', 'matplotlib.pyplot.close', 'matplotlib.pyplot.figure'], 'matplotlib.pyplot.figure': [], '<builtin>.range': [], 'matplotlib.pyplot.subplot': [], 'matplotlib.pyplot.imshow': [], 'matplotlib.pyplot.axis': [], 'matplotlib.pyplot.tight_layout': [], 'matplotlib.pyplot.savefig': [], 'matplotlib.pyplot.close': [], 'main.plot_loss': ['matplotlib.pyplot.plot', 'matplotlib.pyplot.ylabel', 'matplotlib.pyplot.savefig', 'matplotlib.pyplot.legend', 'matplotlib.pyplot.close', 'matplotlib.pyplot.figure', 'matplotlib.pyplot.xlabel'], 'matplotlib.pyplot.plot': [], 'matplotlib.pyplot.xlabel': [], 'matplotlib.pyplot.ylabel': [], 'matplotlib.pyplot.legend': [], 'main.train_gan': ['numpy.concatenate', '<builtin>.print', 'numpy.zeros', '<builtin>.round', 'numpy.hstack', '<builtin>.range', '<builtin>.float', 'numpy.random.normal', 'main.plot_output', 'numpy.random.randint', '<builtin>.int', 'numpy.ones', 'tqdm.tqdm', 'numpy.array', 'numpy.full', 'numpy.add', 'keras.utils.to_categorical'], '<builtin>.round': [], '<builtin>.int': [], 'tqdm.tqdm': [], 'numpy.random.randint': [], 'numpy.random.normal': [], 'numpy.hstack': [], 'numpy.ones': [], 'numpy.zeros': [], 'numpy.add': [], 'numpy.concatenate': [], '<builtin>.print': [], 'numpy.full': [], '<builtin>.float': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hklchung_GAN-GenerativeAdversarialNetwork\\InfoGAN\\main.py\n",
      "[('main', 'keras layers BatchNormalization'), ('main', 'keras layers Input'), ('main', 'keras datasets mnist load_data'), ('main', 'main plot_loss'), ('main', 'keras models Model'), ('main', 'keras layers Activation'), ('main', 'keras layers Conv2D'), ('main', 'keras layers Dropout'), ('main', 'keras layers Reshape'), ('main', 'keras utils to_categorical'), ('main', 'keras utils vis_utils plot_model'), ('main', 'keras layers ZeroPadding2D'), ('main', 'keras layers LeakyReLU'), ('main', 'numpy array'), ('main', 'keras layers Flatten'), ('main', 'keras layers Dense'), ('main', 'main train_gan'), ('main', 'keras layers UpSampling2D'), ('main', 'keras models Sequential'), ('main', 'keras optimizers RMSprop'), ('main plot_output', 'matplotlib pyplot savefig'), ('main plot_output', 'matplotlib pyplot subplot'), ('main plot_output', 'matplotlib pyplot axis'), ('main plot_output', 'matplotlib pyplot imshow'), ('main plot_output', 'matplotlib pyplot tight_layout'), ('main plot_output', 'matplotlib pyplot close'), ('main plot_output', 'matplotlib pyplot figure'), ('main plot_loss', 'matplotlib pyplot plot'), ('main plot_loss', 'matplotlib pyplot ylabel'), ('main plot_loss', 'matplotlib pyplot savefig')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"\n",
      "Copyright (c) 2020, Heung Kit Leslie Chung\n",
      "All rights reserved.\n",
      "Redistribution and use in source and binary forms, with or without\n",
      "    modification, are permitted provided that the following conditions are met:\n",
      "1. Redistributions of source code must retain the above copyright notice, this\n",
      "    list of conditions and the following disclaimer.\n",
      "2. Redistributions in binary form must reproduce the above copyright notice,\n",
      "    this list of conditions and the following disclaimer in the documentation\n",
      "    and/or other materials provided with the distribution.\n",
      "3. Neither the name of the copyright holder nor the names of its contributors\n",
      "    may be used to endorse or promote products derived from this software\n",
      "    without specific prior written permission.\n",
      "    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "    AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "    IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
      "    ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
      "    LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
      "    CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
      "    SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
      "    INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
      "    CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
      "    ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
      "    POSSIBILITY OF SUCH DAMAGE.\n",
      "\"\"\"\n",
      "\n",
      "import os\n",
      "import numpy as np\n",
      "import random\n",
      "import matplotlib.pyplot as plt\n",
      "from tqdm import tqdm\n",
      "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape, LeakyReLU\n",
      "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, BatchNormalization, ZeroPadding2D\n",
      "from keras.models import Sequential, load_model, Model\n",
      "from keras.optimizers import RMSprop, Adam\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
      "from keras.utils.vis_utils import plot_model\n",
      "from keras import backend, Input\n",
      "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
      "from skimage.io import imsave\n",
      "from sklearn.utils import shuffle\n",
      "from sklearn.utils import shuffle\n",
      "from PIL import Image, ImageOps\n",
      "import tensorflow as tf\n",
      "\n",
      "#===========================Resize images======================================\n",
      "img_path = \"../Image/Train/tenk_celebs/100k\"\n",
      "out_path = \"../Image/Train/Resized2\"\n",
      "for filename in tqdm(os.listdir(img_path)):\n",
      "    temp = Image.open(img_path + '/' + filename)\n",
      "    size = 64, 64\n",
      "    temp.thumbnail(size, Image.ANTIALIAS)\n",
      "    temp.save(out_path + '/' + filename, \"JPEG\")\n",
      "\n",
      "#============================Get images========================================\n",
      "images = []\n",
      "# Grab images from folder\n",
      "for filename in tqdm(os.listdir(out_path)):\n",
      "    if np.random.normal(0, 1, 1) > 0.89:\n",
      "        temp = np.array(img_to_array(load_img(out_path + '/' + filename)), dtype=float)\n",
      "        hor = 64 - temp.shape[0]\n",
      "        ver = 64 - temp.shape[1]\n",
      "        if hor%2 != 0:\n",
      "            temp = np.pad(temp, ((hor//2 + 1, hor//2), (ver//2, ver//2), (0, 0)),\n",
      "                  mode='constant', constant_values=0)\n",
      "        elif ver%2 != 0:\n",
      "            temp = np.pad(temp, ((hor//2, hor//2), (ver//2 + 1, ver//2), (0, 0)),\n",
      "                  mode='constant', constant_values=0)\n",
      "        else:\n",
      "        # Pad resized images with zeros such that they are all 64x64x3\n",
      "            temp = np.pad(temp, ((hor//2, hor//2), (ver//2, ver//2), (0, 0)),\n",
      "                  mode='constant', constant_values=0)\n",
      "        # Store images into a list\n",
      "        images.append(np.array(temp, dtype=float))\n",
      "\n",
      "# Normalise RGB intensities, reshape and forced into array\n",
      "X = [1.0/255*x for x in images]\n",
      "X = [x.reshape(64, 64, 3) for x in X]\n",
      "X = np.array(X)\n",
      "\n",
      "# We need only 10k images to train\n",
      "del(images)\n",
      "X = X[:10000]\n",
      "\n",
      "#=========================Discriminator model==================================\n",
      "# Define architecture of the discriminator (police AI)\n",
      "noise = 32\n",
      "depth = 256\n",
      "\n",
      "D = Sequential()\n",
      "# Input + First layer\n",
      "D.add(Conv2D(depth, 3, strides=1, input_shape=X.shape[1:]))\n",
      "D.add(LeakyReLU())\n",
      "# Second layer\n",
      "D.add(Conv2D(depth, 4, strides=2))\n",
      "D.add(LeakyReLU())\n",
      "# Third layer\n",
      "D.add(Conv2D(depth, 4, strides=2))\n",
      "D.add(LeakyReLU())\n",
      "# Forth layer\n",
      "D.add(Conv2D(depth, 4, strides=2))\n",
      "D.add(LeakyReLU())\n",
      "# Fifth layer\n",
      "D.add(Conv2D(depth, 4, strides=2))\n",
      "D.add(LeakyReLU())\n",
      "# Output\n",
      "D.add(Flatten())\n",
      "D.add(Dropout(0.4))\n",
      "D.add(Dense(1))\n",
      "D.add(Activation('sigmoid'))\n",
      "\n",
      "# Print out architecture of the discriminator\n",
      "D.summary()\n",
      "# Save model architecture as .PNG\n",
      "plot_model(D, to_file='discriminator.png', show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Generator model=====================================\n",
      "# Define architecture of the generator (fraudster AI)\n",
      "depth = 128\n",
      "dim = 8\n",
      "noise_vec = 32\n",
      "\n",
      "G = Sequential()\n",
      "# Input + First layer\n",
      "G.add(Dense(dim*dim*depth, input_dim=noise_vec))\n",
      "G.add(LeakyReLU())\n",
      "G.add(Reshape((dim, dim, depth)))\n",
      "# Second layer\n",
      "G.add(Conv2D(depth*2, 5, padding = 'same'))\n",
      "G.add(LeakyReLU())\n",
      "# Third layer\n",
      "G.add(Conv2DTranspose(depth*2, 4, strides=2, padding = 'same'))\n",
      "G.add(LeakyReLU())\n",
      "# Forth layer\n",
      "G.add(Conv2DTranspose(depth*2, 4, strides=2, padding = 'same'))\n",
      "G.add(LeakyReLU())\n",
      "# Fifth layer\n",
      "G.add(Conv2DTranspose(depth*2, 4, strides=2, padding = 'same'))\n",
      "G.add(LeakyReLU())\n",
      "# Sixth layer\n",
      "G.add(Conv2DTranspose(depth*4, 5, strides=1, padding = 'same'))\n",
      "G.add(LeakyReLU())\n",
      "# Seventh layer\n",
      "G.add(Conv2DTranspose(depth*4, 5, strides=1, padding = 'same'))\n",
      "G.add(LeakyReLU())\n",
      "# Output\n",
      "G.add(Conv2DTranspose(3, 7, strides=1, activation = 'tanh', padding = 'same'))\n",
      "\n",
      "# Print out architecture of the generator\n",
      "G.summary()\n",
      "# Save model architecture as .PNG\n",
      "plot_model(G, to_file='generator.png', show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#================================DCGAN=========================================\n",
      "# Define optimisers\n",
      "optimizer = RMSprop(lr=.0001, clipvalue=1.0, decay=1e-8)\n",
      "D.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
      "D.trainable = False\n",
      "\n",
      "# Define architecture of DCGAN\n",
      "GAN = Sequential()\n",
      "GAN.add(G)  # Adding the generator\n",
      "GAN.add(D)  # Adding the discriminator \n",
      "\n",
      "# Compile DCGAN\n",
      "GAN.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
      "\n",
      "# Print out architecture of DCGAN\n",
      "GAN.summary()\n",
      "# Save model architecture as .PNG\n",
      "plot_model(GAN, to_file='DCGAN.png', show_shapes=True, show_layer_names=True)\n",
      "plot_model(GAN, to_file='DCGAN_expand.png', expand_nested=True, show_shapes=True, show_layer_names=True)\n",
      "\n",
      "#==========================Plot image function=================================\n",
      "def plot_output(noise, step):\n",
      "    filename = \"GANmodel_%d.png\" % step\n",
      "    \n",
      "    images = G.predict(noise)\n",
      "\n",
      "    plt.figure(figsize=(10,10))\n",
      "    for i in range(images.shape[0]):\n",
      "        plt.subplot(4, 4, i+1)\n",
      "        image = images[i, :, :, :]\n",
      "        image = image.reshape(images.shape[1], images.shape[2], images.shape[3])\n",
      "        plt.imshow(image)\n",
      "        plt.axis('off')\n",
      "    plt.tight_layout()\n",
      "    plt.savefig(filename)\n",
      "    plt.close('all')\n",
      "    \n",
      "#==========================Plot loss function==================================\n",
      "def plot_loss(d_performance, gan_performance, jump=100):\n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.plot(d_performance[0::jump], label='discriminator')\n",
      "    plt.plot(gan_performance[0::jump], label='GAN')\n",
      "    plt.xlabel('iteration (Skipping every {}its)'.format(jump))\n",
      "    plt.ylabel('loss')\n",
      "    plt.legend()\n",
      "    plt.savefig('loss_over_epoch.png')\n",
      "    plt.close('all')\n",
      "    \n",
      "#=========================Train GAN function===================================\n",
      "def train_gan(X, model, batch_size, epoch, save_interval, noise_len=32):    \n",
      "    d_losses = []\n",
      "    gan_losses = []\n",
      "    \n",
      "    batch_per_epoch = int(round(X.shape[0]/batch_size))\n",
      "    \n",
      "    for i in range(epoch):\n",
      "        start = 0\n",
      "        for j in tqdm(range(batch_per_epoch)):\n",
      "            #=====================Train discriminator==========================\n",
      "            noise_vec = np.random.normal(size=(batch_size, noise))\n",
      "            images_fake = G.predict(noise_vec)\n",
      "\n",
      "            images_real = X[start:start + batch_size]\n",
      "            x = np.concatenate([images_fake, images_real])\n",
      "\n",
      "            y = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
      "            y += .05 * np.random.random(y.shape)\n",
      "\n",
      "            d_loss = D.train_on_batch(x, y)\n",
      "            d_losses.append(d_loss[0])\n",
      "            \n",
      "            #=========================Train GAN================================\n",
      "            noise_vec = np.random.normal(size=(batch_size, noise))\n",
      "            y = np.zeros((batch_size, 1))\n",
      "\n",
      "            gan_loss = GAN.train_on_batch(noise_vec, y)\n",
      "            gan_losses.append(gan_loss)\n",
      "\n",
      "            start += batch_size\n",
      "            if start > X.shape[0] - batch_size:\n",
      "                start = 0\n",
      "        # Print loss and accuracy values \n",
      "        log_msg = \"epoch %d: [D loss: %f]\" % (i, d_loss[0])\n",
      "        log_msg = \"%s  [GAN loss: %f]\" % (log_msg, gan_loss)\n",
      "        print(log_msg)\n",
      "        \n",
      "        # Save ouputs\n",
      "        if save_interval>0 and (i+1)%save_interval==0:\n",
      "            noise_input = np.random.normal(0.0, 1.0, size=[16, noise_len])\n",
      "            plot_output(noise=noise_input, step=(i+1))\n",
      "    \n",
      "    d_losses = [float(x) for x in d_losses]\n",
      "    gan_losses = [float(x) for x in gan_losses]\n",
      "    return(d_losses, gan_losses)\n",
      "\n",
      "#=================================Train GAN====================================\n",
      "d_loss_ls, gan_loss_ls = train_gan(X=X, model=GAN, batch_size=16, epoch=50, \n",
      "                                                         save_interval=1,\n",
      "                                                         noise_len=32)\n",
      "\n",
      "plot_loss(d_loss_ls, gan_loss_ls)\n",
      "\n",
      "#================================Save model====================================\n",
      "model_json = GAN.to_json()\n",
      "with open(\"GAN_model.json\", \"w\") as json_file:\n",
      "    json_file.write(model_json)\n",
      "GAN.save_weights(\"GAN_model.h5\", overwrite=True)\n",
      "\n",
      "GAN.save('DCGAN_full_model.h5')\n",
      "D.save('DCGAN_discriminator.h5')\n",
      "G.save('DCGAN_generator.h5')\n",
      "\n",
      "#================================Result GIF====================================\n",
      "import imageio\n",
      "result_pwd = 'Result/Model11'\n",
      "output_pwd = os.path.abspath(os.getcwd())\n",
      "images = []\n",
      "for filename in tqdm(os.listdir(result_pwd)):\n",
      "    images.append(imageio.imread(result_pwd + '/' + filename))\n",
      "imageio.mimsave(output_pwd + '/' + result_pwd + '/' + 'GAN.gif', images)\n",
      "\n",
      "#=======================Manipulating input vector==============================\n",
      "features = 32\n",
      "preset = [-2, -1, -.5, -.2, -.1, 0, .1, .2, .5, 1, 2]\n",
      "\n",
      "plt.figure(1, figsize=(2 * len(preset), features * 2))\n",
      "i = 0\n",
      "for feature in range(features):\n",
      "    for value in preset:\n",
      "        plt.subplot(features, len(preset), i+1)\n",
      "        latent_vector = np.zeros((1, 32))\n",
      "        latent_vector[0, feature] = value\n",
      "        img = generator.predict(latent_vector)[0]\n",
      "        plt.imshow(img)\n",
      "        plt.savefig('controlled_shifts.png')\n",
      "        plt.axis('off')\n",
      "        i += 1\n",
      "plt.show()\n",
      "Output: {'main': ['numpy.array', 'matplotlib.pyplot.axis', 'matplotlib.pyplot.subplot', 'keras.layers.Conv2D', 'os.listdir', '<builtin>.len', 'imageio.mimsave', 'imageio.imread', 'os.path.abspath', 'keras.models.Sequential', 'keras.layers.Reshape', 'numpy.pad', 'matplotlib.pyplot.show', 'keras.optimizers.RMSprop', 'keras.layers.Dense', 'matplotlib.pyplot.figure', 'keras.preprocessing.image.load_img', 'main.plot_loss', 'keras.layers.Activation', 'numpy.zeros', 'matplotlib.pyplot.savefig', '<builtin>.range', 'main.train_gan', 'keras.layers.Conv2DTranspose', 'numpy.random.normal', 'os.getcwd', 'keras.utils.vis_utils.plot_model', '<builtin>.open', 'keras.layers.LeakyReLU', 'tqdm.tqdm', 'keras.layers.Flatten', 'keras.layers.Dropout', 'PIL.Image.open', 'keras.preprocessing.image.img_to_array', 'matplotlib.pyplot.imshow'], 'os.listdir': [], 'tqdm.tqdm': [], 'PIL.Image.open': [], 'numpy.random.normal': [], 'keras.preprocessing.image.load_img': [], 'keras.preprocessing.image.img_to_array': [], 'numpy.array': [], 'numpy.pad': [], 'keras.models.Sequential': [], 'keras.layers.Conv2D': [], 'keras.layers.LeakyReLU': [], 'keras.layers.Flatten': [], 'keras.layers.Dropout': [], 'keras.layers.Dense': [], 'keras.layers.Activation': [], 'keras.utils.vis_utils.plot_model': [], 'keras.layers.Reshape': [], 'keras.layers.Conv2DTranspose': [], 'keras.optimizers.RMSprop': [], 'main.plot_output': ['matplotlib.pyplot.close', 'matplotlib.pyplot.axis', 'matplotlib.pyplot.figure', 'matplotlib.pyplot.subplot', 'matplotlib.pyplot.tight_layout', 'matplotlib.pyplot.savefig', '<builtin>.range', 'matplotlib.pyplot.imshow'], 'matplotlib.pyplot.figure': [], '<builtin>.range': [], 'matplotlib.pyplot.subplot': [], 'matplotlib.pyplot.imshow': [], 'matplotlib.pyplot.axis': [], 'matplotlib.pyplot.tight_layout': [], 'matplotlib.pyplot.savefig': [], 'matplotlib.pyplot.close': [], 'main.plot_loss': ['matplotlib.pyplot.legend', 'matplotlib.pyplot.close', 'matplotlib.pyplot.plot', 'matplotlib.pyplot.xlabel', 'matplotlib.pyplot.savefig', 'matplotlib.pyplot.figure', 'matplotlib.pyplot.ylabel'], 'matplotlib.pyplot.plot': [], 'matplotlib.pyplot.xlabel': [], 'matplotlib.pyplot.ylabel': [], 'matplotlib.pyplot.legend': [], 'main.train_gan': ['numpy.random.normal', '<builtin>.print', '<builtin>.float', 'tqdm.tqdm', '<builtin>.int', 'numpy.zeros', 'numpy.ones', 'main.plot_output', 'numpy.random.random', '<builtin>.range', 'numpy.concatenate', '<builtin>.round'], '<builtin>.round': [], '<builtin>.int': [], 'numpy.concatenate': [], 'numpy.ones': [], 'numpy.zeros': [], 'numpy.random.random': [], '<builtin>.print': [], '<builtin>.float': [], '<builtin>.open': [], 'os.getcwd': [], 'os.path.abspath': [], 'imageio.imread': [], 'imageio.mimsave': [], '<builtin>.len': [], 'matplotlib.pyplot.show': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\hklchung_GAN-GenerativeAdversarialNetwork\\DCGAN\\main.py\n",
      "[('main', 'numpy array'), ('main', 'matplotlib pyplot axis'), ('main', 'matplotlib pyplot subplot'), ('main', 'keras layers Conv2D'), ('main', 'os listdir'), ('main', 'imageio mimsave'), ('main', 'imageio imread'), ('main', 'os path abspath'), ('main', 'keras models Sequential'), ('main', 'keras layers Reshape'), ('main', 'numpy pad'), ('main', 'matplotlib pyplot show'), ('main', 'keras optimizers RMSprop'), ('main', 'keras layers Dense'), ('main', 'matplotlib pyplot figure'), ('main', 'keras preprocessing image load_img'), ('main', 'main plot_loss'), ('main', 'keras layers Activation'), ('main', 'numpy zeros'), ('main', 'matplotlib pyplot savefig'), ('main', 'main train_gan'), ('main', 'keras layers Conv2DTranspose'), ('main', 'numpy random normal'), ('main', 'os getcwd'), ('main', 'keras utils vis_utils plot_model'), ('main', 'keras layers LeakyReLU'), ('main', 'tqdm tqdm'), ('main', 'keras layers Flatten'), ('main', 'keras layers Dropout'), ('main', 'PIL Image open')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('main_MNIST', 'tqdm tqdm'), ('main_MNIST', 'keras layers Flatten'), ('main_MNIST', 'keras layers Dropout'), ('main_MNIST', 'keras datasets mnist load_data'), ('main_MNIST', 'main_MNIST train_gan'), ('main_MNIST', 'keras layers Activation'), ('main_MNIST', 'imageio mimsave'), ('main_MNIST', 'os getcwd'), ('main_MNIST', 'keras layers Conv2D'), ('main_MNIST', 'main_MNIST plot_loss'), ('main_MNIST', 'os listdir'), ('main_MNIST', 'keras optimizers RMSprop'), ('main_MNIST', 'keras utils vis_utils plot_model'), ('main_MNIST', 'keras layers LeakyReLU'), ('main_MNIST', 'keras layers Conv2DTranspose'), ('main_MNIST', 'keras layers Dense'), ('main_MNIST', 'main_MNIST plot_accuracy'), ('main_MNIST', 'numpy array'), ('main_MNIST', 'keras layers Reshape'), ('main_MNIST', 'imageio imread'), ('main_MNIST', 'keras layers UpSampling2D'), ('main_MNIST', 'os path abspath'), ('main_MNIST', 'keras layers BatchNormalization'), ('main_MNIST', 'keras models Sequential'), ('main_MNIST plot_output', 'matplotlib pyplot savefig'), ('main_MNIST plot_output', 'matplotlib pyplot subplot'), ('main_MNIST plot_output', 'matplotlib pyplot close'), ('main_MNIST plot_output', 'matplotlib pyplot axis'), ('main_MNIST plot_output', 'matplotlib pyplot figure'), ('main_MNIST plot_output', 'matplotlib pyplot tight_layout')], [('main', 'main plot_loss'), ('main', 'keras layers Dense'), ('main', 'keras layers Reshape'), ('main', 'keras layers Activation'), ('main', 'main train_gan'), ('main', 'numpy array'), ('main', 'keras datasets mnist load_data'), ('main', 'keras layers ZeroPadding2D'), ('main', 'keras models Model'), ('main', 'keras layers BatchNormalization'), ('main', 'keras models Sequential'), ('main', 'keras layers Input'), ('main', 'keras layers LeakyReLU'), ('main', 'keras layers Dropout'), ('main', 'keras layers UpSampling2D'), ('main', 'keras utils vis_utils plot_model'), ('main', 'keras optimizers RMSprop'), ('main', 'keras layers Flatten'), ('main', 'keras layers Conv2D'), ('main', 'keras utils to_categorical'), ('main plot_output', 'matplotlib pyplot figure'), ('main plot_output', 'matplotlib pyplot subplot'), ('main plot_output', 'matplotlib pyplot imshow'), ('main plot_output', 'matplotlib pyplot axis'), ('main plot_output', 'matplotlib pyplot close'), ('main plot_output', 'matplotlib pyplot savefig'), ('main plot_output', 'matplotlib pyplot tight_layout'), ('main plot_loss', 'matplotlib pyplot figure'), ('main plot_loss', 'matplotlib pyplot close'), ('main plot_loss', 'matplotlib pyplot xlabel')], [('main_100kCeleb', 'keras utils vis_utils plot_model'), ('main_100kCeleb', 'keras layers Reshape'), ('main_100kCeleb', 'main_100kCeleb plot_loss'), ('main_100kCeleb', 'imageio mimsave'), ('main_100kCeleb', 'keras layers Conv2D'), ('main_100kCeleb', 'tqdm tqdm'), ('main_100kCeleb', 'numpy random normal'), ('main_100kCeleb', 'keras models Sequential'), ('main_100kCeleb', 'imageio imread'), ('main_100kCeleb', 'keras layers LeakyReLU'), ('main_100kCeleb', 'keras layers Activation'), ('main_100kCeleb', 'os listdir'), ('main_100kCeleb', 'numpy pad'), ('main_100kCeleb', 'os getcwd'), ('main_100kCeleb', 'numpy array'), ('main_100kCeleb', 'keras optimizers RMSprop'), ('main_100kCeleb', 'keras preprocessing image img_to_array'), ('main_100kCeleb', 'keras layers Conv2DTranspose'), ('main_100kCeleb', 'PIL Image open'), ('main_100kCeleb', 'keras layers Flatten'), ('main_100kCeleb', 'keras preprocessing image load_img'), ('main_100kCeleb', 'keras layers Dense'), ('main_100kCeleb', 'main_100kCeleb train_gan'), ('main_100kCeleb', 'os path abspath'), ('main_100kCeleb', 'keras layers Dropout'), ('main_100kCeleb plot_output', 'matplotlib pyplot close'), ('main_100kCeleb plot_output', 'matplotlib pyplot axis'), ('main_100kCeleb plot_output', 'matplotlib pyplot imshow'), ('main_100kCeleb plot_output', 'matplotlib pyplot tight_layout'), ('main_100kCeleb plot_output', 'matplotlib pyplot savefig')], [('main_CelebA', 'keras utils vis_utils plot_model'), ('main_CelebA', 'keras layers Dense'), ('main_CelebA', 'keras layers Embedding'), ('main_CelebA', 'keras layers Flatten'), ('main_CelebA', 'keras Input'), ('main_CelebA', 'keras layers Conv2D'), ('main_CelebA', 'keras models Model'), ('main_CelebA', 'keras layers Conv2DTranspose'), ('main_CelebA', 'main_CelebA train_gan'), ('main_CelebA', 'PIL Image open'), ('main_CelebA', 'keras layers Activation'), ('main_CelebA', 'keras optimizers RMSprop'), ('main_CelebA', 'main_CelebA plot_loss'), ('main_CelebA', 'numpy array'), ('main_CelebA', 'keras models Sequential'), ('main_CelebA', 'numpy uint8'), ('main_CelebA', 'keras layers LeakyReLU'), ('main_CelebA', 'os listdir'), ('main_CelebA', 'pandas read_csv'), ('main_CelebA', 'keras layers Dropout'), ('main_CelebA', 'keras layers Concatenate'), ('main_CelebA', 'tqdm tqdm'), ('main_CelebA', 'keras layers Reshape'), ('main_CelebA plot_output', 'matplotlib pyplot close'), ('main_CelebA plot_output', 'matplotlib pyplot savefig'), ('main_CelebA plot_output', 'matplotlib pyplot subplot'), ('main_CelebA plot_output', 'matplotlib pyplot axis'), ('main_CelebA plot_output', 'matplotlib pyplot imshow'), ('main_CelebA plot_output', 'matplotlib pyplot figure'), ('main_CelebA plot_output', 'matplotlib pyplot tight_layout')], [('main_MNIST', 'main_MNIST train_gan'), ('main_MNIST', 'keras utils to_categorical'), ('main_MNIST', 'keras models Sequential'), ('main_MNIST', 'numpy array'), ('main_MNIST', 'keras utils vis_utils plot_model'), ('main_MNIST', 'keras layers Embedding'), ('main_MNIST', 'keras layers BatchNormalization'), ('main_MNIST', 'keras layers Concatenate'), ('main_MNIST', 'keras layers Conv2D'), ('main_MNIST', 'keras optimizers RMSprop'), ('main_MNIST', 'keras layers ZeroPadding2D'), ('main_MNIST', 'keras layers Flatten'), ('main_MNIST', 'keras layers LeakyReLU'), ('main_MNIST', 'main_MNIST plot_loss'), ('main_MNIST', 'keras models Model'), ('main_MNIST', 'keras layers Input'), ('main_MNIST', 'keras layers Dropout'), ('main_MNIST', 'keras layers Activation'), ('main_MNIST', 'keras datasets mnist load_data'), ('main_MNIST', 'keras layers Dense'), ('main_MNIST', 'keras layers UpSampling2D'), ('main_MNIST', 'keras layers Reshape'), ('main_MNIST plot_output', 'matplotlib pyplot imshow'), ('main_MNIST plot_output', 'matplotlib pyplot subplot'), ('main_MNIST plot_output', 'matplotlib pyplot tight_layout'), ('main_MNIST plot_output', 'matplotlib pyplot axis'), ('main_MNIST plot_output', 'matplotlib pyplot close'), ('main_MNIST plot_output', 'matplotlib pyplot savefig'), ('main_MNIST plot_output', 'matplotlib pyplot figure'), ('main_MNIST plot_loss', 'matplotlib pyplot xlabel')], [('main', 'keras layers BatchNormalization'), ('main', 'keras layers Input'), ('main', 'keras datasets mnist load_data'), ('main', 'main plot_loss'), ('main', 'keras models Model'), ('main', 'keras layers Activation'), ('main', 'keras layers Conv2D'), ('main', 'keras layers Dropout'), ('main', 'keras layers Reshape'), ('main', 'keras utils to_categorical'), ('main', 'keras utils vis_utils plot_model'), ('main', 'keras layers ZeroPadding2D'), ('main', 'keras layers LeakyReLU'), ('main', 'numpy array'), ('main', 'keras layers Flatten'), ('main', 'keras layers Dense'), ('main', 'main train_gan'), ('main', 'keras layers UpSampling2D'), ('main', 'keras models Sequential'), ('main', 'keras optimizers RMSprop'), ('main plot_output', 'matplotlib pyplot savefig'), ('main plot_output', 'matplotlib pyplot subplot'), ('main plot_output', 'matplotlib pyplot axis'), ('main plot_output', 'matplotlib pyplot imshow'), ('main plot_output', 'matplotlib pyplot tight_layout'), ('main plot_output', 'matplotlib pyplot close'), ('main plot_output', 'matplotlib pyplot figure'), ('main plot_loss', 'matplotlib pyplot plot'), ('main plot_loss', 'matplotlib pyplot ylabel'), ('main plot_loss', 'matplotlib pyplot savefig')], [('main', 'numpy array'), ('main', 'matplotlib pyplot axis'), ('main', 'matplotlib pyplot subplot'), ('main', 'keras layers Conv2D'), ('main', 'os listdir'), ('main', 'imageio mimsave'), ('main', 'imageio imread'), ('main', 'os path abspath'), ('main', 'keras models Sequential'), ('main', 'keras layers Reshape'), ('main', 'numpy pad'), ('main', 'matplotlib pyplot show'), ('main', 'keras optimizers RMSprop'), ('main', 'keras layers Dense'), ('main', 'matplotlib pyplot figure'), ('main', 'keras preprocessing image load_img'), ('main', 'main plot_loss'), ('main', 'keras layers Activation'), ('main', 'numpy zeros'), ('main', 'matplotlib pyplot savefig'), ('main', 'main train_gan'), ('main', 'keras layers Conv2DTranspose'), ('main', 'numpy random normal'), ('main', 'os getcwd'), ('main', 'keras utils vis_utils plot_model'), ('main', 'keras layers LeakyReLU'), ('main', 'tqdm tqdm'), ('main', 'keras layers Flatten'), ('main', 'keras layers Dropout'), ('main', 'PIL Image open')]]\n",
      "********************doctrings*************************\n",
      "['plot output plot loss plot accuracy train gan', 'plot output plot loss train gan', 'plot output plot loss train gan', 'plot output plot loss random flip train gan', 'plot output plot loss train gan', 'plot output plot loss train gan', 'plot output plot loss train gan']\n",
      "embed index dataset: 14\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Snawoot_rabotaua-cv-updater\\\\rabotaua_cv_updater\\\\__main__.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Snawoot_rabotaua-cv-updater\\\\setup.py']\n",
      "#!/usr/bin/env python3\n",
      "\n",
      "import logging\n",
      "import argparse\n",
      "import enum\n",
      "import os\n",
      "import os.path\n",
      "import sqlite3\n",
      "import signal\n",
      "from time import sleep, time, ctime\n",
      "from random import randrange, random\n",
      "import collections\n",
      "from heapq import merge\n",
      "\n",
      "from selenium import webdriver\n",
      "from selenium.webdriver.chrome.options import Options\n",
      "from selenium.webdriver.common.by import By\n",
      "from selenium.webdriver.common.action_chains import ActionChains\n",
      "from selenium.webdriver.support.ui import WebDriverWait\n",
      "from selenium.webdriver.support import expected_conditions as EC\n",
      "from selenium.common.exceptions import (TimeoutException,\n",
      "                                        StaleElementReferenceException,\n",
      "                                        NoSuchElementException,\n",
      "                                        ElementClickInterceptedException)\n",
      "from webdriver_manager.chrome import ChromeDriverManager\n",
      "from webdriver_manager.utils import ChromeType\n",
      "\n",
      "RESUME_LIST_URL = \"https://account.rabota.ua/jobsearch/notepad/cvs\"\n",
      "RESUME_LIST_URL_PATTERN = r\"^https://account\\.rabota\\.ua/(ua/)?jobsearch/notepad/cvs/?$\"\n",
      "LOGIN_URL = \"https://rabota.ua/jobsearch/login\"\n",
      "POST_LOGIN_URL_PATTERN = r\"^https://account\\.rabota\\.ua/(ua/)?jobsearch/notepad/vacancies_profile/?$\"\n",
      "UPDATE_BUTTON_XPATH = \"//div[contains(@class, 'cv-item-container')]\"\\\n",
      "    \"//button[contains(@data-bind, 'updateDate') and \"\\\n",
      "    \"(contains(text(), '') or contains(text(), ''))]\"\n",
      "UPDATE_INTERVAL = 30 * 60\n",
      "UPDATE_INTERVAL_MIN_DRIFT = 10\n",
      "UPDATE_INTERVAL_MAX_DRIFT = 60\n",
      "MANUAL_LOGIN_TIMEOUT = 3600\n",
      "POST_UPDATE_PAUSE = 30\n",
      "\n",
      "DB_INIT = [\n",
      "    \"CREATE TABLE IF NOT EXISTS update_ts (\\n\"\n",
      "    \"name TEXT PRIMARY KEY,\\n\"\n",
      "    \"value REAL NOT NULL DEFAULT 0)\\n\"\n",
      "]\n",
      "\n",
      "def wall_clock_wait(when, precision=1.):\n",
      "    \"\"\" Sleep variation which is doesn't increases\n",
      "    sleep duration when computer enters suspend/hybernation\n",
      "    \"\"\"\n",
      "    while time() < when:\n",
      "        sleep(precision)\n",
      "\n",
      "def setup_logger(name, verbosity):\n",
      "    logger = logging.getLogger(name)\n",
      "    logger.setLevel(verbosity)\n",
      "    handler = logging.StreamHandler()\n",
      "    handler.setLevel(verbosity)\n",
      "    handler.setFormatter(logging.Formatter(\"%(asctime)s \"\n",
      "                                           \"%(levelname)-8s \"\n",
      "                                           \"%(name)s: %(message)s\",\n",
      "                                           \"%Y-%m-%d %H:%M:%S\"))\n",
      "    logger.addHandler(handler)\n",
      "    return logger\n",
      "\n",
      "class LogLevel(enum.IntEnum):\n",
      "    debug = logging.DEBUG\n",
      "    info = logging.INFO\n",
      "    warn = logging.WARN\n",
      "    error = logging.ERROR\n",
      "    fatal = logging.FATAL\n",
      "    crit = logging.CRITICAL\n",
      "\n",
      "    def __str__(self):\n",
      "        return self.name\n",
      "\n",
      "class Command(enum.Enum):\n",
      "    login = 1\n",
      "    update = 2\n",
      "\n",
      "    def __str__(self):\n",
      "        return self.name\n",
      "\n",
      "class BrowserType(enum.Enum):\n",
      "    chrome = ChromeType.GOOGLE\n",
      "    chromium = ChromeType.CHROMIUM\n",
      "\n",
      "    def __str__(self):\n",
      "        return self.name\n",
      "\n",
      "class ScheduledEvent(enum.Enum):\n",
      "    REFRESH = 1\n",
      "    UPDATE = 2\n",
      "\n",
      "ScheduleEntry = collections.namedtuple('ScheduleEntry', ('when', 'what'))\n",
      "\n",
      "button_wait_condition = EC.presence_of_element_located((By.XPATH, UPDATE_BUTTON_XPATH))\n",
      "\n",
      "def update(browser, timeout):\n",
      "    logger = logging.getLogger(\"UPDATE\")\n",
      "    browser.get(RESUME_LIST_URL)\n",
      "    WebDriverWait(browser, timeout).until(\n",
      "        button_wait_condition\n",
      "    )\n",
      "    update_buttons = browser.find_elements_by_xpath(UPDATE_BUTTON_XPATH)\n",
      "    logger.info(\"Located %d update buttons\", len(update_buttons))\n",
      "    for elem in update_buttons:\n",
      "        sleep(1 + 2 * random())\n",
      "        elem.click()\n",
      "        logger.debug(\"click!\")\n",
      "    # There is no easy reliable way to make sure all outstanding request are\n",
      "    # complete. So, just give it enough time.\n",
      "    sleep(POST_UPDATE_PAUSE)\n",
      "    logger.info('Updated!')\n",
      "\n",
      "def login(browser, timeout):\n",
      "    logger = logging.getLogger(\"LOGIN\")\n",
      "    browser.get(LOGIN_URL)\n",
      "    WebDriverWait(browser, timeout).until(\n",
      "        EC.url_matches(POST_LOGIN_URL_PATTERN)\n",
      "    )\n",
      "    logger.info('Successfully logged in!')\n",
      "\n",
      "def parse_args():\n",
      "    def check_loglevel(arg):\n",
      "        try:\n",
      "            return LogLevel[arg]\n",
      "        except (IndexError, KeyError):\n",
      "            raise argparse.ArgumentTypeError(\"%s is not valid loglevel\" % (repr(arg),))\n",
      "\n",
      "    def check_command(arg):\n",
      "        try:\n",
      "            return Command[arg]\n",
      "        except (IndexError, KeyError):\n",
      "            raise argparse.ArgumentTypeError(\"%s is not valid command\" % (repr(arg),))\n",
      "\n",
      "    def check_browser_type(arg):\n",
      "        try:\n",
      "            return BrowserType[arg]\n",
      "        except (IndexError, KeyError):\n",
      "            raise argparse.ArgumentTypeError(\"%s is not valid browser type\" % (repr(arg),))\n",
      "\n",
      "    def check_positive_float(arg):\n",
      "        def fail():\n",
      "            raise argparse.ArgumentTypeError(\"%s is not valid positive float\" % (repr(arg),))\n",
      "        try:\n",
      "            fvalue = float(arg)\n",
      "        except ValueError:\n",
      "            fail()\n",
      "        if fvalue <= 0:\n",
      "            fail()\n",
      "        return fvalue\n",
      "\n",
      "    parser = argparse.ArgumentParser(\n",
      "        description=\"Python script to update your CV\",\n",
      "        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
      "    parser.add_argument(\"-t\", \"--timeout\",\n",
      "                        help=\"webdriver wait timeout\",\n",
      "                        type=check_positive_float,\n",
      "                        default=10.)\n",
      "    parser.add_argument(\"-b\", \"--browser\",\n",
      "                        help=\"browser type\",\n",
      "                        type=check_browser_type,\n",
      "                        choices=BrowserType,\n",
      "                        default=BrowserType.chromium)\n",
      "    parser.add_argument(\"-v\", \"--verbosity\",\n",
      "                        help=\"logging verbosity\",\n",
      "                        type=check_loglevel,\n",
      "                        choices=LogLevel,\n",
      "                        default=LogLevel.info)\n",
      "    parser.add_argument(\"cmd\", help=\"command\",\n",
      "                        type=check_command,\n",
      "                        choices=Command)\n",
      "    parser.add_argument(\"-d\", \"--data-dir\",\n",
      "                        default=os.path.join(os.path.expanduser(\"~\"),\n",
      "                                             '.config',\n",
      "                                             'rabotaua-cv-updater'),\n",
      "                        help=\"application datadir location\",\n",
      "                        metavar=\"FILE\")\n",
      "    return parser.parse_args()\n",
      "\n",
      "class BrowserFactory:\n",
      "    def __init__(self, profile_dir, browser_type, headless=True):\n",
      "        chrome_options = Options()\n",
      "        # option below causes webdriver process remaining in memory\n",
      "        # chrome_options.add_argument('--no-sandbox')\n",
      "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
      "        chrome_options.add_argument('--disable-gpu')\n",
      "        chrome_options.add_argument('user-data-dir=' + profile_dir)\n",
      "        if headless:\n",
      "            chrome_options.add_argument('--headless')\n",
      "        self._options = chrome_options\n",
      "        self._driver = ChromeDriverManager(chrome_type=browser_type).install()\n",
      "\n",
      "    def new(self):\n",
      "        return webdriver.Chrome(\n",
      "            self._driver,\n",
      "            options=self._options)\n",
      "\n",
      "class UpdateTracker:\n",
      "    def __init__(self, dbpath):\n",
      "        conn = sqlite3.connect(dbpath)\n",
      "        cur = conn.cursor()\n",
      "        try:\n",
      "            for q in DB_INIT:\n",
      "                cur.execute(q)\n",
      "            conn.commit()\n",
      "            cur.execute(\"SELECT 1 FROM update_ts WHERE name = ?\", (\"last\",))\n",
      "            if cur.fetchone() is None:\n",
      "                cur.execute(\"INSERT INTO update_ts (name, value) VALUES (?,?)\",\n",
      "                            (\"last\", 0.))\n",
      "                conn.commit()\n",
      "            cur.execute(\"SELECT 1 FROM update_ts WHERE name = ?\", (\"login\",))\n",
      "            if cur.fetchone() is None:\n",
      "                cur.execute(\"INSERT INTO update_ts (name, value) VALUES (?,?)\",\n",
      "                            (\"login\", 0.))\n",
      "                conn.commit()\n",
      "        finally:\n",
      "            cur.close()\n",
      "        self._conn = conn\n",
      "\n",
      "    def last_update(self):\n",
      "        cur = self._conn.cursor()\n",
      "        try:\n",
      "            cur.execute(\"SELECT value FROM update_ts WHERE name = ?\",\n",
      "                        (\"last\",))\n",
      "            return cur.fetchone()[0]\n",
      "        finally:\n",
      "            cur.close()\n",
      "\n",
      "    def last_login(self):\n",
      "        cur = self._conn.cursor()\n",
      "        try:\n",
      "            cur.execute(\"SELECT value FROM update_ts WHERE name = ?\",\n",
      "                        (\"login\",))\n",
      "            return cur.fetchone()[0]\n",
      "        finally:\n",
      "            cur.close()\n",
      "\n",
      "    def update(self, ts):\n",
      "        c = self._conn\n",
      "        with c:\n",
      "            c.execute(\"UPDATE update_ts SET value = ? WHERE name = ? AND value < ?\",\n",
      "                      (float(ts), \"last\", float(ts)))\n",
      "\n",
      "    def login(self, ts):\n",
      "        c = self._conn\n",
      "        with c:\n",
      "            c.execute(\"UPDATE update_ts SET value = ? WHERE name = ? AND value < ?\",\n",
      "                      (float(ts), \"login\", float(ts)))\n",
      "\n",
      "    def close(self):\n",
      "        self._conn.close()\n",
      "        self._conn = None\n",
      "\n",
      "def random_interval(base, min_drift, max_drift):\n",
      "    return base + min_drift + random() * (max_drift - min_drift)\n",
      "\n",
      "class Scheduler:\n",
      "    def __init__(self, last_login, last_update):\n",
      "        self._it = self._iter_events(last_login, last_update)\n",
      "\n",
      "    def __iter__(self):\n",
      "        return self\n",
      "\n",
      "    def __next__(self):\n",
      "        return next(self._it)\n",
      "\n",
      "    @staticmethod\n",
      "    def _event_stream(token, last_occured, base, min_drift, max_drift):\n",
      "        t = max(last_occured + random_interval(base, min_drift, max_drift), time())\n",
      "        yield ScheduleEntry(when=t, what=token)\n",
      "        while True:\n",
      "            t += random_interval(base, min_drift, max_drift)\n",
      "            yield ScheduleEntry(when=t, what=token)\n",
      "\n",
      "    @staticmethod\n",
      "    def _iter_events(last_login, last_update):\n",
      "        return Scheduler._event_stream(ScheduledEvent.UPDATE,\n",
      "                                       last_update,\n",
      "                                       UPDATE_INTERVAL,\n",
      "                                       UPDATE_INTERVAL_MIN_DRIFT,\n",
      "                                       UPDATE_INTERVAL_MAX_DRIFT)\n",
      "\n",
      "def do_login(browser_factory, timeout):\n",
      "    browser = browser_factory.new()\n",
      "    try:\n",
      "        login(browser, timeout)\n",
      "    finally:\n",
      "        browser.quit()\n",
      "\n",
      "def do_update(browser_factory, timeout):\n",
      "    browser = browser_factory.new()\n",
      "    try:\n",
      "        update(browser, timeout)\n",
      "    finally:\n",
      "        browser.quit()\n",
      "\n",
      "def update_loop(browser_factory, tracker, timeout):\n",
      "    logger = logging.getLogger(\"EVLOOP\")\n",
      "    last_update = tracker.last_update()\n",
      "    last_login = tracker.last_login()\n",
      "    logger.info(\"Starting scheduler. \"\n",
      "                \"Last update @ %.3f (%s); last refresh @ %.3f (%s).\",\n",
      "                last_update, ctime(last_update),\n",
      "                last_login, ctime(last_login))\n",
      "    for ev in Scheduler(last_login, last_update):\n",
      "        logger.info(\"Next event is %s @ %.3f (%s)\",\n",
      "                    ev.what.name, ev.when, ctime(ev.when))\n",
      "        wall_clock_wait(ev.when)\n",
      "        try:\n",
      "            if ev.what is ScheduledEvent.REFRESH:\n",
      "                logger.info(\"Refreshing session now!\")\n",
      "                do_login(browser_factory, timeout)\n",
      "                tracker.login(time())\n",
      "            elif ev.what is ScheduledEvent.UPDATE:\n",
      "                logger.info(\"Updating CVs now!\")\n",
      "                do_update(browser_factory, timeout)\n",
      "                tracker.update(time())\n",
      "        except KeyboardInterrupt:\n",
      "            raise\n",
      "        except Exception as exc:\n",
      "            logger.exception(\"Event %s handling failed: %s\", ev.what.name, str(exc))\n",
      "\n",
      "def sig_handler(signum, frame):\n",
      "    raise KeyboardInterrupt\n",
      "\n",
      "def main():\n",
      "    args = parse_args()\n",
      "    mainlogger = setup_logger(\"MAIN\", args.verbosity)\n",
      "    setup_logger(\"UPDATE\", args.verbosity)\n",
      "    setup_logger(\"LOGIN\", args.verbosity)\n",
      "    setup_logger(\"EVLOOP\", args.verbosity)\n",
      "\n",
      "    os.makedirs(args.data_dir, mode=0o700, exist_ok=True)\n",
      "    profile_dir = os.path.join(args.data_dir, 'profile')\n",
      "    browser_factory = BrowserFactory(profile_dir,\n",
      "                                     args.browser.value,\n",
      "                                     args.cmd is Command.update)\n",
      "    db_path = os.path.join(args.data_dir, 'updater.db')\n",
      "    tracker = UpdateTracker(db_path)\n",
      "    signal.signal(signal.SIGTERM, sig_handler)\n",
      "\n",
      "    try:\n",
      "        if args.cmd is Command.login:\n",
      "            mainlogger.info(\"Login mode. Please enter your credentials in opened \"\n",
      "                            \"browser window.\")\n",
      "            try:\n",
      "                do_login(browser_factory, MANUAL_LOGIN_TIMEOUT)\n",
      "                tracker.login(time())\n",
      "            except KeyboardInterrupt:\n",
      "                mainlogger.warning(\"Interrupted!\")\n",
      "        elif args.cmd is Command.update:\n",
      "            mainlogger.info(\"Update mode. Running headless browser.\")\n",
      "            try:\n",
      "                update_loop(browser_factory, tracker, args.timeout)\n",
      "            except KeyboardInterrupt:\n",
      "                pass\n",
      "            finally:\n",
      "                mainlogger.info(\"Shutting down...\")\n",
      "    finally:\n",
      "        tracker.close()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n",
      "Output: {'__main__': ['collections.namedtuple', '__main__.main', 'selenium.webdriver.support.expected_conditions.presence_of_element_located'], '__main__.wall_clock_wait': ['time.time', 'time.sleep'], 'time.time': [], 'time.sleep': [], '__main__.setup_logger': ['logging.Formatter', 'logging.StreamHandler', 'logging.getLogger'], 'logging.getLogger': [], 'logging.StreamHandler': [], 'logging.Formatter': [], '__main__.LogLevel.__str__': [], '__main__.Command.__str__': [], '__main__.BrowserType.__str__': [], 'collections.namedtuple': [], 'selenium.webdriver.support.expected_conditions.presence_of_element_located': [], '__main__.update': ['selenium.webdriver.support.ui.WebDriverWait', 'logging.getLogger', '<builtin>.len', 'time.sleep', 'random.random'], 'selenium.webdriver.support.ui.WebDriverWait': [], '<builtin>.len': [], 'random.random': [], '__main__.login': ['selenium.webdriver.support.ui.WebDriverWait', 'selenium.webdriver.support.expected_conditions.url_matches', 'logging.getLogger'], 'selenium.webdriver.support.expected_conditions.url_matches': [], '__main__.parse_args': ['os.path.expanduser', 'argparse.ArgumentParser', 'os.path.join'], '__main__.parse_args.check_loglevel': ['<builtin>.repr', 'argparse.ArgumentTypeError'], '<builtin>.repr': [], 'argparse.ArgumentTypeError': [], '__main__.parse_args.check_command': ['<builtin>.repr', 'argparse.ArgumentTypeError'], '__main__.parse_args.check_browser_type': ['<builtin>.repr', 'argparse.ArgumentTypeError'], '__main__.parse_args.check_positive_float': ['__main__.parse_args.check_positive_float.fail', '<builtin>.float'], '__main__.parse_args.check_positive_float.fail': ['<builtin>.repr', 'argparse.ArgumentTypeError'], '<builtin>.float': [], 'argparse.ArgumentParser': [], 'os.path.expanduser': [], 'os.path.join': [], '__main__.BrowserFactory.__init__': ['webdriver_manager.chrome.ChromeDriverManager', 'selenium.webdriver.chrome.options.Options'], 'selenium.webdriver.chrome.options.Options': [], 'webdriver_manager.chrome.ChromeDriverManager': [], '__main__.BrowserFactory.new': ['selenium.webdriver.Chrome'], 'selenium.webdriver.Chrome': [], '__main__.UpdateTracker.__init__': ['sqlite3.connect'], 'sqlite3.connect': [], '__main__.UpdateTracker.last_update': [], '__main__.UpdateTracker.last_login': [], '__main__.UpdateTracker.update': ['<builtin>.float'], '__main__.UpdateTracker.login': ['<builtin>.float'], '__main__.UpdateTracker.close': [], '__main__.random_interval': ['random.random'], '__main__.Scheduler.__init__': ['__main__.Scheduler._iter_events'], '__main__.Scheduler._iter_events': ['__main__.Scheduler._event_stream'], '__main__.Scheduler.__iter__': [], '__main__.Scheduler.__next__': ['<builtin>.next'], '<builtin>.next': [], '__main__.Scheduler._event_stream': ['time.time', '__main__.random_interval', '<builtin>.max'], '<builtin>.max': [], '__main__.do_login': ['__main__.login', '__main__.BrowserFactory.new'], '__main__.do_update': ['__main__.BrowserFactory.new', '__main__.update'], '__main__.update_loop': ['__main__.Scheduler.__init__', '__main__.do_update', '__main__.UpdateTracker.login', 'logging.getLogger', '__main__.Scheduler.__next__', 'time.time', '__main__.UpdateTracker.update', '__main__.do_login', '__main__.UpdateTracker.last_update', '<builtin>.str', '__main__.UpdateTracker.last_login', 'time.ctime', '__main__.Scheduler.__iter__', '__main__.wall_clock_wait'], 'time.ctime': [], '<builtin>.str': [], '__main__.sig_handler': [], '__main__.main': ['os.makedirs', '__main__.update_loop', '__main__.UpdateTracker.login', '__main__.UpdateTracker.close', 'os.path.join', 'time.time', '__main__.UpdateTracker.__init__', '__main__.do_login', '__main__.setup_logger', '__main__.BrowserFactory.__init__', '__main__.parse_args', 'signal.signal'], 'os.makedirs': [], 'signal.signal': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Snawoot_rabotaua-cv-updater\\rabotaua_cv_updater\\__main__.py\n",
      "[('__main__', 'collections namedtuple'), ('__main__', '__main__ main'), ('__main__', 'selenium webdriver support expected_conditions presence_of_element_located'), ('__main__ wall_clock_wait', 'time time'), ('__main__ wall_clock_wait', 'time sleep'), ('__main__ setup_logger', 'logging Formatter'), ('__main__ setup_logger', 'logging StreamHandler'), ('__main__ setup_logger', 'logging getLogger'), ('__main__ update', 'selenium webdriver support ui WebDriverWait'), ('__main__ update', 'logging getLogger'), ('__main__ update', 'time sleep'), ('__main__ update', 'random random'), ('__main__ login', 'selenium webdriver support ui WebDriverWait'), ('__main__ login', 'selenium webdriver support expected_conditions url_matches'), ('__main__ login', 'logging getLogger'), ('__main__ parse_args', 'os path expanduser'), ('__main__ parse_args', 'argparse ArgumentParser'), ('__main__ parse_args', 'os path join'), ('__main__ parse_args check_loglevel', 'argparse ArgumentTypeError'), ('__main__ parse_args check_command', 'argparse ArgumentTypeError'), ('__main__ parse_args check_browser_type', 'argparse ArgumentTypeError'), ('__main__ parse_args check_positive_float', '__main__ parse_args check_positive_float fail'), ('__main__ parse_args check_positive_float fail', 'argparse ArgumentTypeError'), ('__main__ BrowserFactory __init__', 'webdriver_manager chrome ChromeDriverManager'), ('__main__ BrowserFactory __init__', 'selenium webdriver chrome options Options'), ('__main__ BrowserFactory new', 'selenium webdriver Chrome'), ('__main__ UpdateTracker __init__', 'sqlite3 connect'), ('__main__ random_interval', 'random random'), ('__main__ Scheduler __init__', '__main__ Scheduler _iter_events'), ('__main__ Scheduler _iter_events', '__main__ Scheduler _event_stream')]\n",
      "98\n",
      "found files: []\n",
      "from os import path\n",
      "\n",
      "from setuptools import setup\n",
      "\n",
      "this_directory = path.abspath(path.dirname(__file__))\n",
      "with open(path.join(this_directory, 'README.md'), encoding='utf-8') as f:\n",
      "    long_description = f.read()\n",
      "\n",
      "setup(name='rabotaua_cv_updater',\n",
      "      version='0.1.0',\n",
      "      description='Tool which updates your CV on rabota.ua',\n",
      "      url='https://github.com/danilasokolov0103/CV_updater',\n",
      "      author='Danila Sokolov',\n",
      "      author_email='danilasokolov0103@gmail.com',\n",
      "      packages=['rabotaua_cv_updater'],\n",
      "      python_requires='>=3.5.3',\n",
      "      setup_requires=[\n",
      "          'wheel',\n",
      "      ],\n",
      "      install_requires=[\n",
      "          'selenium>=3.141.0',\n",
      "          'webdriver-manager>=2.5.1',\n",
      "      ],\n",
      "      entry_points={\n",
      "          'console_scripts': [\n",
      "              'rabotaua-cv-updater=rabotaua_cv_updater.__main__:main',\n",
      "          ],\n",
      "      },\n",
      "      classifiers=[\n",
      "          \"Programming Language :: Python :: 3\",\n",
      "          \"License :: Public Domain\",\n",
      "          \"Operating System :: OS Independent\",\n",
      "          \"Development Status :: 4 - Beta\",\n",
      "          \"Environment :: Console\",\n",
      "          \"Intended Audience :: End Users/Desktop\",\n",
      "          \"Natural Language :: English\",\n",
      "          \"Topic :: Office/Business\",\n",
      "          \"Topic :: Other/Nonlisted Topic\",\n",
      "      ],\n",
      "      long_description=long_description,\n",
      "      long_description_content_type='text/markdown',\n",
      "      zip_safe=True)\n",
      "\n",
      "Output: {'setup': ['<builtin>.open', 'os.path.dirname', 'os.path.abspath', 'setuptools.setup', 'os.path.join'], 'os.path.dirname': [], 'os.path.abspath': [], 'os.path.join': [], '<builtin>.open': [], 'setuptools.setup': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Snawoot_rabotaua-cv-updater\\setup.py\n",
      "[('setup', 'os path dirname'), ('setup', 'os path abspath'), ('setup', 'setuptools setup'), ('setup', 'os path join')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('__main__', 'collections namedtuple'), ('__main__', '__main__ main'), ('__main__', 'selenium webdriver support expected_conditions presence_of_element_located'), ('__main__ wall_clock_wait', 'time time'), ('__main__ wall_clock_wait', 'time sleep'), ('__main__ setup_logger', 'logging Formatter'), ('__main__ setup_logger', 'logging StreamHandler'), ('__main__ setup_logger', 'logging getLogger'), ('__main__ update', 'selenium webdriver support ui WebDriverWait'), ('__main__ update', 'logging getLogger'), ('__main__ update', 'time sleep'), ('__main__ update', 'random random'), ('__main__ login', 'selenium webdriver support ui WebDriverWait'), ('__main__ login', 'selenium webdriver support expected_conditions url_matches'), ('__main__ login', 'logging getLogger'), ('__main__ parse_args', 'os path expanduser'), ('__main__ parse_args', 'argparse ArgumentParser'), ('__main__ parse_args', 'os path join'), ('__main__ parse_args check_loglevel', 'argparse ArgumentTypeError'), ('__main__ parse_args check_command', 'argparse ArgumentTypeError'), ('__main__ parse_args check_browser_type', 'argparse ArgumentTypeError'), ('__main__ parse_args check_positive_float', '__main__ parse_args check_positive_float fail'), ('__main__ parse_args check_positive_float fail', 'argparse ArgumentTypeError'), ('__main__ BrowserFactory __init__', 'webdriver_manager chrome ChromeDriverManager'), ('__main__ BrowserFactory __init__', 'selenium webdriver chrome options Options'), ('__main__ BrowserFactory new', 'selenium webdriver Chrome'), ('__main__ UpdateTracker __init__', 'sqlite3 connect'), ('__main__ random_interval', 'random random'), ('__main__ Scheduler __init__', '__main__ Scheduler _iter_events'), ('__main__ Scheduler _iter_events', '__main__ Scheduler _event_stream')], [('setup', 'os path dirname'), ('setup', 'os path abspath'), ('setup', 'setuptools setup'), ('setup', 'os path join')]]\n",
      "********************doctrings*************************\n",
      "[\"wall clock wait setup logger update login parse args random interval do login do update update loop sig handler main [SEP] Sleep variation which is doesn't increases sleep duration when computer enters suspend/hybernation\", '']\n",
      "embed index dataset: 15\n",
      "all relevant repo files: []\n",
      "********************pycgContent*************************\n",
      "[]\n",
      "********************doctrings*************************\n",
      "[]\n",
      "embed index dataset: 16\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Adamantios_Atari-Skiing-RL\\\\utils\\\\parser.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Adamantios_Atari-Skiing-RL\\\\core\\\\preprocessing.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Adamantios_Atari-Skiing-RL\\\\core\\\\model.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Adamantios_Atari-Skiing-RL\\\\game_engine\\\\scoring.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Adamantios_Atari-Skiing-RL\\\\utils\\\\system_operations.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Adamantios_Atari-Skiing-RL\\\\core\\\\policy.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Adamantios_Atari-Skiing-RL\\\\skiing.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Adamantios_Atari-Skiing-RL\\\\game_engine\\\\plotting.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Adamantios_Atari-Skiing-RL\\\\core\\\\agent.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\Adamantios_Atari-Skiing-RL\\\\game_engine\\\\game.py']\n",
      "from argparse import ArgumentParser, ArgumentTypeError\n",
      "\n",
      "FILENAME_PREFIX = 'out/models/atari_skiing'\n",
      "PLOT_NAME_PREFIX = 'out/plots/atari_skiing'\n",
      "RESULTS_NAME_PREFIX = 'out/results/atari_skiing'\n",
      "RECORDING_NAME_PREFIX = 'out/recording'\n",
      "SAVE_INTERVAL = 100\n",
      "RESULTS_SAVE_INTERVAL = 100\n",
      "INFO_INTERVAL_CURRENT = 20\n",
      "INFO_INTERVAL_MEAN = 100\n",
      "TARGET_MODEL_CHANGE = int(1E4)\n",
      "AGENT_PATH = ''\n",
      "AGENT_HISTORY = 4\n",
      "PLOT_TRAIN_RESULTS = True\n",
      "SAVE_PLOTS = True\n",
      "RENDER = True\n",
      "RECORD = False\n",
      "DOWNSAMPLE_SCALE = 2\n",
      "STEPS_PER_ACTION = 4\n",
      "FIT_FREQUENCY = 4\n",
      "NO_OPERATION = 30\n",
      "EPISODES = int(1E4)\n",
      "EPSILON = 1.\n",
      "FINAL_EPSILON = .1\n",
      "EPSILON_DECAY = float(1E-4)\n",
      "TOTAL_OBSERVE_COUNT = int(1E4)\n",
      "REPLAY_MEMORY_SIZE = int(4E5)\n",
      "BATCH_SIZE = 32\n",
      "GAMMA = .99\n",
      "OPTIMIZER_NAME = 'RMSProp'\n",
      "OPTIMIZER_CHOICES = 'adam', 'rmsprop', 'sgd', 'adagrad', 'adadelta', 'adamax'\n",
      "LEARNING_RATE = float(25E-5)\n",
      "LR_DECAY = float(1E-6)\n",
      "BETA1 = .9\n",
      "BETA2 = .999\n",
      "RHO = .95\n",
      "FUZZ = .01\n",
      "MOMENTUM = .1\n",
      "\n",
      "\n",
      "def positive_int(value: any) -> int:\n",
      "    \"\"\"\n",
      "    Checks if a value is a positive integer.\n",
      "\n",
      "    :param value: the value to be checked.\n",
      "    :return: the value if valid integer, otherwise raises an ArgumentTypeError.\n",
      "    \"\"\"\n",
      "    int_value = int(value)\n",
      "\n",
      "    if int_value <= 0:\n",
      "        raise ArgumentTypeError(\"%s should be a positive integer value.\" % value)\n",
      "\n",
      "    return int_value\n",
      "\n",
      "\n",
      "def positive_float(value: any) -> float:\n",
      "    \"\"\"\n",
      "    Checks if a value is a positive float.\n",
      "\n",
      "    :param value: the value to be checked.\n",
      "    :return: the value if valid float, otherwise raises an ArgumentTypeError.\n",
      "    \"\"\"\n",
      "    float_value = float(value)\n",
      "\n",
      "    if float_value <= 0:\n",
      "        raise ArgumentTypeError(\"%s should be a positive float value.\" % value)\n",
      "\n",
      "    return float_value\n",
      "\n",
      "\n",
      "def create_parser() -> ArgumentParser:\n",
      "    \"\"\"\n",
      "    Creates an argument parser for the atari skiing script.\n",
      "\n",
      "    :return: ArgumentParser object.\n",
      "    \"\"\"\n",
      "    # TODO add ability to use all or some of the saved parameters of the loaded agent, if loaded.\n",
      "    parser = ArgumentParser(description='Trains a DQN agent to play the Atari Skiing game.')\n",
      "\n",
      "    parser.add_argument('-fp', '--filename_prefix', type=str, required=False, default=FILENAME_PREFIX,\n",
      "                        help='Filename prefix for the trained model to be saved (default %(default)s).')\n",
      "    parser.add_argument('-rp', '--results_name_prefix', type=str, required=False, default=RESULTS_NAME_PREFIX,\n",
      "                        help='Filename prefix for the results history to be saved (default %(default)s).')\n",
      "    parser.add_argument('-recp', '--recording_name_prefix', type=str, required=False, default=RECORDING_NAME_PREFIX,\n",
      "                        help='Filename prefix for the recording if chosen to be saved (default %(default)s).')\n",
      "    parser.add_argument('-si', '--save_interval', type=positive_int, default=SAVE_INTERVAL, required=False,\n",
      "                        help='The save interval for the trained agent (default %(default)s), in episodes.')\n",
      "    parser.add_argument('-rsi', '--results_save_interval', type=int, default=RESULTS_SAVE_INTERVAL, required=False,\n",
      "                        help='The save interval for the results history (default %(default)s), in episodes.'\n",
      "                             'Insert a negative value to not save the results history.')\n",
      "    parser.add_argument('-iic', '--info_interval_current',\n",
      "                        type=positive_int, default=INFO_INTERVAL_CURRENT, required=False,\n",
      "                        help='The current scoring information interval (default %(default)s), in episodes.')\n",
      "    parser.add_argument('-iim', '--info_interval_mean', type=positive_int, default=INFO_INTERVAL_MEAN, required=False,\n",
      "                        help='The mean scoring information interval (default %(default)s), in episodes.')\n",
      "    parser.add_argument('-ti', '--target_interval', type=positive_int, default=TARGET_MODEL_CHANGE, required=False,\n",
      "                        help='The target model change interval (default %(default)s), in steps.')\n",
      "    parser.add_argument('-a', '--agent', type=str, required=False, default=AGENT_PATH,\n",
      "                        help='Filepath for a trained agent to be loaded (default %(default)s).')\n",
      "    parser.add_argument('-ah', '--agent_history', type=positive_int, required=False, default=AGENT_HISTORY,\n",
      "                        help='The agent\\'s frame history (default %(default)s).')\n",
      "    parser.add_argument('-np', '--no_plot', default=not PLOT_TRAIN_RESULTS, required=False, action='store_true',\n",
      "                        help='Whether the train results should not be plot.')\n",
      "    parser.add_argument('-nsp', '--no_save_plots', default=not SAVE_PLOTS, required=False, action='store_true',\n",
      "                        help='Whether the train results plots should not be saved.')\n",
      "    parser.add_argument('-p', '--plot_name', type=str, required=False, default=PLOT_NAME_PREFIX,\n",
      "                        help='Filename prefix for the plots to be saved (default %(default)s).')\n",
      "    parser.add_argument('-nr', '--no_render', default=not RENDER, required=False, action='store_true',\n",
      "                        help='Whether the environment should not be rendered.')\n",
      "    parser.add_argument('-rec', '--record', default=RECORD, required=False, action='store_true',\n",
      "                        help='Whether the game should be recorded. '\n",
      "                             'Please note that you need to have ffmpeg in your path!')\n",
      "    parser.add_argument('-d', '--downsample', type=positive_int, default=DOWNSAMPLE_SCALE, required=False,\n",
      "                        help='The downsampling scale to be used (default %(default)s).')\n",
      "    parser.add_argument('-fs', '--frame_skipping', type=positive_int, default=STEPS_PER_ACTION, required=False,\n",
      "                        help='The frames to skip per action (default %(default)s).')\n",
      "    parser.add_argument('-ff', '--fit_frequency', type=positive_int, default=FIT_FREQUENCY, required=False,\n",
      "                        help='The actions to take between an agent\\'s fit (default %(default)s).')\n",
      "    parser.add_argument('-no', '--no_operation', type=positive_int, default=NO_OPERATION, required=False,\n",
      "                        help='The maximum number of no operation steps at the beginning of the game '\n",
      "                             '(default %(default)s).')\n",
      "    parser.add_argument('-e', '--episodes', type=positive_int, default=EPISODES, required=False,\n",
      "                        help='The episodes to run the training procedure (default %(default)s).')\n",
      "    parser.add_argument('-eps', '--epsilon', type=positive_float, default=EPSILON, required=False,\n",
      "                        help='The epsilon for the e-greedy policy (default %(default)s).')\n",
      "    parser.add_argument('-feps', '--final_epsilon', type=positive_float, default=FINAL_EPSILON, required=False,\n",
      "                        help='The final epsilon for the e-greedy policy (default %(default)s).')\n",
      "    parser.add_argument('-deps', '--decay', type=positive_float, default=EPSILON_DECAY, required=False,\n",
      "                        help='The epsilon decay for the e-greedy policy (default %(default)s).')\n",
      "    parser.add_argument('-o', '--observe', type=int, default=TOTAL_OBSERVE_COUNT, required=False,\n",
      "                        help='The total number of observing steps before the training begins, '\n",
      "                             'thus taking random actions (default %(default)s).')\n",
      "    parser.add_argument('-rm', '--replay_memory', type=positive_int, default=REPLAY_MEMORY_SIZE, required=False,\n",
      "                        help='The replay memory to be used for the agent (default %(default)s).')\n",
      "    parser.add_argument('-b', '--batch', type=positive_int, default=BATCH_SIZE, required=False,\n",
      "                        help='The batch size to be randomly sampled from the memory for the training '\n",
      "                             '(default %(default)s).')\n",
      "    parser.add_argument('-g', '--gamma', type=positive_float, default=GAMMA, required=False,\n",
      "                        help='The discount factor (default %(default)s).')\n",
      "    parser.add_argument('-opt', '--optimizer', type=str.lower, default=OPTIMIZER_NAME, required=False,\n",
      "                        choices=OPTIMIZER_CHOICES,\n",
      "                        help='The optimizer to be used. (default %(default)s).')\n",
      "    parser.add_argument('-lr', '--learning_rate', type=positive_float, default=LEARNING_RATE, required=False,\n",
      "                        help='The learning rate for the optimizer (default %(default)s).')\n",
      "    parser.add_argument('-lrd', '--learning_rate_decay', type=positive_float, default=LR_DECAY, required=False,\n",
      "                        help='The learning rate decay for the optimizer (default %(default)s).')\n",
      "    parser.add_argument('-b1', '--beta1', type=positive_float, default=BETA1, required=False,\n",
      "                        help='The beta 1 for the optimizer (default %(default)s).')\n",
      "    parser.add_argument('-b2', '--beta2', type=positive_float, default=BETA2, required=False,\n",
      "                        help='The beta 2 for the optimizer (default %(default)s).')\n",
      "    parser.add_argument('-rho', type=positive_float, default=RHO, required=False,\n",
      "                        help='The rho for the optimizer (default %(default)s).')\n",
      "    parser.add_argument('-f', '--fuzz', type=positive_float, default=FUZZ, required=False,\n",
      "                        help='The fuzz factor for the rmsprop optimizer (default %(default)s).')\n",
      "    parser.add_argument('-m', '--momentum', type=positive_float, default=MOMENTUM, required=False,\n",
      "                        help='The momentum for the optimizer (default %(default)s).')\n",
      "\n",
      "    return parser\n",
      "\n",
      "Output: {'parser': ['<builtin>.int', '<builtin>.float'], '<builtin>.int': [], '<builtin>.float': [], 'parser.positive_int': ['<builtin>.int', 'argparse.ArgumentTypeError'], 'argparse.ArgumentTypeError': [], 'parser.positive_float': ['<builtin>.float', 'argparse.ArgumentTypeError'], 'parser.create_parser': ['argparse.ArgumentParser'], 'argparse.ArgumentParser': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Adamantios_Atari-Skiing-RL\\utils\\parser.py\n",
      "[('parser positive_int', 'argparse ArgumentTypeError'), ('parser positive_float', 'argparse ArgumentTypeError'), ('parser create_parser', 'argparse ArgumentParser')]\n",
      "290\n",
      "found files: []\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "def rgb2gray(rgb: np.ndarray) -> np.ndarray:\n",
      "    \"\"\"\n",
      "    Converts an rgb image array to a grey image array.\n",
      "\n",
      "    :param rgb: the rgb image array.\n",
      "    :return: the converted array.\n",
      "    \"\"\"\n",
      "    return np.dot(rgb[..., :3], [0.2989, 0.5870, 0.1140]).astype(np.uint8)\n",
      "\n",
      "\n",
      "def downsample(img: np.ndarray, scale: int = 2) -> np.ndarray:\n",
      "    \"\"\"\n",
      "    Downsamples an image array, by a scale factor.\n",
      "\n",
      "    :param img: the image to downsample.\n",
      "    :param scale: the downsampling scale factor.\n",
      "    :return: the downsampled image.\n",
      "    \"\"\"\n",
      "    if scale < 2:\n",
      "        return img\n",
      "\n",
      "    return img[::scale, ::scale]\n",
      "\n",
      "\n",
      "def atari_preprocess(frame_array: np.ndarray, downsample_scale: int = 2) -> np.ndarray:\n",
      "    \"\"\"\n",
      "    Prepossesses the given atari frame array.\n",
      "\n",
      "    :param frame_array: the atari frame array.\n",
      "    :param downsample_scale: a scale to downsample the given array with.\n",
      "    :return: the preprocessed frame array.\n",
      "    \"\"\"\n",
      "    # Converting into greyscale since colors don't matter.\n",
      "    greyscale_frame = rgb2gray(frame_array)\n",
      "\n",
      "    # Downsampling the image.\n",
      "    resized_frame = downsample(greyscale_frame, downsample_scale)\n",
      "\n",
      "    # Reshape for batches, frames and color dimension and return.\n",
      "    return resized_frame[np.newaxis, np.newaxis, :, :, np.newaxis]\n",
      "\n",
      "Output: {'preprocessing': [], 'preprocessing.rgb2gray': ['numpy.dot'], 'numpy.dot': [], 'preprocessing.downsample': [], 'preprocessing.atari_preprocess': ['preprocessing.downsample', 'preprocessing.rgb2gray']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Adamantios_Atari-Skiing-RL\\core\\preprocessing.py\n",
      "[('preprocessing rgb2gray', 'numpy dot'), ('preprocessing atari_preprocess', 'preprocessing downsample'), ('preprocessing atari_preprocess', 'preprocessing rgb2gray')]\n",
      "302\n",
      "found files: []\n",
      "from typing import Union\n",
      "\n",
      "from keras import Input, Model\n",
      "from keras.backend import cast\n",
      "from keras.layers import Lambda, Flatten, Dense, Multiply, ConvLSTM2D, BatchNormalization\n",
      "from keras.optimizers import Optimizer, adam, rmsprop, sgd, adagrad, adadelta, adamax\n",
      "\n",
      "# (last conv size + filter loss) * first conv stride, or first conv size if it is bigger.\n",
      "# ( 4 + 1 ) * 4 or 8\n",
      "MIN_FRAME_DIM_THAT_PASSES_NET = 20\n",
      "\n",
      "\n",
      "def frame_can_pass_the_net(height: int, width: int) -> bool:\n",
      "    \"\"\"\n",
      "    Returns if a frame can successfully pass through the network.\n",
      "\n",
      "    :param height: the frame's height.\n",
      "    :param width: the frame's width.\n",
      "    :return: bool.\n",
      "    \"\"\"\n",
      "    return height >= MIN_FRAME_DIM_THAT_PASSES_NET and width >= MIN_FRAME_DIM_THAT_PASSES_NET\n",
      "\n",
      "\n",
      "def atari_skiing_model(shape: tuple, action_size: int, optimizer: Optimizer) -> Model:\n",
      "    \"\"\"\n",
      "    Defines a Keras Model designed for the atari skiing game.\n",
      "\n",
      "    :param shape: the input shape.\n",
      "    :param action_size: the number of available actions.\n",
      "    :param optimizer: an optimizer to be used for model compilation.\n",
      "    :return: the Keras Model.\n",
      "    \"\"\"\n",
      "    # Create the input layers.\n",
      "    inputs = Input(shape, name='input')\n",
      "    actions_input = Input((action_size,), name='input_mask')\n",
      "    # Create a normalization layer.\n",
      "    normalized = Lambda(lambda x: x / 255.0, name='normalisation')(inputs)\n",
      "\n",
      "    # Create CNN-LSTM layers.\n",
      "    conv_lstm2d_1 = ConvLSTM2D(16, (8, 8), strides=(4, 4), activation='relu', return_sequences=True,\n",
      "                               name='conv_lstm_2D_1')(normalized)\n",
      "    batch_norm = BatchNormalization(name='batch_norm1')(conv_lstm2d_1)\n",
      "    conv_lstm2d_2 = ConvLSTM2D(32, (4, 4), strides=(2, 2), activation='relu', name='conv_lstm_2D_2')(batch_norm)\n",
      "    batch_norm2 = BatchNormalization(name='batch_norm2')(conv_lstm2d_2)\n",
      "\n",
      "    # Flatten the output and pass it to a dense layer.\n",
      "    flattened = Flatten(name='flatten')(batch_norm2)\n",
      "    dense = Dense(256, activation='relu', name='dense1')(flattened)\n",
      "\n",
      "    # Create and filter the output, multiplying it with the actions input mask, in order to get the QTable.\n",
      "    output = Dense(action_size, name='dense2')(dense)\n",
      "    filtered_output = Multiply(name='filtered_output')([output, actions_input])\n",
      "\n",
      "    # Create the model.\n",
      "    model = Model(inputs=[inputs, actions_input], outputs=filtered_output)\n",
      "    # Compile the model.\n",
      "    model.compile(optimizer, loss=huber_loss)\n",
      "\n",
      "    return model\n",
      "\n",
      "\n",
      "def initialize_optimizer(optimizer_name: str, learning_rate: float, beta1: float, beta2: float,\n",
      "                         lr_decay: float, rho: float, fuzz: float, momentum: float) \\\n",
      "        -> Union[adam, rmsprop, sgd, adagrad, adadelta, adamax]:\n",
      "    \"\"\"\n",
      "    Initializes an optimizer based on the user's choices.\n",
      "\n",
      "    :param optimizer_name: the optimizer's name.\n",
      "        Can be one of 'adam', 'rmsprop', 'sgd', 'adagrad', 'adadelta', 'adamax'.\n",
      "    :param learning_rate: the optimizer's learning_rate\n",
      "    :param beta1: the optimizer's beta1\n",
      "    :param beta2: the optimizer's beta2\n",
      "    :param lr_decay: the optimizer's lr_decay\n",
      "    :param rho: the optimizer's rho\n",
      "    :param fuzz: the optimizer's fuzz\n",
      "    :param momentum: the optimizer's momentum\n",
      "    :return: the optimizer.\n",
      "    \"\"\"\n",
      "    if optimizer_name == 'adam':\n",
      "        return adam(lr=learning_rate, beta_1=beta1, beta_2=beta2, decay=lr_decay)\n",
      "    elif optimizer_name == 'rmsprop':\n",
      "        return rmsprop(lr=learning_rate, rho=rho, epsilon=fuzz)\n",
      "    elif optimizer_name == 'sgd':\n",
      "        return sgd(lr=learning_rate, momentum=momentum, decay=lr_decay)\n",
      "    elif optimizer_name == 'adagrad':\n",
      "        return adagrad(lr=learning_rate, decay=lr_decay)\n",
      "    elif optimizer_name == 'adadelta':\n",
      "        return adadelta(lr=learning_rate, rho=rho, decay=lr_decay)\n",
      "    elif optimizer_name == 'adamax':\n",
      "        return adamax(lr=learning_rate, beta_1=beta1, beta_2=beta2, decay=lr_decay)\n",
      "    else:\n",
      "        raise ValueError('An unexpected optimizer name has been encountered.')\n",
      "\n",
      "\n",
      "def huber_loss(y_true, y_pred):\n",
      "    \"\"\"\n",
      "    Define the huber loss.\n",
      "\n",
      "    :param y_true: the true value.\n",
      "    :param y_pred: the predicted value.\n",
      "    :return: a tensor with the result.\n",
      "    \"\"\"\n",
      "    # Calculate the error.\n",
      "    error = abs(y_true - y_pred)\n",
      "\n",
      "    # Calculate MSE.\n",
      "    quadratic_term = error * error / 2\n",
      "    # Calculate MAE.\n",
      "    linear_term = error - 1 / 2\n",
      "\n",
      "    # Use mae if |error| > 1.\n",
      "    use_linear_term = (error > 1.0)\n",
      "    # Cast the boolean to float, in order to be compatible with Keras.\n",
      "    use_linear_term = cast(use_linear_term, 'float32')\n",
      "\n",
      "    # Return MAE or MSE based on the flag.\n",
      "    return use_linear_term * linear_term + (1 - use_linear_term) * quadratic_term\n",
      "\n",
      "Output: {'model': [], 'model.frame_can_pass_the_net': [], 'model.atari_skiing_model': ['keras.layers.Dense', 'keras.layers.Flatten', 'keras.layers.ConvLSTM2D', 'keras.Model', 'keras.layers.Lambda', 'keras.layers.BatchNormalization', 'keras.Input', 'keras.layers.Multiply'], 'keras.Input': [], 'model.atari_skiing_model.<lambda1>': [], 'keras.layers.Lambda': [], 'keras.layers.ConvLSTM2D': [], 'keras.layers.BatchNormalization': [], 'keras.layers.Flatten': [], 'keras.layers.Dense': [], 'keras.layers.Multiply': [], 'keras.Model': [], 'model.initialize_optimizer': ['keras.optimizers.adam', 'keras.optimizers.rmsprop', '<builtin>.ValueError', 'keras.optimizers.sgd', 'keras.optimizers.adagrad', 'keras.optimizers.adadelta', 'keras.optimizers.adamax'], 'keras.optimizers.adam': [], 'keras.optimizers.rmsprop': [], 'keras.optimizers.sgd': [], 'keras.optimizers.adagrad': [], 'keras.optimizers.adadelta': [], 'keras.optimizers.adamax': [], '<builtin>.ValueError': [], 'model.huber_loss': ['<builtin>.abs', 'keras.backend.cast'], '<builtin>.abs': [], 'keras.backend.cast': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Adamantios_Atari-Skiing-RL\\core\\model.py\n",
      "[('model atari_skiing_model', 'keras layers Dense'), ('model atari_skiing_model', 'keras layers Flatten'), ('model atari_skiing_model', 'keras layers ConvLSTM2D'), ('model atari_skiing_model', 'keras Model'), ('model atari_skiing_model', 'keras layers Lambda'), ('model atari_skiing_model', 'keras layers BatchNormalization'), ('model atari_skiing_model', 'keras Input'), ('model atari_skiing_model', 'keras layers Multiply'), ('model initialize_optimizer', 'keras optimizers adam'), ('model initialize_optimizer', 'keras optimizers rmsprop'), ('model initialize_optimizer', 'keras optimizers sgd'), ('model initialize_optimizer', 'keras optimizers adagrad'), ('model initialize_optimizer', 'keras optimizers adadelta'), ('model initialize_optimizer', 'keras optimizers adamax'), ('model huber_loss', 'keras backend cast')]\n",
      "403\n",
      "found files: []\n",
      "import pickle\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "class Scorer(object):\n",
      "    def __init__(self, episodes: int, info_interval_mean: int, results_name_prefix: str):\n",
      "        self.episodes = episodes\n",
      "        self.info_interval_mean = info_interval_mean\n",
      "        self.results_name_prefix = results_name_prefix\n",
      "\n",
      "        # Initialize arrays for the scores and history.\n",
      "        self.max_scores = np.empty(episodes, dtype=np.int32)\n",
      "        self.total_scores = np.empty(episodes, dtype=np.int32)\n",
      "        self.huber_loss_history = np.zeros(episodes, dtype=np.float16)\n",
      "\n",
      "    def save_results(self, episode: int) -> None:\n",
      "        \"\"\"\n",
      "        Saves the results in files.\n",
      "\n",
      "        :param episode: the current episode.\n",
      "        \"\"\"\n",
      "        print('Saving results.')\n",
      "\n",
      "        # Save total scores.\n",
      "        with open('{}_total_scores_episode{}.{}'.format(self.results_name_prefix, episode, 'pickle'), 'wb') as stream:\n",
      "            pickle.dump(self.total_scores[:episode], stream, protocol=pickle.HIGHEST_PROTOCOL)\n",
      "\n",
      "        # Save max scores.\n",
      "        with open('{}_max_scores_episode{}.{}'.format(self.results_name_prefix, episode, 'pickle'), 'wb') as stream:\n",
      "            pickle.dump(self.max_scores[:episode], stream, protocol=pickle.HIGHEST_PROTOCOL)\n",
      "\n",
      "        # Save losses.\n",
      "        with open('{}_losses_episode{}.{}'.format(self.results_name_prefix, episode, 'pickle'), 'wb') as stream:\n",
      "            pickle.dump(self.huber_loss_history[:episode], stream, protocol=pickle.HIGHEST_PROTOCOL)\n",
      "\n",
      "        print('Results have been saved successfully.')\n",
      "\n",
      "    def show_episode_scoring(self, episode: int) -> None:\n",
      "        \"\"\"\n",
      "        Shows an episode's scoring information.\n",
      "\n",
      "        :param episode: the episode for which the actions will be taken.\n",
      "        \"\"\"\n",
      "        # Print the episode's scores.\n",
      "        print(\"Max score for the episode {} is: {} \".format(episode, self.max_scores[episode - 1]))\n",
      "        print(\"Total score for the episode {} is: {} \".format(episode, self.total_scores[episode - 1]))\n",
      "\n",
      "    def show_mean_scoring(self, episode: int) -> None:\n",
      "        \"\"\"\n",
      "        Shows the mean scoring information for the current episode.\n",
      "\n",
      "        :param episode: the episode.\n",
      "        \"\"\"\n",
      "        # Print the episodes mean scores.\n",
      "        mean_max_score = \\\n",
      "            self.max_scores[episode - self.info_interval_mean:episode].sum() / self.info_interval_mean\n",
      "        mean_total_score = \\\n",
      "            self.total_scores[episode - self.info_interval_mean:episode].sum() / self.info_interval_mean\n",
      "\n",
      "        print(\"Mean Max score for {}-{} episodes is: {} \"\n",
      "              .format(episode - self.info_interval_mean + 1, episode, mean_max_score))\n",
      "        print(\"Mean Total score for {}-{} episodes is: {} \"\n",
      "              .format(episode - self.info_interval_mean + 1, episode, mean_total_score))\n",
      "\n",
      "Output: {'scoring': [], 'scoring.Scorer.__init__': ['numpy.empty', 'numpy.zeros'], 'numpy.empty': [], 'numpy.zeros': [], 'scoring.Scorer.save_results': ['<builtin>.print', '<builtin>.open', 'pickle.dump'], '<builtin>.print': [], '<builtin>.open': [], 'pickle.dump': [], 'scoring.Scorer.show_episode_scoring': ['<builtin>.print'], 'scoring.Scorer.show_mean_scoring': ['<builtin>.print']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Adamantios_Atari-Skiing-RL\\game_engine\\scoring.py\n",
      "[('scoring Scorer __init__', 'numpy empty'), ('scoring Scorer __init__', 'numpy zeros'), ('scoring Scorer save_results', 'pickle dump')]\n",
      "0\n",
      "found files: []\n",
      "import sys\n",
      "from os import makedirs, path\n",
      "\n",
      "\n",
      "def create_path(filepath: str) -> None:\n",
      "    \"\"\"\n",
      "    Creates a path to a file, if it does not exist.\n",
      "\n",
      "    :param filepath: the filepath.\n",
      "    \"\"\"\n",
      "    # Get the file's directory.\n",
      "    directory = path.dirname(filepath)\n",
      "\n",
      "    # Create directory if it does not exist\n",
      "    if not path.exists(directory) and not directory == '':\n",
      "        makedirs(directory)\n",
      "\n",
      "\n",
      "def print_progressbar(iteration: int, total: int, prefix: str = '', suffix: str = '', decimals: int = 0,\n",
      "                      length: int = 50, fill: str = '='):\n",
      "    \"\"\"\n",
      "    Call in a loop to create terminal progress bar.\n",
      "    @params:\n",
      "        iteration    - Required  : current iteration (Int)\n",
      "        total        - Required  : total iterations (Int)\n",
      "        prefix       - Optional  : prefix string (Str)\n",
      "        suffix       - Optional  : suffix string (Str)\n",
      "        decimals     - Optional  : positive number of decimals in percent complete (Int)\n",
      "        length       - Optional  : character length of bar (Int)\n",
      "        fill         - Optional  : bar fill character (Str)\n",
      "        clean_update - Optional  : if the update should leave a new line after the progressbar (bool)\n",
      "    \"\"\"\n",
      "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
      "    filled_length = int(length * iteration // total)\n",
      "    finish = '>' if iteration != 0 else ''\n",
      "    bar = fill * filled_length + finish + '-' * (length - filled_length)\n",
      "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end='\\r')\n",
      "\n",
      "    # Print New Line on Complete.\n",
      "    if iteration == total:\n",
      "        print()\n",
      "\n",
      "Output: {'system_operations': [], 'system_operations.create_path': ['os.path.dirname', 'os.makedirs', 'os.path.exists'], 'os.path.dirname': [], 'os.path.exists': [], 'os.makedirs': [], 'system_operations.print_progressbar': ['<builtin>.print', '<builtin>.float', '<builtin>.int', '<builtin>.str'], '<builtin>.float': [], '<builtin>.str': [], '<builtin>.int': [], '<builtin>.print': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Adamantios_Atari-Skiing-RL\\utils\\system_operations.py\n",
      "[('system_operations create_path', 'os path dirname'), ('system_operations create_path', 'os makedirs'), ('system_operations create_path', 'os path exists')]\n",
      "180\n",
      "found files: []\n",
      "from random import randrange\n",
      "\n",
      "import numpy as np\n",
      "from keras import Model\n",
      "\n",
      "\n",
      "class EGreedyPolicy(object):\n",
      "    def __init__(self, e: float, final_e: float, epsilon_decay: float, total_observe_count: int, action_size: int):\n",
      "        self.e = e\n",
      "        self.final_e = final_e\n",
      "        self.epsilon_decay = epsilon_decay\n",
      "        self.total_observe_count = total_observe_count\n",
      "        self.action_size = action_size\n",
      "        self.observing_steps_taken = 0\n",
      "        self.observing = False if self.total_observe_count == 0 else True\n",
      "        self.episode_observation_stopped = 0\n",
      "\n",
      "    def _decay_epsilon(self, episode: int) -> None:\n",
      "        \"\"\"\n",
      "        Decays the policy's epsilon.\n",
      "\n",
      "        :param episode: the current episode.\n",
      "        \"\"\"\n",
      "        if self.e > self.final_e and not self.observing:\n",
      "            self.e -= self.epsilon_decay\n",
      "\n",
      "            if self.e < self.final_e:\n",
      "                self.e = self.final_e\n",
      "\n",
      "            if self.e == self.final_e:\n",
      "                print('Final epsilon reached at episode {}'.format(episode))\n",
      "\n",
      "    def _update_observation_state(self, episode: int) -> None:\n",
      "        \"\"\"\n",
      "        Updates the observing value if needed.\n",
      "\n",
      "        :param episode: the current episode.\n",
      "        \"\"\"\n",
      "        if self.observing:\n",
      "            self.observing_steps_taken += 1\n",
      "            if self.total_observe_count == self.observing_steps_taken:\n",
      "                self.observing = False\n",
      "                self.episode_observation_stopped = episode\n",
      "                print('Agent has stopped observing at episode {}.\\nThings are about to get serious!\\nOr not...'\n",
      "                      .format(self.episode_observation_stopped))\n",
      "\n",
      "    def take_action(self, model: Model, current_state: np.ndarray, episode: int) -> int:\n",
      "        \"\"\"\n",
      "        Takes an action based on the policy.\n",
      "\n",
      "        :param model: the model to use.\n",
      "        :param current_state: the state for which the action will be taken.\n",
      "        :param episode: the current episode.\n",
      "        :return: the action number.\n",
      "        \"\"\"\n",
      "        if np.random.rand() <= self.e or self.observing:\n",
      "            # Take random action.\n",
      "            action = randrange(self.action_size)\n",
      "        else:\n",
      "            # Take the best action.\n",
      "            q_value = model.predict([current_state, np.expand_dims(np.ones(self.action_size), 0)])\n",
      "            action = np.argmax(q_value[0])\n",
      "\n",
      "        # Decay epsilon.\n",
      "        self._decay_epsilon(episode)\n",
      "\n",
      "        # Update observation state.\n",
      "        self._update_observation_state(episode)\n",
      "\n",
      "        return action\n",
      "\n",
      "Output: {'policy': [], 'policy.EGreedyPolicy.__init__': [], 'policy.EGreedyPolicy._decay_epsilon': ['<builtin>.print'], '<builtin>.print': [], 'policy.EGreedyPolicy._update_observation_state': ['<builtin>.print'], 'policy.EGreedyPolicy.take_action': ['numpy.argmax', 'policy.EGreedyPolicy._decay_epsilon', 'numpy.random.rand', 'policy.EGreedyPolicy._update_observation_state', 'random.randrange'], 'numpy.random.rand': [], 'random.randrange': [], 'numpy.argmax': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Adamantios_Atari-Skiing-RL\\core\\policy.py\n",
      "[('policy EGreedyPolicy take_action', 'numpy argmax'), ('policy EGreedyPolicy take_action', 'policy EGreedyPolicy _decay_epsilon'), ('policy EGreedyPolicy take_action', 'numpy random rand'), ('policy EGreedyPolicy take_action', 'policy EGreedyPolicy _update_observation_state'), ('policy EGreedyPolicy take_action', 'random randrange')]\n",
      "0\n",
      "found files: []\n",
      "from os import path\n",
      "from warnings import warn\n",
      "\n",
      "from core.agent import DQN, load_dqn_agent\n",
      "from core.model import atari_skiing_model, huber_loss, frame_can_pass_the_net, MIN_FRAME_DIM_THAT_PASSES_NET, \\\n",
      "    initialize_optimizer\n",
      "from core.policy import EGreedyPolicy\n",
      "from game_engine.game import Game, GameResultSpecs\n",
      "from utils.parser import create_parser\n",
      "from utils.system_operations import create_path\n",
      "\n",
      "\n",
      "def run_checks() -> None:\n",
      "    \"\"\" Checks the input arguments. \"\"\"\n",
      "    # Set default variables.\n",
      "    poor_observe = bad_target_model_change = 500\n",
      "    frame_history_ceiling = 10\n",
      "\n",
      "    # Create the path to the files, if necessary.\n",
      "    create_path(agent_name_prefix)\n",
      "    create_path(plots_name_prefix)\n",
      "    create_path(results_name_prefix)\n",
      "\n",
      "    if info_interval_mean == 1:\n",
      "        warn('Info interval mean has no point to be 1. '\n",
      "             'The program will continue, but the means will be ignored.'.format(info_interval_mean))\n",
      "\n",
      "    if target_model_change < bad_target_model_change:\n",
      "        warn('Target model change is extremely small ({}). This will possibly make the agent unstable.'\n",
      "             'Consider a value greater than {}'.format(target_model_change, bad_target_model_change))\n",
      "\n",
      "    if not path.exists(agent_path) and agent_path != '':\n",
      "        raise FileNotFoundError('File {} not found.'.format(agent_path))\n",
      "\n",
      "    if agent_frame_history > frame_history_ceiling:\n",
      "        warn('The agent\\'s frame history is too big ({}). This will possibly make the agent unstable and slower.'\n",
      "             'Consider a value smaller than {}'.format(agent_frame_history, frame_history_ceiling))\n",
      "\n",
      "    if downsample_scale == 1:\n",
      "        warn('Downsample scale set to 1. This means that the atari frames will not be scaled down.')\n",
      "\n",
      "    # Downsampling should result with at least 32 pixels on each dimension,\n",
      "    # because the first convolutional layer has a filter 8x8 with stride 4x4.\n",
      "    if not frame_can_pass_the_net(game.observation_space_shape[1], game.observation_space_shape[2]):\n",
      "        raise ValueError('Downsample is too big. It can be set from 1 to {}'\n",
      "                         .format(min(int(game.pixel_rows / MIN_FRAME_DIM_THAT_PASSES_NET),\n",
      "                                     int(game.pixel_columns / MIN_FRAME_DIM_THAT_PASSES_NET))))\n",
      "\n",
      "    if plot_train_results and episodes == 1:\n",
      "        warn('Cannot plot for 1 episode only.')\n",
      "\n",
      "    if epsilon > 1:\n",
      "        raise ValueError('Epsilon cannot be set to a greater value than 1.'\n",
      "                         'Got {}'.format(epsilon))\n",
      "\n",
      "    if final_epsilon > 1:\n",
      "        raise ValueError('Epsilon cannot be set to a greater value than 1.'\n",
      "                         'Got {}'.format(final_epsilon))\n",
      "\n",
      "    if final_epsilon > epsilon:\n",
      "        raise ValueError('Final epsilon ({}) cannot be greater than epsilon ({}).'\n",
      "                         .format(final_epsilon, epsilon))\n",
      "\n",
      "    if (epsilon_decay > epsilon - final_epsilon) and epsilon != final_epsilon:\n",
      "        warn('Epsilon decay ({}) is too big, compared with epsilon ({}) and final epsilon ({})!'\n",
      "             .format(epsilon_decay, epsilon, final_epsilon))\n",
      "\n",
      "    if total_observe_count < poor_observe and agent_path == '':\n",
      "        warn('The total number of observing steps ({}) is too small and could bring poor results.'\n",
      "             'Consider a value grater than {}'.format(total_observe_count, poor_observe))\n",
      "\n",
      "    final_memory_size = agent.memory.end + total_observe_count\n",
      "    if final_memory_size < batch_size:\n",
      "        raise ValueError('The total number of observing steps ({}) '\n",
      "                         'cannot be smaller than the agent\\'s memory size ( current = {}, final = {} )'\n",
      "                         ' after the observing steps ({}).'\n",
      "                         .format(total_observe_count, agent.memory.end, final_memory_size,\n",
      "                                 total_observe_count))\n",
      "\n",
      "\n",
      "class IncompatibleAgentConfigurationError(Exception):\n",
      "    pass\n",
      "\n",
      "\n",
      "def create_agent() -> DQN:\n",
      "    \"\"\"\n",
      "    Creates the atari skiing agent.\n",
      "\n",
      "    :return: the agent.\n",
      "    \"\"\"\n",
      "    if agent_path != '':\n",
      "        # Load the agent.\n",
      "        dqn = load_dqn_agent(agent_path, {'huber_loss': huber_loss})\n",
      "\n",
      "        # Check for agent configuration conflicts.\n",
      "        if dqn.observation_space_shape != game.observation_space_shape:\n",
      "            raise IncompatibleAgentConfigurationError('Incompatible observation space shapes have been encountered.'\n",
      "                                                      'The loaded agent has shape {}, '\n",
      "                                                      'but the new requested shape is {}.'\n",
      "                                                      .format(dqn.observation_space_shape,\n",
      "                                                              game.observation_space_shape))\n",
      "\n",
      "        if dqn.action_size != game.action_space_size:\n",
      "            raise IncompatibleAgentConfigurationError('')\n",
      "\n",
      "        # Use the new configuration parameters.\n",
      "        dqn.target_model_change = target_model_change\n",
      "        dqn.gamma = gamma\n",
      "        dqn.batch_size = batch_size\n",
      "        dqn.policy = policy\n",
      "        print('Agent {} has been loaded successfully.'.format(agent_path))\n",
      "    else:\n",
      "        # Init the model.\n",
      "        model = atari_skiing_model(game.observation_space_shape, game.action_space_size, optimizer)\n",
      "        # Create the agent.\n",
      "        dqn = DQN(model, target_model_change, gamma, batch_size, game.observation_space_shape,\n",
      "                  game.action_space_size, policy, memory_size=replay_memory_size)\n",
      "\n",
      "    return dqn\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    # Get arguments.\n",
      "    args = create_parser().parse_args()\n",
      "    agent_name_prefix = args.filename_prefix\n",
      "    results_name_prefix = args.results_name_prefix\n",
      "    recording_name_prefix = args.recording_name_prefix\n",
      "    results_save_interval = args.results_save_interval\n",
      "    agent_save_interval = args.save_interval\n",
      "    info_interval_current = args.info_interval_current\n",
      "    info_interval_mean = args.info_interval_mean\n",
      "    target_model_change = args.target_interval\n",
      "    agent_path = args.agent\n",
      "    agent_frame_history = args.agent_history\n",
      "    plot_train_results = not args.no_plot\n",
      "    save_plots = not args.no_save_plots\n",
      "    plots_name_prefix = args.plot_name\n",
      "    render = not args.no_render\n",
      "    record = args.record\n",
      "    downsample_scale = args.downsample\n",
      "    steps_per_action = args.frame_skipping\n",
      "    fit_frequency = args.fit_frequency\n",
      "    no_operation = args.no_operation\n",
      "    episodes = args.episodes\n",
      "    epsilon = args.epsilon\n",
      "    final_epsilon = args.final_epsilon\n",
      "    epsilon_decay = args.decay\n",
      "    total_observe_count = args.observe\n",
      "    replay_memory_size = args.replay_memory\n",
      "    batch_size = args.batch\n",
      "    gamma = args.gamma\n",
      "    optimizer_name = args.optimizer\n",
      "    learning_rate = args.learning_rate\n",
      "    lr_decay = args.learning_rate_decay\n",
      "    beta1 = args.beta1\n",
      "    beta2 = args.beta2\n",
      "    rho = args.rho\n",
      "    fuzz = args.fuzz\n",
      "    momentum = args.momentum\n",
      "\n",
      "    # Create the game specs.\n",
      "    game_specs = GameResultSpecs(info_interval_current, info_interval_mean, agent_save_interval, results_save_interval,\n",
      "                                 plots_name_prefix, results_name_prefix, agent_name_prefix, recording_name_prefix,\n",
      "                                 plot_train_results, save_plots)\n",
      "\n",
      "    # Create the game.\n",
      "    game = Game(episodes, downsample_scale, agent_frame_history, steps_per_action, fit_frequency,\n",
      "                no_operation, game_specs, render, record)\n",
      "\n",
      "    # Create the optimizer.\n",
      "    optimizer = initialize_optimizer(optimizer_name, learning_rate, beta1, beta2, lr_decay, rho, fuzz, momentum)\n",
      "\n",
      "    # Create the policy.\n",
      "    policy = EGreedyPolicy(epsilon, final_epsilon, epsilon_decay, total_observe_count, game.action_space_size)\n",
      "\n",
      "    # Create the agent.\n",
      "    agent = create_agent()\n",
      "\n",
      "    # Check arguments.\n",
      "    run_checks()\n",
      "\n",
      "    # Play the game, using the agent.\n",
      "    game.play_game(agent)\n",
      "\n",
      "Output: {'skiing': ['game_engine.game.Game', 'skiing.create_agent', 'core.policy.EGreedyPolicy', 'game_engine.game.GameResultSpecs', 'skiing.run_checks', 'utils.parser.create_parser', 'core.model.initialize_optimizer'], 'skiing.run_checks': ['<builtin>.FileNotFoundError', '<builtin>.ValueError', '<builtin>.int', 'os.path.exists', 'warnings.warn', '<builtin>.min', 'core.model.frame_can_pass_the_net', 'utils.system_operations.create_path'], 'utils.system_operations.create_path': ['os.path.dirname', 'os.makedirs', 'os.path.exists'], 'warnings.warn': [], 'os.path.exists': [], '<builtin>.FileNotFoundError': [], 'core.model.frame_can_pass_the_net': [], '<builtin>.int': [], '<builtin>.min': [], '<builtin>.ValueError': [], 'skiing.create_agent': ['core.model.atari_skiing_model', '<builtin>.print', 'core.agent.load_dqn_agent', 'core.agent.DQN'], 'core.agent.load_dqn_agent': ['os.remove', 'pickle.load', 'zipfile.ZipFile', 'keras.engine.saving.load_model', '<builtin>.open', 'os.path.join', 'core.agent.DQN', 'os.path.dirname'], '<builtin>.print': [], 'core.model.atari_skiing_model': ['keras.Input', 'keras.layers.Flatten', 'keras.layers.Multiply', 'keras.layers.Lambda', 'keras.layers.Dense', 'keras.layers.BatchNormalization', 'keras.Model', 'keras.layers.ConvLSTM2D'], 'core.agent.DQN': [], 'utils.parser.create_parser': ['argparse.ArgumentParser'], 'game_engine.game.GameResultSpecs': [], 'game_engine.game.Game': [], 'core.model.initialize_optimizer': ['keras.optimizers.adadelta', '<builtin>.ValueError', 'keras.optimizers.rmsprop', 'keras.optimizers.sgd', 'keras.optimizers.adam', 'keras.optimizers.adamax', 'keras.optimizers.adagrad'], 'core.policy.EGreedyPolicy': [], 'core.policy': [], 'core.policy.EGreedyPolicy.__init__': [], 'core.policy.EGreedyPolicy._decay_epsilon': ['<builtin>.print'], 'core.policy.EGreedyPolicy._update_observation_state': ['<builtin>.print'], 'core.policy.EGreedyPolicy.take_action': ['numpy.argmax', 'random.randrange', 'numpy.random.rand'], 'numpy.random.rand': [], 'random.randrange': [], 'numpy.argmax': [], 'game_engine.game': [], 'game_engine.game.Game.__init__': ['math.ceil', 'game_engine.plotting.Plotter', 'game_engine.scoring.Scorer'], 'math.ceil': [], 'game_engine.scoring.Scorer': [], 'game_engine.plotting.Plotter': [], 'game_engine.game.Game._create_skiing_environment': ['gym.wrappers.Monitor', 'gym.make'], 'gym.make': [], 'gym.wrappers.Monitor': [], 'game_engine.game.Game._begin_episode': [], 'game_engine.game.Game._observe': ['random.randint', '<builtin>.range'], 'random.randint': [], '<builtin>.range': [], 'game_engine.game.Game._pretrain_phase': ['core.preprocessing.atari_preprocess', 'numpy.concatenate', '<builtin>.range', '<builtin>.tuple'], 'core.preprocessing.atari_preprocess': ['core.preprocessing.downsample', 'core.preprocessing.rgb2gray'], '<builtin>.tuple': [], 'numpy.concatenate': [], 'game_engine.game.Game._take_frame_skipping_action': ['core.preprocessing.atari_preprocess', '<builtin>.range', 'numpy.append'], 'numpy.append': [], 'game_engine.game.Game._train_and_play': ['<builtin>.range'], 'game_engine.game.Game._game_loop': ['<builtin>.max', '<builtin>.range'], '<builtin>.max': [], 'game_engine.game.Game._update_progressbar': ['<builtin>.print', 'utils.system_operations.print_progressbar'], 'utils.system_operations.print_progressbar': ['<builtin>.print', '<builtin>.float', '<builtin>.str', '<builtin>.int'], 'game_engine.game.Game._end_of_episode_actions': ['<builtin>.print'], 'game_engine.game.Game.play_game': [], 'utils': [], 'game_engine.plotting': [], 'game_engine.plotting.Plotter.__init__': [], 'game_engine.plotting.Plotter._plot_and_save': ['matplotlib.pyplot.show'], 'matplotlib.pyplot.show': [], 'game_engine.plotting.Plotter._plot_score_vs_episodes': ['matplotlib.pyplot.MaxNLocator', 'numpy.roll', 'numpy.argmin', 'numpy.mean', 'numpy.asarray', 'numpy.argmax', '<builtin>.range', 'numpy.append', 'matplotlib.pyplot.subplots'], 'matplotlib.pyplot.subplots': [], 'numpy.asarray': [], 'numpy.roll': [], 'numpy.mean': [], 'numpy.argmin': [], 'matplotlib.pyplot.MaxNLocator': [], 'game_engine.plotting.Plotter.plot_max_score_vs_episodes': [], 'game_engine.plotting.Plotter.plot_total_score_vs_episodes': [], 'game_engine.plotting.Plotter.plot_huber_loss_vs_episodes': [], 'game_engine.plotting.Plotter._annotate_state_of_the_art': ['numpy.asarray', '<builtin>.range'], 'utils.system_operations': [], 'os.path.dirname': [], 'os.makedirs': [], '<builtin>.float': [], '<builtin>.str': [], 'core.preprocessing': [], 'core.preprocessing.rgb2gray': ['numpy.dot'], 'numpy.dot': [], 'core.preprocessing.downsample': [], 'game_engine.scoring': [], 'game_engine.scoring.Scorer.__init__': ['numpy.empty', 'numpy.zeros'], 'numpy.empty': [], 'numpy.zeros': [], 'game_engine.scoring.Scorer.save_results': ['pickle.dump', '<builtin>.print', '<builtin>.open'], '<builtin>.open': [], 'pickle.dump': [], 'game_engine.scoring.Scorer.show_episode_scoring': ['<builtin>.print'], 'game_engine.scoring.Scorer.show_mean_scoring': ['<builtin>.print'], 'core.agent': [], 'core.agent.ExperienceReplayMemory.__init__': ['<builtin>.ValueError'], 'core.agent.ExperienceReplayMemory.append': ['<builtin>.len'], '<builtin>.len': [], 'core.agent.ExperienceReplayMemory.randomly_sample': ['<builtin>.len', '<builtin>.range', 'random.sample'], 'random.sample': [], 'core.agent.ExperienceReplayMemory.__getitem__': ['<builtin>.len'], 'core.agent.ExperienceReplayMemory.__len__': ['<builtin>.len'], 'core.agent.ExperienceReplayMemory.__iter__': ['<builtin>.len', '<builtin>.range'], 'core.agent.DQN.__init__': ['core.agent.ExperienceReplayMemory.__init__'], 'core.agent.DQN._create_target_model': ['keras.models.clone_model'], 'keras.models.clone_model': [], 'core.agent.DQN._get_mini_batch': ['<builtin>.enumerate', 'numpy.empty'], '<builtin>.enumerate': [], 'core.agent.DQN.take_action': [], 'core.agent.DQN.append_to_memory': [], 'core.agent.DQN.update_target_model': [], 'core.agent.DQN.fit': ['numpy.expand_dims', '<builtin>.print', 'numpy.empty', '<builtin>.range', 'keras.utils.to_categorical', 'numpy.ones', 'numpy.amax'], 'numpy.ones': [], 'numpy.amax': [], 'keras.utils.to_categorical': [], 'numpy.expand_dims': [], 'core.agent.DQN.save_agent': ['zipfile.ZipFile', '<builtin>.open', '<builtin>.dict', 'os.remove', 'pickle.dump', 'os.path.basename'], '<builtin>.dict': [], 'zipfile.ZipFile': [], 'os.path.basename': [], 'os.remove': [], 'os.path.join': [], 'keras.engine.saving.load_model': [], 'pickle.load': [], 'game_engine': [], 'utils.parser': ['<builtin>.float', '<builtin>.int'], 'utils.parser.positive_int': ['<builtin>.int', 'argparse.ArgumentTypeError'], 'argparse.ArgumentTypeError': [], 'utils.parser.positive_float': ['<builtin>.float', 'argparse.ArgumentTypeError'], 'argparse.ArgumentParser': [], 'core.model': [], 'keras.Input': [], 'core.model.atari_skiing_model.<lambda1>': [], 'keras.layers.Lambda': [], 'keras.layers.ConvLSTM2D': [], 'keras.layers.BatchNormalization': [], 'keras.layers.Flatten': [], 'keras.layers.Dense': [], 'keras.layers.Multiply': [], 'keras.Model': [], 'keras.optimizers.adam': [], 'keras.optimizers.rmsprop': [], 'keras.optimizers.sgd': [], 'keras.optimizers.adagrad': [], 'keras.optimizers.adadelta': [], 'keras.optimizers.adamax': [], 'core.model.huber_loss': ['keras.backend.cast', '<builtin>.abs'], '<builtin>.abs': [], 'keras.backend.cast': [], 'core': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Adamantios_Atari-Skiing-RL\\skiing.py\n",
      "[('skiing', 'game_engine game Game'), ('skiing', 'skiing create_agent'), ('skiing', 'core policy EGreedyPolicy'), ('skiing', 'game_engine game GameResultSpecs'), ('skiing', 'skiing run_checks'), ('skiing', 'utils parser create_parser'), ('skiing', 'core model initialize_optimizer'), ('skiing run_checks', 'os path exists'), ('skiing run_checks', 'warnings warn'), ('skiing run_checks', 'core model frame_can_pass_the_net'), ('skiing run_checks', 'utils system_operations create_path'), ('utils system_operations create_path', 'os path dirname'), ('utils system_operations create_path', 'os makedirs'), ('utils system_operations create_path', 'os path exists'), ('skiing create_agent', 'core model atari_skiing_model'), ('skiing create_agent', 'core agent load_dqn_agent'), ('skiing create_agent', 'core agent DQN'), ('core agent load_dqn_agent', 'os remove'), ('core agent load_dqn_agent', 'pickle load'), ('core agent load_dqn_agent', 'zipfile ZipFile'), ('core agent load_dqn_agent', 'keras engine saving load_model'), ('core agent load_dqn_agent', 'os path join'), ('core agent load_dqn_agent', 'core agent DQN'), ('core agent load_dqn_agent', 'os path dirname'), ('core model atari_skiing_model', 'keras Input'), ('core model atari_skiing_model', 'keras layers Flatten'), ('core model atari_skiing_model', 'keras layers Multiply'), ('core model atari_skiing_model', 'keras layers Lambda'), ('core model atari_skiing_model', 'keras layers Dense'), ('core model atari_skiing_model', 'keras layers BatchNormalization')]\n",
      "81\n",
      "found files: []\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "from matplotlib.axes import Axes\n",
      "from matplotlib.figure import Figure\n",
      "\n",
      "\n",
      "class Plotter(object):\n",
      "    def __init__(self, episodes: int, plots_name_prefix: str, plot_train_results: bool, save_plot: bool):\n",
      "        self.episodes = episodes\n",
      "        self.plots_name_prefix = plots_name_prefix\n",
      "        self.plot_train_results = plot_train_results\n",
      "        self.save_plot = save_plot\n",
      "\n",
      "    def _plot_and_save(self, fig: Figure, filename: str) -> None:\n",
      "        \"\"\"\n",
      "        Plots and saves the results, after checking if it should.\n",
      "\n",
      "        :param fig: the figure.\n",
      "        :param filename: the filename.\n",
      "        \"\"\"\n",
      "        if self.plot_train_results:\n",
      "            plt.show()\n",
      "\n",
      "        if self.save_plot:\n",
      "            fig.savefig(filename)\n",
      "\n",
      "    def _plot_score_vs_episodes(self, score: np.ndarray, observing_episodes: int, title: str, y_label: str,\n",
      "                                more_is_better=True) -> [Figure, Axes]:\n",
      "        \"\"\"\n",
      "        Plots a score array vs episodes.\n",
      "\n",
      "        :param score: the array with the scores.\n",
      "        :param title: the plot's title.\n",
      "        :param y_label: the y label text.\n",
      "        :param observing_episodes: the number of episodes to fill the area between them\n",
      "         and not consider them for the min and max values.\n",
      "         These should be the episodes that the agent was taking random actions.\n",
      "        \"\"\"\n",
      "        if self.plot_train_results or self.save_plot:\n",
      "            # Create subplot.\n",
      "            fig, ax = plt.subplots(figsize=(12, 10))\n",
      "\n",
      "            # Set x and y.\n",
      "            x = np.asarray(range(self.episodes + 1))\n",
      "            y = np.append(np.roll(score, 1), score[self.episodes - 1])\n",
      "\n",
      "            # Plot mean.\n",
      "            mean = np.mean(score)\n",
      "            ax.plot(np.asarray([mean for _ in x]), label='Mean={:.4f}'.format(mean))\n",
      "\n",
      "            # Plot data.\n",
      "            ax.set_xlim(1, self.episodes)\n",
      "            ax.plot(y, label='Score')\n",
      "\n",
      "            # Fill episodes.\n",
      "            ax.fill_between(x, y.min(), y.max(), where=x <= observing_episodes, alpha=.4, color='#574ae2',\n",
      "                            label='Random Behavior({} first episodes)'.format(observing_episodes))\n",
      "\n",
      "            # Unroll x and y.\n",
      "            x = x[1:]\n",
      "            y = y[1:]\n",
      "\n",
      "            # Calculate max and min values, without including the observing episodes.\n",
      "            if observing_episodes < self.episodes:\n",
      "                x_no_fill = x[observing_episodes:]\n",
      "                y_no_fill = y[observing_episodes:]\n",
      "                x_max, y_max = x_no_fill[np.argmax(y_no_fill)], y_no_fill.max()\n",
      "                x_min, y_min = x_no_fill[np.argmin(y_no_fill)], y_no_fill.min()\n",
      "\n",
      "                # Annotate max and min values, only if they are different.\n",
      "                if x_max != x_min:\n",
      "                    # Initialize color and marker for max and min values.\n",
      "                    max_marker = '*' if more_is_better else 'X'\n",
      "                    max_color = '#f1d302' if more_is_better else '#161925'\n",
      "                    min_marker = 'X' if more_is_better else '*'\n",
      "                    min_color = '#161925' if more_is_better else '#f1d302'\n",
      "\n",
      "                    ax.scatter(x_max, y_max, label='Episode={}, Max={}'.format(x_max, y_max),\n",
      "                               color=max_color, s=150, marker=max_marker)\n",
      "                    ax.scatter(x_min, y_min, label='Episode={}, Min={}'.format(x_min, y_min),\n",
      "                               color=min_color, s=150, marker=min_marker)\n",
      "\n",
      "            # Arrange ticks, only if the episodes are less or equal with 20.\n",
      "            if self.episodes <= 20:\n",
      "                ax.set_xticks(range(1, self.episodes + 1))\n",
      "            else:\n",
      "                ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
      "\n",
      "            # Add title, legends and labels.\n",
      "            ax.set_title(title, fontsize='x-large')\n",
      "            ax.legend()\n",
      "            ax.set_xlabel('Episode', fontsize='large')\n",
      "            ax.set_ylabel(y_label, fontsize='large')\n",
      "\n",
      "            return fig, ax\n",
      "\n",
      "    def plot_max_score_vs_episodes(self, score: np.ndarray, observing_episodes: int, title: str,\n",
      "                                   filename_suffix: str) -> None:\n",
      "        \"\"\"\n",
      "        Plots max score array vs episodes.\n",
      "\n",
      "        :param score: the array with the scores.\n",
      "        :param title: the plot's title.\n",
      "        :param filename_suffix: the saved plot's filename suffix.\n",
      "        :param observing_episodes: the number of episodes to fill the area between them\n",
      "         and not consider them for the min and max values.\n",
      "         These should be the episodes that the agent was taking random actions.\n",
      "        \"\"\"\n",
      "        fig, ax = self._plot_score_vs_episodes(score, observing_episodes, title, 'Score')\n",
      "        self._plot_and_save(fig, self.plots_name_prefix + filename_suffix)\n",
      "\n",
      "    def plot_total_score_vs_episodes(self, score: np.ndarray, observing_episodes: int, title: str,\n",
      "                                     filename_suffix: str, compare: bool = True) -> None:\n",
      "        \"\"\"\n",
      "        Plots total score array vs episodes.\n",
      "\n",
      "        :param score: the array with the scores.\n",
      "        :param title: the plot's title.\n",
      "        :param filename_suffix: the saved plot's filename suffix.\n",
      "        :param compare: whether the plot should be compared with the state of art.\n",
      "        :param observing_episodes: the number of episodes to fill the area between them\n",
      "         and not consider them for the min and max values.\n",
      "         These should be the episodes that the agent was taking random actions.\n",
      "        \"\"\"\n",
      "        fig, ax = self._plot_score_vs_episodes(score, observing_episodes, title, 'Score')\n",
      "\n",
      "        if compare:\n",
      "            self._annotate_state_of_the_art(ax)\n",
      "\n",
      "        self._plot_and_save(fig, self.plots_name_prefix + filename_suffix)\n",
      "\n",
      "    def plot_huber_loss_vs_episodes(self, loss: np.ndarray, observing_episodes: int, title: str,\n",
      "                                    filename_suffix: str) -> None:\n",
      "        \"\"\"\n",
      "        Plots max score array vs episodes.\n",
      "\n",
      "        :param loss: the array with the losses.\n",
      "        :param title: the plot's title.\n",
      "        :param filename_suffix: the saved plot's filename suffix.\n",
      "        :param observing_episodes: the number of episodes to fill the area between them\n",
      "         and not consider them for the min and max values.\n",
      "         These should be the episodes that the agent was taking random actions.\n",
      "        \"\"\"\n",
      "        fig, ax = self._plot_score_vs_episodes(loss, observing_episodes, title, 'Loss', False)\n",
      "        self._plot_and_save(fig, self.plots_name_prefix + filename_suffix)\n",
      "\n",
      "    def _annotate_state_of_the_art(self, ax: Axes) -> None:\n",
      "        \"\"\"\n",
      "        Annotates state of the art.\n",
      "\n",
      "        :param ax: the ax to annotate.\n",
      "        \"\"\"\n",
      "        # Init state of the art dictionary.\n",
      "        state_of_the_art = {\n",
      "            'Human': -4336.9,\n",
      "            'NN DDQN': -7550,\n",
      "            'DQN': -12630,\n",
      "            'Random': -17098.1\n",
      "        }\n",
      "\n",
      "        # Plot state of the art measurements.\n",
      "        for whom, score in state_of_the_art.items():\n",
      "            ax.plot(np.asarray([score for _ in range(self.episodes + 1)]), linestyle='--',\n",
      "                    label='{}={}'.format(whom, score))\n",
      "\n",
      "        # Reset legends.\n",
      "        ax.legend()\n",
      "\n",
      "Output: {'plotting': [], 'plotting.Plotter.__init__': [], 'plotting.Plotter._plot_and_save': ['matplotlib.pyplot.show'], 'matplotlib.pyplot.show': [], 'plotting.Plotter._plot_score_vs_episodes': ['numpy.asarray', 'numpy.mean', 'matplotlib.pyplot.MaxNLocator', 'numpy.argmax', 'matplotlib.pyplot.subplots', 'numpy.append', 'numpy.argmin', 'numpy.roll', '<builtin>.range'], 'matplotlib.pyplot.subplots': [], '<builtin>.range': [], 'numpy.asarray': [], 'numpy.roll': [], 'numpy.append': [], 'numpy.mean': [], 'numpy.argmax': [], 'numpy.argmin': [], 'matplotlib.pyplot.MaxNLocator': [], 'plotting.Plotter.plot_max_score_vs_episodes': ['plotting.Plotter._plot_score_vs_episodes', 'plotting.Plotter._plot_and_save'], 'plotting.Plotter.plot_total_score_vs_episodes': ['plotting.Plotter._plot_score_vs_episodes', 'plotting.Plotter._annotate_state_of_the_art', 'plotting.Plotter._plot_and_save'], 'plotting.Plotter._annotate_state_of_the_art': ['numpy.asarray', '<builtin>.range'], 'plotting.Plotter.plot_huber_loss_vs_episodes': ['plotting.Plotter._plot_score_vs_episodes', 'plotting.Plotter._plot_and_save']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Adamantios_Atari-Skiing-RL\\game_engine\\plotting.py\n",
      "[('plotting Plotter _plot_and_save', 'matplotlib pyplot show'), ('plotting Plotter _plot_score_vs_episodes', 'numpy asarray'), ('plotting Plotter _plot_score_vs_episodes', 'numpy mean'), ('plotting Plotter _plot_score_vs_episodes', 'matplotlib pyplot MaxNLocator'), ('plotting Plotter _plot_score_vs_episodes', 'numpy argmax'), ('plotting Plotter _plot_score_vs_episodes', 'matplotlib pyplot subplots'), ('plotting Plotter _plot_score_vs_episodes', 'numpy append'), ('plotting Plotter _plot_score_vs_episodes', 'numpy argmin'), ('plotting Plotter _plot_score_vs_episodes', 'numpy roll'), ('plotting Plotter plot_max_score_vs_episodes', 'plotting Plotter _plot_score_vs_episodes'), ('plotting Plotter plot_max_score_vs_episodes', 'plotting Plotter _plot_and_save'), ('plotting Plotter plot_total_score_vs_episodes', 'plotting Plotter _plot_score_vs_episodes'), ('plotting Plotter plot_total_score_vs_episodes', 'plotting Plotter _annotate_state_of_the_art'), ('plotting Plotter plot_total_score_vs_episodes', 'plotting Plotter _plot_and_save'), ('plotting Plotter _annotate_state_of_the_art', 'numpy asarray'), ('plotting Plotter plot_huber_loss_vs_episodes', 'plotting Plotter _plot_score_vs_episodes'), ('plotting Plotter plot_huber_loss_vs_episodes', 'plotting Plotter _plot_and_save')]\n",
      "0\n",
      "found files: []\n",
      "import pickle\n",
      "from os import remove\n",
      "from os.path import basename, dirname, join\n",
      "from random import sample\n",
      "from typing import Union\n",
      "from zipfile import ZipFile\n",
      "\n",
      "import numpy as np\n",
      "from keras import Model\n",
      "from keras.callbacks import History\n",
      "from keras.engine.saving import load_model\n",
      "from keras.models import clone_model\n",
      "from keras.utils import to_categorical\n",
      "\n",
      "from core.policy import EGreedyPolicy\n",
      "\n",
      "\n",
      "class ExperienceReplayMemory(object):\n",
      "    \"\"\" Implements a Ring Buffer with an extra function which randomly samples elements from it,\n",
      "    in order to be used as an Experience Replay Memory for the agent. \"\"\"\n",
      "\n",
      "    def __init__(self, size: int):\n",
      "        # Check size value.\n",
      "        if size < 1:\n",
      "            raise ValueError('Memory size must be a positive integer. Got {} instead.'.format(size))\n",
      "\n",
      "        # Initialize array.\n",
      "        # Allocate one extra element, so that self.start == self.end always means the buffer is EMPTY,\n",
      "        # whereas if exactly the right number of elements is allocated,\n",
      "        # it also means the buffer is full. This greatly simplifies the rest of the code.\n",
      "        self.data = [None] * (size + 1)\n",
      "        # Initialize start pointer.\n",
      "        self.start = 0\n",
      "        # Initialize end pointer.\n",
      "        self.end = 0\n",
      "\n",
      "    def append(self, element) -> None:\n",
      "        \"\"\"\n",
      "        Appends an element to the memory.\n",
      "\n",
      "        :param element: the element to append.\n",
      "        \"\"\"\n",
      "        # Add the element to the end of the memory.\n",
      "        self.data[self.end] = element\n",
      "        # Increment the end pointer.\n",
      "        self.end = (self.end + 1) % len(self.data)\n",
      "\n",
      "        # Remove the first element by incrementing start pointer, if the memory size has been reached.\n",
      "        if self.end == self.start:\n",
      "            self.start = (self.start + 1) % len(self.data)\n",
      "\n",
      "    def randomly_sample(self, num_items: int) -> list:\n",
      "        \"\"\"\n",
      "        Samples a number of items from the memory randomly.\n",
      "\n",
      "        :param num_items: the number of the random items to be sampled.\n",
      "        :return: the items.\n",
      "        \"\"\"\n",
      "        # Sample a random number of memory indexes, which result in non empty contents and return the contents.\n",
      "        indexes = sample(range(len(self)), num_items)\n",
      "        return [self[idx] for idx in indexes]\n",
      "\n",
      "    def __getitem__(self, idx):\n",
      "        return self.data[(self.start + idx) % len(self.data)]\n",
      "\n",
      "    def __len__(self):\n",
      "        if self.end < self.start:\n",
      "            return self.end + len(self.data) - self.start\n",
      "        else:\n",
      "            return self.end - self.start\n",
      "\n",
      "    def __iter__(self):\n",
      "        for i in range(len(self)):\n",
      "            yield self[i]\n",
      "\n",
      "\n",
      "class DQN(object):\n",
      "    def __init__(self, model: Model, target_model_change: int, gamma: float, batch_size: int,\n",
      "                 observation_space_shape: tuple, action_size: int, policy: EGreedyPolicy, target_model: Model = None,\n",
      "                 memory_size: int = None, memory: ExperienceReplayMemory = None):\n",
      "        self.model = model\n",
      "        self.target_model_change = target_model_change\n",
      "        self.memory = ExperienceReplayMemory(memory_size) if memory is None else memory\n",
      "        self.gamma = gamma\n",
      "        self.batch_size = batch_size\n",
      "        self.observation_space_shape = observation_space_shape\n",
      "        self.action_size = action_size\n",
      "        self.policy = policy\n",
      "        self.target_model = self._create_target_model() if target_model is None else target_model\n",
      "        self.steps_from_update = 0\n",
      "\n",
      "    def _create_target_model(self) -> Model:\n",
      "        \"\"\"\n",
      "        Creates the target model, by copying the model.\n",
      "\n",
      "        :return: the target model.\n",
      "        \"\"\"\n",
      "        target_model = clone_model(self.model)\n",
      "        target_model.build(self.observation_space_shape)\n",
      "        target_model.compile(optimizer=self.model.optimizer, loss=self.model.loss)\n",
      "        target_model.set_weights(self.model.get_weights())\n",
      "\n",
      "        return target_model\n",
      "\n",
      "    def _get_mini_batch(self) -> [np.ndarray]:\n",
      "        \"\"\"\n",
      "        Samples a random mini batch from the replay memory.\n",
      "\n",
      "        :return: the current state batch, the actions batch, the rewards batch and the next state batch\n",
      "        \"\"\"\n",
      "        # Randomly sample a mini batch.\n",
      "        mini_batch = self.memory.randomly_sample(self.batch_size)\n",
      "\n",
      "        # Initialize arrays.\n",
      "        current_state_batch, next_state_batch, actions, rewards = \\\n",
      "            np.empty(((self.batch_size,) + self.observation_space_shape)), \\\n",
      "            np.empty(((self.batch_size,) + self.observation_space_shape)), \\\n",
      "            np.empty(self.batch_size), \\\n",
      "            np.empty(self.batch_size)\n",
      "\n",
      "        # Get values from the mini batch.\n",
      "        for idx, val in enumerate(mini_batch):\n",
      "            current_state_batch[idx] = val[0]\n",
      "            actions[idx] = val[1]\n",
      "            rewards[idx] = val[2]\n",
      "            next_state_batch[idx] = val[3]\n",
      "\n",
      "        return current_state_batch, actions, rewards, next_state_batch\n",
      "\n",
      "    def take_action(self, current_state: np.ndarray, episode: int) -> int:\n",
      "        \"\"\"\n",
      "        Takes an action based on the policy.\n",
      "\n",
      "        :param current_state: the state for which the action will be taken.\n",
      "        :param episode: the current episode.\n",
      "        :return: the action number.\n",
      "        \"\"\"\n",
      "        return self.policy.take_action(self.model, current_state, episode)\n",
      "\n",
      "    def append_to_memory(self, current_state: np.ndarray, action: int, reward: float, next_state: np.ndarray) -> None:\n",
      "        \"\"\"\n",
      "        Adds values to the agent's memory.\n",
      "\n",
      "        :param current_state: the state to add.\n",
      "        :param action: the action to add.\n",
      "        :param reward: the reward to add.\n",
      "        :param next_state: the next state to add.\n",
      "        \"\"\"\n",
      "        self.memory.append((current_state, action, reward, next_state))\n",
      "\n",
      "    def update_target_model(self) -> None:\n",
      "        \"\"\" Updates the target model. \"\"\"\n",
      "        self.target_model.set_weights(self.model.get_weights())\n",
      "        self.steps_from_update = 0\n",
      "\n",
      "    def fit(self) -> Union[History, None]:\n",
      "        \"\"\"\n",
      "        Fits the agent.\n",
      "\n",
      "        :return: the fit history.\n",
      "        \"\"\"\n",
      "        # Fit only if the agent is not observing.\n",
      "        if not self.policy.observing:\n",
      "            # Increase the steps from update indicator.\n",
      "            self.steps_from_update += 1\n",
      "\n",
      "            # Get the mini batches.\n",
      "            current_state_batch, actions, rewards, next_state_batch = self._get_mini_batch()\n",
      "\n",
      "            # Create the actions mask.\n",
      "            actions_mask = np.ones((self.batch_size, self.action_size))\n",
      "            # Predict the next QValues.\n",
      "            next_q_values = self.target_model.predict([next_state_batch, actions_mask])\n",
      "            # Initialize the target QValues for the mini batch.\n",
      "            target_q_values = np.empty((self.batch_size,))\n",
      "\n",
      "            for i in range(self.batch_size):\n",
      "                # Update rewards, using the Deep Q Learning rule.\n",
      "                target_q_values[i] = rewards[i] + self.gamma * np.amax(next_q_values[i])\n",
      "\n",
      "            # One hot encode the actions.\n",
      "            one_hot_actions = to_categorical(actions, self.action_size)\n",
      "            # One hot encode the target QValues.\n",
      "            one_hot_target_q_values = one_hot_actions * np.expand_dims(target_q_values, 1)\n",
      "\n",
      "            # Fit the model to the batches.\n",
      "            history = self.model.fit([current_state_batch, one_hot_actions],\n",
      "                                     one_hot_target_q_values, epochs=1, batch_size=self.batch_size, verbose=0)\n",
      "\n",
      "            # Update the target model if necessary.\n",
      "            if self.steps_from_update == self.target_model_change or self.target_model_change < 1:\n",
      "                print('Updating target model.')\n",
      "                self.update_target_model()\n",
      "                print('Target model has been successfully updated.')\n",
      "\n",
      "            return history\n",
      "\n",
      "    def save_agent(self, filename_prefix: str = 'dqn') -> str:\n",
      "        \"\"\"\n",
      "        Saves the agent.\n",
      "\n",
      "        :param filename_prefix: the agent's filename prefix.\n",
      "        :return: the filename.\n",
      "        \"\"\"\n",
      "        # Create filenames.\n",
      "        model_filename = 'model.h5'\n",
      "        target_model_filename = 'target_model.h5'\n",
      "        config_filename = 'config.pickle'\n",
      "        zip_filename = filename_prefix + '.zip'\n",
      "\n",
      "        # Save models.\n",
      "        self.model.save(model_filename)\n",
      "        self.target_model.save(target_model_filename)\n",
      "\n",
      "        # Create configuration dict.\n",
      "        config = dict({\n",
      "            'target_model_change': self.target_model_change,\n",
      "            'gamma': self.gamma,\n",
      "            'batch_size': self.batch_size,\n",
      "            'observation_space_shape': self.observation_space_shape,\n",
      "            'action_size': self.action_size,\n",
      "            'policy': self.policy,\n",
      "            'memory': self.memory\n",
      "        })\n",
      "\n",
      "        # Save configuration.\n",
      "        with open(config_filename, 'wb') as stream:\n",
      "            pickle.dump(config, stream, protocol=pickle.HIGHEST_PROTOCOL)\n",
      "\n",
      "        # Zip models and configuration together.\n",
      "        with ZipFile(zip_filename, 'w') as model_zip:\n",
      "            model_zip.write(model_filename, basename(model_filename))\n",
      "            model_zip.write(target_model_filename, basename(target_model_filename))\n",
      "            model_zip.write(config_filename, basename(config_filename))\n",
      "\n",
      "        # Remove files out of the zip.\n",
      "        remove(model_filename)\n",
      "        remove(target_model_filename)\n",
      "        remove(config_filename)\n",
      "\n",
      "        return zip_filename\n",
      "\n",
      "\n",
      "def load_dqn_agent(filename: str, custom_objects: dict) -> DQN:\n",
      "    \"\"\"\n",
      "    Loads an agent from a file, using the given parameters.\n",
      "\n",
      "    :param filename: the agent's filename.\n",
      "    :param custom_objects: custom_objects for the keras model.\n",
      "    :return: the DQN agent.\n",
      "    \"\"\"\n",
      "    # Create filenames.\n",
      "    directory = dirname(filename)\n",
      "    model_filename = join(directory, 'model.h5')\n",
      "    target_model_filename = join(directory, 'target_model.h5')\n",
      "    config_filename = join(directory, 'config.pickle')\n",
      "\n",
      "    # Read models and memory.\n",
      "    with ZipFile(filename) as model_zip:\n",
      "        model_zip.extractall(directory)\n",
      "\n",
      "    # Load models.\n",
      "    model = load_model(model_filename, custom_objects=custom_objects)\n",
      "    target_model = load_model(target_model_filename, custom_objects=custom_objects)\n",
      "\n",
      "    # Load configuration.\n",
      "    with open(config_filename, 'rb') as stream:\n",
      "        config = pickle.load(stream)\n",
      "\n",
      "    # Remove files out of the zip.\n",
      "    remove(model_filename)\n",
      "    remove(target_model_filename)\n",
      "    remove(config_filename)\n",
      "\n",
      "    return DQN(model, config['target_model_change'], config['gamma'], config['batch_size'],\n",
      "               config['observation_space_shape'], config['action_size'], config['policy'], target_model,\n",
      "               memory=config['memory'])\n",
      "\n",
      "Output: {'agent': [], 'agent.ExperienceReplayMemory.__init__': ['<builtin>.ValueError'], '<builtin>.ValueError': [], 'agent.ExperienceReplayMemory.append': ['<builtin>.len'], '<builtin>.len': [], 'agent.ExperienceReplayMemory.randomly_sample': ['random.sample', '<builtin>.range', '<builtin>.len'], '<builtin>.range': [], 'random.sample': [], 'agent.ExperienceReplayMemory.__getitem__': ['<builtin>.len'], 'agent.ExperienceReplayMemory.__len__': ['<builtin>.len'], 'agent.ExperienceReplayMemory.__iter__': ['<builtin>.range', '<builtin>.len'], 'agent.DQN.__init__': ['agent.ExperienceReplayMemory.__init__', 'agent.DQN._create_target_model'], 'agent.DQN._create_target_model': ['keras.models.clone_model'], 'keras.models.clone_model': [], 'agent.DQN._get_mini_batch': ['<builtin>.enumerate', 'numpy.empty'], 'numpy.empty': [], '<builtin>.enumerate': [], 'agent.DQN.take_action': [], 'agent.DQN.append_to_memory': [], 'agent.DQN.update_target_model': [], 'agent.DQN.fit': ['numpy.ones', 'agent.DQN._get_mini_batch', '<builtin>.range', '<builtin>.print', 'numpy.empty', 'agent.DQN.update_target_model', 'numpy.amax', 'keras.utils.to_categorical', 'numpy.expand_dims'], 'numpy.ones': [], 'numpy.amax': [], 'keras.utils.to_categorical': [], 'numpy.expand_dims': [], '<builtin>.print': [], 'agent.DQN.save_agent': ['<builtin>.open', '<builtin>.dict', 'pickle.dump', 'os.remove', 'os.path.basename', 'zipfile.ZipFile'], '<builtin>.dict': [], '<builtin>.open': [], 'pickle.dump': [], 'zipfile.ZipFile': [], 'os.path.basename': [], 'os.remove': [], 'agent.load_dqn_agent': ['<builtin>.open', 'agent.DQN.__init__', 'os.remove', 'pickle.load', 'os.path.join', 'os.path.dirname', 'zipfile.ZipFile', 'keras.engine.saving.load_model'], 'os.path.dirname': [], 'os.path.join': [], 'keras.engine.saving.load_model': [], 'pickle.load': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Adamantios_Atari-Skiing-RL\\core\\agent.py\n",
      "[('agent ExperienceReplayMemory randomly_sample', 'random sample'), ('agent DQN __init__', 'agent ExperienceReplayMemory __init__'), ('agent DQN __init__', 'agent DQN _create_target_model'), ('agent DQN _create_target_model', 'keras models clone_model'), ('agent DQN _get_mini_batch', 'numpy empty'), ('agent DQN fit', 'numpy ones'), ('agent DQN fit', 'agent DQN _get_mini_batch'), ('agent DQN fit', 'numpy empty'), ('agent DQN fit', 'agent DQN update_target_model'), ('agent DQN fit', 'numpy amax'), ('agent DQN fit', 'keras utils to_categorical'), ('agent DQN fit', 'numpy expand_dims'), ('agent DQN save_agent', 'pickle dump'), ('agent DQN save_agent', 'os remove'), ('agent DQN save_agent', 'os path basename'), ('agent DQN save_agent', 'zipfile ZipFile'), ('agent load_dqn_agent', 'agent DQN __init__'), ('agent load_dqn_agent', 'os remove'), ('agent load_dqn_agent', 'pickle load'), ('agent load_dqn_agent', 'os path join'), ('agent load_dqn_agent', 'os path dirname'), ('agent load_dqn_agent', 'zipfile ZipFile'), ('agent load_dqn_agent', 'keras engine saving load_model')]\n",
      "100\n",
      "found files: []\n",
      "from collections import Generator\n",
      "from dataclasses import dataclass\n",
      "from random import randint\n",
      "\n",
      "import gym\n",
      "import numpy as np\n",
      "from gym.wrappers import TimeLimit\n",
      "from math import inf, ceil\n",
      "\n",
      "from core.agent import DQN\n",
      "from core.preprocessing import atari_preprocess\n",
      "from game_engine.plotting import Plotter\n",
      "from game_engine.scoring import Scorer\n",
      "from utils.system_operations import print_progressbar\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class GameResultSpecs:\n",
      "    info_interval_current: int\n",
      "    info_interval_mean: int\n",
      "    agent_save_interval: int\n",
      "    results_save_interval: int\n",
      "    plots_name_prefix: str\n",
      "    results_name_prefix: str\n",
      "    agent_name_prefix: str\n",
      "    recording_name_prefix: str\n",
      "    plot_train_results: bool = True\n",
      "    save_plots: bool = True\n",
      "\n",
      "\n",
      "_GameInfo = [np.ndarray, float, bool]\n",
      "\n",
      "\n",
      "class Game(object):\n",
      "    def __init__(self, episodes: int, downsample_scale: int, agent_frame_history: int, steps_per_action: int,\n",
      "                 fit_frequency: int, no_operation: int, specs: GameResultSpecs, render: bool, record: bool):\n",
      "        self.episodes = episodes\n",
      "        self.downsample_scale = downsample_scale\n",
      "        self.agent_frame_history = agent_frame_history\n",
      "        self.steps_per_action = steps_per_action\n",
      "        self.fit_frequency = fit_frequency\n",
      "        self.no_operation = no_operation\n",
      "        self.specs = specs\n",
      "        self.render = render\n",
      "        self.record = record\n",
      "\n",
      "        # Create the skiing environment.\n",
      "        self._env, self.pixel_rows, self.pixel_columns, self.action_space_size = self._create_skiing_environment()\n",
      "\n",
      "        # Create the observation space's shape.\n",
      "        self.observation_space_shape = (self.agent_frame_history,\n",
      "                                        ceil(self.pixel_rows / self.downsample_scale),\n",
      "                                        ceil(self.pixel_columns / self.downsample_scale),\n",
      "                                        1)\n",
      "\n",
      "        # Create a scorer.\n",
      "        self.scorer = Scorer(episodes, self.specs.info_interval_mean, self.specs.results_name_prefix)\n",
      "\n",
      "        # Create a plotter.\n",
      "        self.plotter = Plotter(self.episodes, self.specs.plots_name_prefix, self.specs.plot_train_results,\n",
      "                               self.specs.save_plots)\n",
      "\n",
      "    def _create_skiing_environment(self) -> [TimeLimit, int, int, int]:\n",
      "        \"\"\"\n",
      "        Creates a skiing environment.\n",
      "\n",
      "        :return: the skiing environment, the image's height, the image's width and the action space's size.\n",
      "        \"\"\"\n",
      "        # Create the skiing environment.\n",
      "        environment = gym.make('SkiingDeterministic-v4')\n",
      "\n",
      "        # Record environment.\n",
      "        if self.record:\n",
      "            environment = gym.wrappers.Monitor(environment, self.specs.recording_name_prefix, force=True)\n",
      "\n",
      "        # Get the observation space's height and width.\n",
      "        height, width = environment.observation_space.shape[0], environment.observation_space.shape[1]\n",
      "        # Get the number of possible moves.\n",
      "        act_space_size = environment.action_space.n\n",
      "\n",
      "        return environment, height, width, act_space_size\n",
      "\n",
      "    def _begin_episode(self) -> np.ndarray:\n",
      "        \"\"\"\n",
      "        Begins an episode.\n",
      "\n",
      "        :return: the initial state.\n",
      "        \"\"\"\n",
      "        # Reset and render the environment.\n",
      "        init_state = self._env.reset()\n",
      "        if self.render:\n",
      "            self._env.render()\n",
      "\n",
      "        return init_state\n",
      "\n",
      "    def _observe(self, init_state: np.ndarray) -> [np.ndarray, bool]:\n",
      "        \"\"\"\n",
      "        Take no action.\n",
      "\n",
      "        :param init_state: the initial state.\n",
      "        :return: the next state and if game is done.\n",
      "        \"\"\"\n",
      "        # Init variables.\n",
      "        observe, done = init_state, False\n",
      "\n",
      "        # Observe for a random number of steps picked from [1, self._no_operation].\n",
      "        for _ in range(randint(1, self.no_operation)):\n",
      "            # Take no action.\n",
      "            observe, _, done, _ = self._env.step(0)\n",
      "            # Render the frame.\n",
      "            if self.render:\n",
      "                self._env.render()\n",
      "\n",
      "            if done:\n",
      "                break\n",
      "\n",
      "        return observe, done\n",
      "\n",
      "    def _pretrain_phase(self) -> np.ndarray:\n",
      "        \"\"\"\n",
      "        Completes pretrain phase.\n",
      "\n",
      "        :return: the state that was created.\n",
      "        \"\"\"\n",
      "        # Start the episode.\n",
      "        init_state = self._begin_episode()\n",
      "\n",
      "        # Just observe.\n",
      "        current_state, done = self._observe(init_state)\n",
      "\n",
      "        # Preprocess current_state.\n",
      "        current_state = atari_preprocess(current_state, self.downsample_scale)\n",
      "\n",
      "        # Create preceding frames, using the starting frame.\n",
      "        current_state = np.concatenate(tuple([current_state for _ in range(self.agent_frame_history)]), axis=1)\n",
      "\n",
      "        return current_state\n",
      "\n",
      "    def _take_frame_skipping_action(self, agent: DQN, current_state: np.ndarray, episode: int) -> _GameInfo:\n",
      "        \"\"\"\n",
      "        Takes an action, using frame skipping.\n",
      "\n",
      "        :param agent: the agent to take the action.\n",
      "        :param current_state: the current state.\n",
      "        :param episode: the current episode.\n",
      "        :return: the next state, the reward and if game is done.\n",
      "        \"\"\"\n",
      "        # Let the agent take an action.\n",
      "        action = agent.take_action(current_state, episode)\n",
      "        # Init variables.\n",
      "        reward, next_state, done = 0, current_state, False\n",
      "\n",
      "        for _ in range(self.steps_per_action):\n",
      "            # Take a step, using the action.\n",
      "            next_state, new_reward, done, _ = self._env.step(action)\n",
      "            # Render the frame.\n",
      "            if self.render:\n",
      "                self._env.render()\n",
      "            # Add reward.\n",
      "            reward += new_reward\n",
      "\n",
      "            if done:\n",
      "                break\n",
      "\n",
      "            # Preprocess the state.\n",
      "            next_state = atari_preprocess(next_state, self.downsample_scale)\n",
      "            # Append the frame history.\n",
      "            next_state = np.append(next_state, current_state[:, :self.agent_frame_history - 1, :, :, :], axis=1)\n",
      "\n",
      "            # Save sample <s,a,r,s'> to the replay memory.\n",
      "            agent.append_to_memory(current_state, action, reward, next_state)\n",
      "\n",
      "            # Set current state with the next.\n",
      "            current_state = next_state\n",
      "\n",
      "        return next_state, reward, done\n",
      "\n",
      "    def _train_and_play(self, agent: DQN, current_state: np.ndarray, episode: int) -> _GameInfo:\n",
      "        \"\"\"\n",
      "        Train the agent while playing, using the current state.\n",
      "\n",
      "        :param agent: the agent to train.\n",
      "        :param current_state: the current state.\n",
      "        :param episode: the current episode.\n",
      "        :return: the next state, the reward and if game is done.\n",
      "        \"\"\"\n",
      "        # Init variables.\n",
      "        reward, next_state, done = 0, current_state, False\n",
      "\n",
      "        # Repeat actions before fitting time.\n",
      "        for _ in range(self.fit_frequency):\n",
      "            # Take an action.\n",
      "            next_state, new_reward, done = self._take_frame_skipping_action(agent, current_state, episode)\n",
      "            # Add reward.\n",
      "            reward += new_reward\n",
      "            if done:\n",
      "                break\n",
      "\n",
      "        # Fit agent and keep fitting history.\n",
      "        fitting_history = agent.fit()\n",
      "        if fitting_history is not None:\n",
      "            self.scorer.huber_loss_history[episode - 1] += fitting_history.history['loss']\n",
      "\n",
      "        return next_state, reward, done\n",
      "\n",
      "    def _game_loop(self, agent: DQN) -> Generator:\n",
      "        \"\"\"\n",
      "        Starts the game loop and trains the agent.\n",
      "\n",
      "        :param agent: the agent to play the game.\n",
      "        :return: generator containing the finished episode number.\n",
      "        \"\"\"\n",
      "        # Run for a number of episodes.\n",
      "        for episode in range(1, self.episodes + 1):\n",
      "            # Init vars.\n",
      "            reward, max_score, total_score, done = 0, -inf, 0, False\n",
      "            # Complete pretrain phase.\n",
      "            current_state = self._pretrain_phase()\n",
      "\n",
      "            while not done:\n",
      "                # Train the agent while playing.\n",
      "                current_state, reward, done = self._train_and_play(agent, current_state, episode)\n",
      "                # Add reward to the total score.\n",
      "                total_score += reward\n",
      "                # Set max score.\n",
      "                max_score = max(max_score, reward)\n",
      "\n",
      "            # Add scores to the scores arrays.\n",
      "            self.scorer.max_scores[episode - 1] = max_score\n",
      "            self.scorer.total_scores[episode - 1] = total_score\n",
      "\n",
      "            # Yield the finished episode.\n",
      "            yield episode\n",
      "\n",
      "    def _update_progressbar(self, finished_episode: int) -> None:\n",
      "        \"\"\"\n",
      "        Updates game progressbar.\n",
      "\n",
      "        :param finished_episode: the episode that just finished.\n",
      "        \"\"\"\n",
      "        remaining_episodes = self.episodes - finished_episode\n",
      "\n",
      "        if not self.specs.info_interval_current == 1 and remaining_episodes > 0:\n",
      "            # Set the progressbar's remaining episodes number.\n",
      "            if self.specs.info_interval_current <= remaining_episodes \\\n",
      "                    or self.episodes - (self.episodes % self.specs.info_interval_current) > finished_episode:\n",
      "                bar_num_episodes = self.specs.info_interval_current\n",
      "            else:\n",
      "                bar_num_episodes = self.episodes % self.specs.info_interval_current\n",
      "\n",
      "            # Reinitialize progressbar if it just finished, but the game did not.\n",
      "            if finished_episode % self.specs.info_interval_current == 0:\n",
      "                print_progressbar(0, bar_num_episodes,\n",
      "                                  'Episode: 0/{}'.format(bar_num_episodes),\n",
      "                                  'Finished: {}/{}'.format(finished_episode, self.episodes))\n",
      "\n",
      "            else:\n",
      "                print_progressbar(finished_episode % self.specs.info_interval_current, bar_num_episodes,\n",
      "                                  'Episode: {}/{}'.format(finished_episode % self.specs.info_interval_current,\n",
      "                                                          bar_num_episodes),\n",
      "                                  'Finished: {}/{}'.format(finished_episode, self.episodes))\n",
      "\n",
      "        elif remaining_episodes == 0:\n",
      "            print('All the episodes have finished!')\n",
      "\n",
      "    def _end_of_episode_actions(self, finished_episode: int, agent: DQN) -> None:\n",
      "        \"\"\"\n",
      "        Takes actions after the episode finishes.\n",
      "        Shows scoring information and saves the model.\n",
      "\n",
      "        :param finished_episode: the episode for which the actions will be taken.\n",
      "        :param agent: the agent with whom the episode was played.\n",
      "        \"\"\"\n",
      "        # Save agent.\n",
      "        if finished_episode % self.specs.agent_save_interval == 0 or self.specs.agent_save_interval == 1:\n",
      "            print('Saving agent.')\n",
      "            filename = agent.save_agent(\"{}_{}\".format(self.specs.agent_name_prefix, finished_episode))\n",
      "            print('Agent has been successfully saved as {}.'.format(filename))\n",
      "\n",
      "        # Show scores.\n",
      "        if finished_episode % self.specs.info_interval_current == 0 or self.specs.info_interval_current == 1:\n",
      "            self.scorer.show_episode_scoring(finished_episode)\n",
      "\n",
      "        if self.specs.info_interval_mean > 1 and finished_episode % self.specs.info_interval_mean == 0:\n",
      "            self.scorer.show_mean_scoring(finished_episode)\n",
      "\n",
      "        # Update progressbar.\n",
      "        self._update_progressbar(finished_episode)\n",
      "\n",
      "        # Plot scores.\n",
      "        if finished_episode == self.episodes and self.episodes > 1:\n",
      "            observing_episodes = self.episodes if agent.policy.observing else agent.policy.episode_observation_stopped\n",
      "\n",
      "            # Max score.\n",
      "            self.plotter.plot_max_score_vs_episodes(self.scorer.max_scores, observing_episodes,\n",
      "                                                    'Max Score vs Episodes',\n",
      "                                                    '_max_scores_vs_episodes.png')\n",
      "            # Total score.\n",
      "            self.plotter.plot_total_score_vs_episodes(self.scorer.total_scores, observing_episodes,\n",
      "                                                      'Total Score vs Episodes',\n",
      "                                                      '_total_scores_vs_episodes.png', False)\n",
      "            # Total score compared with the state of the art.\n",
      "            self.plotter.plot_total_score_vs_episodes(self.scorer.total_scores, observing_episodes,\n",
      "                                                      'Total Score vs Episodes',\n",
      "                                                      '_total_scores_vs_episodes_soa_compared.png')\n",
      "            # Huber loss.\n",
      "            self.plotter.plot_huber_loss_vs_episodes(self.scorer.huber_loss_history, observing_episodes,\n",
      "                                                     'Total Huber loss vs episodes', '_loss_vs_episodes.png')\n",
      "\n",
      "        # Save results.\n",
      "        if self.specs.results_save_interval > 0 and (\n",
      "                finished_episode % self.specs.results_save_interval == 0 or self.specs.results_save_interval == 1):\n",
      "            self.scorer.save_results(finished_episode)\n",
      "\n",
      "    def play_game(self, agent: DQN) -> None:\n",
      "        \"\"\"\n",
      "        Plays the game.\n",
      "\n",
      "        :param agent: the agent who will take the actions in the game.\n",
      "        \"\"\"\n",
      "        # Initialize progressbar.\n",
      "        self._update_progressbar(0)\n",
      "\n",
      "        # Start the game loop.\n",
      "        for finished_episode in self._game_loop(agent):\n",
      "            # Take specific actions after the end of each episode.\n",
      "            self._end_of_episode_actions(finished_episode, agent)\n",
      "\n",
      "Output: {'game': [], 'game.Game.__init__': ['game_engine.plotting.Plotter', 'game.Game._create_skiing_environment', 'game_engine.scoring.Scorer', 'math.ceil'], 'game.Game._create_skiing_environment': ['gym.wrappers.Monitor', 'gym.make'], 'math.ceil': [], 'game_engine.scoring.Scorer': [], 'game_engine.plotting.Plotter': [], 'gym.make': [], 'gym.wrappers.Monitor': [], 'game.Game._begin_episode': [], 'game.Game._observe': ['random.randint', '<builtin>.range'], 'random.randint': [], '<builtin>.range': [], 'game.Game._pretrain_phase': ['game.Game._begin_episode', 'numpy.concatenate', 'core.preprocessing.atari_preprocess', 'game.Game._observe', '<builtin>.range', '<builtin>.tuple'], 'core.preprocessing.atari_preprocess': [], '<builtin>.tuple': [], 'numpy.concatenate': [], 'game.Game._take_frame_skipping_action': ['core.preprocessing.atari_preprocess', 'numpy.append', '<builtin>.range'], 'numpy.append': [], 'game.Game._train_and_play': ['game.Game._take_frame_skipping_action', '<builtin>.range'], 'game.Game._game_loop': ['game.Game._train_and_play', '<builtin>.max', 'game.Game._pretrain_phase', '<builtin>.range'], '<builtin>.max': [], 'game.Game._update_progressbar': ['utils.system_operations.print_progressbar', '<builtin>.print'], 'utils.system_operations.print_progressbar': [], '<builtin>.print': [], 'game.Game._end_of_episode_actions': ['<builtin>.print', 'game.Game._update_progressbar'], 'game.Game.play_game': ['game.Game._game_loop', 'game.Game._end_of_episode_actions', 'game.Game._update_progressbar']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\Adamantios_Atari-Skiing-RL\\game_engine\\game.py\n",
      "[('game Game __init__', 'game_engine plotting Plotter'), ('game Game __init__', 'game Game _create_skiing_environment'), ('game Game __init__', 'game_engine scoring Scorer'), ('game Game __init__', 'math ceil'), ('game Game _create_skiing_environment', 'gym wrappers Monitor'), ('game Game _create_skiing_environment', 'gym make'), ('game Game _observe', 'random randint'), ('game Game _pretrain_phase', 'game Game _begin_episode'), ('game Game _pretrain_phase', 'numpy concatenate'), ('game Game _pretrain_phase', 'core preprocessing atari_preprocess'), ('game Game _pretrain_phase', 'game Game _observe'), ('game Game _take_frame_skipping_action', 'core preprocessing atari_preprocess'), ('game Game _take_frame_skipping_action', 'numpy append'), ('game Game _train_and_play', 'game Game _take_frame_skipping_action'), ('game Game _game_loop', 'game Game _train_and_play'), ('game Game _game_loop', 'game Game _pretrain_phase'), ('game Game _update_progressbar', 'utils system_operations print_progressbar'), ('game Game _end_of_episode_actions', 'game Game _update_progressbar'), ('game Game play_game', 'game Game _game_loop'), ('game Game play_game', 'game Game _end_of_episode_actions'), ('game Game play_game', 'game Game _update_progressbar')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('parser positive_int', 'argparse ArgumentTypeError'), ('parser positive_float', 'argparse ArgumentTypeError'), ('parser create_parser', 'argparse ArgumentParser')], [('preprocessing rgb2gray', 'numpy dot'), ('preprocessing atari_preprocess', 'preprocessing downsample'), ('preprocessing atari_preprocess', 'preprocessing rgb2gray')], [('model atari_skiing_model', 'keras layers Dense'), ('model atari_skiing_model', 'keras layers Flatten'), ('model atari_skiing_model', 'keras layers ConvLSTM2D'), ('model atari_skiing_model', 'keras Model'), ('model atari_skiing_model', 'keras layers Lambda'), ('model atari_skiing_model', 'keras layers BatchNormalization'), ('model atari_skiing_model', 'keras Input'), ('model atari_skiing_model', 'keras layers Multiply'), ('model initialize_optimizer', 'keras optimizers adam'), ('model initialize_optimizer', 'keras optimizers rmsprop'), ('model initialize_optimizer', 'keras optimizers sgd'), ('model initialize_optimizer', 'keras optimizers adagrad'), ('model initialize_optimizer', 'keras optimizers adadelta'), ('model initialize_optimizer', 'keras optimizers adamax'), ('model huber_loss', 'keras backend cast')], [('scoring Scorer __init__', 'numpy empty'), ('scoring Scorer __init__', 'numpy zeros'), ('scoring Scorer save_results', 'pickle dump')], [('system_operations create_path', 'os path dirname'), ('system_operations create_path', 'os makedirs'), ('system_operations create_path', 'os path exists')], [('policy EGreedyPolicy take_action', 'numpy argmax'), ('policy EGreedyPolicy take_action', 'policy EGreedyPolicy _decay_epsilon'), ('policy EGreedyPolicy take_action', 'numpy random rand'), ('policy EGreedyPolicy take_action', 'policy EGreedyPolicy _update_observation_state'), ('policy EGreedyPolicy take_action', 'random randrange')], [('skiing', 'game_engine game Game'), ('skiing', 'skiing create_agent'), ('skiing', 'core policy EGreedyPolicy'), ('skiing', 'game_engine game GameResultSpecs'), ('skiing', 'skiing run_checks'), ('skiing', 'utils parser create_parser'), ('skiing', 'core model initialize_optimizer'), ('skiing run_checks', 'os path exists'), ('skiing run_checks', 'warnings warn'), ('skiing run_checks', 'core model frame_can_pass_the_net'), ('skiing run_checks', 'utils system_operations create_path'), ('utils system_operations create_path', 'os path dirname'), ('utils system_operations create_path', 'os makedirs'), ('utils system_operations create_path', 'os path exists'), ('skiing create_agent', 'core model atari_skiing_model'), ('skiing create_agent', 'core agent load_dqn_agent'), ('skiing create_agent', 'core agent DQN'), ('core agent load_dqn_agent', 'os remove'), ('core agent load_dqn_agent', 'pickle load'), ('core agent load_dqn_agent', 'zipfile ZipFile'), ('core agent load_dqn_agent', 'keras engine saving load_model'), ('core agent load_dqn_agent', 'os path join'), ('core agent load_dqn_agent', 'core agent DQN'), ('core agent load_dqn_agent', 'os path dirname'), ('core model atari_skiing_model', 'keras Input'), ('core model atari_skiing_model', 'keras layers Flatten'), ('core model atari_skiing_model', 'keras layers Multiply'), ('core model atari_skiing_model', 'keras layers Lambda'), ('core model atari_skiing_model', 'keras layers Dense'), ('core model atari_skiing_model', 'keras layers BatchNormalization')], [('plotting Plotter _plot_and_save', 'matplotlib pyplot show'), ('plotting Plotter _plot_score_vs_episodes', 'numpy asarray'), ('plotting Plotter _plot_score_vs_episodes', 'numpy mean'), ('plotting Plotter _plot_score_vs_episodes', 'matplotlib pyplot MaxNLocator'), ('plotting Plotter _plot_score_vs_episodes', 'numpy argmax'), ('plotting Plotter _plot_score_vs_episodes', 'matplotlib pyplot subplots'), ('plotting Plotter _plot_score_vs_episodes', 'numpy append'), ('plotting Plotter _plot_score_vs_episodes', 'numpy argmin'), ('plotting Plotter _plot_score_vs_episodes', 'numpy roll'), ('plotting Plotter plot_max_score_vs_episodes', 'plotting Plotter _plot_score_vs_episodes'), ('plotting Plotter plot_max_score_vs_episodes', 'plotting Plotter _plot_and_save'), ('plotting Plotter plot_total_score_vs_episodes', 'plotting Plotter _plot_score_vs_episodes'), ('plotting Plotter plot_total_score_vs_episodes', 'plotting Plotter _annotate_state_of_the_art'), ('plotting Plotter plot_total_score_vs_episodes', 'plotting Plotter _plot_and_save'), ('plotting Plotter _annotate_state_of_the_art', 'numpy asarray'), ('plotting Plotter plot_huber_loss_vs_episodes', 'plotting Plotter _plot_score_vs_episodes'), ('plotting Plotter plot_huber_loss_vs_episodes', 'plotting Plotter _plot_and_save')], [('agent ExperienceReplayMemory randomly_sample', 'random sample'), ('agent DQN __init__', 'agent ExperienceReplayMemory __init__'), ('agent DQN __init__', 'agent DQN _create_target_model'), ('agent DQN _create_target_model', 'keras models clone_model'), ('agent DQN _get_mini_batch', 'numpy empty'), ('agent DQN fit', 'numpy ones'), ('agent DQN fit', 'agent DQN _get_mini_batch'), ('agent DQN fit', 'numpy empty'), ('agent DQN fit', 'agent DQN update_target_model'), ('agent DQN fit', 'numpy amax'), ('agent DQN fit', 'keras utils to_categorical'), ('agent DQN fit', 'numpy expand_dims'), ('agent DQN save_agent', 'pickle dump'), ('agent DQN save_agent', 'os remove'), ('agent DQN save_agent', 'os path basename'), ('agent DQN save_agent', 'zipfile ZipFile'), ('agent load_dqn_agent', 'agent DQN __init__'), ('agent load_dqn_agent', 'os remove'), ('agent load_dqn_agent', 'pickle load'), ('agent load_dqn_agent', 'os path join'), ('agent load_dqn_agent', 'os path dirname'), ('agent load_dqn_agent', 'zipfile ZipFile'), ('agent load_dqn_agent', 'keras engine saving load_model')], [('game Game __init__', 'game_engine plotting Plotter'), ('game Game __init__', 'game Game _create_skiing_environment'), ('game Game __init__', 'game_engine scoring Scorer'), ('game Game __init__', 'math ceil'), ('game Game _create_skiing_environment', 'gym wrappers Monitor'), ('game Game _create_skiing_environment', 'gym make'), ('game Game _observe', 'random randint'), ('game Game _pretrain_phase', 'game Game _begin_episode'), ('game Game _pretrain_phase', 'numpy concatenate'), ('game Game _pretrain_phase', 'core preprocessing atari_preprocess'), ('game Game _pretrain_phase', 'game Game _observe'), ('game Game _take_frame_skipping_action', 'core preprocessing atari_preprocess'), ('game Game _take_frame_skipping_action', 'numpy append'), ('game Game _train_and_play', 'game Game _take_frame_skipping_action'), ('game Game _game_loop', 'game Game _train_and_play'), ('game Game _game_loop', 'game Game _pretrain_phase'), ('game Game _update_progressbar', 'utils system_operations print_progressbar'), ('game Game _end_of_episode_actions', 'game Game _update_progressbar'), ('game Game play_game', 'game Game _game_loop'), ('game Game play_game', 'game Game _end_of_episode_actions'), ('game Game play_game', 'game Game _update_progressbar')]]\n",
      "********************doctrings*************************\n",
      "['positive int positive float create parser [SEP] Checks if a value is a positive integer. :param value: the value to be checked. :return: the value Checks if a value is a positive float. :param value: the value to be checked. :return: the value if Creates an argument parser for the atari skiing', 'rgb2gray downsample atari preprocess [SEP] Converts an rgb image array to a grey image array. :param rgb: the rgb image array. :return: the co Downsamples an image array, by a scale factor. :param img: the image to downsample. :param scale: t Prepossesses the given atari frame array. :para', \"frame can pass the net atari skiing model initialize optimizer huber loss [SEP] Returns if a frame can successfully pass through the network. :param height: the frame's height. :p Defines a Keras Model designed for the atari skiing game. :param shape: the input shape. :param act Initializes an optimizer based on the user's cho\", '', 'create path print progressbar [SEP] Creates a path to a file, if it does not exist. :param filepath: the filepath. Call in a loop to create terminal progress bar. @params:   iteration  - Required : current iter', '', 'run checks create agent [SEP] Checks the input arguments. Creates the atari skiing agent. :return: the agent.', '', \"load dqn agent [SEP] Loads an agent from a file, using the given parameters. :param filename: the agent's filename. :par\", '']\n",
      "embed index dataset: 17\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\nicehiro_puck-world\\\\puck_world\\\\envs\\\\multi_agents\\\\puckworld_with_wheel.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\nicehiro_puck-world\\\\setup.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\nicehiro_puck-world\\\\puck_world\\\\envs\\\\single_agent\\\\puckworld.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\nicehiro_puck-world\\\\puck_world\\\\envs\\\\multi_agents\\\\agent.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\nicehiro_puck-world\\\\puck_world\\\\envs\\\\multi_agents\\\\agent_type.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\nicehiro_puck-world\\\\puck_world\\\\envs\\\\multi_agents\\\\puckworld.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\nicehiro_puck-world\\\\puck_world\\\\envs\\\\single_agent\\\\puckworld_continuous.py']\n",
      "import math\n",
      "import random\n",
      "import time\n",
      "\n",
      "import gym\n",
      "import numpy as np\n",
      "from gym import spaces\n",
      "from gym.utils import seeding\n",
      "\n",
      "from puck_world.envs.multi_agents.agent import AgentWithWheel\n",
      "from puck_world.envs.multi_agents.agent_type import AgentType\n",
      "\n",
      "\n",
      "class PuckWorldWheel(gym.Env):\n",
      "    metadata = {\n",
      "        'render.modes': ['human', 'rgb_array'],\n",
      "        'video.frames_per_second': 1\n",
      "    }\n",
      "\n",
      "    def __init__(self, fps=60):\n",
      "        self.width = 400\n",
      "        self.height = 400\n",
      "        self.len_unit = 1.0\n",
      "        self.vel = 20.0\n",
      "        self.runner_vel = 50.0\n",
      "        self.agents = {agent_type: None for agent_type in AgentType}\n",
      "        self.time = 0\n",
      "        self.rewards = []\n",
      "        self.viewer = None\n",
      "        self.radian2angle = math.pi / 180\n",
      "        self.RAD2DEG = 57.29577951308232\n",
      "\n",
      "        self.np_random = None\n",
      "        self.action_space_bound = (-180, 180)\n",
      "        self.action_space = spaces.Box(np.array(self.action_space_bound[0]),\n",
      "                                       np.array(self.action_space_bound[1]))\n",
      "\n",
      "        self.normal_reward = 1\n",
      "        self.special_reward = 10\n",
      "\n",
      "        self.state = [0, 0, 0, 0]\n",
      "        self.fps = fps\n",
      "\n",
      "        self.seed()\n",
      "\n",
      "    def seed(self, seed=None):\n",
      "        self.np_random, seed = seeding.np_random(seed)\n",
      "        return [seed]\n",
      "\n",
      "    def add_agent(self, agent):\n",
      "        if agent.type == AgentType.Chaser:\n",
      "            self.agents[AgentType.Chaser] = agent\n",
      "        else:\n",
      "            self.agents[AgentType.Runner] = agent\n",
      "\n",
      "    def __dis(self, s_x, s_y, t_x, t_y):\n",
      "        return math.sqrt((s_x - t_x) ** 2 + (s_y - t_y) ** 2)\n",
      "\n",
      "    def is_done(self):\n",
      "        chaser = self.agents[AgentType.Chaser]\n",
      "        runner = self.agents[AgentType.Runner]\n",
      "        return self.__dis(chaser.x, chaser.y, runner.x, runner.y) <= min(chaser.r, runner.r)\n",
      "\n",
      "    def step(self, agent_type, action:int):\n",
      "        \"\"\"\n",
      "        Agent how to move based on action in this envs.\n",
      "\n",
      "        :param name: agent's name\n",
      "        :param action: agent's action\n",
      "        :return: next_state, reward, done, info\n",
      "        \"\"\"\n",
      "        assert self.action_space_bound[0] <= action <= self.action_space_bound[1], \\\n",
      "            '%r (%s) invalid' % (action, type(action))\n",
      "        agent = self.agents[agent_type]\n",
      "        if agent_type == AgentType.Chaser:\n",
      "            target = self.agents[AgentType.Runner]\n",
      "        else:\n",
      "            target = self.agents[AgentType.Chaser]\n",
      "        delta_x = self.vel * math.cos(action * self.radian2angle)\n",
      "        delta_y = self.vel * math.sin(action * self.radian2angle)\n",
      "        new_x, new_y = agent.x + delta_x, agent.y + delta_y\n",
      "        if agent_type == AgentType.Chaser:\n",
      "            new_x, new_y, direction = self._wheel_move(agent.x, agent.y, agent.r, agent.direction, agent.left_v, agent.right_v)\n",
      "            agent.direction = direction\n",
      "\n",
      "        if new_x - agent.r <= 0:\n",
      "            new_x = agent.r\n",
      "        if new_x + agent.r >= self.width:\n",
      "            new_x = self.width - agent.r\n",
      "        if new_y - agent.r <= 0:\n",
      "            new_y = agent.r\n",
      "        if new_y + agent.r >= self.height:\n",
      "            new_y = self.height - agent.r\n",
      "\n",
      "        # reward_prefix = 1\n",
      "        # reward = self.normal_reward\n",
      "        # if agent.type == AgentType.Chaser:\n",
      "        #     if not done:\n",
      "        #         reward_prefix = -1\n",
      "        #     else:\n",
      "        #         reward = self.special_reward\n",
      "        # if agent.type == AgentType.Runner:\n",
      "        #     if done:\n",
      "        #         reward_prefix = -1\n",
      "        #         reward = self.special_reward\n",
      "        # reward = reward_prefix * reward\n",
      "        done = self.is_done()\n",
      "        reward = self._cal_reward(agent, target)\n",
      "        info = {}\n",
      "        self.state = [new_x, new_y, target.x, target.y]\n",
      "        if agent.type == AgentType.Chaser:\n",
      "            self.state.append(agent.direction)\n",
      "        agent.x, agent.y = new_x, new_y\n",
      "        return self.state, reward, done, info\n",
      "\n",
      "    def _cal_reward(self, chaser, runner):\n",
      "        \"\"\"\n",
      "        Calculate cahser's reward regard as distance of chaser and runner.\n",
      "        :param chaser: Chaser\n",
      "        :param runner: Runner\n",
      "        :return: reward\n",
      "        \"\"\"\n",
      "        return - 10 * math.sqrt(((chaser.x - runner.x) ** 2 + (chaser.y - runner.y) ** 2))\n",
      "\n",
      "    def reset(self):\n",
      "        chaser_x = self.width * random.random()\n",
      "        chaser_y = self.height * random.random()\n",
      "        runner_x = self.width * random.random()\n",
      "        runner_y = self.height * random.random()\n",
      "        chaser = self.agents[AgentType.Chaser]\n",
      "        runner = self.agents[AgentType.Runner]\n",
      "        chaser.x, chaser.y, runner.x, runner.y = chaser_x, chaser_y, runner_x, runner_y\n",
      "        self.state = [chaser_x, chaser_y, runner_x, runner_y, chaser.direction]\n",
      "        return self.state\n",
      "\n",
      "    def _wheel_move(self, x, y, r, direction, left_v, right_v):\n",
      "        \"\"\"\n",
      "        Get chaser's next position and direction.\n",
      "        :param x: chaser_x\n",
      "        :param y: chaser_y\n",
      "        :param direction: chaser's direction\n",
      "        :param left_v: left wheel vector\n",
      "        :param right_v: right wheel vector\n",
      "        :return: new_x, new_y, new_direction\n",
      "        \"\"\"\n",
      "        l1 = left_v / self.fps\n",
      "        l2 = right_v / self.fps\n",
      "        direct_rad = direction * self.radian2angle\n",
      "        if l1 == l2:\n",
      "            return x + l1 * math.cos(direct_rad), y + l1 * math.sin(direct_rad), direction\n",
      "        elif l1 > l2:\n",
      "            alpha = direction * self.radian2angle\n",
      "            theta = abs(l1 - l2) / (2 * r)\n",
      "            direction -= theta / self.radian2angle\n",
      "            if direction < -180:\n",
      "                direction += 360\n",
      "            tmp = (2 * r * min(l1, l2)) / abs(l1 - l2)\n",
      "            p_x = x + (r + tmp) * math.cos(math.pi / 2 - alpha)\n",
      "            p_y = y - (r + tmp) * math.sin(math.pi / 2 - alpha)\n",
      "            new_x = p_x + (r + tmp) * math.cos(math.pi / 2 + alpha - theta)\n",
      "            new_y = p_y + (r + tmp) * math.sin(math.pi / 2 + alpha - theta)\n",
      "            return new_x, new_y, direction\n",
      "        elif l1 < l2:\n",
      "            alpha = direction * self.radian2angle\n",
      "            theta = l2 / (2 * r)\n",
      "            direction += theta / self.radian2angle\n",
      "            if direction > 180:\n",
      "                direction -= 360\n",
      "            tmp = (2 * r * min(l1, l2)) / abs(l1 - l2)\n",
      "            p_x = x - (r + tmp) * math.cos(alpha - math.pi / 2)\n",
      "            p_y = y - (r + tmp) * math.sin(alpha - math.pi / 2)\n",
      "            new_x = p_x - (r + tmp) * math.cos(3 * math.pi / 2 - alpha - theta)\n",
      "            new_y = p_y + (r + tmp) * math.sin(3 * math.pi / 2 - alpha - theta)\n",
      "            return new_x, new_y, direction\n",
      "\n",
      "    def render(self, mode='human', close=False):\n",
      "        if close:\n",
      "            if self.viewer is not None:\n",
      "                self.viewer.close()\n",
      "                self.viewer = None\n",
      "            return\n",
      "\n",
      "        time.sleep(1 / self.fps)\n",
      "\n",
      "        chaser = self.agents[AgentType.Chaser]\n",
      "        runner = self.agents[AgentType.Runner]\n",
      "\n",
      "        if self.viewer is None:\n",
      "            from gym.envs.classic_control import rendering\n",
      "            self.viewer = rendering.Viewer(self.width, self.height)\n",
      "\n",
      "            # chaser circle object\n",
      "            chaser_obj = rendering.make_circle(chaser.r, 30, True)\n",
      "            chaser_obj.set_color(*chaser.color)\n",
      "            self.viewer.add_geom(chaser_obj)\n",
      "            self.chaser_trans = rendering.Transform()\n",
      "            chaser_obj.add_attr(self.chaser_trans)\n",
      "\n",
      "            # chaser wheel object\n",
      "            left_wheel = rendering.make_polygon([\n",
      "                (chaser.wheel_radius, chaser.r),\n",
      "                (chaser.wheel_radius, chaser.r + chaser.wheel_width),\n",
      "                (-chaser.wheel_radius, chaser.r + chaser.wheel_width),\n",
      "                (-chaser.wheel_radius, chaser.r)\n",
      "            ])\n",
      "            right_wheel = rendering.make_polygon([\n",
      "                (chaser.wheel_radius, -chaser.r - chaser.wheel_width),\n",
      "                (chaser.wheel_radius, -chaser.r),\n",
      "                (-chaser.wheel_radius, -chaser.r),\n",
      "                (-chaser.wheel_radius, -chaser.r - chaser.wheel_width)\n",
      "            ])\n",
      "            left_wheel.set_color(*chaser.left_wheel_color)\n",
      "            right_wheel.set_color(*chaser.right_wheel_color)\n",
      "            self.left_trans = rendering.Transform()\n",
      "            left_wheel.add_attr(self.left_trans)\n",
      "            self.right_trans = rendering.Transform()\n",
      "            right_wheel.add_attr(self.right_trans)\n",
      "            self.viewer.add_geom(left_wheel)\n",
      "            self.viewer.add_geom(right_wheel)\n",
      "\n",
      "            # direction arrow object\n",
      "            direct_obj = rendering.FilledPolygon([\n",
      "                (0.5 * chaser.r, 0.15 * chaser.r),\n",
      "                (chaser.r, 0),\n",
      "                (0.5 * chaser.r, -0.15 * chaser.r)\n",
      "            ])\n",
      "            self.line_trans = rendering.Transform()\n",
      "            direct_obj.set_color(1, 1, 1)\n",
      "            direct_obj.add_attr(self.line_trans)\n",
      "            self.viewer.add_geom(direct_obj)\n",
      "\n",
      "            # runner circle object\n",
      "            runner_obj = rendering.make_circle(runner.r, 30, True)\n",
      "            runner_obj.set_color(*runner.color)\n",
      "            self.viewer.add_geom(runner_obj)\n",
      "            self.runner_trans = rendering.Transform()\n",
      "            runner_obj.add_attr(self.runner_trans)\n",
      "\n",
      "        self.chaser_trans.set_translation(chaser.x, chaser.y)\n",
      "        self.runner_trans.set_translation(runner.x, runner.y)\n",
      "        self.line_trans.set_translation(chaser.x, chaser.y)\n",
      "        self.line_trans.set_rotation(chaser.direction * self.radian2angle)\n",
      "        self.left_trans.set_translation(chaser.x, chaser.y)\n",
      "        self.left_trans.set_rotation(chaser.direction * self.radian2angle)\n",
      "        self.right_trans.set_translation(chaser.x, chaser.y)\n",
      "        self.right_trans.set_rotation(chaser.direction * self.radian2angle)\n",
      "        return self.viewer.render(return_rgb_array=mode == 'rgb_array')\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    env = PuckWorldWheel(fps=60)\n",
      "    chaser = AgentWithWheel(50, 50, 30, (1, 0, 0), AgentType.Chaser)\n",
      "    runner = AgentWithWheel(300, 300, 30, (0, 0, 1), AgentType.Runner)\n",
      "\n",
      "    env.add_agent(chaser)\n",
      "    env.add_agent(runner)\n",
      "\n",
      "    env.reset()\n",
      "\n",
      "    for i in range(10000):\n",
      "        env.render()\n",
      "        if i % 2 == 0:\n",
      "            agent_type = AgentType.Chaser\n",
      "        else:\n",
      "            agent_type = AgentType.Runner\n",
      "        env.step(agent_type, env.action_space.sample())\n",
      "\n",
      "Output: {'puckworld_with_wheel': ['puckworld_with_wheel.PuckWorldWheel.render', '<builtin>.range', 'puckworld_with_wheel.PuckWorldWheel.step', 'puckworld_with_wheel.PuckWorldWheel.reset', 'puckworld_with_wheel.PuckWorldWheel.__init__', 'puck_world.envs.multi_agents.agent.AgentWithWheel', 'puckworld_with_wheel.PuckWorldWheel.add_agent'], 'puckworld_with_wheel.PuckWorldWheel.__init__': ['puckworld_with_wheel.PuckWorldWheel.seed', 'gym.spaces.Box', 'numpy.array'], 'numpy.array': [], 'gym.spaces.Box': [], 'puckworld_with_wheel.PuckWorldWheel.seed': ['gym.utils.seeding.np_random'], 'gym.utils.seeding.np_random': [], 'puckworld_with_wheel.PuckWorldWheel.add_agent': [], 'puckworld_with_wheel.PuckWorldWheel.__dis': ['math.sqrt'], 'math.sqrt': [], 'puckworld_with_wheel.PuckWorldWheel.is_done': ['puckworld_with_wheel.PuckWorldWheel.__dis', '<builtin>.min'], '<builtin>.min': [], 'puckworld_with_wheel.PuckWorldWheel.step': ['math.cos', '<builtin>.type', 'puckworld_with_wheel.PuckWorldWheel._cal_reward', 'puckworld_with_wheel.PuckWorldWheel._wheel_move', 'math.sin', 'puckworld_with_wheel.PuckWorldWheel.is_done'], '<builtin>.type': [], 'math.cos': [], 'math.sin': [], 'puckworld_with_wheel.PuckWorldWheel._wheel_move': ['math.sin', 'math.cos', '<builtin>.abs', '<builtin>.min'], 'puckworld_with_wheel.PuckWorldWheel._cal_reward': ['math.sqrt'], 'puckworld_with_wheel.PuckWorldWheel.reset': ['random.random'], 'random.random': [], '<builtin>.abs': [], 'puckworld_with_wheel.PuckWorldWheel.render': ['gym.envs.classic_control.rendering.FilledPolygon', 'gym.envs.classic_control.rendering.Viewer', 'gym.envs.classic_control.rendering.make_circle', 'gym.envs.classic_control.rendering.Transform', 'gym.envs.classic_control.rendering.make_polygon'], 'gym.envs.classic_control.rendering.Viewer': [], 'gym.envs.classic_control.rendering.make_circle': [], 'gym.envs.classic_control.rendering.Transform': [], 'gym.envs.classic_control.rendering.make_polygon': [], 'gym.envs.classic_control.rendering.FilledPolygon': [], 'puck_world.envs.multi_agents.agent.AgentWithWheel': [], '<builtin>.range': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\nicehiro_puck-world\\puck_world\\envs\\multi_agents\\puckworld_with_wheel.py\n",
      "[('puckworld_with_wheel', 'puckworld_with_wheel PuckWorldWheel render'), ('puckworld_with_wheel', 'puckworld_with_wheel PuckWorldWheel step'), ('puckworld_with_wheel', 'puckworld_with_wheel PuckWorldWheel reset'), ('puckworld_with_wheel', 'puckworld_with_wheel PuckWorldWheel __init__'), ('puckworld_with_wheel', 'puck_world envs multi_agents agent AgentWithWheel'), ('puckworld_with_wheel', 'puckworld_with_wheel PuckWorldWheel add_agent'), ('puckworld_with_wheel PuckWorldWheel __init__', 'puckworld_with_wheel PuckWorldWheel seed'), ('puckworld_with_wheel PuckWorldWheel __init__', 'gym spaces Box'), ('puckworld_with_wheel PuckWorldWheel __init__', 'numpy array'), ('puckworld_with_wheel PuckWorldWheel seed', 'gym utils seeding np_random'), ('puckworld_with_wheel PuckWorldWheel __dis', 'math sqrt'), ('puckworld_with_wheel PuckWorldWheel is_done', 'puckworld_with_wheel PuckWorldWheel __dis'), ('puckworld_with_wheel PuckWorldWheel step', 'math cos'), ('puckworld_with_wheel PuckWorldWheel step', 'puckworld_with_wheel PuckWorldWheel _cal_reward'), ('puckworld_with_wheel PuckWorldWheel step', 'puckworld_with_wheel PuckWorldWheel _wheel_move'), ('puckworld_with_wheel PuckWorldWheel step', 'math sin'), ('puckworld_with_wheel PuckWorldWheel step', 'puckworld_with_wheel PuckWorldWheel is_done'), ('puckworld_with_wheel PuckWorldWheel _wheel_move', 'math sin'), ('puckworld_with_wheel PuckWorldWheel _wheel_move', 'math cos'), ('puckworld_with_wheel PuckWorldWheel _cal_reward', 'math sqrt'), ('puckworld_with_wheel PuckWorldWheel reset', 'random random'), ('puckworld_with_wheel PuckWorldWheel render', 'gym envs classic_control rendering FilledPolygon'), ('puckworld_with_wheel PuckWorldWheel render', 'gym envs classic_control rendering Viewer'), ('puckworld_with_wheel PuckWorldWheel render', 'gym envs classic_control rendering make_circle'), ('puckworld_with_wheel PuckWorldWheel render', 'gym envs classic_control rendering Transform'), ('puckworld_with_wheel PuckWorldWheel render', 'gym envs classic_control rendering make_polygon')]\n",
      "0\n",
      "found files: []\n",
      "from setuptools import setup\n",
      "\n",
      "\n",
      "setup(\n",
      "    name='puck_world',\n",
      "    version='0.0.1',\n",
      "    install_requires=['gym', 'numpy']\n",
      ")\n",
      "Output: {'setup': ['setuptools.setup'], 'setuptools.setup': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\nicehiro_puck-world\\setup.py\n",
      "[('setup', 'setuptools setup')]\n",
      "0\n",
      "found files: []\n",
      "import math\n",
      "import random\n",
      "from enum import unique, Enum\n",
      "\n",
      "import gym\n",
      "from gym import spaces\n",
      "from gym.utils import seeding\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "class Entity():\n",
      "    def __init__(self):\n",
      "        self.type = None\n",
      "        self.name = None\n",
      "        self.state = None\n",
      "        self.movable = False\n",
      "        self.radius = None\n",
      "        self.color = None\n",
      "\n",
      "\n",
      "@unique\n",
      "class EntityType(Enum):\n",
      "    Agent = 0\n",
      "    Landmark = 1\n",
      "\n",
      "\n",
      "class Agent(Entity):\n",
      "    def __init__(self, name='agent'):\n",
      "        self.type = EntityType.Agent\n",
      "        self.name = name\n",
      "        # state info: [agent_x, agent_y]\n",
      "        self.state = [0, 0]\n",
      "        # vector info: [vector_x, vector_y]\n",
      "        self.vector = [0, 0]\n",
      "        self.vector_threshold = [-5, 5]\n",
      "        self.movable = True\n",
      "        self.radius = 0.3\n",
      "        self.unit = 100\n",
      "        self.color = (1.0, 0.0, 0.0)\n",
      "\n",
      "\n",
      "class Landmark(Entity):\n",
      "    def __init__(self, name='landmark'):\n",
      "        self.type = EntityType.Landmark\n",
      "        self.name = name\n",
      "        # state info: [mark_x, mark_y]\n",
      "        self.state = [0, 0]\n",
      "        self.movable = False\n",
      "        self.unit = 100\n",
      "        self.radius = 0.1\n",
      "        self.color = (0.0, 1.0, 0.0)\n",
      "\n",
      "\n",
      "class PuckWorld(gym.Env):\n",
      "    metadata = {\n",
      "        'render.modes': ['human', 'rgb_array'],\n",
      "        'video.frames_per_second': 30\n",
      "    }\n",
      "\n",
      "    def __init__(self):\n",
      "        self.width = 3\n",
      "        self.height = 3\n",
      "        self.unit = 100\n",
      "        self.time = 0\n",
      "        self.rewards = []\n",
      "        self.viewer = None\n",
      "        self.np_random = None\n",
      "        # action_space\n",
      "        # 0: left   1: right    2:up    3:down\n",
      "        self.action_space = spaces.Discrete(4)\n",
      "        self.observation_space = spaces.Box(low=np.array([0, 0, -5, -5, 0, 0]),\n",
      "                                            high=np.array([self.width, self.height, 5, 5, self.width, self.height]))\n",
      "        self.agent = Agent()\n",
      "        self.landmark = Landmark()\n",
      "        self.state = None\n",
      "        self.acclerate = 1\n",
      "        self.seed()\n",
      "\n",
      "    def seed(self, seed=None):\n",
      "        self.np_random, seed = seeding.np_random(seed)\n",
      "        return [seed]\n",
      "\n",
      "    def __dis(self, s_x, s_y, t_x, t_y):\n",
      "        return math.sqrt((s_x - t_x) ** 2 + (s_y - t_y) ** 2)\n",
      "\n",
      "    def __is_done(self):\n",
      "        return self.__dis(*self.agent.state, *self.landmark.state) \\\n",
      "               <= max(self.agent.radius, self.landmark.radius)\n",
      "\n",
      "    def step(self, action):\n",
      "        if action not in [0, 1, 2, 3]:\n",
      "            assert 'Wrong action!'\n",
      "        if action == 0:\n",
      "            # left\n",
      "            self.agent.vector[0] -= self.acclerate\n",
      "        elif action == 1:\n",
      "            # right\n",
      "            self.agent.vector[0] += self.acclerate\n",
      "        elif action == 2:\n",
      "            # up\n",
      "            self.agent.vector[1] += self.acclerate\n",
      "        elif action == 3:\n",
      "            # down\n",
      "            self.agent.vector[1] -= self.acclerate\n",
      "        self.__cal_real_vector()\n",
      "        self.agent.state[0] += self.agent.vector[0] / self.unit\n",
      "        self.agent.state[1] += self.agent.vector[1] / self.unit\n",
      "        if self.agent.state[0] < 0:\n",
      "            self.agent.state[0] = 0\n",
      "        if self.agent.state[0] > self.width:\n",
      "            self.agent.state[0] = self.width\n",
      "        if self.agent.state[1] < 0:\n",
      "            self.agent.state[1] = 0\n",
      "        if self.agent.state[1] > self.height:\n",
      "            self.agent.state[1] = self.height\n",
      "        self.state = self.__concat_state()\n",
      "        info = {}\n",
      "        return self.state, self.__get_reward(), self.__is_done(), info\n",
      "\n",
      "    def __get_reward(self):\n",
      "        if self.__is_done():\n",
      "            return 1\n",
      "        return - self.__dis(*self.agent.state, *self.landmark.state)\n",
      "\n",
      "    def __concat_state(self):\n",
      "        return self.agent.state + self.agent.vector + self.landmark.state\n",
      "\n",
      "    def __cal_real_vector(self):\n",
      "        for i in range(len(self.agent.vector)):\n",
      "            if self.agent.vector[i] < self.agent.vector_threshold[0]:\n",
      "                self.agent.vector[i] = self.agent.vector_threshold[0]\n",
      "            elif self.agent.vector[i] > self.agent.vector_threshold[1]:\n",
      "                self.agent.vector[i] = self.agent.vector_threshold[1]\n",
      "\n",
      "    def reset(self):\n",
      "        rand_wrap = lambda x: x * random.random()\n",
      "        self.landmark.state = list(map(rand_wrap, [self.width, self.height]))\n",
      "        self.state = self.__concat_state()\n",
      "        return self.state\n",
      "\n",
      "    def render(self, mode='human', close=False):\n",
      "        if close:\n",
      "            if self.viewer is not None:\n",
      "                self.viewer.close()\n",
      "                self.viewer = None\n",
      "            return\n",
      "        if self.viewer is None:\n",
      "            from gym.envs.classic_control import rendering\n",
      "            self.viewer = rendering.Viewer(self.width*self.unit, self.height*self.unit)\n",
      "            landmark = rendering.make_circle(self.landmark.radius*self.unit)\n",
      "            landmark.set_color(*self.landmark.color)\n",
      "            self.viewer.add_geom(landmark)\n",
      "            self.landmark_trans = rendering.Transform()\n",
      "            landmark.add_attr(self.landmark_trans)\n",
      "\n",
      "            agent_obj = rendering.make_circle(self.agent.radius*self.unit)\n",
      "            agent_obj.set_color(*self.agent.color)\n",
      "            self.viewer.add_geom(agent_obj)\n",
      "            self.agent_trans = rendering.Transform()\n",
      "            agent_obj.add_attr(self.agent_trans)\n",
      "        self.agent_trans.set_translation(*[x * self.unit for x in self.agent.state])\n",
      "        self.landmark_trans.set_translation(*[x * self.unit for x in self.landmark.state])\n",
      "        return self.viewer.render(return_rgb_array=mode == 'rgb_array')\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    env = PuckWorld()\n",
      "    for _ in range(100):\n",
      "        env.reset()\n",
      "        for _ in range(100):\n",
      "            env.render(close=False)\n",
      "            a = env.action_space.sample()\n",
      "            _, _, done, _ = env.step(a)\n",
      "            if done:\n",
      "                break\n",
      "\n",
      "Output: {'puckworld': ['<builtin>.range', 'puckworld.PuckWorld.step', 'puckworld.PuckWorld.render', 'puckworld.PuckWorld.reset', 'puckworld.PuckWorld.__init__'], 'puckworld.Entity.__init__': [], 'puckworld.Agent.__init__': [], 'puckworld.Landmark.__init__': [], 'puckworld.PuckWorld.__init__': ['gym.spaces.Discrete', 'puckworld.PuckWorld.seed', 'numpy.array', 'gym.spaces.Box', 'puckworld.Landmark.__init__', 'puckworld.Agent.__init__'], 'gym.spaces.Discrete': [], 'numpy.array': [], 'gym.spaces.Box': [], 'puckworld.PuckWorld.seed': ['gym.utils.seeding.np_random'], 'gym.utils.seeding.np_random': [], 'puckworld.PuckWorld.__dis': ['math.sqrt'], 'math.sqrt': [], 'puckworld.PuckWorld.__is_done': ['<builtin>.max', 'puckworld.PuckWorld.__dis'], '<builtin>.max': [], 'puckworld.PuckWorld.step': ['puckworld.PuckWorld.__get_reward', 'puckworld.PuckWorld.__cal_real_vector', 'puckworld.PuckWorld.__concat_state', 'puckworld.PuckWorld.__is_done'], 'puckworld.PuckWorld.__cal_real_vector': ['<builtin>.len', '<builtin>.range'], 'puckworld.PuckWorld.__concat_state': [], 'puckworld.PuckWorld.__get_reward': ['puckworld.PuckWorld.__is_done', 'puckworld.PuckWorld.__dis'], '<builtin>.len': [], '<builtin>.range': [], 'puckworld.PuckWorld.reset': ['<builtin>.list', '<builtin>.map', 'puckworld.PuckWorld.__concat_state'], 'puckworld.PuckWorld.reset.<lambda1>': ['random.random'], 'random.random': [], '<builtin>.map': [], '<builtin>.list': [], 'puckworld.PuckWorld.render': ['gym.envs.classic_control.rendering.Transform', 'gym.envs.classic_control.rendering.Viewer', 'gym.envs.classic_control.rendering.make_circle'], 'gym.envs.classic_control.rendering.Viewer': [], 'gym.envs.classic_control.rendering.make_circle': [], 'gym.envs.classic_control.rendering.Transform': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\nicehiro_puck-world\\puck_world\\envs\\single_agent\\puckworld.py\n",
      "[('puckworld', 'puckworld PuckWorld step'), ('puckworld', 'puckworld PuckWorld render'), ('puckworld', 'puckworld PuckWorld reset'), ('puckworld', 'puckworld PuckWorld __init__'), ('puckworld PuckWorld __init__', 'gym spaces Discrete'), ('puckworld PuckWorld __init__', 'puckworld PuckWorld seed'), ('puckworld PuckWorld __init__', 'numpy array'), ('puckworld PuckWorld __init__', 'gym spaces Box'), ('puckworld PuckWorld __init__', 'puckworld Landmark __init__'), ('puckworld PuckWorld __init__', 'puckworld Agent __init__'), ('puckworld PuckWorld seed', 'gym utils seeding np_random'), ('puckworld PuckWorld __dis', 'math sqrt'), ('puckworld PuckWorld __is_done', 'puckworld PuckWorld __dis'), ('puckworld PuckWorld step', 'puckworld PuckWorld __get_reward'), ('puckworld PuckWorld step', 'puckworld PuckWorld __cal_real_vector'), ('puckworld PuckWorld step', 'puckworld PuckWorld __concat_state'), ('puckworld PuckWorld step', 'puckworld PuckWorld __is_done'), ('puckworld PuckWorld __get_reward', 'puckworld PuckWorld __is_done'), ('puckworld PuckWorld __get_reward', 'puckworld PuckWorld __dis'), ('puckworld PuckWorld reset', 'puckworld PuckWorld __concat_state'), ('puckworld PuckWorld reset <lambda1>', 'random random'), ('puckworld PuckWorld render', 'gym envs classic_control rendering Transform'), ('puckworld PuckWorld render', 'gym envs classic_control rendering Viewer'), ('puckworld PuckWorld render', 'gym envs classic_control rendering make_circle')]\n",
      "0\n",
      "found files: []\n",
      "class Agent:\n",
      "    def __init__(self, init_x, init_y, radius, color, agent_type):\n",
      "        self.x = init_x\n",
      "        self.y = init_y\n",
      "        self.r = radius\n",
      "        self.color = color\n",
      "        self.type = agent_type\n",
      "\n",
      "    def act(self, state):\n",
      "        pass\n",
      "\n",
      "\n",
      "class AgentWithWheel(Agent):\n",
      "    def __init__(self, init_x, init_y, radius, color, agent_type):\n",
      "        super().__init__(init_x, init_y, radius, color, agent_type)\n",
      "        self.wheel_radius = 0.4 * radius\n",
      "        self.wheel_width = 0.1 * radius\n",
      "        self.left_wheel_color = (0, 0, 0)\n",
      "        self.right_wheel_color = (0, 0, 0)\n",
      "        # unit: px/s\n",
      "        self.left_v = 40\n",
      "        self.right_v = 20\n",
      "        # direction: 0~360\n",
      "        self.direction = 0\n",
      "        self.v_unit = 50\n",
      "\n",
      "    def set_left_v(self, left_v):\n",
      "        self.left_v = left_v * self.v_unit\n",
      "\n",
      "    def set_right_v(self, right_v):\n",
      "        self.right_v = right_v * self.v_unit\n",
      "\n",
      "    def act(self, state):\n",
      "        pass\n",
      "\n",
      "Output: {'agent': [], 'agent.Agent.__init__': [], 'agent.Agent.act': [], 'agent.AgentWithWheel.__init__': ['<builtin>.super'], '<builtin>.super': [], 'agent.AgentWithWheel.set_left_v': [], 'agent.AgentWithWheel.set_right_v': [], 'agent.AgentWithWheel.act': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\nicehiro_puck-world\\puck_world\\envs\\multi_agents\\agent.py\n",
      "[]\n",
      "found files: []\n",
      "from enum import Enum, unique\n",
      "\n",
      "\n",
      "@unique\n",
      "class AgentType(Enum):\n",
      "    \"\"\"Agent \n",
      "    \"\"\"\n",
      "    # \n",
      "    Chaser = 1\n",
      "    # \n",
      "    Runner = 2\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\nicehiro_puck-world\\puck_world\\envs\\multi_agents\\agent_type.py\n",
      "[]\n",
      "found files: []\n",
      "import math\n",
      "import random\n",
      "\n",
      "import gym\n",
      "import numpy as np\n",
      "from gym import spaces\n",
      "from gym.utils import seeding\n",
      "\n",
      "from puck_world.envs.multi_agents.agent import Agent\n",
      "from puck_world.envs.multi_agents.agent_type import AgentType\n",
      "\n",
      "\n",
      "class PuckWorld(gym.Env):\n",
      "    metadata = {\n",
      "        'render.modes': ['human', 'rgb_array'],\n",
      "        'video.frames_per_second': 30\n",
      "    }\n",
      "\n",
      "    def __init__(self):\n",
      "        self.width = 600\n",
      "        self.height = 600\n",
      "        self.len_unit = 1.0\n",
      "        self.vel = 20.0\n",
      "        self.runner_vel = 50.0\n",
      "        self.agents = {agent_type: None for agent_type in AgentType}\n",
      "        self.time = 0\n",
      "        self.rewards = []\n",
      "        self.viewer = None\n",
      "        self.radian2angle = math.pi / 180\n",
      "\n",
      "        self.np_random = None\n",
      "        self.action_space_bound = (-180, 180)\n",
      "        self.action_space = spaces.Box(np.array(self.action_space_bound[0]),\n",
      "                                       np.array(self.action_space_bound[1]))\n",
      "\n",
      "        self.normal_reward = 1\n",
      "        self.special_reward = 10\n",
      "\n",
      "        self.state = [0, 0, 0, 0]\n",
      "\n",
      "        self.seed()\n",
      "\n",
      "    def seed(self, seed=None):\n",
      "        self.np_random, seed = seeding.np_random(seed)\n",
      "        return [seed]\n",
      "\n",
      "    def add_agent(self, agent):\n",
      "        if agent.type == AgentType.Chaser:\n",
      "            self.agents[AgentType.Chaser] = agent\n",
      "        else:\n",
      "            self.agents[AgentType.Runner] = agent\n",
      "\n",
      "    def __dis(self, s_x, s_y, t_x, t_y):\n",
      "        return math.sqrt((s_x - t_x) ** 2 + (s_y - t_y) ** 2)\n",
      "\n",
      "    def is_done(self):\n",
      "        chaser = self.agents[AgentType.Chaser]\n",
      "        runner = self.agents[AgentType.Runner]\n",
      "        return self.__dis(chaser.x, chaser.y, runner.x, runner.y) <= min(chaser.r, runner.r)\n",
      "\n",
      "    def step(self, agent_type, action:int):\n",
      "        \"\"\"\n",
      "        Agent how to move based on action in this envs.\n",
      "\n",
      "        :param name: agent's name\n",
      "        :param action: agent's action\n",
      "        :return: next_state, reward, done, info\n",
      "        \"\"\"\n",
      "        assert self.action_space_bound[0] <= action <= self.action_space_bound[1], \\\n",
      "            '%r (%s) invalid' % (action, type(action))\n",
      "        agent = self.agents[agent_type]\n",
      "        if agent_type == AgentType.Chaser:\n",
      "            target = self.agents[AgentType.Runner]\n",
      "        else:\n",
      "            target = self.agents[AgentType.Chaser]\n",
      "        delta_x = self.vel * math.cos(action * self.radian2angle)\n",
      "        delta_y = self.vel * math.sin(action * self.radian2angle)\n",
      "        new_x, new_y = agent.x + delta_x, agent.y + delta_y\n",
      "\n",
      "        if new_x - agent.r <= 0:\n",
      "            new_x = agent.r\n",
      "        if new_x + agent.r >= self.width:\n",
      "            new_x = self.width - agent.r\n",
      "        if new_y - agent.r <= 0:\n",
      "            new_y = agent.r\n",
      "        if new_y + agent.r >= self.height:\n",
      "            new_y = self.height - agent.r\n",
      "\n",
      "        reward_prefix = 1\n",
      "        reward = self.normal_reward\n",
      "        done = self.is_done()\n",
      "        if agent.type == AgentType.Chaser:\n",
      "            if not done:\n",
      "                reward_prefix = -1\n",
      "            else:\n",
      "                reward = self.special_reward\n",
      "        if agent.type == AgentType.Runner:\n",
      "            if done:\n",
      "                reward_prefix = -1\n",
      "                reward = self.special_reward\n",
      "        reward = reward_prefix * reward\n",
      "        info = {}\n",
      "        self.state = [new_x, new_y, target.x, target.y]\n",
      "        agent.x, agent.y = new_x, new_y\n",
      "        return self.state, reward, done, info\n",
      "\n",
      "    def reset(self):\n",
      "        chaser_x = self.width * random.random()\n",
      "        chaser_y = self.height * random.random()\n",
      "        runner_x = self.width * random.random()\n",
      "        runner_y = self.height * random.random()\n",
      "        chaser = self.agents[AgentType.Chaser]\n",
      "        runner = self.agents[AgentType.Runner]\n",
      "        chaser.x, chaser.y, runner.x, runner.y = chaser_x, chaser_y, runner_x, runner_y\n",
      "        self.state = [chaser_x, chaser_y, runner_x, runner_y]\n",
      "        return self.state\n",
      "\n",
      "    def render(self, mode='human', close=False):\n",
      "        if close:\n",
      "            if self.viewer is not None:\n",
      "                self.viewer.close()\n",
      "                self.viewer = None\n",
      "            return\n",
      "\n",
      "        chaser = self.agents[AgentType.Chaser]\n",
      "        runner = self.agents[AgentType.Runner]\n",
      "\n",
      "        if self.viewer is None:\n",
      "            from gym.envs.classic_control import rendering\n",
      "            self.viewer = rendering.Viewer(self.width, self.height)\n",
      "\n",
      "            chaser_obj = rendering.make_circle(chaser.r, 30, True)\n",
      "            chaser_obj.set_color(*chaser.color)\n",
      "            self.viewer.add_geom(chaser_obj)\n",
      "            self.chaser_trans = rendering.Transform()\n",
      "            chaser_obj.add_attr(self.chaser_trans)\n",
      "\n",
      "            runner_obj = rendering.make_circle(runner.r, 30, True)\n",
      "            runner_obj.set_color(*runner.color)\n",
      "            self.viewer.add_geom(runner_obj)\n",
      "            self.runner_trans = rendering.Transform()\n",
      "            runner_obj.add_attr(self.runner_trans)\n",
      "\n",
      "        self.chaser_trans.set_translation(chaser.x, chaser.y)\n",
      "        self.runner_trans.set_translation(runner.x, runner.y)\n",
      "        return self.viewer.render(return_rgb_array=mode == 'rgb_array')\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    env = PuckWorld()\n",
      "    chaser = Agent(50, 50, 30, (1, 0, 0), AgentType.Chaser)\n",
      "    runner = Agent(500, 500, 30, (0, 0, 1), AgentType.Runner)\n",
      "\n",
      "    env.add_agent(chaser)\n",
      "    env.add_agent(runner)\n",
      "\n",
      "    env.reset()\n",
      "\n",
      "    for i in range(10000):\n",
      "        env.render()\n",
      "        if i % 2 == 0:\n",
      "            agent_type = AgentType.Chaser\n",
      "        else:\n",
      "            agent_type = AgentType.Runner\n",
      "        env.step(agent_type, env.action_space.sample())\n",
      "\n",
      "Output: {'puckworld': ['puckworld.PuckWorld.add_agent', 'puckworld.PuckWorld.reset', 'puckworld.PuckWorld.__init__', 'puckworld.PuckWorld.render', '<builtin>.range', 'puckworld.PuckWorld.step', 'puck_world.envs.multi_agents.agent.Agent'], 'puckworld.PuckWorld.__init__': ['numpy.array', 'puckworld.PuckWorld.seed', 'gym.spaces.Box'], 'numpy.array': [], 'gym.spaces.Box': [], 'puckworld.PuckWorld.seed': ['gym.utils.seeding.np_random'], 'gym.utils.seeding.np_random': [], 'puckworld.PuckWorld.add_agent': [], 'puckworld.PuckWorld.__dis': ['math.sqrt'], 'math.sqrt': [], 'puckworld.PuckWorld.is_done': ['<builtin>.min', 'puckworld.PuckWorld.__dis'], '<builtin>.min': [], 'puckworld.PuckWorld.step': ['<builtin>.type', 'math.sin', 'puckworld.PuckWorld.is_done', 'math.cos'], '<builtin>.type': [], 'math.cos': [], 'math.sin': [], 'puckworld.PuckWorld.reset': ['random.random'], 'random.random': [], 'puckworld.PuckWorld.render': ['gym.envs.classic_control.rendering.Viewer', 'gym.envs.classic_control.rendering.Transform', 'gym.envs.classic_control.rendering.make_circle'], 'gym.envs.classic_control.rendering.Viewer': [], 'gym.envs.classic_control.rendering.make_circle': [], 'gym.envs.classic_control.rendering.Transform': [], 'puck_world.envs.multi_agents.agent.Agent': [], '<builtin>.range': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\nicehiro_puck-world\\puck_world\\envs\\multi_agents\\puckworld.py\n",
      "[('puckworld', 'puckworld PuckWorld add_agent'), ('puckworld', 'puckworld PuckWorld reset'), ('puckworld', 'puckworld PuckWorld __init__'), ('puckworld', 'puckworld PuckWorld render'), ('puckworld', 'puckworld PuckWorld step'), ('puckworld', 'puck_world envs multi_agents agent Agent'), ('puckworld PuckWorld __init__', 'numpy array'), ('puckworld PuckWorld __init__', 'puckworld PuckWorld seed'), ('puckworld PuckWorld __init__', 'gym spaces Box'), ('puckworld PuckWorld seed', 'gym utils seeding np_random'), ('puckworld PuckWorld __dis', 'math sqrt'), ('puckworld PuckWorld is_done', 'puckworld PuckWorld __dis'), ('puckworld PuckWorld step', 'math sin'), ('puckworld PuckWorld step', 'puckworld PuckWorld is_done'), ('puckworld PuckWorld step', 'math cos'), ('puckworld PuckWorld reset', 'random random'), ('puckworld PuckWorld render', 'gym envs classic_control rendering Viewer'), ('puckworld PuckWorld render', 'gym envs classic_control rendering Transform'), ('puckworld PuckWorld render', 'gym envs classic_control rendering make_circle')]\n",
      "0\n",
      "found files: []\n",
      "import math\n",
      "import random\n",
      "from enum import unique, Enum\n",
      "\n",
      "import gym\n",
      "from gym import spaces\n",
      "from gym.utils import seeding\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "class Entity():\n",
      "    def __init__(self):\n",
      "        self.type = None\n",
      "        self.name = None\n",
      "        self.state = None\n",
      "        self.movable = False\n",
      "        self.radius = None\n",
      "        self.color = None\n",
      "\n",
      "\n",
      "@unique\n",
      "class EntityType(Enum):\n",
      "    Agent = 0\n",
      "    Landmark = 1\n",
      "\n",
      "\n",
      "class Agent(Entity):\n",
      "    def __init__(self, name='agent'):\n",
      "        self.type = EntityType.Agent\n",
      "        self.name = name\n",
      "        # state info: [agent_x, agent_y]\n",
      "        self.state = [150, 150]\n",
      "        # vector info: [vector_x, vector_y]\n",
      "        self.vector = [0, 0]\n",
      "        self.vector_threshold = [-5, 5]\n",
      "        self.accelerate = 2\n",
      "        self.movable = True\n",
      "        self.radius = 0.3\n",
      "        self.unit = 100\n",
      "        self.color = (1.0, 0.0, 0.0)\n",
      "\n",
      "    def update_vector(self, radian: float):\n",
      "        self.vector[0] += self.accelerate * math.cos(radian)\n",
      "        self.vector[1] += self.accelerate * math.sin(radian)\n",
      "        for i in range(len(self.vector)):\n",
      "            if self.vector[i] > self.vector_threshold[1]:\n",
      "                self.vector[i] = self.vector_threshold[1]\n",
      "            if self.vector[i] < self.vector_threshold[0]:\n",
      "                self.vector[i] = self.vector_threshold[0]\n",
      "\n",
      "    def update_state(self):\n",
      "        self.state[0] += self.vector[0] / self.unit\n",
      "        self.state[1] += self.vector[1] / self.unit\n",
      "\n",
      "\n",
      "class Landmark(Entity):\n",
      "    def __init__(self, name='landmark'):\n",
      "        self.type = EntityType.Landmark\n",
      "        self.name = name\n",
      "        # state info: [mark_x, mark_y]\n",
      "        self.state = [0, 0]\n",
      "        self.movable = False\n",
      "        self.radius = 0.1\n",
      "        self.unit = 100\n",
      "        self.color = (0.0, 1.0, 0.0)\n",
      "\n",
      "\n",
      "class PuckWorld(gym.Env):\n",
      "    metadata = {\n",
      "        'render.modes': ['human', 'rgb_array'],\n",
      "        'video.frames_per_second': 30\n",
      "    }\n",
      "\n",
      "    def __init__(self):\n",
      "        self.width = 3\n",
      "        self.height = 3\n",
      "        self.unit = 100\n",
      "        self.time = 0\n",
      "        self.rewards = []\n",
      "        self.viewer = None\n",
      "        self.np_random = None\n",
      "        # action_space\n",
      "        # (-pi, pi)\n",
      "        self.action_space = spaces.Box(low=np.array([-math.pi]),\n",
      "                                       high=np.array([math.pi]))\n",
      "        # observation space\n",
      "        # (agent_x, agent_y, agent_v_x, agent_v_y, mark_x, mark_y)\n",
      "        self.observation_space = spaces.Box(low=np.array([0, 0, -5, -5, 0, 0]),\n",
      "                                            high=np.array([3, 3, 5, 5, 3, 3]),\n",
      "                                            dtype=np.float)\n",
      "        self.agent = Agent()\n",
      "        self.landmark = Landmark()\n",
      "        self.state = None\n",
      "        # self.seed()\n",
      "\n",
      "    def seed(self, seed=None):\n",
      "        self.np_random, seed = seeding.np_random(seed)\n",
      "        return [seed]\n",
      "\n",
      "    def __dis(self, s_x, s_y, t_x, t_y):\n",
      "        return math.sqrt((s_x - t_x) ** 2 + (s_y - t_y) ** 2)\n",
      "\n",
      "    def __is_done(self):\n",
      "        return self.__dis(*self.agent.state, *self.landmark.state) \\\n",
      "               <= max(self.agent.radius, self.landmark.radius)\n",
      "\n",
      "    def step(self, action):\n",
      "        action = action[0]\n",
      "        self.agent.update_vector(action)\n",
      "        self.agent.update_state()\n",
      "        if self.agent.state[0] < 0:\n",
      "            self.agent.state[0] = 0\n",
      "        if self.agent.state[0] > self.width:\n",
      "            self.agent.state[0] = self.width\n",
      "        if self.agent.state[1] < 0:\n",
      "            self.agent.state[1] = 0\n",
      "        if self.agent.state[1] > self.height:\n",
      "            self.agent.state[1] = self.height\n",
      "        self.state = self.__concat_state()\n",
      "        info = {}\n",
      "        return self.state, self.__get_reward(), self.__is_done(), info\n",
      "\n",
      "    def __get_reward(self):\n",
      "        reward = 1 - math.exp(1e-2 * self.__dis(*self.agent.state, *self.landmark.state))\n",
      "        return reward\n",
      "\n",
      "    def __concat_state(self):\n",
      "        return self.agent.state + self.agent.vector + self.landmark.state\n",
      "\n",
      "    def reset(self):\n",
      "        rand_wrap = lambda x: x * random.random()\n",
      "        self.landmark.state = list(map(rand_wrap, [self.width, self.height]))\n",
      "        self.state = self.__concat_state()\n",
      "        return self.state\n",
      "\n",
      "    def render(self, mode='human', close=False):\n",
      "        if close:\n",
      "            if self.viewer is not None:\n",
      "                self.viewer.close()\n",
      "                self.viewer = None\n",
      "            return\n",
      "        if self.viewer is None:\n",
      "            from gym.envs.classic_control import rendering\n",
      "            self.viewer = rendering.Viewer(self.width*self.unit, self.height*self.unit)\n",
      "            landmark = rendering.make_circle(self.landmark.radius*self.unit)\n",
      "            landmark.set_color(*self.landmark.color)\n",
      "            self.viewer.add_geom(landmark)\n",
      "            self.landmark_trans = rendering.Transform()\n",
      "            landmark.add_attr(self.landmark_trans)\n",
      "\n",
      "            agent_obj = rendering.make_circle(self.agent.radius*self.unit)\n",
      "            agent_obj.set_color(*self.agent.color)\n",
      "            self.viewer.add_geom(agent_obj)\n",
      "            self.agent_trans = rendering.Transform()\n",
      "            agent_obj.add_attr(self.agent_trans)\n",
      "        self.agent_trans.set_translation(*[x * self.unit for x in self.agent.state])\n",
      "        self.landmark_trans.set_translation(*[x * self.unit for x in self.landmark.state])\n",
      "        return self.viewer.render(return_rgb_array=mode == 'rgb_array')\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    env = PuckWorld()\n",
      "    for _ in range(100):\n",
      "        env.reset()\n",
      "        for _ in range(100):\n",
      "            env.render(close=False)\n",
      "            a = env.action_space.sample()\n",
      "            _, _, done, _ = env.step(a.item())\n",
      "            if done:\n",
      "                break\n",
      "\n",
      "Output: {'puckworld_continuous': ['puckworld_continuous.PuckWorld.reset', 'puckworld_continuous.PuckWorld.__init__', 'puckworld_continuous.PuckWorld.render', 'puckworld_continuous.PuckWorld.step', '<builtin>.range'], 'puckworld_continuous.Entity.__init__': [], 'puckworld_continuous.Agent.__init__': [], 'puckworld_continuous.Agent.update_vector': ['<builtin>.range', 'math.sin', '<builtin>.len', 'math.cos'], 'math.cos': [], 'math.sin': [], '<builtin>.len': [], '<builtin>.range': [], 'puckworld_continuous.Agent.update_state': [], 'puckworld_continuous.Landmark.__init__': [], 'puckworld_continuous.PuckWorld.__init__': ['gym.spaces.Box', 'numpy.array', 'puckworld_continuous.Agent.__init__', 'puckworld_continuous.Landmark.__init__'], 'numpy.array': [], 'gym.spaces.Box': [], 'puckworld_continuous.PuckWorld.seed': ['gym.utils.seeding.np_random'], 'gym.utils.seeding.np_random': [], 'puckworld_continuous.PuckWorld.__dis': ['math.sqrt'], 'math.sqrt': [], 'puckworld_continuous.PuckWorld.__is_done': ['puckworld_continuous.PuckWorld.__dis', '<builtin>.max'], '<builtin>.max': [], 'puckworld_continuous.PuckWorld.step': ['puckworld_continuous.PuckWorld.__is_done', 'puckworld_continuous.Agent.update_state', 'puckworld_continuous.Agent.update_vector', 'puckworld_continuous.PuckWorld.__concat_state', 'puckworld_continuous.PuckWorld.__get_reward'], 'puckworld_continuous.PuckWorld.__concat_state': [], 'puckworld_continuous.PuckWorld.__get_reward': ['math.exp', 'puckworld_continuous.PuckWorld.__dis'], 'math.exp': [], 'puckworld_continuous.PuckWorld.reset': ['puckworld_continuous.PuckWorld.__concat_state', '<builtin>.list', '<builtin>.map'], 'puckworld_continuous.PuckWorld.reset.<lambda1>': ['random.random'], 'random.random': [], '<builtin>.map': [], '<builtin>.list': [], 'puckworld_continuous.PuckWorld.render': ['gym.envs.classic_control.rendering.Transform', 'gym.envs.classic_control.rendering.make_circle', 'gym.envs.classic_control.rendering.Viewer'], 'gym.envs.classic_control.rendering.Viewer': [], 'gym.envs.classic_control.rendering.make_circle': [], 'gym.envs.classic_control.rendering.Transform': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\nicehiro_puck-world\\puck_world\\envs\\single_agent\\puckworld_continuous.py\n",
      "[('puckworld_continuous', 'puckworld_continuous PuckWorld reset'), ('puckworld_continuous', 'puckworld_continuous PuckWorld __init__'), ('puckworld_continuous', 'puckworld_continuous PuckWorld render'), ('puckworld_continuous', 'puckworld_continuous PuckWorld step'), ('puckworld_continuous Agent update_vector', 'math sin'), ('puckworld_continuous Agent update_vector', 'math cos'), ('puckworld_continuous PuckWorld __init__', 'gym spaces Box'), ('puckworld_continuous PuckWorld __init__', 'numpy array'), ('puckworld_continuous PuckWorld __init__', 'puckworld_continuous Agent __init__'), ('puckworld_continuous PuckWorld __init__', 'puckworld_continuous Landmark __init__'), ('puckworld_continuous PuckWorld seed', 'gym utils seeding np_random'), ('puckworld_continuous PuckWorld __dis', 'math sqrt'), ('puckworld_continuous PuckWorld __is_done', 'puckworld_continuous PuckWorld __dis'), ('puckworld_continuous PuckWorld step', 'puckworld_continuous PuckWorld __is_done'), ('puckworld_continuous PuckWorld step', 'puckworld_continuous Agent update_state'), ('puckworld_continuous PuckWorld step', 'puckworld_continuous Agent update_vector'), ('puckworld_continuous PuckWorld step', 'puckworld_continuous PuckWorld __concat_state'), ('puckworld_continuous PuckWorld step', 'puckworld_continuous PuckWorld __get_reward'), ('puckworld_continuous PuckWorld __get_reward', 'math exp'), ('puckworld_continuous PuckWorld __get_reward', 'puckworld_continuous PuckWorld __dis'), ('puckworld_continuous PuckWorld reset', 'puckworld_continuous PuckWorld __concat_state'), ('puckworld_continuous PuckWorld reset <lambda1>', 'random random'), ('puckworld_continuous PuckWorld render', 'gym envs classic_control rendering Transform'), ('puckworld_continuous PuckWorld render', 'gym envs classic_control rendering make_circle'), ('puckworld_continuous PuckWorld render', 'gym envs classic_control rendering Viewer')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('puckworld_with_wheel', 'puckworld_with_wheel PuckWorldWheel render'), ('puckworld_with_wheel', 'puckworld_with_wheel PuckWorldWheel step'), ('puckworld_with_wheel', 'puckworld_with_wheel PuckWorldWheel reset'), ('puckworld_with_wheel', 'puckworld_with_wheel PuckWorldWheel __init__'), ('puckworld_with_wheel', 'puck_world envs multi_agents agent AgentWithWheel'), ('puckworld_with_wheel', 'puckworld_with_wheel PuckWorldWheel add_agent'), ('puckworld_with_wheel PuckWorldWheel __init__', 'puckworld_with_wheel PuckWorldWheel seed'), ('puckworld_with_wheel PuckWorldWheel __init__', 'gym spaces Box'), ('puckworld_with_wheel PuckWorldWheel __init__', 'numpy array'), ('puckworld_with_wheel PuckWorldWheel seed', 'gym utils seeding np_random'), ('puckworld_with_wheel PuckWorldWheel __dis', 'math sqrt'), ('puckworld_with_wheel PuckWorldWheel is_done', 'puckworld_with_wheel PuckWorldWheel __dis'), ('puckworld_with_wheel PuckWorldWheel step', 'math cos'), ('puckworld_with_wheel PuckWorldWheel step', 'puckworld_with_wheel PuckWorldWheel _cal_reward'), ('puckworld_with_wheel PuckWorldWheel step', 'puckworld_with_wheel PuckWorldWheel _wheel_move'), ('puckworld_with_wheel PuckWorldWheel step', 'math sin'), ('puckworld_with_wheel PuckWorldWheel step', 'puckworld_with_wheel PuckWorldWheel is_done'), ('puckworld_with_wheel PuckWorldWheel _wheel_move', 'math sin'), ('puckworld_with_wheel PuckWorldWheel _wheel_move', 'math cos'), ('puckworld_with_wheel PuckWorldWheel _cal_reward', 'math sqrt'), ('puckworld_with_wheel PuckWorldWheel reset', 'random random'), ('puckworld_with_wheel PuckWorldWheel render', 'gym envs classic_control rendering FilledPolygon'), ('puckworld_with_wheel PuckWorldWheel render', 'gym envs classic_control rendering Viewer'), ('puckworld_with_wheel PuckWorldWheel render', 'gym envs classic_control rendering make_circle'), ('puckworld_with_wheel PuckWorldWheel render', 'gym envs classic_control rendering Transform'), ('puckworld_with_wheel PuckWorldWheel render', 'gym envs classic_control rendering make_polygon')], [('setup', 'setuptools setup')], [('puckworld', 'puckworld PuckWorld step'), ('puckworld', 'puckworld PuckWorld render'), ('puckworld', 'puckworld PuckWorld reset'), ('puckworld', 'puckworld PuckWorld __init__'), ('puckworld PuckWorld __init__', 'gym spaces Discrete'), ('puckworld PuckWorld __init__', 'puckworld PuckWorld seed'), ('puckworld PuckWorld __init__', 'numpy array'), ('puckworld PuckWorld __init__', 'gym spaces Box'), ('puckworld PuckWorld __init__', 'puckworld Landmark __init__'), ('puckworld PuckWorld __init__', 'puckworld Agent __init__'), ('puckworld PuckWorld seed', 'gym utils seeding np_random'), ('puckworld PuckWorld __dis', 'math sqrt'), ('puckworld PuckWorld __is_done', 'puckworld PuckWorld __dis'), ('puckworld PuckWorld step', 'puckworld PuckWorld __get_reward'), ('puckworld PuckWorld step', 'puckworld PuckWorld __cal_real_vector'), ('puckworld PuckWorld step', 'puckworld PuckWorld __concat_state'), ('puckworld PuckWorld step', 'puckworld PuckWorld __is_done'), ('puckworld PuckWorld __get_reward', 'puckworld PuckWorld __is_done'), ('puckworld PuckWorld __get_reward', 'puckworld PuckWorld __dis'), ('puckworld PuckWorld reset', 'puckworld PuckWorld __concat_state'), ('puckworld PuckWorld reset <lambda1>', 'random random'), ('puckworld PuckWorld render', 'gym envs classic_control rendering Transform'), ('puckworld PuckWorld render', 'gym envs classic_control rendering Viewer'), ('puckworld PuckWorld render', 'gym envs classic_control rendering make_circle')], [('puckworld', 'puckworld PuckWorld add_agent'), ('puckworld', 'puckworld PuckWorld reset'), ('puckworld', 'puckworld PuckWorld __init__'), ('puckworld', 'puckworld PuckWorld render'), ('puckworld', 'puckworld PuckWorld step'), ('puckworld', 'puck_world envs multi_agents agent Agent'), ('puckworld PuckWorld __init__', 'numpy array'), ('puckworld PuckWorld __init__', 'puckworld PuckWorld seed'), ('puckworld PuckWorld __init__', 'gym spaces Box'), ('puckworld PuckWorld seed', 'gym utils seeding np_random'), ('puckworld PuckWorld __dis', 'math sqrt'), ('puckworld PuckWorld is_done', 'puckworld PuckWorld __dis'), ('puckworld PuckWorld step', 'math sin'), ('puckworld PuckWorld step', 'puckworld PuckWorld is_done'), ('puckworld PuckWorld step', 'math cos'), ('puckworld PuckWorld reset', 'random random'), ('puckworld PuckWorld render', 'gym envs classic_control rendering Viewer'), ('puckworld PuckWorld render', 'gym envs classic_control rendering Transform'), ('puckworld PuckWorld render', 'gym envs classic_control rendering make_circle')], [('puckworld_continuous', 'puckworld_continuous PuckWorld reset'), ('puckworld_continuous', 'puckworld_continuous PuckWorld __init__'), ('puckworld_continuous', 'puckworld_continuous PuckWorld render'), ('puckworld_continuous', 'puckworld_continuous PuckWorld step'), ('puckworld_continuous Agent update_vector', 'math sin'), ('puckworld_continuous Agent update_vector', 'math cos'), ('puckworld_continuous PuckWorld __init__', 'gym spaces Box'), ('puckworld_continuous PuckWorld __init__', 'numpy array'), ('puckworld_continuous PuckWorld __init__', 'puckworld_continuous Agent __init__'), ('puckworld_continuous PuckWorld __init__', 'puckworld_continuous Landmark __init__'), ('puckworld_continuous PuckWorld seed', 'gym utils seeding np_random'), ('puckworld_continuous PuckWorld __dis', 'math sqrt'), ('puckworld_continuous PuckWorld __is_done', 'puckworld_continuous PuckWorld __dis'), ('puckworld_continuous PuckWorld step', 'puckworld_continuous PuckWorld __is_done'), ('puckworld_continuous PuckWorld step', 'puckworld_continuous Agent update_state'), ('puckworld_continuous PuckWorld step', 'puckworld_continuous Agent update_vector'), ('puckworld_continuous PuckWorld step', 'puckworld_continuous PuckWorld __concat_state'), ('puckworld_continuous PuckWorld step', 'puckworld_continuous PuckWorld __get_reward'), ('puckworld_continuous PuckWorld __get_reward', 'math exp'), ('puckworld_continuous PuckWorld __get_reward', 'puckworld_continuous PuckWorld __dis'), ('puckworld_continuous PuckWorld reset', 'puckworld_continuous PuckWorld __concat_state'), ('puckworld_continuous PuckWorld reset <lambda1>', 'random random'), ('puckworld_continuous PuckWorld render', 'gym envs classic_control rendering Transform'), ('puckworld_continuous PuckWorld render', 'gym envs classic_control rendering make_circle'), ('puckworld_continuous PuckWorld render', 'gym envs classic_control rendering Viewer')]]\n",
      "********************doctrings*************************\n",
      "['', '', '', '', '']\n",
      "embed index dataset: 18\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\CUN-bjy_gym-ddpg-keras\\\\utils\\\\noise_process.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\CUN-bjy_gym-ddpg-keras\\\\agent\\\\actor.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\CUN-bjy_gym-ddpg-keras\\\\utils\\\\memory_buffer.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\CUN-bjy_gym-ddpg-keras\\\\utils\\\\sumtree.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\CUN-bjy_gym-ddpg-keras\\\\env_test.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\CUN-bjy_gym-ddpg-keras\\\\play.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\CUN-bjy_gym-ddpg-keras\\\\train.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\CUN-bjy_gym-ddpg-keras\\\\agent\\\\ddpg.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\CUN-bjy_gym-ddpg-keras\\\\agent\\\\critic.py']\n",
      "import numpy as np\n",
      "class OrnsteinUhlenbeckProcess(object):\n",
      "    \"\"\" Ornstein-Uhlenbeck Noise (original code by @slowbull)\n",
      "    \"\"\"\n",
      "    def __init__(self, theta=0.15, mu=0, sigma=0.2, x0=0, dt=1e-2, n_steps_annealing=100, size=1):\n",
      "        self.theta = theta\n",
      "        self.sigma = sigma\n",
      "        self.n_steps_annealing = n_steps_annealing\n",
      "        self.sigma_step = - self.sigma / float(self.n_steps_annealing)\n",
      "        self.x0 = x0\n",
      "        self.mu = mu\n",
      "        self.dt = dt\n",
      "        self.size = size\n",
      "\n",
      "    def generate(self, step):\n",
      "        sigma = max(0, self.sigma_step * step + self.sigma)\n",
      "        x = self.x0 + self.theta * (self.mu - self.x0) * self.dt + sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n",
      "        self.x0 = x\n",
      "        return x\n",
      "\n",
      "Output: {'noise_process': [], 'noise_process.OrnsteinUhlenbeckProcess.__init__': ['<builtin>.float'], '<builtin>.float': [], 'noise_process.OrnsteinUhlenbeckProcess.generate': ['numpy.random.normal', 'numpy.sqrt', '<builtin>.max'], '<builtin>.max': [], 'numpy.sqrt': [], 'numpy.random.normal': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\CUN-bjy_gym-ddpg-keras\\utils\\noise_process.py\n",
      "[('noise_process OrnsteinUhlenbeckProcess generate', 'numpy random normal'), ('noise_process OrnsteinUhlenbeckProcess generate', 'numpy sqrt')]\n",
      "0\n",
      "found files: []\n",
      "'''\n",
      "MIT License\n",
      "\n",
      "Copyright (c) 2020 Junyoeb Baek\n",
      "\n",
      "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
      "of this software and associated documentation files (the \"Software\"), to deal\n",
      "in the Software without restriction, including without limitation the rights\n",
      "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
      "copies of the Software, and to permit persons to whom the Software is\n",
      "furnished to do so, subject to the following conditions:\n",
      "\n",
      "The above copyright notice and this permission notice shall be included in all\n",
      "copies or substantial portions of the Software.\n",
      "\n",
      "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
      "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
      "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
      "SOFTWARE.\n",
      "'''\n",
      "\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "import keras.backend as K\n",
      "\n",
      "from keras.initializers import GlorotNormal\n",
      "from keras.models import Model\n",
      "from keras.optimizers import Adam\n",
      "from keras.layers import Input, Dense, BatchNormalization, Activation, Lambda\n",
      "\n",
      "\n",
      "class ActorNet():\n",
      "\t\"\"\" Actor Network for DDPG\n",
      "\t\"\"\"\n",
      "\tdef __init__(self, in_dim, out_dim, act_range, lr_, tau_):\n",
      "\t\tself.obs_dim = in_dim\n",
      "\t\tself.act_dim = out_dim\n",
      "\t\tself.act_range = act_range\n",
      "\t\tself.lr = lr_; self.tau = tau_\n",
      "\n",
      "\t\t# initialize actor network and target\n",
      "\t\tself.network = self.create_network()\n",
      "\t\tself.target_network = self.create_network()\n",
      "\n",
      "\t\t# initialize optimizer\n",
      "\t\tself.optimizer = Adam(self.lr)\n",
      "\n",
      "\t\t# copy the weights for initialization\n",
      "\t\tweights_ = self.network.get_weights()\n",
      "\t\tself.target_network.set_weights(weights_)\n",
      "\n",
      "\n",
      "\tdef create_network(self):\n",
      "\t\t\"\"\" Create a Actor Network Model using Keras\n",
      "\t\t\"\"\"\n",
      "\t\t# input layer(observations)\n",
      "\t\tinput_ = Input(shape=self.obs_dim)\n",
      "\n",
      "\t\t# hidden layer 1\n",
      "\t\th1_ = Dense(300,kernel_initializer=GlorotNormal())(input_)\n",
      "\t\th1_b = BatchNormalization()(h1_)\n",
      "\t\th1 = Activation('relu')(h1_b)\n",
      "\n",
      "\t\t# hidden_layer 2\n",
      "\t\th2_ = Dense(400,kernel_initializer=GlorotNormal())(h1)\n",
      "\t\th2_b = BatchNormalization()(h2_)\n",
      "\t\th2 = Activation('relu')(h2_b)\n",
      "\n",
      "\t\t# output layer(actions)\n",
      "\t\toutput_ = Dense(self.act_dim,kernel_initializer=GlorotNormal())(h2)\n",
      "\t\toutput_b = BatchNormalization()(output_)\n",
      "\t\toutput = Activation('tanh')(output_b)\n",
      "\t\tscalar = self.act_range * np.ones(self.act_dim)\n",
      "\t\tout = Lambda(lambda i: i * scalar)(output)\n",
      "\n",
      "\t\treturn Model(input_,out)\n",
      "\n",
      "\tdef train(self, obs, critic, q_grads):\n",
      "\t\t\"\"\" training Actor's Weights\n",
      "\t\t\"\"\"\n",
      "\t\twith tf.GradientTape() as tape:\n",
      "\t\t\tactions = self.network(obs)\n",
      "\t\t\tactor_loss = -tf.reduce_mean(critic([obs,actions]))\n",
      "\t\t\t# actor_grad = tape.gradient(self.network(obs), self.network.trainable_variables,-q_grads)\n",
      "\t\tactor_grad = tape.gradient(actor_loss,self.network.trainable_variables)\n",
      "\t\tself.optimizer.apply_gradients(zip(actor_grad,self.network.trainable_variables))\n",
      "\n",
      "\tdef target_update(self):\n",
      "\t\t\"\"\" soft target update for training target actor network\n",
      "\t\t\"\"\"\n",
      "\t\tweights, weights_t = self.network.get_weights(), self.target_network.get_weights()\n",
      "\t\tfor i in range(len(weights)):\n",
      "\t\t\tweights_t[i] = self.tau*weights[i] + (1-self.tau)*weights_t[i]\n",
      "\t\tself.target_network.set_weights(weights_t)\n",
      "\n",
      "\tdef predict(self, obs):\n",
      "\t\t\"\"\" predict function for Actor Network\n",
      "\t\t\"\"\"\n",
      "\t\treturn self.network.predict(np.expand_dims(obs, axis=0))\n",
      "\n",
      "\tdef target_predict(self, new_obs):\n",
      "\t\t\"\"\"  predict function for Target Actor Network\n",
      "\t\t\"\"\"\n",
      "\t\treturn self.target_network.predict(new_obs)\n",
      "\n",
      "\tdef save_network(self, path):\n",
      "\t\tself.network.save_weights(path + '_actor.h5')\n",
      "\t\tself.target_network.save_weights(path +'_actor_t.h5')\n",
      "\n",
      "\tdef load_network(self, path):\n",
      "\t\tself.network.load_weights(path + '_actor.h5')\n",
      "\t\tself.target_network.load_weights(path + '_actor_t.h5')\n",
      "\t\tprint(self.network.summary())\n",
      "\n",
      "\n",
      "# for test\n",
      "if __name__ == '__main__':\n",
      "\tactor = ActorNet()\n",
      "Output: {'actor': ['actor.ActorNet.__init__'], 'actor.ActorNet.__init__': ['actor.ActorNet.create_network', 'keras.optimizers.Adam'], 'actor.ActorNet.create_network': ['keras.layers.Activation', 'keras.layers.Dense', 'keras.models.Model', 'keras.layers.Input', 'keras.initializers.GlorotNormal', 'keras.layers.BatchNormalization', 'numpy.ones', 'keras.layers.Lambda'], 'keras.optimizers.Adam': [], 'keras.layers.Input': [], 'keras.initializers.GlorotNormal': [], 'keras.layers.Dense': [], 'keras.layers.BatchNormalization': [], 'keras.layers.Activation': [], 'numpy.ones': [], 'actor.ActorNet.create_network.<lambda1>': [], 'keras.layers.Lambda': [], 'keras.models.Model': [], 'actor.ActorNet.train': ['<builtin>.zip', 'tensorflow.GradientTape', 'tensorflow.reduce_mean'], 'tensorflow.GradientTape': [], 'tensorflow.reduce_mean': [], '<builtin>.zip': [], 'actor.ActorNet.target_update': ['<builtin>.range', '<builtin>.len'], '<builtin>.len': [], '<builtin>.range': [], 'actor.ActorNet.predict': ['numpy.expand_dims'], 'numpy.expand_dims': [], 'actor.ActorNet.target_predict': [], 'actor.ActorNet.save_network': [], 'actor.ActorNet.load_network': ['<builtin>.print'], '<builtin>.print': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\CUN-bjy_gym-ddpg-keras\\agent\\actor.py\n",
      "[('actor', 'actor ActorNet __init__'), ('actor ActorNet __init__', 'actor ActorNet create_network'), ('actor ActorNet __init__', 'keras optimizers Adam'), ('actor ActorNet create_network', 'keras layers Activation'), ('actor ActorNet create_network', 'keras layers Dense'), ('actor ActorNet create_network', 'keras models Model'), ('actor ActorNet create_network', 'keras layers Input'), ('actor ActorNet create_network', 'keras initializers GlorotNormal'), ('actor ActorNet create_network', 'keras layers BatchNormalization'), ('actor ActorNet create_network', 'numpy ones'), ('actor ActorNet create_network', 'keras layers Lambda'), ('actor ActorNet train', 'tensorflow GradientTape'), ('actor ActorNet train', 'tensorflow reduce_mean'), ('actor ActorNet predict', 'numpy expand_dims')]\n",
      "0\n",
      "found files: []\n",
      "import random\n",
      "import numpy as np\n",
      "\n",
      "from collections import deque\n",
      "from .sumtree import SumTree\n",
      "\n",
      "class MemoryBuffer(object):\n",
      "    \"\"\" Memory Buffer Helper class for Experience Replay\n",
      "    using a double-ended queue or a Sum Tree (for PER)\n",
      "    \"\"\"\n",
      "    def __init__(self, buffer_size, with_per = False):\n",
      "        \"\"\" Initialization\n",
      "        \"\"\"\n",
      "        if(with_per):\n",
      "            # Prioritized Experience Replay(propositional)\n",
      "            self.alpha = 0.5\n",
      "            self.epsilon = 0.01\n",
      "            self.buffer = SumTree(buffer_size)\n",
      "        else:\n",
      "            # Standard Buffer\n",
      "            self.buffer = deque()\n",
      "        self.count = 0\n",
      "        self.with_per = with_per\n",
      "        self.buffer_size = buffer_size\n",
      "\n",
      "    def memorize(self, state, action, reward, done, new_state, error=None):\n",
      "        \"\"\" Save an experience to memory, optionally with its TD-Error\n",
      "        \"\"\"\n",
      "\n",
      "        experience = (state, action, reward, done, new_state)\n",
      "        if(self.with_per):\n",
      "            priority = self.priority(error[0])\n",
      "            self.buffer.add(priority, experience)\n",
      "            self.count += 1\n",
      "        else:\n",
      "            # Check if buffer is already full\n",
      "            if self.count < self.buffer_size:\n",
      "                self.buffer.append(experience)\n",
      "                self.count += 1\n",
      "            else:\n",
      "                self.buffer.popleft()\n",
      "                self.buffer.append(experience)\n",
      "\n",
      "    def priority(self, error):\n",
      "        \"\"\" Compute an experience priority, as per Schaul et al.\n",
      "        \"\"\"\n",
      "        return (error + self.epsilon) ** self.alpha\n",
      "\n",
      "    def size(self):\n",
      "        \"\"\" Current Buffer Occupation\n",
      "        \"\"\"\n",
      "        return self.count\n",
      "\n",
      "    def sample_batch(self, batch_size):\n",
      "        \"\"\" Sample a batch, optionally with (PER)\n",
      "        \"\"\"\n",
      "        batch = []\n",
      "\n",
      "        # Sample using prorities\n",
      "        if(self.with_per):\n",
      "            T = self.buffer.total() / batch_size\n",
      "            for i in range(batch_size):\n",
      "                a, b = T * i, T * (i + 1)\n",
      "                s = random.uniform(a, b)\n",
      "                idx, error, data = self.buffer.get(s)\n",
      "                batch.append((*data, idx))\n",
      "            idx = np.array([i[5] for i in batch])\n",
      "        # Sample randomly from Buffer\n",
      "        elif self.count < batch_size:\n",
      "            idx = None\n",
      "            batch = random.sample(self.buffer, self.count)\n",
      "        else:\n",
      "            idx = None\n",
      "            batch = random.sample(self.buffer, batch_size)\n",
      "\n",
      "        # Return a batch of experience\n",
      "        s_batch = np.array([i[0] for i in batch])\n",
      "        a_batch = np.array([i[1] for i in batch])\n",
      "        r_batch = np.array([i[2] for i in batch])\n",
      "        d_batch = np.array([i[3] for i in batch])\n",
      "        new_s_batch = np.array([i[4] for i in batch])\n",
      "        return s_batch, a_batch, r_batch, d_batch, new_s_batch, idx\n",
      "\n",
      "    def update(self, idx, new_error):\n",
      "        \"\"\" Update priority for idx (PER)\n",
      "        \"\"\"\n",
      "        self.buffer.update(idx, self.priority(new_error))\n",
      "\n",
      "    def clear(self):\n",
      "        \"\"\" Clear buffer / Sum Tree\n",
      "        \"\"\"\n",
      "        if(self.with_per): self.buffer = SumTree(buffer_size)\n",
      "        else: self.buffer = deque()\n",
      "        self.count = 0\n",
      "\n",
      "Output: {'memory_buffer': [], 'memory_buffer.MemoryBuffer.__init__': ['collections.deque', 'sumtree.SumTree'], 'sumtree.SumTree': [], 'collections.deque': [], 'memory_buffer.MemoryBuffer.memorize': ['memory_buffer.MemoryBuffer.priority'], 'memory_buffer.MemoryBuffer.priority': [], 'memory_buffer.MemoryBuffer.size': [], 'memory_buffer.MemoryBuffer.sample_batch': ['<builtin>.range', 'random.sample', 'numpy.array', 'random.uniform'], '<builtin>.range': [], 'random.uniform': [], 'numpy.array': [], 'random.sample': [], 'memory_buffer.MemoryBuffer.update': ['memory_buffer.MemoryBuffer.priority'], 'memory_buffer.MemoryBuffer.clear': ['collections.deque', 'sumtree.SumTree']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\CUN-bjy_gym-ddpg-keras\\utils\\memory_buffer.py\n",
      "[('memory_buffer MemoryBuffer __init__', 'collections deque'), ('memory_buffer MemoryBuffer __init__', 'sumtree SumTree'), ('memory_buffer MemoryBuffer memorize', 'memory_buffer MemoryBuffer priority'), ('memory_buffer MemoryBuffer sample_batch', 'random sample'), ('memory_buffer MemoryBuffer sample_batch', 'numpy array'), ('memory_buffer MemoryBuffer sample_batch', 'random uniform'), ('memory_buffer MemoryBuffer update', 'memory_buffer MemoryBuffer priority'), ('memory_buffer MemoryBuffer clear', 'collections deque'), ('memory_buffer MemoryBuffer clear', 'sumtree SumTree')]\n",
      "0\n",
      "found files: []\n",
      "import numpy\n",
      "\n",
      "\n",
      "# SumTree\n",
      "# a binary tree data structure where the parents value is the sum of its children\n",
      "class SumTree:\n",
      "    write = 0\n",
      "\n",
      "    def __init__(self, capacity):\n",
      "        self.capacity = capacity\n",
      "        self.tree = numpy.zeros(2 * capacity - 1)\n",
      "        self.data = numpy.zeros(capacity, dtype=object)\n",
      "        self.n_entries = 0\n",
      "\n",
      "    # update to the root node\n",
      "    def _propagate(self, idx, change):\n",
      "        parent = (idx - 1) // 2\n",
      "\n",
      "        self.tree[parent] += change\n",
      "\n",
      "        if parent != 0:\n",
      "            self._propagate(parent, change)\n",
      "\n",
      "    # find sample on leaf node\n",
      "    def _retrieve(self, idx, s):\n",
      "        left = 2 * idx + 1\n",
      "        right = left + 1\n",
      "\n",
      "        if left >= len(self.tree):\n",
      "            return idx\n",
      "\n",
      "        if s <= self.tree[left]:\n",
      "            return self._retrieve(left, s)\n",
      "        else:\n",
      "            return self._retrieve(right, s - self.tree[left])\n",
      "\n",
      "    def total(self):\n",
      "        return self.tree[0]\n",
      "\n",
      "    # store priority and sample\n",
      "    def add(self, p, data):\n",
      "        idx = self.write + self.capacity - 1\n",
      "\n",
      "        self.data[self.write] = data\n",
      "        self.update(idx, p)\n",
      "\n",
      "        self.write += 1\n",
      "        if self.write >= self.capacity:\n",
      "            self.write = 0\n",
      "\n",
      "        if self.n_entries < self.capacity:\n",
      "            self.n_entries += 1\n",
      "\n",
      "    # update priority\n",
      "    def update(self, idx, p):\n",
      "        change = p - self.tree[idx]\n",
      "\n",
      "        self.tree[idx] = p\n",
      "        self._propagate(idx, change)\n",
      "\n",
      "    # get priority and sample\n",
      "    def get(self, s):\n",
      "        idx = self._retrieve(0, s)\n",
      "        dataIdx = idx - self.capacity + 1\n",
      "\n",
      "        return (idx, self.tree[idx], self.data[dataIdx])\n",
      "Output: {'sumtree': [], 'sumtree.SumTree.__init__': ['numpy.zeros'], 'numpy.zeros': [], 'sumtree.SumTree._propagate': ['sumtree.SumTree._propagate'], 'sumtree.SumTree._retrieve': ['sumtree.SumTree._retrieve', '<builtin>.len'], '<builtin>.len': [], 'sumtree.SumTree.total': [], 'sumtree.SumTree.add': ['sumtree.SumTree.update'], 'sumtree.SumTree.update': ['sumtree.SumTree._propagate'], 'sumtree.SumTree.get': ['sumtree.SumTree._retrieve']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\CUN-bjy_gym-ddpg-keras\\utils\\sumtree.py\n",
      "[('sumtree SumTree __init__', 'numpy zeros'), ('sumtree SumTree _propagate', 'sumtree SumTree _propagate'), ('sumtree SumTree _retrieve', 'sumtree SumTree _retrieve'), ('sumtree SumTree add', 'sumtree SumTree update'), ('sumtree SumTree update', 'sumtree SumTree _propagate'), ('sumtree SumTree get', 'sumtree SumTree _retrieve')]\n",
      "0\n",
      "found files: []\n",
      "import roboschool\n",
      "import gym\n",
      "\n",
      "env = gym.make('RoboschoolAnt-v1')\n",
      "env.reset()\n",
      "while True:\n",
      "    env.step(env.action_space.sample())\n",
      "    env.render()\n",
      "Output: {'env_test': ['gym.make'], 'gym.make': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\CUN-bjy_gym-ddpg-keras\\env_test.py\n",
      "[('env_test', 'gym make')]\n",
      "0\n",
      "found files: []\n",
      "'''\n",
      "MIT License\n",
      "\n",
      "Copyright (c) 2020 Junyoeb Baek\n",
      "\n",
      "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
      "of this software and associated documentation files (the \"Software\"), to deal\n",
      "in the Software without restriction, including without limitation the rights\n",
      "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
      "copies of the Software, and to permit persons to whom the Software is\n",
      "furnished to do so, subject to the following conditions:\n",
      "\n",
      "The above copyright notice and this permission notice shall be included in all\n",
      "copies or substantial portions of the Software.\n",
      "\n",
      "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
      "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
      "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
      "SOFTWARE.\n",
      "'''\n",
      "\n",
      "# Implementation of DDPG(Deep Deterministic Policy Gradient) \n",
      "# on OpenAI gym framwork\n",
      "\n",
      "\n",
      "import roboschool, gym\n",
      "import numpy as np, time, os\n",
      "from tqdm import tqdm\n",
      "\n",
      "import argparse\n",
      "\n",
      "from agent.ddpg import ddpgAgent\n",
      "\n",
      "NUM_EPISODES_ = 1000\n",
      "\n",
      "def model_play(pretrained_):\n",
      "\t# Create Environments\n",
      "\tmodels = {\t'cheetah':\"RoboschoolHalfCheetah-v1\",\n",
      "\t\t\t\t'ant':'RoboschoolAnt-v1',\n",
      "\t\t\t\t'pong':\"RoboschoolPong-v1\",\n",
      "\t\t\t\t'walker':\"RoboschoolWalker2d-v1\",\n",
      "\t\t\t\t'hopper':\"RoboschoolHopper-v1\",\n",
      "\t\t\t\t'humanoid':\"RoboschoolHumanoid-v1\",\n",
      "\t\t\t\t'humanoidflag':\"RoboschoolHumanoidFlagrun-v1\"}\n",
      "\t\n",
      "\tenv = gym.make(models['ant'])\n",
      "\t\n",
      "\t# Create Agent model\n",
      "\tagent = ddpgAgent(env)\n",
      "\n",
      "\tif not pretrained_ == None:\n",
      "\t\tagent.load_weights(pretrained_)\n",
      "\n",
      "\t# Initialize Environments\n",
      "\tsteps = env._max_episode_steps # steps per episode\n",
      "\tnum_act_ = env.action_space.shape[0]\n",
      "\tnum_obs_ = env.observation_space.shape[0]\n",
      "\tprint(\"============ENVIRONMENT===============\")\n",
      "\tprint(\"num_of_action_spaces : %d\"%num_act_)\n",
      "\tprint(\"num_of_observation_spaces: %d\"%num_obs_)\t\n",
      "\tprint(\"max_steps_per_episode: %d\"%steps)\n",
      "\tprint(\"======================================\")\n",
      "\n",
      "\n",
      "\ttry:\n",
      "\t\tact_range = env.action_space.high\n",
      "\t\tfor epi in range(NUM_EPISODES_):\n",
      "\t\t\tobs = env.reset()\n",
      "\t\t\tactions, states, rewards, dones, new_states = [],[],[],[],[]\n",
      "\n",
      "\t\t\tepi_reward = 0\n",
      "\t\t\twhile True:\n",
      "\t\t\t\t# environment rendering on Graphics\n",
      "\t\t\t\tenv.render()\n",
      "\t\t\t\t\n",
      "\t\t\t\t# Make action from the current policy\n",
      "\t\t\t\taction = agent.make_action(obs)#env.action_space.sample()#\n",
      "\n",
      "\t\t\t\t# do step on gym at t-time\n",
      "\t\t\t\tnew_obs, reward, done, info = env.step(action) \n",
      "\n",
      "\t\t\t\t# grace finish and go to t+1 time\n",
      "\t\t\t\tobs = new_obs\n",
      "\t\t\t\tepi_reward = epi_reward + reward\n",
      "\n",
      "\t\t\t\tif done: break\n",
      "\n",
      "\n",
      "\texcept KeyboardInterrupt as e:\n",
      "\t\tprint(e)\n",
      "\tfinally:\n",
      "\t\tenv.close()\n",
      "\n",
      "\n",
      "argparser = argparse.ArgumentParser(\n",
      "\tdescription='Train DDPG Agent on the openai gym')\n",
      "\n",
      "argparser.add_argument(\n",
      "\t'-w',\t'--weights',help='path to pretrained weights')\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\t#################################\n",
      "\t#   Parse Configurations\n",
      "\t#################################\n",
      "\n",
      "\targs = argparser.parse_args()\n",
      "\tweights_path = args.weights\n",
      "\t\n",
      "\tmodel_play(pretrained_=weights_path)\n",
      "\n",
      "Output: {'play': ['argparse.ArgumentParser', 'play.model_play'], 'play.model_play': ['agent.ddpg.ddpgAgent', '<builtin>.print', 'gym.make', '<builtin>.range'], 'gym.make': [], 'agent.ddpg.ddpgAgent': [], '<builtin>.print': [], '<builtin>.range': [], 'argparse.ArgumentParser': [], 'agent': [], 'agent.ddpg': [], 'agent.ddpg.ddpgAgent.__init__': ['utils.memory_buffer.MemoryBuffer', 'utils.noise_process.OrnsteinUhlenbeckProcess', 'critic.CriticNet', 'actor.ActorNet'], 'actor.ActorNet': [], 'critic.CriticNet': [], 'utils.memory_buffer.MemoryBuffer': [], 'utils.noise_process.OrnsteinUhlenbeckProcess': [], 'agent.ddpg.ddpgAgent.make_action': ['numpy.clip'], 'numpy.clip': [], 'agent.ddpg.ddpgAgent.update_networks': [], 'agent.ddpg.ddpgAgent.replay': ['numpy.asarray', '<builtin>.range', '<builtin>.abs'], 'numpy.asarray': [], '<builtin>.abs': [], 'agent.ddpg.ddpgAgent.memorize': ['numpy.expand_dims', '<builtin>.abs'], 'numpy.expand_dims': [], 'agent.ddpg.ddpgAgent.sample_batch': [], 'agent.ddpg.ddpgAgent.save_weights': [], 'agent.ddpg.ddpgAgent.load_weights': [], 'agent.critic': [], 'agent.critic.CriticNet.__init__': ['keras.optimizers.Adam', 'agent.critic.CriticNet.create_network'], 'agent.critic.CriticNet.create_network': ['keras.regularizers.l2', 'keras.models.Model', 'keras.layers.Input', 'keras.layers.BatchNormalization', 'keras.layers.Concatenate', 'keras.initializers.GlorotNormal', 'keras.layers.Dense', 'keras.layers.Activation'], 'keras.optimizers.Adam': [], 'keras.layers.Input': [], 'keras.layers.Concatenate': [], 'keras.initializers.GlorotNormal': [], 'keras.regularizers.l2': [], 'keras.layers.Dense': [], 'keras.layers.BatchNormalization': [], 'keras.layers.Activation': [], 'keras.models.Model': [], 'agent.critic.CriticNet.Qgradient': ['tensorflow.squeeze', 'tensorflow.GradientTape', 'tensorflow.convert_to_tensor'], 'tensorflow.convert_to_tensor': [], 'tensorflow.GradientTape': [], 'tensorflow.squeeze': [], 'agent.critic.CriticNet.train': ['<builtin>.float', '<builtin>.zip', 'tensorflow.reduce_mean', 'tensorflow.GradientTape', 'tensorflow.print', 'tensorflow.math.square'], 'tensorflow.math.square': [], 'tensorflow.reduce_mean': [], 'tensorflow.print': [], '<builtin>.float': [], '<builtin>.zip': [], 'agent.critic.CriticNet.predict': [], 'agent.critic.CriticNet.target_predict': [], 'agent.critic.CriticNet.target_update': ['<builtin>.range', '<builtin>.len'], '<builtin>.len': [], 'agent.critic.CriticNet.save_network': [], 'agent.critic.CriticNet.load_network': ['<builtin>.print'], 'utils.memory_buffer': [], 'utils.memory_buffer.MemoryBuffer.__init__': ['sumtree.SumTree', 'collections.deque'], 'sumtree.SumTree': [], 'collections.deque': [], 'utils.memory_buffer.MemoryBuffer.memorize': [], 'utils.memory_buffer.MemoryBuffer.priority': [], 'utils.memory_buffer.MemoryBuffer.size': [], 'utils.memory_buffer.MemoryBuffer.sample_batch': ['numpy.array', 'random.uniform', 'random.sample', '<builtin>.range'], 'random.uniform': [], 'numpy.array': [], 'random.sample': [], 'utils.memory_buffer.MemoryBuffer.update': [], 'utils.memory_buffer.MemoryBuffer.clear': ['sumtree.SumTree', 'collections.deque'], 'utils.sumtree': [], 'utils.sumtree.SumTree.__init__': ['numpy.zeros'], 'numpy.zeros': [], 'utils.sumtree.SumTree._propagate': ['utils.sumtree.SumTree._propagate'], 'utils.sumtree.SumTree._retrieve': ['utils.sumtree.SumTree._retrieve', '<builtin>.len'], 'utils.sumtree.SumTree.total': [], 'utils.sumtree.SumTree.add': ['utils.sumtree.SumTree.update'], 'utils.sumtree.SumTree.update': ['utils.sumtree.SumTree._propagate'], 'utils.sumtree.SumTree.get': ['utils.sumtree.SumTree._retrieve'], 'utils.noise_process': [], 'utils.noise_process.OrnsteinUhlenbeckProcess.__init__': ['<builtin>.float'], 'utils.noise_process.OrnsteinUhlenbeckProcess.generate': ['numpy.sqrt', '<builtin>.max', 'numpy.random.normal'], '<builtin>.max': [], 'numpy.sqrt': [], 'numpy.random.normal': [], 'utils': [], 'agent.actor': ['agent.actor.ActorNet.__init__'], 'agent.actor.ActorNet.__init__': ['agent.actor.ActorNet.create_network', 'keras.optimizers.Adam'], 'agent.actor.ActorNet.create_network': ['numpy.ones', 'keras.models.Model', 'keras.layers.Input', 'keras.layers.BatchNormalization', 'keras.layers.Lambda', 'keras.initializers.GlorotNormal', 'keras.layers.Dense', 'keras.layers.Activation'], 'numpy.ones': [], 'agent.actor.ActorNet.create_network.<lambda1>': [], 'keras.layers.Lambda': [], 'agent.actor.ActorNet.train': ['<builtin>.zip', 'tensorflow.reduce_mean', 'tensorflow.GradientTape'], 'agent.actor.ActorNet.target_update': ['<builtin>.range', '<builtin>.len'], 'agent.actor.ActorNet.predict': ['numpy.expand_dims'], 'agent.actor.ActorNet.target_predict': [], 'agent.actor.ActorNet.save_network': [], 'agent.actor.ActorNet.load_network': ['<builtin>.print']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\CUN-bjy_gym-ddpg-keras\\play.py\n",
      "[('play', 'argparse ArgumentParser'), ('play', 'play model_play'), ('play model_play', 'agent ddpg ddpgAgent'), ('play model_play', 'gym make'), ('agent ddpg ddpgAgent __init__', 'utils memory_buffer MemoryBuffer'), ('agent ddpg ddpgAgent __init__', 'utils noise_process OrnsteinUhlenbeckProcess'), ('agent ddpg ddpgAgent __init__', 'critic CriticNet'), ('agent ddpg ddpgAgent __init__', 'actor ActorNet'), ('agent ddpg ddpgAgent make_action', 'numpy clip'), ('agent ddpg ddpgAgent replay', 'numpy asarray'), ('agent ddpg ddpgAgent memorize', 'numpy expand_dims'), ('agent critic CriticNet __init__', 'keras optimizers Adam'), ('agent critic CriticNet __init__', 'agent critic CriticNet create_network'), ('agent critic CriticNet create_network', 'keras regularizers l2'), ('agent critic CriticNet create_network', 'keras models Model'), ('agent critic CriticNet create_network', 'keras layers Input'), ('agent critic CriticNet create_network', 'keras layers BatchNormalization'), ('agent critic CriticNet create_network', 'keras layers Concatenate'), ('agent critic CriticNet create_network', 'keras initializers GlorotNormal'), ('agent critic CriticNet create_network', 'keras layers Dense'), ('agent critic CriticNet create_network', 'keras layers Activation'), ('agent critic CriticNet Qgradient', 'tensorflow squeeze'), ('agent critic CriticNet Qgradient', 'tensorflow GradientTape'), ('agent critic CriticNet Qgradient', 'tensorflow convert_to_tensor'), ('agent critic CriticNet train', 'tensorflow reduce_mean'), ('agent critic CriticNet train', 'tensorflow GradientTape'), ('agent critic CriticNet train', 'tensorflow print'), ('agent critic CriticNet train', 'tensorflow math square'), ('utils memory_buffer MemoryBuffer __init__', 'sumtree SumTree'), ('utils memory_buffer MemoryBuffer __init__', 'collections deque')]\n",
      "0\n",
      "found files: []\n",
      "'''\n",
      "MIT License\n",
      "\n",
      "Copyright (c) 2020 Junyoeb Baek\n",
      "\n",
      "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
      "of this software and associated documentation files (the \"Software\"), to deal\n",
      "in the Software without restriction, including without limitation the rights\n",
      "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
      "copies of the Software, and to permit persons to whom the Software is\n",
      "furnished to do so, subject to the following conditions:\n",
      "\n",
      "The above copyright notice and this permission notice shall be included in all\n",
      "copies or substantial portions of the Software.\n",
      "\n",
      "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
      "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
      "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
      "SOFTWARE.\n",
      "'''\n",
      "\n",
      "# Implementation of DDPG(Deep Deterministic Policy Gradient) \n",
      "# on OpenAI gym framwork\n",
      "\n",
      "\n",
      "import roboschool, gym\n",
      "import numpy as np, time, os\n",
      "from tqdm import tqdm\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import pandas as pd\n",
      "\n",
      "import argparse\n",
      "\n",
      "from agent.ddpg import ddpgAgent\n",
      "\n",
      "NUM_EPISODES_ = 20000\n",
      "\n",
      "def model_train(pretrained_):\n",
      "\t# Create Environments\n",
      "\tmodels = {\t'cartpole':\"CartPole-v1\",\n",
      "\t\t\t\t'pendulum':\"RoboschoolInvertedPendulum-v1\",\n",
      "\t\t\t\t'cheetah':\"RoboschoolHalfCheetah-v1\",\n",
      "\t\t\t\t'walker':\"RoboschoolWalker2d-v1\",\n",
      "\t\t\t\t'hopper':\"RoboschoolHopper-v1\"}\n",
      "\t\n",
      "\tenv = gym.make(models['hopper'])\n",
      "\t\n",
      "\ttry:\n",
      "\t\t# Ensure action bound is symmetric\n",
      "\t\tassert (np.all(env.action_space.high+env.action_space.low) == 0)\n",
      "\t\tis_discrete = False\n",
      "\t\tprint('Continuous Action Space')\n",
      "\texcept AttributeError:\n",
      "\t\tis_discrete = True\n",
      "\t\tprint('Discrete Action Space')\n",
      "\n",
      "\t# Create Agent model\n",
      "\tagent = ddpgAgent(env, batch_size=128, w_per=False, is_discrete=is_discrete)\n",
      "\n",
      "\tif not pretrained_ == None:\n",
      "\t\tagent.load_weights(pretrained_)\n",
      "\n",
      "\t# Initialize Environments\n",
      "\tsteps = 500#env._max_episode_steps # steps per episode\n",
      "\tnum_act_ = env.action_space.n if is_discrete else env.action_space.shape[0]\n",
      "\tnum_obs_ = env.observation_space.shape[0]\n",
      "\tprint(\"============ENVIRONMENT===============\")\n",
      "\tprint(\"num_of_action_spaces : %d\"%num_act_)\n",
      "\tprint(\"num_of_observation_spaces: %d\"%num_obs_)\t\n",
      "\tprint(\"max_steps_per_episode: %d\"%steps)\n",
      "\tprint(\"======================================\")\n",
      "\n",
      "\n",
      "\tlogger = dict(episode=[],reward=[],critic_loss=[])\n",
      "\tplt.ion()\n",
      "\tfig1 = plt.figure(1);\tfig2 = plt.figure(2)\n",
      "\tax1 = fig1.add_subplot(111)\n",
      "\tax2 = fig2.add_subplot(111)\n",
      "\n",
      "\n",
      "\ttry:\n",
      "\t\tact_range = (env.action_space.high - env.action_space.low) / 2 if not is_discrete else 1.\n",
      "\t\trewards = []; critic_losses = []\n",
      "\t\tmax_reward = 0\n",
      "\t\tfor epi in range(NUM_EPISODES_):\n",
      "\t\t\tprint(\"=========EPISODE # %d ==========\"%epi)\n",
      "\t\t\tobs = env.reset()\n",
      "\n",
      "\t\t\tepi_reward = 0\n",
      "\t\t\tfor t in tqdm(range(steps)):\n",
      "\t\t\t\tplt.pause(0.01)\n",
      "\t\t\t\t# environment rendering on Graphics\n",
      "\t\t\t\tenv.render()\n",
      "\t\t\t\t\n",
      "\t\t\t\t# Make action from the current policy\n",
      "\t\t\t\ta = agent.make_action(obs, t)#env.action_space.sample()#\n",
      "\t\t\t\taction = np.argmax(a) if is_discrete else a\n",
      "\n",
      "\t\t\t\t# do step on gym at t-time\n",
      "\t\t\t\tnew_obs, reward, done, info = env.step(action) \n",
      "\n",
      "\t\t\t\t# store the results to buffer\t\n",
      "\t\t\t\tagent.memorize(obs, a, reward, done, new_obs)\n",
      "\n",
      "\t\t\t\t# grace finish and go to t+1 time\n",
      "\t\t\t\tobs = new_obs\n",
      "\t\t\t\tepi_reward = epi_reward + reward\n",
      "\n",
      "\t\t\t\tagent.replay(1)\n",
      "\n",
      "\t\t\t\t# check if the episode is finished\n",
      "\t\t\t\tif done or (t == steps-1):\n",
      "\t\t\t\t\tprint(\"Episode#%d, steps:%d, rewards:%f\"%(epi,t,epi_reward))\n",
      "\t\t\t\t\t# agent.replay(1)\n",
      "\n",
      "\t\t\t\t\t# save weights at the new records performance\n",
      "\t\t\t\t\tif epi_reward >= max_reward:\n",
      "\t\t\t\t\t\tmax_reward = epi_reward\n",
      "\t\t\t\t\t\tdir_path = \"%s/weights\"%os.getcwd()\n",
      "\t\t\t\t\t\tif not os.path.isdir(dir_path):\n",
      "\t\t\t\t\t\t\tos.mkdir(dir_path)\n",
      "\t\t\t\t\t\tpath = dir_path+'/'+'gym_ddpg_'\n",
      "\t\t\t\t\t\tagent.save_weights(path + 'ep%d_%f'%(epi,max_reward))\n",
      "\n",
      "\n",
      "\t\t\t\t\t# save reward logs\n",
      "\t\t\t\t\tax1.cla(); ax2.cla();\n",
      "\t\t\t\t\tlogger['episode'] = range(epi+1)\n",
      "\t\t\t\t\tlogger['reward'].append(epi_reward)\n",
      "\t\t\t\t\tlogger['critic_loss'].append(agent.critic.critic_loss)\n",
      "\n",
      "\t\t\t\t\tdf = pd.DataFrame(logger)\n",
      "\t\t\t\t\tsns.lineplot(ax=ax1,x='episode',y='reward', data=df)\n",
      "\t\t\t\t\tsns.lineplot(ax=ax2,x='episode',y='critic_loss', data=df)\n",
      "\t\t\t\t\tbreak;\n",
      "\n",
      "\texcept KeyboardInterrupt as e: print(e)\n",
      "\tfinally:\n",
      "\t\t# weight saver\n",
      "\t\tdir_path = \"%s/weights\"%os.getcwd()\n",
      "\t\tif not os.path.isdir(dir_path):\n",
      "\t\t\tos.mkdir(dir_path)\n",
      "\t\tpath = dir_path+'/'+'gym_ddpg_'\n",
      "\t\tagent.save_weights(path +'lastest')\n",
      "\t\tenv.close()\n",
      "\n",
      "\t\t# log saver\n",
      "\t\timport pickle\n",
      "\t\tpickle.dump(logger,open(path+'%s.log'%time.time(),'wb'))\n",
      "\n",
      "\n",
      "argparser = argparse.ArgumentParser(\n",
      "\tdescription='Train DDPG Agent on the openai gym')\n",
      "\n",
      "argparser.add_argument(\n",
      "\t'-w',\t'--weights',help='path to pretrained weights')\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\t#################################\n",
      "\t#   Parse Configurations\n",
      "\t#################################\n",
      "\n",
      "\targs = argparser.parse_args()\n",
      "\tweights_path = args.weights\n",
      "\t\n",
      "\tmodel_train(pretrained_=weights_path)\n",
      "\n",
      "Output: {'train': ['train.model_train', 'argparse.ArgumentParser'], 'train.model_train': ['matplotlib.pyplot.pause', 'os.getcwd', 'numpy.all', 'seaborn.lineplot', 'matplotlib.pyplot.figure', 'gym.make', 'matplotlib.pyplot.ion', '<builtin>.open', 'os.mkdir', '<builtin>.print', '<builtin>.dict', '<builtin>.range', 'tqdm.tqdm', 'agent.ddpg.ddpgAgent', 'time.time', 'pickle.dump', 'os.path.isdir', 'pandas.DataFrame', 'numpy.argmax'], 'gym.make': [], 'numpy.all': [], '<builtin>.print': [], 'agent.ddpg.ddpgAgent': [], '<builtin>.dict': [], 'matplotlib.pyplot.ion': [], 'matplotlib.pyplot.figure': [], '<builtin>.range': [], 'tqdm.tqdm': [], 'matplotlib.pyplot.pause': [], 'numpy.argmax': [], 'os.getcwd': [], 'os.path.isdir': [], 'os.mkdir': [], 'pandas.DataFrame': [], 'seaborn.lineplot': [], 'time.time': [], '<builtin>.open': [], 'pickle.dump': [], 'argparse.ArgumentParser': [], 'agent.ddpg': [], 'agent.ddpg.ddpgAgent.__init__': ['critic.CriticNet', 'actor.ActorNet', 'utils.memory_buffer.MemoryBuffer', 'utils.noise_process.OrnsteinUhlenbeckProcess'], 'actor.ActorNet': [], 'critic.CriticNet': [], 'utils.memory_buffer.MemoryBuffer': [], 'utils.noise_process.OrnsteinUhlenbeckProcess': [], 'agent.ddpg.ddpgAgent.make_action': ['numpy.clip'], 'numpy.clip': [], 'agent.ddpg.ddpgAgent.update_networks': [], 'agent.ddpg.ddpgAgent.replay': ['<builtin>.range', '<builtin>.abs', 'numpy.asarray'], 'numpy.asarray': [], '<builtin>.abs': [], 'agent.ddpg.ddpgAgent.memorize': ['numpy.expand_dims', '<builtin>.abs'], 'numpy.expand_dims': [], 'agent.ddpg.ddpgAgent.sample_batch': [], 'agent.ddpg.ddpgAgent.save_weights': [], 'agent.ddpg.ddpgAgent.load_weights': [], 'agent.actor': ['agent.actor.ActorNet.__init__'], 'agent.actor.ActorNet.__init__': ['keras.optimizers.Adam', 'agent.actor.ActorNet.create_network'], 'agent.actor.ActorNet.create_network': ['keras.layers.Dense', 'keras.layers.Lambda', 'keras.initializers.GlorotNormal', 'keras.layers.BatchNormalization', 'keras.layers.Input', 'keras.models.Model', 'keras.layers.Activation', 'numpy.ones'], 'keras.optimizers.Adam': [], 'keras.layers.Input': [], 'keras.initializers.GlorotNormal': [], 'keras.layers.Dense': [], 'keras.layers.BatchNormalization': [], 'keras.layers.Activation': [], 'numpy.ones': [], 'agent.actor.ActorNet.create_network.<lambda1>': [], 'keras.layers.Lambda': [], 'keras.models.Model': [], 'agent.actor.ActorNet.train': ['<builtin>.zip', 'tensorflow.reduce_mean', 'tensorflow.GradientTape'], 'tensorflow.GradientTape': [], 'tensorflow.reduce_mean': [], '<builtin>.zip': [], 'agent.actor.ActorNet.target_update': ['<builtin>.range', '<builtin>.len'], '<builtin>.len': [], 'agent.actor.ActorNet.predict': ['numpy.expand_dims'], 'agent.actor.ActorNet.target_predict': [], 'agent.actor.ActorNet.save_network': [], 'agent.actor.ActorNet.load_network': ['<builtin>.print'], 'utils.memory_buffer': [], 'utils.memory_buffer.MemoryBuffer.__init__': ['sumtree.SumTree', 'collections.deque'], 'sumtree.SumTree': [], 'collections.deque': [], 'utils.memory_buffer.MemoryBuffer.memorize': [], 'utils.memory_buffer.MemoryBuffer.priority': [], 'utils.memory_buffer.MemoryBuffer.size': [], 'utils.memory_buffer.MemoryBuffer.sample_batch': ['<builtin>.range', 'random.sample', 'random.uniform', 'numpy.array'], 'random.uniform': [], 'numpy.array': [], 'random.sample': [], 'utils.memory_buffer.MemoryBuffer.update': [], 'utils.memory_buffer.MemoryBuffer.clear': ['sumtree.SumTree', 'collections.deque'], 'utils.sumtree': [], 'utils.sumtree.SumTree.__init__': ['numpy.zeros'], 'numpy.zeros': [], 'utils.sumtree.SumTree._propagate': ['utils.sumtree.SumTree._propagate'], 'utils.sumtree.SumTree._retrieve': ['<builtin>.len', 'utils.sumtree.SumTree._retrieve'], 'utils.sumtree.SumTree.total': [], 'utils.sumtree.SumTree.add': ['utils.sumtree.SumTree.update'], 'utils.sumtree.SumTree.update': ['utils.sumtree.SumTree._propagate'], 'utils.sumtree.SumTree.get': ['utils.sumtree.SumTree._retrieve'], 'utils': [], 'utils.noise_process': [], 'utils.noise_process.OrnsteinUhlenbeckProcess.__init__': ['<builtin>.float'], '<builtin>.float': [], 'utils.noise_process.OrnsteinUhlenbeckProcess.generate': ['numpy.sqrt', 'numpy.random.normal', '<builtin>.max'], '<builtin>.max': [], 'numpy.sqrt': [], 'numpy.random.normal': [], 'agent.critic': [], 'agent.critic.CriticNet.__init__': ['keras.optimizers.Adam', 'agent.critic.CriticNet.create_network'], 'agent.critic.CriticNet.create_network': ['keras.layers.Dense', 'keras.initializers.GlorotNormal', 'keras.regularizers.l2', 'keras.layers.Concatenate', 'keras.layers.Input', 'keras.layers.BatchNormalization', 'keras.models.Model', 'keras.layers.Activation'], 'keras.layers.Concatenate': [], 'keras.regularizers.l2': [], 'agent.critic.CriticNet.Qgradient': ['tensorflow.squeeze', 'tensorflow.GradientTape', 'tensorflow.convert_to_tensor'], 'tensorflow.convert_to_tensor': [], 'tensorflow.squeeze': [], 'agent.critic.CriticNet.train': ['tensorflow.math.square', 'tensorflow.GradientTape', '<builtin>.zip', 'tensorflow.print', 'tensorflow.reduce_mean', '<builtin>.float'], 'tensorflow.math.square': [], 'tensorflow.print': [], 'agent.critic.CriticNet.predict': [], 'agent.critic.CriticNet.target_predict': [], 'agent.critic.CriticNet.target_update': ['<builtin>.range', '<builtin>.len'], 'agent.critic.CriticNet.save_network': [], 'agent.critic.CriticNet.load_network': ['<builtin>.print'], 'agent': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\CUN-bjy_gym-ddpg-keras\\train.py\n",
      "[('train', 'train model_train'), ('train', 'argparse ArgumentParser'), ('train model_train', 'matplotlib pyplot pause'), ('train model_train', 'os getcwd'), ('train model_train', 'numpy all'), ('train model_train', 'seaborn lineplot'), ('train model_train', 'matplotlib pyplot figure'), ('train model_train', 'gym make'), ('train model_train', 'matplotlib pyplot ion'), ('train model_train', 'os mkdir'), ('train model_train', 'tqdm tqdm'), ('train model_train', 'agent ddpg ddpgAgent'), ('train model_train', 'time time'), ('train model_train', 'pickle dump'), ('train model_train', 'os path isdir'), ('train model_train', 'pandas DataFrame'), ('train model_train', 'numpy argmax'), ('agent ddpg ddpgAgent __init__', 'critic CriticNet'), ('agent ddpg ddpgAgent __init__', 'actor ActorNet'), ('agent ddpg ddpgAgent __init__', 'utils memory_buffer MemoryBuffer'), ('agent ddpg ddpgAgent __init__', 'utils noise_process OrnsteinUhlenbeckProcess'), ('agent ddpg ddpgAgent make_action', 'numpy clip'), ('agent ddpg ddpgAgent replay', 'numpy asarray'), ('agent ddpg ddpgAgent memorize', 'numpy expand_dims'), ('agent actor', 'agent actor ActorNet __init__'), ('agent actor ActorNet __init__', 'keras optimizers Adam'), ('agent actor ActorNet __init__', 'agent actor ActorNet create_network'), ('agent actor ActorNet create_network', 'keras layers Dense'), ('agent actor ActorNet create_network', 'keras layers Lambda'), ('agent actor ActorNet create_network', 'keras initializers GlorotNormal')]\n",
      "0\n",
      "found files: []\n",
      "'''\n",
      "MIT License\n",
      "\n",
      "Copyright (c) 2020 Junyoeb Baek\n",
      "\n",
      "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
      "of this software and associated documentation files (the \"Software\"), to deal\n",
      "in the Software without restriction, including without limitation the rights\n",
      "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
      "copies of the Software, and to permit persons to whom the Software is\n",
      "furnished to do so, subject to the following conditions:\n",
      "\n",
      "The above copyright notice and this permission notice shall be included in all\n",
      "copies or substantial portions of the Software.\n",
      "\n",
      "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
      "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
      "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
      "SOFTWARE.\n",
      "'''\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from .actor import ActorNet\n",
      "from .critic import CriticNet\n",
      "\n",
      "from utils.memory_buffer import MemoryBuffer\n",
      "from utils.noise_process import OrnsteinUhlenbeckProcess\n",
      "\n",
      "BUFFER_SIZE = 20000\n",
      "class ddpgAgent():\n",
      "\t\"\"\"Deep Deterministic Policy Gradient(DDPG) Agent\n",
      "\t\"\"\"\n",
      "\tdef __init__(self, env_, is_discrete=False, batch_size=100, w_per=True):\n",
      "\t\t# gym environments\n",
      "\t\tself.env = env_\n",
      "\t\tself.discrete = is_discrete\n",
      "\t\tself.obs_dim = env_.observation_space.shape[0]\n",
      "\t\tself.act_dim = env_.action_space.n if is_discrete else env_.action_space.shape[0]\n",
      "\n",
      "\t\tself.action_bound = (env_.action_space.high - env_.action_space.low) / 2 if not is_discrete else 1.\n",
      "\t\tself.action_shift = (env_.action_space.high + env_.action_space.low) / 2 if not is_discrete else 0.\n",
      "\n",
      "\t\t# initialize actor & critic and its targets\n",
      "\t\tself.discount_factor = 0.99\n",
      "\t\tself.actor = ActorNet(self.obs_dim, self.act_dim, self.action_bound, lr_=1e-4,tau_=1e-3)\n",
      "\t\tself.critic = CriticNet(self.obs_dim, self.act_dim, lr_=1e-3,tau_=1e-3,discount_factor=self.discount_factor)\n",
      "\n",
      "\t\t# Experience Buffer\n",
      "\t\tself.buffer = MemoryBuffer(BUFFER_SIZE, with_per=w_per)\n",
      "\t\tself.with_per = w_per\n",
      "\t\tself.batch_size = batch_size\n",
      "\t\t# OU-Noise-Process\n",
      "\t\tself.noise = OrnsteinUhlenbeckProcess(size=self.act_dim)\n",
      "\n",
      "\t###################################################\n",
      "\t# Network Related\n",
      "\t###################################################\n",
      "\tdef make_action(self, obs, t, noise=True):\n",
      "\t\t\"\"\" predict next action from Actor's Policy\n",
      "\t\t\"\"\"\n",
      "\t\taction_ = self.actor.predict(obs)[0]\n",
      "\t\ta = np.clip(action_ + self.noise.generate(t) if noise else 0, -self.action_bound, self.action_bound)\n",
      "\t\treturn a\n",
      "\n",
      "\tdef update_networks(self, obs, acts, critic_target):\n",
      "\t\t\"\"\" Train actor & critic from sampled experience\n",
      "\t\t\"\"\"\n",
      "\t\t# update critic\n",
      "\t\tself.critic.train(obs, acts, critic_target)\n",
      "\n",
      "\t\t# get next action and Q-value Gradient\n",
      "\t\tn_actions = self.actor.network.predict(obs)\n",
      "\t\tq_grads = self.critic.Qgradient(obs, n_actions)\n",
      "\n",
      "\t\t# update actor\n",
      "\t\tself.actor.train(obs,self.critic.network,q_grads)\n",
      "\n",
      "\t\t# update target networks\n",
      "\t\tself.actor.target_update()\n",
      "\t\tself.critic.target_update()\n",
      "\n",
      "\tdef replay(self, replay_num_):\n",
      "\t\tif self.with_per and (self.buffer.size() <= self.batch_size): return\n",
      "\n",
      "\t\tfor _ in range(replay_num_):\n",
      "\t\t\t# sample from buffer\n",
      "\t\t\tstates, actions, rewards, dones, new_states, idx = self.sample_batch(self.batch_size)\n",
      "\n",
      "\t\t\t# get target q-value using target network\n",
      "\t\t\tq_vals = self.critic.target_predict([new_states,self.actor.target_predict(new_states)])\n",
      "\n",
      "\t\t\t# bellman iteration for target critic value\n",
      "\t\t\tcritic_target = np.asarray(q_vals)\n",
      "\t\t\tfor i in range(q_vals.shape[0]):\n",
      "\t\t\t\tif dones[i]:\n",
      "\t\t\t\t\tcritic_target[i] = rewards[i]\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tcritic_target[i] = self.discount_factor * q_vals[i] + rewards[i]\n",
      "\n",
      "\t\t\t\tif self.with_per:\n",
      "\t\t\t\t\tself.buffer.update(idx[i], abs(q_vals[i]-critic_target[i]))\n",
      "\n",
      "\t\t\t# train(or update) the actor & critic and target networks\n",
      "\t\t\tself.update_networks(states, actions, critic_target)\n",
      "\n",
      "\n",
      "\t####################################################\n",
      "\t# Buffer Related\n",
      "\t####################################################\n",
      "\n",
      "\tdef memorize(self,obs,act,reward,done,new_obs):\n",
      "\t\t\"\"\"store experience in the buffer\n",
      "\t\t\"\"\"\n",
      "\t\tif self.with_per:\n",
      "\t\t\tq_val = self.critic.network([np.expand_dims(obs,axis=0),self.actor.predict(obs)])\n",
      "\t\t\tnext_action = self.actor.target_network.predict(np.expand_dims(new_obs, axis=0))\n",
      "\t\t\tq_val_t = self.critic.target_predict([np.expand_dims(new_obs,axis=0), next_action])\n",
      "\t\t\tnew_val = reward + self.discount_factor * q_val_t\n",
      "\t\t\ttd_error = abs(new_val - q_val)[0]\n",
      "\t\telse:\n",
      "\t\t\ttd_error = 0\t\t\t\n",
      "\n",
      "\t\tself.buffer.memorize(obs,act,reward,done,new_obs,td_error)\n",
      "\n",
      "\tdef sample_batch(self, batch_size):\n",
      "\t\t\"\"\" Sampling from the batch\n",
      "\t\t\"\"\"\n",
      "\t\treturn self.buffer.sample_batch(batch_size)\n",
      "\n",
      "\t###################################################\n",
      "\t# Save & Load Networks\n",
      "\t###################################################\n",
      "\tdef save_weights(self,path):\n",
      "\t\t\"\"\" Agent's Weights Saver\n",
      "\t\t\"\"\"\n",
      "\t\tself.actor.save_network(path)\n",
      "\t\tself.critic.save_network(path)\n",
      "\n",
      "\tdef load_weights(self, pretrained):\n",
      "\t\t\"\"\" Agent's Weights Loader\n",
      "\t\t\"\"\"\n",
      "\t\tself.actor.load_network(pretrained)\n",
      "\t\tself.critic.load_network(pretrained)\n",
      "Output: {'ddpg': [], 'ddpg.ddpgAgent.__init__': ['utils.noise_process.OrnsteinUhlenbeckProcess', 'actor.ActorNet', 'critic.CriticNet', 'utils.memory_buffer.MemoryBuffer'], 'actor.ActorNet': [], 'critic.CriticNet': [], 'utils.memory_buffer.MemoryBuffer': [], 'utils.noise_process.OrnsteinUhlenbeckProcess': [], 'ddpg.ddpgAgent.make_action': ['numpy.clip'], 'numpy.clip': [], 'ddpg.ddpgAgent.update_networks': [], 'ddpg.ddpgAgent.replay': ['<builtin>.range', 'ddpg.ddpgAgent.sample_batch', '<builtin>.abs', 'ddpg.ddpgAgent.update_networks', 'numpy.asarray'], '<builtin>.range': [], 'ddpg.ddpgAgent.sample_batch': [], 'numpy.asarray': [], '<builtin>.abs': [], 'ddpg.ddpgAgent.memorize': ['<builtin>.abs', 'numpy.expand_dims'], 'numpy.expand_dims': [], 'ddpg.ddpgAgent.save_weights': [], 'ddpg.ddpgAgent.load_weights': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\CUN-bjy_gym-ddpg-keras\\agent\\ddpg.py\n",
      "[('ddpg ddpgAgent __init__', 'utils noise_process OrnsteinUhlenbeckProcess'), ('ddpg ddpgAgent __init__', 'actor ActorNet'), ('ddpg ddpgAgent __init__', 'critic CriticNet'), ('ddpg ddpgAgent __init__', 'utils memory_buffer MemoryBuffer'), ('ddpg ddpgAgent make_action', 'numpy clip'), ('ddpg ddpgAgent replay', 'ddpg ddpgAgent sample_batch'), ('ddpg ddpgAgent replay', 'ddpg ddpgAgent update_networks'), ('ddpg ddpgAgent replay', 'numpy asarray'), ('ddpg ddpgAgent memorize', 'numpy expand_dims')]\n",
      "0\n",
      "found files: []\n",
      "'''\n",
      "MIT License\n",
      "\n",
      "Copyright (c) 2020 Junyoeb Baek\n",
      "\n",
      "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
      "of this software and associated documentation files (the \"Software\"), to deal\n",
      "in the Software without restriction, including without limitation the rights\n",
      "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
      "copies of the Software, and to permit persons to whom the Software is\n",
      "furnished to do so, subject to the following conditions:\n",
      "\n",
      "The above copyright notice and this permission notice shall be included in all\n",
      "copies or substantial portions of the Software.\n",
      "\n",
      "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
      "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
      "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
      "SOFTWARE.\n",
      "'''\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "import keras.backend as K\n",
      "\n",
      "from keras.initializers import GlorotNormal\n",
      "from keras.models import Model\n",
      "from keras.optimizers import Adam\n",
      "from keras.regularizers import l2\n",
      "from keras.layers import Input, Dense, Concatenate, Activation, BatchNormalization\n",
      "\n",
      "\n",
      "class CriticNet():\n",
      "\t\"\"\" Critic Network for DDPG\n",
      "\t\"\"\"\n",
      "\tdef __init__(self, in_dim, out_dim, lr_, tau_, discount_factor):\n",
      "\t\tself.obs_dim = in_dim\n",
      "\t\tself.act_dim = out_dim\n",
      "\t\tself.lr = lr_; self.discount_factor=discount_factor;self.tau = tau_\n",
      "\n",
      "\t\t# initialize critic network and target\n",
      "\t\tself.network = self.create_network()\n",
      "\t\tself.target_network = self.create_network()\n",
      "\n",
      "\t\tself.optimizer = Adam(self.lr)\n",
      "\n",
      "\t\t# copy the weights for initialization\n",
      "\t\tweights_ = self.network.get_weights()\n",
      "\t\tself.target_network.set_weights(weights_)\n",
      "\n",
      "\t\tself.critic_loss = None\n",
      "\n",
      "\tdef create_network(self):\n",
      "\t\t\"\"\" Create a Critic Network Model using Keras\n",
      "\t\t\tas a Q-value approximator function\n",
      "\t\t\"\"\"\n",
      "\t\t# input layer(observations and actions)\n",
      "\t\tinput_obs = Input(shape=self.obs_dim)\n",
      "\t\tinput_act = Input(shape=(self.act_dim,))\n",
      "\t\tinputs = [input_obs,input_act]\n",
      "\t\tconcat = Concatenate(axis=-1)(inputs)\n",
      "\n",
      "\t\t# hidden layer 1\n",
      "\t\th1_ = Dense(300, kernel_initializer=GlorotNormal(), kernel_regularizer=l2(0.01))(concat)\n",
      "\t\th1_b = BatchNormalization()(h1_)\n",
      "\t\th1 = Activation('relu')(h1_b)\n",
      "\n",
      "\t\t# hidden_layer 2\n",
      "\t\th2_ = Dense(400, kernel_initializer=GlorotNormal(), kernel_regularizer=l2(0.01))(h1)\n",
      "\t\th2_b = BatchNormalization()(h2_)\n",
      "\t\th2 = Activation('relu')(h2_b)\n",
      "\n",
      "\t\t# output layer(actions)\n",
      "\t\toutput_ = Dense(1, kernel_initializer=GlorotNormal(), kernel_regularizer=l2(0.01))(h2)\n",
      "\t\toutput_b = BatchNormalization()(output_)\n",
      "\t\toutput = Activation('linear')(output_b)\n",
      "\n",
      "\t\treturn Model(inputs,output)\n",
      "\n",
      "\tdef Qgradient(self, obs, acts):\n",
      "\t\tacts = tf.convert_to_tensor(acts)\n",
      "\t\twith tf.GradientTape() as tape:\n",
      "\t\t\ttape.watch(acts)\n",
      "\t\t\tq_values = self.network([obs,acts])\n",
      "\t\t\tq_values = tf.squeeze(q_values)\n",
      "\t\treturn tape.gradient(q_values, acts)\n",
      "\n",
      "\tdef train(self, obs, acts, target):\n",
      "\t\t\"\"\"Train Q-network for critic on sampled batch\n",
      "\t\t\"\"\"\n",
      "\t\twith tf.GradientTape() as tape:\n",
      "\t\t\tq_values = self.network([obs, acts], training=True)\n",
      "\t\t\ttd_error = q_values - target\n",
      "\t\t\tcritic_loss = tf.reduce_mean(tf.math.square(td_error))\n",
      "\t\t\ttf.print(\"critic loss :\",critic_loss)\n",
      "\t\t\tself.critic_loss = float(critic_loss)\n",
      "\n",
      "\t\tcritic_grad = tape.gradient(critic_loss, self.network.trainable_variables)  # compute critic gradient\n",
      "\t\tself.optimizer.apply_gradients(zip(critic_grad, self.network.trainable_variables))\n",
      "\n",
      "\tdef predict(self, obs):\n",
      "\t\t\"\"\"Predict Q-value from approximation function(Q-network)\n",
      "\t\t\"\"\"\n",
      "\t\treturn self.network.predict(obs)\n",
      "\n",
      "\tdef target_predict(self, new_obs):\n",
      "\t\t\"\"\"Predict target Q-value from approximation function(Q-network)\n",
      "\t\t\"\"\"\n",
      "\t\treturn self.target_network.predict(new_obs)\n",
      "\n",
      "\tdef target_update(self):\n",
      "\t\t\"\"\" soft target update for training target critic network\n",
      "\t\t\"\"\"\n",
      "\t\tweights, weights_t = self.network.get_weights(), self.target_network.get_weights()\n",
      "\t\tfor i in range(len(weights)):\n",
      "\t\t\tweights_t[i] = self.tau*weights[i] + (1-self.tau)*weights_t[i]\n",
      "\t\tself.target_network.set_weights(weights_t)\n",
      "\n",
      "\tdef save_network(self, path):\n",
      "\t\tself.network.save_weights(path + '_critic.h5')\n",
      "\t\tself.target_network.save_weights(path + '_critic_t.h5')\n",
      "\n",
      "\tdef load_network(self, path):\n",
      "\t\tself.network.load_weights(path + '_critic.h5')\n",
      "\t\tself.target_network.load_weights(path + '_critic_t.h5')\n",
      "\t\tprint(self.network.summary())\n",
      "Output: {'critic': [], 'critic.CriticNet.__init__': ['critic.CriticNet.create_network', 'keras.optimizers.Adam'], 'critic.CriticNet.create_network': ['keras.layers.Activation', 'keras.layers.Dense', 'keras.models.Model', 'keras.initializers.GlorotNormal', 'keras.layers.Concatenate', 'keras.layers.Input', 'keras.layers.BatchNormalization', 'keras.regularizers.l2'], 'keras.optimizers.Adam': [], 'keras.layers.Input': [], 'keras.layers.Concatenate': [], 'keras.initializers.GlorotNormal': [], 'keras.regularizers.l2': [], 'keras.layers.Dense': [], 'keras.layers.BatchNormalization': [], 'keras.layers.Activation': [], 'keras.models.Model': [], 'critic.CriticNet.Qgradient': ['tensorflow.squeeze', 'tensorflow.GradientTape', 'tensorflow.convert_to_tensor'], 'tensorflow.convert_to_tensor': [], 'tensorflow.GradientTape': [], 'tensorflow.squeeze': [], 'critic.CriticNet.train': ['tensorflow.GradientTape', 'tensorflow.reduce_mean', '<builtin>.zip', 'tensorflow.print', 'tensorflow.math.square', '<builtin>.float'], 'tensorflow.math.square': [], 'tensorflow.reduce_mean': [], 'tensorflow.print': [], '<builtin>.float': [], '<builtin>.zip': [], 'critic.CriticNet.predict': [], 'critic.CriticNet.target_predict': [], 'critic.CriticNet.target_update': ['<builtin>.range', '<builtin>.len'], '<builtin>.len': [], '<builtin>.range': [], 'critic.CriticNet.save_network': [], 'critic.CriticNet.load_network': ['<builtin>.print'], '<builtin>.print': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\CUN-bjy_gym-ddpg-keras\\agent\\critic.py\n",
      "[('critic CriticNet __init__', 'critic CriticNet create_network'), ('critic CriticNet __init__', 'keras optimizers Adam'), ('critic CriticNet create_network', 'keras layers Activation'), ('critic CriticNet create_network', 'keras layers Dense'), ('critic CriticNet create_network', 'keras models Model'), ('critic CriticNet create_network', 'keras initializers GlorotNormal'), ('critic CriticNet create_network', 'keras layers Concatenate'), ('critic CriticNet create_network', 'keras layers Input'), ('critic CriticNet create_network', 'keras layers BatchNormalization'), ('critic CriticNet create_network', 'keras regularizers l2'), ('critic CriticNet Qgradient', 'tensorflow squeeze'), ('critic CriticNet Qgradient', 'tensorflow GradientTape'), ('critic CriticNet Qgradient', 'tensorflow convert_to_tensor'), ('critic CriticNet train', 'tensorflow GradientTape'), ('critic CriticNet train', 'tensorflow reduce_mean'), ('critic CriticNet train', 'tensorflow print'), ('critic CriticNet train', 'tensorflow math square')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('noise_process OrnsteinUhlenbeckProcess generate', 'numpy random normal'), ('noise_process OrnsteinUhlenbeckProcess generate', 'numpy sqrt')], [('actor', 'actor ActorNet __init__'), ('actor ActorNet __init__', 'actor ActorNet create_network'), ('actor ActorNet __init__', 'keras optimizers Adam'), ('actor ActorNet create_network', 'keras layers Activation'), ('actor ActorNet create_network', 'keras layers Dense'), ('actor ActorNet create_network', 'keras models Model'), ('actor ActorNet create_network', 'keras layers Input'), ('actor ActorNet create_network', 'keras initializers GlorotNormal'), ('actor ActorNet create_network', 'keras layers BatchNormalization'), ('actor ActorNet create_network', 'numpy ones'), ('actor ActorNet create_network', 'keras layers Lambda'), ('actor ActorNet train', 'tensorflow GradientTape'), ('actor ActorNet train', 'tensorflow reduce_mean'), ('actor ActorNet predict', 'numpy expand_dims')], [('memory_buffer MemoryBuffer __init__', 'collections deque'), ('memory_buffer MemoryBuffer __init__', 'sumtree SumTree'), ('memory_buffer MemoryBuffer memorize', 'memory_buffer MemoryBuffer priority'), ('memory_buffer MemoryBuffer sample_batch', 'random sample'), ('memory_buffer MemoryBuffer sample_batch', 'numpy array'), ('memory_buffer MemoryBuffer sample_batch', 'random uniform'), ('memory_buffer MemoryBuffer update', 'memory_buffer MemoryBuffer priority'), ('memory_buffer MemoryBuffer clear', 'collections deque'), ('memory_buffer MemoryBuffer clear', 'sumtree SumTree')], [('sumtree SumTree __init__', 'numpy zeros'), ('sumtree SumTree _propagate', 'sumtree SumTree _propagate'), ('sumtree SumTree _retrieve', 'sumtree SumTree _retrieve'), ('sumtree SumTree add', 'sumtree SumTree update'), ('sumtree SumTree update', 'sumtree SumTree _propagate'), ('sumtree SumTree get', 'sumtree SumTree _retrieve')], [('env_test', 'gym make')], [('play', 'argparse ArgumentParser'), ('play', 'play model_play'), ('play model_play', 'agent ddpg ddpgAgent'), ('play model_play', 'gym make'), ('agent ddpg ddpgAgent __init__', 'utils memory_buffer MemoryBuffer'), ('agent ddpg ddpgAgent __init__', 'utils noise_process OrnsteinUhlenbeckProcess'), ('agent ddpg ddpgAgent __init__', 'critic CriticNet'), ('agent ddpg ddpgAgent __init__', 'actor ActorNet'), ('agent ddpg ddpgAgent make_action', 'numpy clip'), ('agent ddpg ddpgAgent replay', 'numpy asarray'), ('agent ddpg ddpgAgent memorize', 'numpy expand_dims'), ('agent critic CriticNet __init__', 'keras optimizers Adam'), ('agent critic CriticNet __init__', 'agent critic CriticNet create_network'), ('agent critic CriticNet create_network', 'keras regularizers l2'), ('agent critic CriticNet create_network', 'keras models Model'), ('agent critic CriticNet create_network', 'keras layers Input'), ('agent critic CriticNet create_network', 'keras layers BatchNormalization'), ('agent critic CriticNet create_network', 'keras layers Concatenate'), ('agent critic CriticNet create_network', 'keras initializers GlorotNormal'), ('agent critic CriticNet create_network', 'keras layers Dense'), ('agent critic CriticNet create_network', 'keras layers Activation'), ('agent critic CriticNet Qgradient', 'tensorflow squeeze'), ('agent critic CriticNet Qgradient', 'tensorflow GradientTape'), ('agent critic CriticNet Qgradient', 'tensorflow convert_to_tensor'), ('agent critic CriticNet train', 'tensorflow reduce_mean'), ('agent critic CriticNet train', 'tensorflow GradientTape'), ('agent critic CriticNet train', 'tensorflow print'), ('agent critic CriticNet train', 'tensorflow math square'), ('utils memory_buffer MemoryBuffer __init__', 'sumtree SumTree'), ('utils memory_buffer MemoryBuffer __init__', 'collections deque')], [('train', 'train model_train'), ('train', 'argparse ArgumentParser'), ('train model_train', 'matplotlib pyplot pause'), ('train model_train', 'os getcwd'), ('train model_train', 'numpy all'), ('train model_train', 'seaborn lineplot'), ('train model_train', 'matplotlib pyplot figure'), ('train model_train', 'gym make'), ('train model_train', 'matplotlib pyplot ion'), ('train model_train', 'os mkdir'), ('train model_train', 'tqdm tqdm'), ('train model_train', 'agent ddpg ddpgAgent'), ('train model_train', 'time time'), ('train model_train', 'pickle dump'), ('train model_train', 'os path isdir'), ('train model_train', 'pandas DataFrame'), ('train model_train', 'numpy argmax'), ('agent ddpg ddpgAgent __init__', 'critic CriticNet'), ('agent ddpg ddpgAgent __init__', 'actor ActorNet'), ('agent ddpg ddpgAgent __init__', 'utils memory_buffer MemoryBuffer'), ('agent ddpg ddpgAgent __init__', 'utils noise_process OrnsteinUhlenbeckProcess'), ('agent ddpg ddpgAgent make_action', 'numpy clip'), ('agent ddpg ddpgAgent replay', 'numpy asarray'), ('agent ddpg ddpgAgent memorize', 'numpy expand_dims'), ('agent actor', 'agent actor ActorNet __init__'), ('agent actor ActorNet __init__', 'keras optimizers Adam'), ('agent actor ActorNet __init__', 'agent actor ActorNet create_network'), ('agent actor ActorNet create_network', 'keras layers Dense'), ('agent actor ActorNet create_network', 'keras layers Lambda'), ('agent actor ActorNet create_network', 'keras initializers GlorotNormal')], [('ddpg ddpgAgent __init__', 'utils noise_process OrnsteinUhlenbeckProcess'), ('ddpg ddpgAgent __init__', 'actor ActorNet'), ('ddpg ddpgAgent __init__', 'critic CriticNet'), ('ddpg ddpgAgent __init__', 'utils memory_buffer MemoryBuffer'), ('ddpg ddpgAgent make_action', 'numpy clip'), ('ddpg ddpgAgent replay', 'ddpg ddpgAgent sample_batch'), ('ddpg ddpgAgent replay', 'ddpg ddpgAgent update_networks'), ('ddpg ddpgAgent replay', 'numpy asarray'), ('ddpg ddpgAgent memorize', 'numpy expand_dims')], [('critic CriticNet __init__', 'critic CriticNet create_network'), ('critic CriticNet __init__', 'keras optimizers Adam'), ('critic CriticNet create_network', 'keras layers Activation'), ('critic CriticNet create_network', 'keras layers Dense'), ('critic CriticNet create_network', 'keras models Model'), ('critic CriticNet create_network', 'keras initializers GlorotNormal'), ('critic CriticNet create_network', 'keras layers Concatenate'), ('critic CriticNet create_network', 'keras layers Input'), ('critic CriticNet create_network', 'keras layers BatchNormalization'), ('critic CriticNet create_network', 'keras regularizers l2'), ('critic CriticNet Qgradient', 'tensorflow squeeze'), ('critic CriticNet Qgradient', 'tensorflow GradientTape'), ('critic CriticNet Qgradient', 'tensorflow convert_to_tensor'), ('critic CriticNet train', 'tensorflow GradientTape'), ('critic CriticNet train', 'tensorflow reduce_mean'), ('critic CriticNet train', 'tensorflow print'), ('critic CriticNet train', 'tensorflow math square')]]\n",
      "********************doctrings*************************\n",
      "['', '', '', '', '', 'model play', 'model train', '', '']\n",
      "embed index dataset: 19\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\FixedThink_RocketCogs\\\\reputation\\\\reputation.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\FixedThink_RocketCogs\\\\rlcd_various\\\\rlcd_various.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\FixedThink_RocketCogs\\\\lafusee\\\\json_data.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\FixedThink_RocketCogs\\\\reputation\\\\db_queries.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\FixedThink_RocketCogs\\\\lafusee\\\\static_functions.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\FixedThink_RocketCogs\\\\lafusee\\\\steam_calls.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\FixedThink_RocketCogs\\\\lafusee\\\\lafusee.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\FixedThink_RocketCogs\\\\lafusee\\\\psyonix_calls.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\FixedThink_RocketCogs\\\\lafusee\\\\db_queries.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\FixedThink_RocketCogs\\\\lafusee\\\\exceptions.py']\n",
      "# Default Library.\n",
      "import asyncio\n",
      "import datetime as dt\n",
      "from asyncio import sleep\n",
      "from typing import Literal, Optional, Tuple, Set\n",
      "\n",
      "# Used by Red.\n",
      "import discord\n",
      "import redbot.core.utils.menus as red_menu\n",
      "from redbot.core import commands, checks, Config, data_manager\n",
      "from redbot.core.bot import Red  # For type hints.\n",
      "from redbot.core.commands.context import Context  # For type hints.\n",
      "\n",
      "# Local files.\n",
      "from .db_queries import DbQueries\n",
      "\n",
      "\n",
      "class Reputation(commands.Cog):\n",
      "    \"\"\"Give people reputation and reward reputable members\"\"\"\n",
      "    __author__ = \"#s#8059, HRAND5#0101\"\n",
      "\n",
      "    # Defaults.\n",
      "    DEFAULT_COOLDOWN = 60 * 60 * 24 * 7  # 1 week (cooldown for user A to give user B rep).\n",
      "    DEFAULT_DECAY = 60 * 60 * 24 * 7 * 5  # 5 weeks (35 days, time before the reputation role will decay).\n",
      "    DEFAULT_LOG_MESSAGE = \"{user} has received the reputation role.\"\n",
      "    LOOP_SLEEP_TIME = 60 * 60 * 12  # 12 hours.\n",
      "\n",
      "    # Notice emote prefixes.\n",
      "    BIN = \":put_litter_in_its_place: \"\n",
      "    ERROR = \":x: Error: \"\n",
      "    DONE = \":white_check_mark: \"\n",
      "    # Notices.\n",
      "    DEL_REQUEST = \":information_source: `reputation`: Data removal request for userID {} of type `{}`.\\n\" \\\n",
      "                  \"Please consider deleting unnecessary data (such as usernames, and the reputation message itself), \" \\\n",
      "                  \"whilst not deleting data necessary for the operation of the reputation system.\"\n",
      "    BAD_CHANNEL = ERROR + \"Reputation not added, please use the correct channel for reputations!\"\n",
      "    REP_CHANNEL_CLEARED = BIN + \"Cleared the channel configuration. Reputation can now be given in any channel.\"\n",
      "    LOG_CHANNEL_CLEARED = BIN + \"Cleared the channel configuration. Logs are disabled.\"\n",
      "    CHANNEL_SET = DONE + \"Set the channel to {}.\"\n",
      "    COOLDOWN_CLEARED = BIN + \"Set the reputation cooldown back to the default settings.\"\n",
      "    COOLDOWN_REMOVED = BIN + \"Disabled the reputation cooldown.\"\n",
      "    COOLDOWN_SET = DONE + \"Set the reputation cooldown to {}.\"\n",
      "    DECAY_CLEARED = BIN + \"Set the reputation decay back to the default settings.\"\n",
      "    DECAY_REMOVED = BIN + \"Disabled reputation decay.\"\n",
      "    DECAY_SET = DONE + \"Set the reputation decay to {}\"\n",
      "    DECAY_THRESHOLD_CLEARED = BIN + \"Successfully set the decay threshold to the default: `2`\"\n",
      "    DECAY_THRESHOLD_SET = DONE + \"Successfully set the decay threshold to {}\"\n",
      "    LOG_MSG_RESET = BIN + \"Log message reset to default.\"\n",
      "    MANUAL_CHECK = DONE + \"Performed the manual server check!\\n\" \\\n",
      "                          \"**{add_n}** member{s} received a role, **{del_n}** lost a role.\"\n",
      "    REP_BAD_INPUT = ERROR + \"Your input was not fully valid! Note that a username is case-sensitive.\\n\" \\\n",
      "                            \"This message (and yours) will self-destruct after 30 seconds.\"\n",
      "    REP_NOT_COOL = ERROR + \"You have given that user a reputation too recently!\"\n",
      "    REP_COMMENT_HAS_AT = ERROR + \"Please do not tag any people in the rep reason!\\n\" \\\n",
      "                                 \"If you must mention someone, use their name instead.\"\n",
      "    REP_YOURSELF = ERROR + \"Loving yourself is great, but giving yourself reputation is a bit extreme.\"\n",
      "    ROLE_CONFIG_CLEARED = BIN + \"Cleared the role configuration.\\n\" \\\n",
      "                                \"You can configure the role by including it at the end of the command.\"\n",
      "    ROLE_CONFIG_SET = DONE + \"Successfully configured the role.\"\n",
      "    ROLE_THRESHOLD_CLEARED = BIN + \"Successfully set the role threshold to the default value: `10`\"\n",
      "    ROLE_THRESHOLD_SET = DONE + \"Successfully set the role threshold to {}\"\n",
      "    USER_OPT_IN = DONE + \"You will now receive a reputation role when eligible.\"\n",
      "    USER_OPT_OUT = BIN + \"You will no longer receive a reputation role, even when eligible.\"\n",
      "    # Audit log reasons.\n",
      "    ONE_ADD = \"Single reputation role check\"\n",
      "    GLD_ADD = \"Guild reputation role check\"\n",
      "    # Other constant strings.\n",
      "    COUNT_DESC = \"{} has received **{}** reputation{} from **{}** user{}.\"\n",
      "    COUNT_NO_REPS = \"{} has not received any reputations.\"\n",
      "    LEADERBOARD_NO_REPS = ERROR + \"No reputations in the database.\"\n",
      "    LEADERBOARD_DESC = \"Users with at least 1 reputation: **{}**\"\n",
      "    LEADERBOARD_ROW = \"`{:0{}d}` {}  **{}**\"\n",
      "    OFF = \"Disabled\"\n",
      "    TIME_FMT = \"%Y-%m-%d %H:%M:%S.%f\"\n",
      "\n",
      "    def __init__(self, bot: Red):\n",
      "        super().__init__()\n",
      "        self.bot = bot\n",
      "        self.FOLDER = str(data_manager.cog_data_path(self))\n",
      "        self.PATH_DB = self.FOLDER + \"/reputation.db\"\n",
      "        self.config = Config.get_conf(self, identifier=5006, force_registration=True)\n",
      "        self.config.register_guild(cooldown_period=self.DEFAULT_COOLDOWN, decay_period=self.DEFAULT_DECAY,\n",
      "                                   reputation_role=None, role_threshold=10, decay_threshold=2,\n",
      "                                   reputation_channel=None, shadow_role=None, log_channel=None,\n",
      "                                   log_message=self.DEFAULT_LOG_MESSAGE)\n",
      "        self.config.register_user(opt_out=False)\n",
      "        self.rep_db = DbQueries(self.PATH_DB)\n",
      "        self.decay_loop = asyncio.ensure_future(self.periodical_decay_check())\n",
      "\n",
      "    # Loops\n",
      "    async def periodical_decay_check(self):\n",
      "        \"\"\"Periodically perform the decay check for all guilds the bot is in\"\"\"\n",
      "        await self.bot.wait_until_ready()\n",
      "        while self == self.bot.get_cog(self.__class__.__name__):\n",
      "            for gld in self.bot.guilds:\n",
      "                await self.guild_role_check(gld)\n",
      "            await asyncio.sleep(self.LOOP_SLEEP_TIME)\n",
      "\n",
      "    # Commands\n",
      "    @commands.guild_only()  # Group not restricted to admins so that abstain can be used.\n",
      "    @commands.group(name=\"repset\", invoke_without_command=True)\n",
      "    async def _reputation_settings(self, ctx: Context):\n",
      "        \"\"\"Configure the reputation commands\n",
      "\n",
      "        Note that the `channel` command does not take parameters and will use the current channel when called.\"\"\"\n",
      "        await ctx.send_help()\n",
      "\n",
      "    # TODO: Update for added config options.\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @_reputation_settings.command(name=\"view\")\n",
      "    async def view_current_config(self, ctx: Context):\n",
      "        \"\"\"Shows the current configuration of the module\"\"\"\n",
      "        gld = ctx.guild\n",
      "        config_dict = await self.config.guild(gld).all()\n",
      "        embed = discord.Embed(title=\"Current Reputation configuration\", colour=discord.Colour.lighter_grey())\n",
      "        # Log message\n",
      "        log_message = config_dict[\"log_message\"]\n",
      "        embed.description = f\"```{log_message}```\" if log_message else \"`log message not set`\"\n",
      "        # Channel ID.\n",
      "        chn_id = config_dict[\"reputation_channel\"]\n",
      "        embed.add_field(name=\"Reputation channel\", value=f\"<#{chn_id}>\" if chn_id else self.OFF)\n",
      "        # Reputation role.\n",
      "        rep_role_obj = await self.get_reputation_role_obj(gld)\n",
      "        rep_role_str = rep_role_obj.mention if rep_role_obj else self.OFF\n",
      "        embed.add_field(name=\"Reputation role\", value=rep_role_str)\n",
      "        # Reputation cooldown.\n",
      "        cooldown = config_dict[\"cooldown_period\"]\n",
      "        embed.add_field(name=\"Cooldown period\", value=str(dt.timedelta(seconds=cooldown)) if cooldown else self.OFF)\n",
      "        # Log channel.\n",
      "        log_channel: discord.TextChannel = discord.utils.get(gld.channels, id=config_dict[\"log_channel\"])\n",
      "        embed.add_field(name=\"Log channel\", value=log_channel.mention if log_channel else self.OFF)\n",
      "        # Shadow role.\n",
      "        shadow_role_obj = await self.get_shadow_role_obj(gld)\n",
      "        shadow_role_str = shadow_role_obj.mention if shadow_role_obj else self.OFF\n",
      "        embed.add_field(name=\"Shadow role\", value=shadow_role_str)\n",
      "        # Reputation decay.\n",
      "        decay = config_dict[\"decay_period\"]\n",
      "        embed.add_field(name=\"Decay period\", value=str(dt.timedelta(seconds=decay)) if decay else self.OFF)\n",
      "        # Reputation threshold.\n",
      "        role_min = str(config_dict[\"role_threshold\"])\n",
      "        embed.add_field(name=\"Role threshold\", value=role_min if role_min else self.OFF)\n",
      "        # Decay threshold.\n",
      "        decay_min = str(config_dict[\"decay_threshold\"])\n",
      "        embed.add_field(name=\"Decay threshold\", value=decay_min if decay_min else self.OFF)\n",
      "        # Send embed.\n",
      "        await ctx.send(embed=embed)\n",
      "\n",
      "    @commands.guild_only()\n",
      "    @_reputation_settings.command(name=\"opt_out\", aliases=[\"abstain\"])\n",
      "    async def role_opt_out(self, ctx: Context):\n",
      "        \"\"\"Opt in/out of receiving a reputation role\n",
      "\n",
      "        If you opt out, you will not receive a role even if you are eligible for it.\"\"\"\n",
      "        aut = ctx.author\n",
      "        current_opt_out = await self.config.user(aut).opt_out()\n",
      "        # Set opt_out as the inverse of current_opt_out (as this command is a toggle).\n",
      "        await self.config.user(aut).opt_out.set(not current_opt_out)\n",
      "        if current_opt_out:\n",
      "            to_send = self.USER_OPT_IN\n",
      "            await self.user_role_check(ctx)  # TODO: modify the opt-in message if role is granted.\n",
      "        else:\n",
      "            to_send = self.USER_OPT_OUT\n",
      "            rep_role_obj = await self.get_reputation_role_obj(ctx.guild)\n",
      "            if rep_role_obj and rep_role_obj in aut.roles:\n",
      "                await aut.remove_roles(rep_role_obj)\n",
      "        await ctx.send(to_send)\n",
      "\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @_reputation_settings.command(name=\"decay_threshold\")\n",
      "    async def set_decay_threshold(self, ctx: Context, threshold: int = None):\n",
      "        \"\"\"Configure the decay threshold\n",
      "\n",
      "        A user must have received at least this amount of reputation during the decay period to be eligible for a role.\n",
      "        \"\"\"\n",
      "        gld = ctx.guild\n",
      "        if not threshold:  # Clear config.\n",
      "            await self.config.guild(gld).decay_threshold.clear()\n",
      "            msg = self.DECAY_THRESHOLD_CLEARED\n",
      "        else:  # Set decay threshold to int provided.\n",
      "            await self.config.guild(gld).decay_threshold.set(threshold)\n",
      "            msg = self.DECAY_THRESHOLD_SET.format(str(threshold))\n",
      "        await ctx.send(msg)\n",
      "\n",
      "    @_reputation_settings.command(name=\"log_message\")\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def set_log_message(self, ctx: Context, *, message_text=None):\n",
      "        \"\"\"Set the message to be used when a member gets the reputation role for the first time\n",
      "\n",
      "        In order to specify a user mention, please use `{user}` inside the text.\n",
      "        Please avoid the usage of any other curly brackets.\"\"\"\n",
      "        if message_text is None:\n",
      "            await self.config.guild(ctx.guild).log_message.clear()\n",
      "            await ctx.send(self.LOG_MSG_RESET)\n",
      "        else:\n",
      "            await self.config.guild(ctx.guild).log_message.set(message_text)\n",
      "            await ctx.tick()\n",
      "\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @_reputation_settings.command(name=\"role\")\n",
      "    async def set_reputation_role(self, ctx: Context, role: discord.Role = None):\n",
      "        \"\"\"Configure the reputation role to be given\n",
      "\n",
      "        If no role is provided, the role functionality will be disabled.\"\"\"\n",
      "        gld = ctx.guild\n",
      "        if not role:  # Clear config.\n",
      "            await self.config.guild(gld).reputation_role.clear()\n",
      "            msg = self.ROLE_CONFIG_CLEARED\n",
      "        else:  # Set reputation role to role provided.\n",
      "            await self.config.guild(gld).reputation_role.set(role.id)\n",
      "            msg = self.ROLE_CONFIG_SET\n",
      "        await ctx.send(msg)\n",
      "\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @_reputation_settings.command(name=\"shadow_role\")\n",
      "    async def set_shadow_role(self, ctx: Context, role: discord.Role = None):\n",
      "        \"\"\"Configure the shadow reputation role\n",
      "\n",
      "        This role is for everyone who fulfils the base reputation threshold,\n",
      "        including those whose main role has decayed, or those who abstained from the main role.\"\"\"\n",
      "        gld = ctx.guild\n",
      "        if not role:  # Clear config.\n",
      "            await self.config.guild(gld).shadow_role.clear()\n",
      "            msg = self.ROLE_CONFIG_CLEARED\n",
      "        else:  # Set reputation role to role provided.\n",
      "            await self.config.guild(gld).shadow_role.set(role.id)\n",
      "            msg = self.ROLE_CONFIG_SET\n",
      "        await ctx.send(msg)\n",
      "\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @_reputation_settings.command(name=\"log_channel\")\n",
      "    async def set_log_channel(self, ctx: Context):\n",
      "        \"\"\"Set the current channel as the reputation channel\n",
      "\n",
      "        If this channel is already the reputation channel, the config will be cleared.\"\"\"\n",
      "        channel = ctx.channel\n",
      "        gld = ctx.guild\n",
      "        if channel.id == await self.config.guild(gld).log_channel():\n",
      "            await self.config.guild(gld).log_channel.clear()\n",
      "            msg = self.LOG_CHANNEL_CLEARED\n",
      "        else:\n",
      "            await self.config.guild(gld).log_channel.set(channel.id)\n",
      "            msg = self.CHANNEL_SET.format(channel.mention)\n",
      "        await ctx.send(msg)\n",
      "\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @_reputation_settings.command(name=\"reputation_channel\")\n",
      "    async def set_rep_channel(self, ctx: Context):\n",
      "        \"\"\"Set the current channel as the reputation channel\n",
      "\n",
      "        If this channel is already the reputation channel, the config will be cleared.\"\"\"\n",
      "        channel = ctx.channel\n",
      "        gld = ctx.guild\n",
      "        if channel.id == await self.config.guild(gld).reputation_channel():\n",
      "            await self.config.guild(gld).reputation_channel.clear()\n",
      "            msg = self.REP_CHANNEL_CLEARED\n",
      "        else:\n",
      "            await self.config.guild(gld).reputation_channel.set(channel.id)\n",
      "            msg = self.CHANNEL_SET.format(channel.mention)\n",
      "        await ctx.send(msg)\n",
      "\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @_reputation_settings.command(name=\"cooldown\")\n",
      "    async def set_rep_cooldown(self, ctx: Context, days: int, hours: int = 0, minutes: int = 0, seconds: int = 0):\n",
      "        \"\"\"Set the reputation cooldown\n",
      "\n",
      "        If a cooldown is active, user A cannot give user B a reputation for the set period after the last rep pair.\n",
      "\n",
      "        You must use the `days` argument. If the time provided equals zero, the cooldown will be disabled.\n",
      "        If the time provided < 0, then the config will be reset to its default (1 week).\n",
      "        \"\"\"\n",
      "        gld = ctx.guild\n",
      "        delta = dt.timedelta(days=days, hours=hours, minutes=minutes, seconds=seconds)\n",
      "        delta_sec = int(delta.total_seconds())  # Float by default.\n",
      "        if delta_sec < 0:  # Clear config.\n",
      "            await self.config.guild(gld).cooldown_period.clear()\n",
      "            msg = self.COOLDOWN_CLEARED\n",
      "        elif delta_sec == 0:  # Set config to None.\n",
      "            await self.config.guild(gld).cooldown_period.set(None)\n",
      "            msg = self.COOLDOWN_REMOVED\n",
      "        else:  # Set cooldown to time provided.\n",
      "            await self.config.guild(gld).cooldown_period.set(delta_sec)\n",
      "            msg = self.COOLDOWN_SET.format(str(delta))\n",
      "        await ctx.send(msg)\n",
      "\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @_reputation_settings.command(name=\"decay\")\n",
      "    async def set_rep_decay(self, ctx: Context, days: int, hours: int = 0, minutes: int = 0, seconds: int = 0):\n",
      "        \"\"\"Set the decay period\n",
      "\n",
      "        If the decay is active, a user will lose their role if they haven't received sufficient reputation \\\n",
      "        during the decay period.\n",
      "\n",
      "        You must use the `days` argument. If the time provided equals zero, the decay will be disabled.\n",
      "        If the time provided < 0, then the config will be reset to its default (5 weeks).\n",
      "        \"\"\"\n",
      "        gld = ctx.guild\n",
      "        delta = dt.timedelta(days=days, hours=hours, minutes=minutes, seconds=seconds)\n",
      "        delta_sec = int(delta.total_seconds())  # Float by default.\n",
      "        if delta_sec < 0:  # Clear config.\n",
      "            await self.config.guild(gld).decay_period.clear()\n",
      "            msg = self.DECAY_CLEARED\n",
      "        elif delta_sec == 0:  # Set config to None.\n",
      "            await self.config.guild(gld).decay_period.set(None)\n",
      "            msg = self.DECAY_REMOVED\n",
      "        else:  # Set decay to time provided.\n",
      "            await self.config.guild(gld).decay_period.set(delta_sec)\n",
      "            msg = self.DECAY_SET.format(str(delta))\n",
      "        await ctx.send(msg)\n",
      "\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @_reputation_settings.command(name=\"role_threshold\")\n",
      "    async def set_role_threshold(self, ctx: Context, threshold: int = None):\n",
      "        \"\"\"Set the role threshold\n",
      "\n",
      "        Role threshold is the amount of reputations you need to have received before getting the reputation role.\n",
      "        \"\"\"\n",
      "        gld = ctx.guild\n",
      "        if not threshold:  # Clear config.\n",
      "            await self.config.guild(gld).role_threshold.clear()\n",
      "            msg = self.ROLE_THRESHOLD_CLEARED\n",
      "        else:  # Set role threshold to int provided.\n",
      "            await self.config.guild(gld).role_threshold.set(threshold)\n",
      "            msg = self.ROLE_THRESHOLD_SET.format(str(threshold))\n",
      "        await ctx.send(msg)\n",
      "\n",
      "    @_reputation_settings.command(name=\"full_check\")\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def manual_guild_check(self, ctx: Context):\n",
      "        \"\"\"Do a manual reputation eligibility check for all members on the server\"\"\"\n",
      "        add_n, del_n = await self.guild_role_check(ctx.guild)\n",
      "        await ctx.send(self.MANUAL_CHECK.format(add_n=add_n, s=self.plural_s(add_n), del_n=del_n))\n",
      "\n",
      "    @commands.guild_only()\n",
      "    @commands.command()\n",
      "    async def rep(self, ctx: Context, user: discord.Member, *, comment: str = None):\n",
      "        \"\"\"Give someone reputation\n",
      "\n",
      "        You may add a comment, but this is not necessary.\"\"\"\n",
      "        # TODO: Possibly restrict length of rep message.\n",
      "        aut = ctx.author\n",
      "        gld = ctx.guild\n",
      "        channel = ctx.channel\n",
      "        cooldown_secs = await self.config.guild(ctx.guild).cooldown_period()\n",
      "        if user == ctx.author:\n",
      "            notice = self.REP_YOURSELF\n",
      "        elif comment and \"@\" in comment:\n",
      "            notice = self.REP_COMMENT_HAS_AT\n",
      "        else:\n",
      "            rep_channel = await self.config.guild(gld).reputation_channel()\n",
      "            if rep_channel is None or rep_channel == channel.id:\n",
      "                rep_msg = None if not comment else comment  # Add message as NULL to db if empty string.\n",
      "                is_added = await self.rep_db.insert_rep(aut.id, str(aut), user.id, str(user),\n",
      "                                                        ctx.message.created_at, rep_msg, cooldown_secs)\n",
      "                if is_added:\n",
      "                    notice = None\n",
      "                    await self.user_role_check(ctx, member=user)\n",
      "                    await ctx.tick()\n",
      "                else:\n",
      "                    notice = self.REP_NOT_COOL\n",
      "            else:\n",
      "                notice = self.BAD_CHANNEL\n",
      "        if notice:  # Delete after some seconds as to not clog the channel.\n",
      "            await ctx.send(notice, delete_after=20)\n",
      "            await sleep(20)\n",
      "            try:  # Delete the original message at the same time.\n",
      "                await ctx.message.delete()\n",
      "            except discord.Forbidden:\n",
      "                print(\"rep -> I lack manage messages permissions!\")\n",
      "\n",
      "    @rep.error\n",
      "    async def rep_error(self, ctx, error):\n",
      "        \"\"\"Ensure that input errors cause message deletions\"\"\"\n",
      "        if isinstance(error, commands.BadArgument):\n",
      "            await ctx.send(self.REP_BAD_INPUT, delete_after=30)\n",
      "        # Delete the original message.\n",
      "        await sleep(20)\n",
      "        try:\n",
      "            await ctx.message.delete()\n",
      "        except discord.Forbidden:\n",
      "            print(\"rep_error -> I lack manage messages permissions!\")\n",
      "\n",
      "    @commands.command(name=\"reps\", aliases=[\"rep_count\"])\n",
      "    async def rep_count(self, ctx: Context, user: discord.Member = None):\n",
      "        \"\"\"See the amount of reps given to a user\"\"\"\n",
      "        if user is None:\n",
      "            user = ctx.author\n",
      "        embed = discord.Embed(title=\"User reputation count\", colour=discord.Colour.purple())\n",
      "\n",
      "        count, distinct_count, dt_str = await self.rep_db.user_rep_count(user.id)\n",
      "        if count:\n",
      "            cs, dcs = self.plural_s(count), self.plural_s(distinct_count)\n",
      "            embed.description = self.COUNT_DESC.format(user.mention, count, cs, distinct_count, dcs)\n",
      "            embed.timestamp = dt.datetime.strptime(dt_str, self.TIME_FMT)\n",
      "            embed.set_footer(text=\"User ID: {} | Last rep given\".format(user.id))\n",
      "        else:\n",
      "            embed.description = self.COUNT_NO_REPS.format(user.mention)\n",
      "        await ctx.send(embed=embed)\n",
      "\n",
      "    @commands.command(name=\"leaderboard\", aliases=[\"lboard\"])\n",
      "    async def rep_leaderboard(self, ctx: Context):\n",
      "        \"\"\"See the reputation leaderboard\n",
      "\n",
      "        Ties are broken based on who received a reputation the most recently.\"\"\"\n",
      "        board_list = await self.rep_db.rep_leaderboard()\n",
      "        if board_list is None:\n",
      "            await ctx.send(self.LEADERBOARD_NO_REPS)\n",
      "        else:  # At least one rep given\n",
      "            repped_count = len(board_list)\n",
      "            width = len(str(repped_count))\n",
      "            desc = self.LEADERBOARD_DESC.format(repped_count)\n",
      "            # Split the leaderboard into fields with at most 10 rows each.\n",
      "            field_list = []\n",
      "            for i in range((repped_count // 10) + 1):\n",
      "                start = 10 * i\n",
      "                end = start + 10 if repped_count > (start + 10) else repped_count\n",
      "\n",
      "                field_name = \"{}-{}\".format(start + 1, end)\n",
      "                field_value = \"\\n\".join((self.LEADERBOARD_ROW.format((i + 1), width, f\"<@{t[0]}>\", t[1])\n",
      "                                         for i, t in enumerate(board_list[start:end], start=start)))\n",
      "                field_list.append((field_name, field_value))\n",
      "\n",
      "            field_count = len(field_list)\n",
      "            if field_count == 1:  # If only 1 field, send as 1 embed.\n",
      "                f_name = field_list[0][0]\n",
      "                f_value = field_list[0][1]\n",
      "                embed = discord.Embed(title=\"Reputation leaderboard\", description=desc, colour=discord.Colour.purple())\n",
      "                embed.add_field(name=f_name, value=f_value)\n",
      "                footer = \"1 of 1\"\n",
      "                embed.set_footer(text=footer)\n",
      "                await ctx.send(embed=embed)\n",
      "            else:  # If more than one field, send as a pagified menu.\n",
      "                embed_list = []\n",
      "                for n, (f_name, f_value) in enumerate(field_list, start=1):\n",
      "                    embed = discord.Embed(title=\"Reputation leaderboard\", colour=discord.Colour.purple())\n",
      "                    embed.description = desc\n",
      "                    embed.add_field(name=f_name, value=f_value)\n",
      "                    footer = \"{n} of {total}.\".format(n=n, total=field_count)\n",
      "                    embed.set_footer(text=footer)\n",
      "                    embed_list.append(embed)\n",
      "                await red_menu.menu(ctx, embed_list, red_menu.DEFAULT_CONTROLS, timeout=30.0)\n",
      "\n",
      "    # Utilities\n",
      "    async def red_delete_data_for_user(\n",
      "        self,\n",
      "        *,\n",
      "        requester: Literal[\"discord_deleted_user\", \"owner\", \"user\", \"user_strict\"],\n",
      "        user_id: int,\n",
      "    ):\n",
      "        \"\"\"Delete someone's linked account (only info stored)\n",
      "\n",
      "        This does not take care of any rank roles that the user may have.\"\"\"\n",
      "        await self.bot.send_to_owners(self.DEL_REQUEST.format(user_id, requester))\n",
      "\n",
      "    async def user_role_check(self, ctx: Context, member: discord.Member = None) -> None:\n",
      "        \"\"\"\n",
      "        :param ctx: The Context object of the message that requests the check\n",
      "        :param member: (Optional) The user to check. If not provided, the author of the command will be checked instead.\n",
      "        :return: None\n",
      "\n",
      "        Check whether a user is eligible for the reputation role\n",
      "\n",
      "        If so, the role will be added if they do not have it. If not, the role will be removed if they have it.\n",
      "        \"\"\"\n",
      "        gld = ctx.guild\n",
      "        if member is None:\n",
      "            member = ctx.author\n",
      "\n",
      "        rep_role = await self.get_reputation_role_obj(gld)\n",
      "        user_opt_out = await self.config.user(member).opt_out()\n",
      "        if rep_role and not user_opt_out:  # Don't check if the role is not configured.\n",
      "            has_role: bool = rep_role in member.roles  # Check if user has the reputation role.\n",
      "            # Check whether a user's total reputations exceed the threshold.\n",
      "            u_total_reps: int = (await self.rep_db.user_rep_count(member.id))[0]\n",
      "            gld_config = await self.config.guild(gld).all()\n",
      "            role_threshold = gld_config[\"role_threshold\"]\n",
      "            if u_total_reps >= role_threshold:\n",
      "                # Get decay period, decay threshold, and use those for comparisons.\n",
      "                decay_secs = gld_config[\"decay_period\"]\n",
      "                if decay_secs:  # Decay threshold configured.\n",
      "                    decay_min = gld_config[\"decay_threshold\"]\n",
      "                    decay_dt = ctx.message.created_at - dt.timedelta(seconds=decay_secs)\n",
      "                    recent_rep_count = await self.rep_db.recent_reps(user_id=member.id, start_time=decay_dt)\n",
      "                    if not has_role and recent_rep_count >= decay_min:\n",
      "                        await self.give_reputation_role(member, rep_role, gld, gld_config, reason=self.ONE_ADD)\n",
      "                    elif has_role and recent_rep_count < decay_min:\n",
      "                        await member.remove_roles(rep_role)\n",
      "                elif not has_role:  # No decay, but above rep threshold.\n",
      "                    await self.give_reputation_role(member, rep_role, gld, gld_config, reason=self.ONE_ADD)\n",
      "            elif has_role:\n",
      "                await member.remove_roles(rep_role)\n",
      "\n",
      "    async def give_reputation_role(self, member: discord.Member, rep_role: discord.Role,\n",
      "                                   guild: discord.Guild, guild_config: dict, reason: str = None) -> bool:\n",
      "        \"\"\"\n",
      "        :param member: The member to which a reputation role should be added\n",
      "        :param rep_role: The role to be given.\n",
      "        :param guild: The guild on which the role should be given.\n",
      "        :param guild_config: Configuration of this module for guild.\n",
      "        :param reason: (Optional) The reason in the audit log for adding the role(s).\n",
      "        :return: Boolean determining whether a user has received a role.\n",
      "\n",
      "        Give a user the reputation role, and perform other operations if need be\n",
      "\n",
      "        The reputation role will only be added if they did not opt out for it.\n",
      "        \"\"\"\n",
      "        to_return, should_log = False, False\n",
      "        shadow_role = await self.get_shadow_role_obj(guild)\n",
      "        opt_out = await self.config.user(member).opt_out()\n",
      "\n",
      "        roles_to_add = []\n",
      "        if shadow_role:\n",
      "            if shadow_role not in member.roles:\n",
      "                should_log = True\n",
      "                roles_to_add.append(shadow_role)\n",
      "                if not opt_out:\n",
      "                    roles_to_add.append(rep_role)\n",
      "            elif not opt_out:\n",
      "                roles_to_add.append(rep_role)\n",
      "        elif not opt_out:\n",
      "            should_log = True\n",
      "            roles_to_add.append(rep_role)\n",
      "\n",
      "        if roles_to_add:  # First add role(s), then log (if needed).\n",
      "            to_return = True\n",
      "            await member.add_roles(*roles_to_add, reason=reason)\n",
      "            if should_log:\n",
      "                log_channel_id, log_message = guild_config[\"log_channel\"], guild_config[\"log_message\"]\n",
      "                log_channel = discord.utils.get(guild.channels, id=log_channel_id)\n",
      "                assert log_channel or not log_channel_id, \"Log channel is configured but does not exist!\"\n",
      "                if log_channel:\n",
      "                    await log_channel.send(log_message.format(user=member.mention))\n",
      "        return to_return\n",
      "\n",
      "    async def guild_role_check(self, gld: discord.Guild) -> Tuple[int, int]:\n",
      "        \"\"\"\n",
      "        Check which users on a guild should or shouldn't have the rep role\n",
      "\n",
      "        Roles will be edited accordingly.\n",
      "        \"\"\"\n",
      "        rep_role = await self.get_reputation_role_obj(gld)\n",
      "        if rep_role:\n",
      "            gld_config = await self.config.guild(gld).all()\n",
      "            db_args = gld_config[\"decay_threshold\"], gld_config[\"role_threshold\"], gld_config[\"decay_period\"]\n",
      "            eligible_set = await self.rep_db.all_eligible_users(*db_args)\n",
      "            current_list = [member for member in gld.members if rep_role in member.roles]\n",
      "            current_id_set = {m.id for m in current_list}\n",
      "            # Get list of users which should gain the role, and list which should lose the role.\n",
      "            give_set: Set[int] = {i for i in eligible_set if i not in current_id_set}\n",
      "            give_tup: Tuple[discord.Member, ...] = tuple(m for m in gld.members if m.id in give_set)\n",
      "            take_tup: Tuple[discord.Member, ...] = tuple(m for m in current_list if m.id not in eligible_set)\n",
      "\n",
      "            remove_count = len(take_tup)\n",
      "            add_count = 0  # Accumulator.\n",
      "            for member in give_tup:\n",
      "                is_given = await self.give_reputation_role(member, rep_role, gld, gld_config, reason=self.GLD_ADD)\n",
      "                add_count += bool(is_given)\n",
      "            for member in take_tup:\n",
      "                await member.remove_roles(rep_role, reason=self.GLD_ADD)\n",
      "            return add_count, remove_count\n",
      "\n",
      "    async def get_reputation_role_obj(self, guild: discord.Guild) -> Optional[discord.Role]:\n",
      "        \"\"\"Get the reputation role object if a role ID is set, None otherwise\n",
      "\n",
      "        If a role ID is set but no role is found, this will return an error\"\"\"\n",
      "        rep_role = None\n",
      "        rep_role_id = await self.config.guild(guild).reputation_role()\n",
      "        if rep_role_id:\n",
      "            rep_role = discord.utils.get(guild.roles, id=rep_role_id)\n",
      "            assert rep_role, \"The reputation role ID is configured, but the role does not exist!\"\n",
      "        return rep_role\n",
      "\n",
      "    async def get_shadow_role_obj(self, guild: discord.Guild) -> Optional[discord.Role]:\n",
      "        \"\"\"Get the shadow role object if a role ID is set, None otherwise\n",
      "\n",
      "        If a role ID is set but no role is found, this will return an error\"\"\"\n",
      "        rep_role = None\n",
      "        rep_role_id = await self.config.guild(guild).shadow_role()\n",
      "        if rep_role_id:\n",
      "            rep_role = discord.utils.get(guild.roles, id=rep_role_id)\n",
      "            assert rep_role, \"The shadow role ID is configured, but the role does not exist!\"\n",
      "        return rep_role\n",
      "\n",
      "    @staticmethod\n",
      "    def plural_s(n: int) -> str:\n",
      "        \"\"\"Returns an 's' if n is not 1, otherwise returns an empty string\"\"\"\n",
      "        return \"\" if n == 1 else \"s\"\n",
      "\n",
      "Output: {'reputation': [], 'reputation.Reputation.__init__': ['<builtin>.super', 'redbot.core.Config.get_conf', 'redbot.core.data_manager.cog_data_path', 'reputation.Reputation.periodical_decay_check', 'asyncio.ensure_future', '<builtin>.str', 'db_queries.DbQueries'], '<builtin>.super': [], 'redbot.core.data_manager.cog_data_path': [], '<builtin>.str': [], 'redbot.core.Config.get_conf': [], 'db_queries.DbQueries': [], 'reputation.Reputation.periodical_decay_check': ['asyncio.sleep', 'reputation.Reputation.guild_role_check'], 'asyncio.ensure_future': [], 'reputation.Reputation.guild_role_check': ['<builtin>.bool', 'reputation.Reputation.give_reputation_role', '<builtin>.len', '<builtin>.tuple', 'reputation.Reputation.get_reputation_role_obj'], 'asyncio.sleep': [], 'redbot.core.commands.guild_only': [], 'reputation.Reputation': ['redbot.core.commands.group', 'redbot.core.commands.guild_only', 'redbot.core.checks.admin_or_permissions', 'redbot.core.commands.command'], 'redbot.core.commands.group': [], 'reputation.Reputation._reputation_settings': [], 'redbot.core.checks.admin_or_permissions': [], 'reputation.Reputation.view_current_config': ['discord.Embed', 'datetime.timedelta', 'discord.utils.get', 'reputation.Reputation.get_shadow_role_obj', '<builtin>.str', 'reputation.Reputation.get_reputation_role_obj', 'discord.Colour.lighter_grey'], 'discord.Colour.lighter_grey': [], 'discord.Embed': [], 'reputation.Reputation.get_reputation_role_obj': ['discord.utils.get'], 'datetime.timedelta': [], 'discord.utils.get': [], 'reputation.Reputation.get_shadow_role_obj': ['discord.utils.get'], 'reputation.Reputation.role_opt_out': ['reputation.Reputation.get_reputation_role_obj', 'reputation.Reputation.user_role_check'], 'reputation.Reputation.user_role_check': ['datetime.timedelta', 'reputation.Reputation.get_reputation_role_obj', 'reputation.Reputation.give_reputation_role'], 'reputation.Reputation.set_decay_threshold': ['<builtin>.str'], 'reputation.Reputation.set_log_message': [], 'reputation.Reputation.set_reputation_role': [], 'reputation.Reputation.set_shadow_role': [], 'reputation.Reputation.set_log_channel': [], 'reputation.Reputation.set_rep_channel': [], 'reputation.Reputation.set_rep_cooldown': ['datetime.timedelta', '<builtin>.int', '<builtin>.str'], '<builtin>.int': [], 'reputation.Reputation.set_rep_decay': ['datetime.timedelta', '<builtin>.int', '<builtin>.str'], 'reputation.Reputation.set_role_threshold': ['<builtin>.str'], 'reputation.Reputation.manual_guild_check': ['reputation.Reputation.guild_role_check', 'reputation.Reputation.plural_s'], 'reputation.Reputation.plural_s': [], 'redbot.core.commands.command': [], 'reputation.Reputation.rep': ['<builtin>.print', 'asyncio.sleep', '<builtin>.str', 'reputation.Reputation.user_role_check'], '<builtin>.print': [], 'reputation.Reputation.rep_error': ['<builtin>.isinstance', '<builtin>.print', 'asyncio.sleep'], '<builtin>.isinstance': [], 'reputation.Reputation.rep_count': ['discord.Colour.purple', 'datetime.datetime.strptime', 'reputation.Reputation.plural_s', 'discord.Embed'], 'discord.Colour.purple': [], 'datetime.datetime.strptime': [], 'reputation.Reputation.rep_leaderboard': ['<builtin>.range', 'discord.Embed', '<builtin>.len', '<builtin>.enumerate', '<builtin>.str', 'discord.Colour.purple', 'redbot.core.utils.menus.menu'], '<builtin>.len': [], '<builtin>.range': [], '<builtin>.enumerate': [], 'redbot.core.utils.menus.menu': [], 'reputation.Reputation.red_delete_data_for_user': [], 'reputation.Reputation.give_reputation_role': ['discord.utils.get', 'reputation.Reputation.get_shadow_role_obj'], '<builtin>.tuple': [], '<builtin>.bool': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\FixedThink_RocketCogs\\reputation\\reputation.py\n",
      "[('reputation Reputation __init__', 'redbot core Config get_conf'), ('reputation Reputation __init__', 'redbot core data_manager cog_data_path'), ('reputation Reputation __init__', 'reputation Reputation periodical_decay_check'), ('reputation Reputation __init__', 'asyncio ensure_future'), ('reputation Reputation __init__', 'db_queries DbQueries'), ('reputation Reputation periodical_decay_check', 'asyncio sleep'), ('reputation Reputation periodical_decay_check', 'reputation Reputation guild_role_check'), ('reputation Reputation guild_role_check', 'reputation Reputation give_reputation_role'), ('reputation Reputation guild_role_check', 'reputation Reputation get_reputation_role_obj'), ('reputation Reputation', 'redbot core commands group'), ('reputation Reputation', 'redbot core commands guild_only'), ('reputation Reputation', 'redbot core checks admin_or_permissions'), ('reputation Reputation', 'redbot core commands command'), ('reputation Reputation view_current_config', 'discord Embed'), ('reputation Reputation view_current_config', 'datetime timedelta'), ('reputation Reputation view_current_config', 'discord utils get'), ('reputation Reputation view_current_config', 'reputation Reputation get_shadow_role_obj'), ('reputation Reputation view_current_config', 'reputation Reputation get_reputation_role_obj'), ('reputation Reputation view_current_config', 'discord Colour lighter_grey'), ('reputation Reputation get_reputation_role_obj', 'discord utils get'), ('reputation Reputation get_shadow_role_obj', 'discord utils get'), ('reputation Reputation role_opt_out', 'reputation Reputation get_reputation_role_obj'), ('reputation Reputation role_opt_out', 'reputation Reputation user_role_check'), ('reputation Reputation user_role_check', 'datetime timedelta'), ('reputation Reputation user_role_check', 'reputation Reputation get_reputation_role_obj'), ('reputation Reputation user_role_check', 'reputation Reputation give_reputation_role'), ('reputation Reputation set_rep_cooldown', 'datetime timedelta'), ('reputation Reputation set_rep_decay', 'datetime timedelta'), ('reputation Reputation manual_guild_check', 'reputation Reputation guild_role_check'), ('reputation Reputation manual_guild_check', 'reputation Reputation plural_s')]\n",
      "0\n",
      "found files: []\n",
      "# Default Library.\n",
      "import asyncio\n",
      "from textwrap import shorten\n",
      "from typing import List, Optional\n",
      "\n",
      "# Used by Red.\n",
      "import discord\n",
      "from redbot.core import checks, Config\n",
      "from redbot.core import commands\n",
      "from redbot.core.bot import Red\n",
      "from redbot.core.commands import Cog\n",
      "\n",
      "RLCD_GLD_ID = 317323644961554434\n",
      "\n",
      "\n",
      "def is_in_rlcd():\n",
      "    async def predicate(ctx):\n",
      "        return ctx.guild and ctx.guild.id == RLCD_GLD_ID\n",
      "\n",
      "    return commands.check(predicate)\n",
      "\n",
      "\n",
      "class RlcdVarious(Cog):\n",
      "    \"\"\"A collection of commands tailored to the needs of RLCD\n",
      "\n",
      "    Some of these commands may be moved to a separate cog later on.\n",
      "    \"\"\"\n",
      "    __author__ = \"#s#8059\"\n",
      "\n",
      "    ERROR = \":x: Error: \"\n",
      "    DONE = \":white_check_mark: \"\n",
      "    BIN = \":put_litter_in_its_place: \"\n",
      "    # Notices.\n",
      "    INHOUSES_CHANNEL_CLEARED = BIN + \"Cleared the inhouses channel configuration.\" \\\n",
      "                                     \"Effectively the lobby command functionality is disabled as well.\"\n",
      "    INHOUSES_CHANNEL_SET = DONE + \"Successfully set the inhouses channel to {c}.\"\n",
      "    INHOUSES_NO_CHANNEL = ERROR + \"The inhouses channel is not configured!\"\n",
      "    INHOUSES_WRONG_CHANNEL = ERROR + \"This is not the channel for inhouses! Go to <#{}> instead.\"\n",
      "    LTC_ROLE_CLEARED = BIN + \"Successfully cleared the LTC role.\"\n",
      "    LTC_ROLE_U_DEL = BIN + \"Removed your LTC role.\"\n",
      "    LTC_NOT_ONLINE = ERROR + \"You are not online (green bulb)!\\nPlease set yourself to online first.\"\n",
      "    LTC_NOT_SET = ERROR + \"No LTC role is configured! Please contact an admin.\"\n",
      "    NICKNAME_TOO_LONG = ERROR + \"Your provided nickname is too long!\\n\" \\\n",
      "                                \"To fit your nickname along with the region tag, it can be at most 27 characters.\"\n",
      "    NO_REGION_ROLE = ERROR + \"You do not have a region role! Please set one first.\"\n",
      "    NICKNAME_SET = DONE + \"Nickname set.\"\n",
      "    NICKNAME_PERMISSIONS = ERROR + \"I cannot give you a nickname!\"\n",
      "    SUGGESTION_CHANNEL_SET = DONE + \"Successfully set the suggestions channel to {c}.\"\n",
      "    SUGGESTION_CHANNEL_CLEARED = BIN + \"Cleared the suggestions channel configuration.\"\n",
      "    TWITCH_ROLES_CLEARED = BIN + \"Successfully cleared the Twitch roles configuration.\"\n",
      "    TWITCH_NO_SUB = ERROR + \"You are not subscribed to the Twitch channel!\"\n",
      "    TWITCH_NOT_CONFIGURED = ERROR + \"The Twitch roles are not configured!\"\n",
      "\n",
      "    # Other constants.\n",
      "    LOBBY_EMBED_TITLE = \"Inhouses invite by {}.\"\n",
      "    LTC_SLEEP_TIME = 28 * 60  # 28 minutes.\n",
      "    SUGGEST_EMOTES = \"\"\n",
      "    REGION_ROLE_TAG = {\"Africa\": \"AF\", \"Asia Central\": \"AS\", \"Europe\": \"EU\", \"North America\": \"NA\",\n",
      "                       \"Middle East\": \"ME\", \"Oceania\": \"OC\", \"South America\": \"SA\"}\n",
      "    CONVERT_REGION = {\"eu\": \"Europe\", \"europe\": \"Europe\", \"use\": \"US-East\", \"us-e\": \"US-East\",\n",
      "                      \"nae\": \"US-East\", \"us-east\": \"US-East\", \"us east\": \"US-East\", \"usw\": \"US-West\",\n",
      "                      \"us-w\": \"US-West\", \"naw\": \"US-West\", \"us-west\": \"US-West\", \"us wast\": \"US-West\"}\n",
      "    FEENIX_INCREASE = \"Count successfully increased. Feenix has now mentioned his MMR **{count}** times in RLCD.\"\n",
      "    FEENIX_SET = \"The counter has been set to: **{}**.\"\n",
      "    FEENIX_VIEW = \"Feenix has mentioned his MMR **{}** times in RLCD.\"\n",
      "\n",
      "    def __init__(self, bot: Red):\n",
      "        super().__init__()\n",
      "        self.bot = bot\n",
      "        self.config = Config.get_conf(self, identifier=7509)\n",
      "        # TODO: Make role toggles for inhouses and meme (low-priority).\n",
      "        self.config.register_guild(inhouses_channel_id=None, suggest_channel_id=None,\n",
      "                                   ltc_role_id=None, twitch_role_id=None, hoist_twitch_id=None, feenix_mmr_counter=0)\n",
      "        self.ltc_loop = asyncio.ensure_future(self.check_ltc())\n",
      "\n",
      "    # Loops\n",
      "    async def check_ltc(self):\n",
      "        \"\"\"Remove the LTC role from whoever has the role and is offline\"\"\"\n",
      "        await self.bot.wait_until_ready()\n",
      "        while self == self.bot.get_cog(self.__class__.__name__):\n",
      "            gld: discord.Guild = self.bot.get_guild(RLCD_GLD_ID)\n",
      "            ltc_id = await self.config.guild(gld).ltc_role_id()\n",
      "            if ltc_id:  # Role ID is configured.\n",
      "                role_obj: discord.Role = discord.utils.get(gld.roles, id=ltc_id)\n",
      "                assert role_obj, \"No role object!\"\n",
      "                # Get all members with the LTC role.\n",
      "                ltc_members: List[discord.Member] = [m for m in gld.members if role_obj in m.roles]\n",
      "                for member in ltc_members:\n",
      "                    if member.status == discord.Status.offline:  # Only remove it when they're offline.\n",
      "                        await member.remove_roles(role_obj)\n",
      "            await asyncio.sleep(self.LTC_SLEEP_TIME)\n",
      "\n",
      "    # Events\n",
      "    @Cog.listener()\n",
      "    async def on_message(self, msg: discord.Message):\n",
      "        \"\"\"Add suggestion reactions\"\"\"\n",
      "        gld = msg.guild\n",
      "        channel = msg.channel\n",
      "        suggest_id = await self.config.guild(gld).suggest_channel_id()\n",
      "        if suggest_id and channel.id == suggest_id:\n",
      "            aut = msg.author\n",
      "            perms = dict(aut.permissions_in(channel))\n",
      "            if not (perms[\"manage_channels\"] or perms[\"manage_messages\"]):\n",
      "                for emote in self.SUGGEST_EMOTES:\n",
      "                    await msg.add_reaction(emote)\n",
      "\n",
      "    @Cog.listener()\n",
      "    async def on_member_update(self, m_old: discord.Member, m_new: discord.Member):\n",
      "        \"\"\"Give a member a nickname if they set a region, and do the Twitch sub check\"\"\"\n",
      "        gld = m_new.guild\n",
      "        twitch_role_id = await self.config.guild(gld).twitch_role_id()\n",
      "        added_role: Optional[discord.Role] = next((r for r in m_new.roles if r not in m_old.roles), None)\n",
      "        if added_role:\n",
      "            region_tag = self.REGION_ROLE_TAG.get(added_role.name, None)\n",
      "            if region_tag:  # Region role added, give nickname.\n",
      "                # Create the nickname to set. Shorten to 32 if it would exceed 32 chars.\n",
      "                to_set = shorten(f\"[{region_tag}] {m_new.name}\", 32, placeholder=\"...\")\n",
      "                try:\n",
      "                    await m_new.edit(nick=to_set, reason=\"RLCD region addition.\")\n",
      "                except discord.Forbidden:\n",
      "                    pass\n",
      "            else:\n",
      "                if twitch_role_id and added_role.id == twitch_role_id:\n",
      "                    hoist_twitch_id = await self.config.guild(gld).hoist_twitch_id()\n",
      "                    hoist_role = discord.utils.get(gld.roles, id=hoist_twitch_id)\n",
      "                    assert hoist_role, \"Somehow, the twitch role is configured, but not the hoist role.\"\n",
      "                    await m_new.add_roles(hoist_role, reason=\"Received the Twitch sub role.\")\n",
      "        elif twitch_role_id:  # Check role removals.\n",
      "            removed_role: Optional[discord.Role] = next((r for r in m_old.roles if r not in m_new.roles), None)\n",
      "            if removed_role.id == twitch_role_id:\n",
      "                hoist_twitch_id = await self.config.guild(gld).hoist_twitch_id()\n",
      "                hoist_role = discord.utils.get(gld.roles, id=hoist_twitch_id)\n",
      "                assert hoist_role, \"Somehow, the twitch role is configured, but not the hoist role.\"\n",
      "                if hoist_role in m_new.roles:\n",
      "                    await m_new.remove_roles(hoist_role, reason=\"Twitch sub ended.\")\n",
      "\n",
      "    # Config commands\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @commands.group(name=\"rlcdset\", invoke_without_command=True)\n",
      "    async def _rlcd_various_settings(self, ctx: commands.Context):\n",
      "        \"\"\"Configure the settings for this module.\"\"\"\n",
      "        await ctx.send_help()\n",
      "\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @_rlcd_various_settings.command(name=\"inhouses_channel\")\n",
      "    async def set_inhouses_channel(self, ctx: commands.Context):\n",
      "        \"\"\"Set the inhouses channel to the current channel\n",
      "\n",
      "        If the current channel is already the inhouses channel, the config gets cleared.\"\"\"\n",
      "        gld = ctx.guild\n",
      "        channel = ctx.channel\n",
      "        if channel.id == await self.config.guild(gld).inhouses_channel_id():\n",
      "            await self.config.guild(gld).inhouses_channel_id.clear()\n",
      "            to_send = self.SUGGESTION_CHANNEL_CLEARED\n",
      "        else:\n",
      "            await self.config.guild(gld).inhouses_channel_id.set(channel.id)\n",
      "            to_send = self.SUGGESTION_CHANNEL_SET.format(c=channel.mention)\n",
      "        await ctx.send(to_send)\n",
      "\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @_rlcd_various_settings.command(name=\"suggestions_channel\")\n",
      "    async def set_suggestions_channel(self, ctx: commands.Context):\n",
      "        \"\"\"Set the suggestions channel to the current channel\n",
      "\n",
      "        If the current channel is already the suggestions channel, the config gets cleared.\"\"\"\n",
      "        gld = ctx.guild\n",
      "        channel = ctx.channel\n",
      "        if channel.id == await self.config.guild(gld).suggest_channel_id():\n",
      "            await self.config.guild(gld).suggest_channel_id.clear()\n",
      "            to_send = self.INHOUSES_CHANNEL_CLEARED\n",
      "        else:\n",
      "            await self.config.guild(gld).suggest_channel_id.set(channel.id)\n",
      "            to_send = self.INHOUSES_CHANNEL_SET.format(c=channel.mention)\n",
      "        await ctx.send(to_send)\n",
      "\n",
      "    @_rlcd_various_settings.command(name=\"ltc_role\")\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def set_ltc_role(self, ctx: commands.Context, role: discord.Role = None):\n",
      "        \"\"\"Set the role to perform the LTC check on\n",
      "\n",
      "        If no role is provided, the currently set role will be deleted.\"\"\"\n",
      "        if not role:\n",
      "            await self.config.guild(ctx.guild).ltc_role_id.clear()\n",
      "            await ctx.send(self.LTC_ROLE_CLEARED)\n",
      "        else:\n",
      "            await self.config.guild(ctx.guild).ltc_role_id.set(role.id)\n",
      "            await ctx.tick()\n",
      "\n",
      "    @_rlcd_various_settings.command(name=\"twitch\")\n",
      "    @commands.guild_only()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def set_twitch_roles(self, ctx: commands.Context, role_1: discord.Role, role_2: discord.Role):\n",
      "        \"\"\"Set the pair of Twitch roles\n",
      "\n",
      "        The first role must be the integration role, the second one the role to be added.\n",
      "        Config can be cleared by using the same role for both arguments\"\"\"\n",
      "        gld = ctx.guild\n",
      "        if role_1 == role_2:\n",
      "            # twitch_role_id=None, hoist_twitch_id=None)\n",
      "            await self.config.guild(gld).twitch_role_id.clear()\n",
      "            await self.config.guild(gld).hoist_twitch_id.clear()\n",
      "            await ctx.send(self.TWITCH_ROLES_CLEARED)\n",
      "        else:\n",
      "            await self.config.guild(ctx.guild).twitch_role_id.set(role_1.id)\n",
      "            await self.config.guild(ctx.guild).hoist_twitch_id.set(role_2.id)\n",
      "            await ctx.tick()\n",
      "\n",
      "    # Main commands.\n",
      "    @commands.guild_only()\n",
      "    @commands.command()\n",
      "    @commands.cooldown(1, 60 * 10, type=commands.BucketType.channel)  # 1 message per 10 minutes.\n",
      "    async def lobby(self, ctx: commands.Context, region: str, lobby_name: str, password: str, *, optional_text=None):\n",
      "        \"\"\"Create an invite message for an inhouses lobby\n",
      "\n",
      "        This invite will ping `@here`. Note that there is a 10-minute cooldown on the command.\"\"\"\n",
      "        chn = ctx.channel\n",
      "        inhouses_id = await self.config.guild(ctx.guild).inhouses_channel_id()\n",
      "        if not inhouses_id or chn.id != inhouses_id:\n",
      "            await ctx.send(self.INHOUSES_NO_CHANNEL if not inhouses_id\n",
      "                           else self.INHOUSES_WRONG_CHANNEL.format(inhouses_id))\n",
      "        else:\n",
      "            region_str = self.CONVERT_REGION.get(region.lower(), region)\n",
      "            embed = discord.Embed(colour=discord.Colour.purple(), description=optional_text)\n",
      "            embed.title = \"Inhouses invite by {}\".format(str(ctx.author))\n",
      "            embed.add_field(name=\"Region\", value=region_str)\n",
      "            embed.add_field(name=\"Lobby name\", value=lobby_name)\n",
      "            embed.add_field(name=\"Password\", value=password)\n",
      "            await ctx.send(\"New inhouses invite. @here\", embed=embed, filter=None)\n",
      "\n",
      "    @is_in_rlcd()\n",
      "    @commands.guild_only()\n",
      "    @commands.command(name=\"ltc\")\n",
      "    async def looking_to_coach(self, ctx: commands.Context):\n",
      "        \"\"\"Give yourself the Looking to Coach role\n",
      "\n",
      "        You must have set a region and you must be in online status.\n",
      "        If you already have the role, this command will remove it.\"\"\"\n",
      "        notice = None\n",
      "        user = ctx.author\n",
      "        gld = ctx.guild\n",
      "        ltc_id = await self.config.guild(gld).ltc_role_id()\n",
      "\n",
      "        if ltc_id:  # Role ID is configured.\n",
      "            role_obj: discord.Role = discord.utils.get(gld.roles, id=ltc_id)\n",
      "            assert role_obj, \"No role object!\"\n",
      "            if role_obj in user.roles:\n",
      "                await user.remove_roles(role_obj)\n",
      "                notice = self.LTC_ROLE_U_DEL\n",
      "            elif any(self.REGION_ROLE_TAG.get(r.name, False) for r in user.roles):\n",
      "                if user.status == discord.Status.online:\n",
      "                    await user.add_roles(role_obj)\n",
      "                    await ctx.tick()\n",
      "                else:\n",
      "                    notice = self.LTC_NOT_ONLINE\n",
      "            else:\n",
      "                notice = self.NO_REGION_ROLE\n",
      "        else:\n",
      "            notice = self.LTC_NOT_SET\n",
      "        if notice:\n",
      "            await ctx.send(notice)\n",
      "\n",
      "    @is_in_rlcd()\n",
      "    @commands.guild_only()\n",
      "    @commands.command(name=\"nickname\", aliases=[\"nick\"])\n",
      "    async def user_set_nickname(self, ctx: commands.Context, *, nickname: str):\n",
      "        \"\"\"Set your own nickname\n",
      "\n",
      "        Your nickname will be automatically prefixed with your region, like [EU].\"\"\"\n",
      "        user = ctx.author\n",
      "        region_tag = next((self.REGION_ROLE_TAG[r.name] for r in user.roles if r.name in self.REGION_ROLE_TAG), None)\n",
      "        if not region_tag:\n",
      "            to_say = self.NO_REGION_ROLE\n",
      "        elif len(nickname) > 27:\n",
      "            to_say = self.NICKNAME_TOO_LONG\n",
      "        else:\n",
      "            to_set = f\"[{region_tag}] {nickname}\"\n",
      "            try:\n",
      "                await user.edit(nick=to_set, reason=\"RLCD nickname command.\")\n",
      "            except discord.Forbidden:\n",
      "                to_say = self.NICKNAME_PERMISSIONS\n",
      "            else:\n",
      "                to_say = self.NICKNAME_SET\n",
      "        await ctx.send(to_say)\n",
      "\n",
      "    @is_in_rlcd()\n",
      "    @commands.group(name=\"feenixmmr\", invoke_without_command=True)\n",
      "    async def _feenix_mmr_counter(self, ctx: commands.Context):\n",
      "        \"\"\"Counter for how many times Feenix has talked about his MMR\"\"\"\n",
      "        await ctx.send_help()\n",
      "\n",
      "    @is_in_rlcd()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @_feenix_mmr_counter.command(name=\"set\")\n",
      "    async def set_counter(self, ctx, amount: int = 0):\n",
      "        \"\"\"Set the counter to a specific amount.\n",
      "\n",
      "        If no amount is given, it will reset the counter to 0.\"\"\"\n",
      "        await self.config.guild(ctx.guild).feenix_mmr_counter.set(amount)\n",
      "        await ctx.send(self.FEENIX_SET.format(amount))\n",
      "\n",
      "    @is_in_rlcd()\n",
      "    @_feenix_mmr_counter.command(name=\"view\")\n",
      "    async def view_counter(self, ctx):\n",
      "        \"\"\"View how many times Feenix has mentioned his MMR.\"\"\"\n",
      "        amount = await self.config.guild(ctx.guild).feenix_mmr_counter()\n",
      "        await ctx.send(self.FEENIX_VIEW.format(amount))\n",
      "\n",
      "    @is_in_rlcd()\n",
      "    @_feenix_mmr_counter.command(name=\"add\")\n",
      "    async def add_to_counter(self, ctx):\n",
      "        \"\"\"Add 1 to the counter.\"\"\"\n",
      "        current_count = await self.config.guild(ctx.guild).feenix_mmr_counter()\n",
      "        new_count = current_count + 1\n",
      "        await self.config.guild(ctx.guild).feenix_mmr_counter.set(new_count)\n",
      "        await ctx.send(self.FEENIX_INCREASE.format(count=new_count))\n",
      "\n",
      "    @is_in_rlcd()\n",
      "    @commands.guild_only()\n",
      "    @commands.command(name=\"toggle_twitch\")\n",
      "    async def toggle_twitch_role(self, ctx: commands.Context):\n",
      "        \"\"\"Remove the hoisted twitch role if you have it, otherwise add it\n",
      "\n",
      "        Obviously, you must be subscribed to Twitch in order to do this.\"\"\"\n",
      "        gld = ctx.guild\n",
      "        t_id = await self.config.guild(gld).twitch_role_id()\n",
      "        h_id = await self.config.guild(gld).hoist_twitch_id()\n",
      "        if t_id and h_id:\n",
      "            t_role = discord.utils.get(gld.roles, id=t_id)\n",
      "            h_role = discord.utils.get(gld.roles, id=h_id)\n",
      "            assert t_role and h_role, \"Twitch roles do not exist!\"\n",
      "            aut: discord.Member = ctx.author\n",
      "            if t_role in aut.roles:  # Toggle.\n",
      "                if h_role in aut.roles:\n",
      "                    await aut.remove_roles(h_role, reason=\"Twitch toggle command\")\n",
      "                else:\n",
      "                    await aut.add_roles(h_role, reason=\"Twitch toggle command\")\n",
      "                await ctx.tick()\n",
      "                notice = None\n",
      "            else:\n",
      "                notice = self.TWITCH_NO_SUB\n",
      "        else:\n",
      "            notice = self.TWITCH_NOT_CONFIGURED\n",
      "        if notice:\n",
      "            await ctx.send(notice)\n",
      "\n",
      "    # Utilities\n",
      "    async def red_delete_data_for_user(self, **kwargs):\n",
      "        pass  # No user data stored.\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\FixedThink_RocketCogs\\rlcd_various\\rlcd_various.py\n",
      "[]\n",
      "found files: []\n",
      "# Default library.\n",
      "import json\n",
      "import os\n",
      "from typing import Optional, Dict\n",
      "\n",
      "\n",
      "def _json_key_to_int(to_convert: dict) -> dict:\n",
      "    \"\"\"Converts the keys of a (JSON) dictionary to integers\"\"\"\n",
      "    return {int(k): v for k, v in to_convert.items()}\n",
      "\n",
      "\n",
      "class GetJsonData:\n",
      "    \"\"\"Obtains the data to be retrieved from the conversion dict json\"\"\"\n",
      "    CURRENT_FOLDER = os.path.dirname(os.path.realpath(__file__))\n",
      "    DATA_FOLDER = CURRENT_FOLDER + \"/Data/\"\n",
      "    JSON_PATH = DATA_FOLDER + \"conversion_dicts.json\"\n",
      "    PLAYLIST_ID_SET = {0, 10, 11, 12, 13, 27, 28, 29, 30}\n",
      "    MODE_DICT = {1: \"short\", 2: \"medium\", 3: \"long\"}\n",
      "\n",
      "    def __init__(self):\n",
      "        with open(self.JSON_PATH, 'r') as f:\n",
      "            json_dict = json.load(f)\n",
      "        self.divmod_colours: Dict[int, str] = _json_key_to_int(json_dict[\"embed_divmod_colours\"])\n",
      "        self.divmod_tiers: Dict[int, str] = _json_key_to_int(json_dict[\"tier_divmod_names\"])\n",
      "        self.icons: Dict[int, str] = _json_key_to_int(json_dict[\"tier_icons\"])\n",
      "        self.roman_nums: Dict[int, str] = _json_key_to_int(json_dict[\"roman_numerals\"])\n",
      "        self.str_to_platform: Dict[str, list] = json_dict[\"platform_convert\"]\n",
      "        self.str_to_playlist: Dict[str, int] = json_dict[\"playlist_convert\"]\n",
      "        self.int_to_plist_str: Dict[str, Dict[int, str]] = {}  # To be filled.\n",
      "        for k, v in json_dict[\"playlist_names\"].items():  # Manually unpack nested dict to convert str keys to int.\n",
      "            self.int_to_plist_str[k] = _json_key_to_int(v)\n",
      "\n",
      "    def get_input_platform(self, platform_in: str) -> Optional[str]:\n",
      "        \"\"\"\n",
      "        :param platform_in: a string with the platform as put in by the user.\n",
      "        :return: The platform string needed for an API request.\n",
      "        \"\"\"\n",
      "        to_return = None  # Default value (if no matching platform found).\n",
      "        to_check = platform_in.lower()\n",
      "        if to_check in self.str_to_platform[\"pc_names\"]:\n",
      "            to_return = \"steam\"\n",
      "        elif to_check in self.str_to_platform[\"ps4_names\"]:\n",
      "            to_return = \"ps4\"\n",
      "        elif to_check in self.str_to_platform[\"xbox_names\"]:\n",
      "            to_return = \"xboxone\"\n",
      "        elif to_check in self.str_to_platform[\"switch_names\"]:\n",
      "            to_return = \"switch\"  # Currently not supported by API.\n",
      "        return to_return\n",
      "\n",
      "    def get_input_playlist(self, playlist_str: str) -> Optional[int]:\n",
      "        \"\"\"\n",
      "        :param playlist_str: a string with the playlist as put in by the user\n",
      "        :return: The playlist ID (int) if there is a match, None otherwise.\n",
      "        \"\"\"\n",
      "        try:  # Allow people to put in actual playlist IDs too.\n",
      "            playlist_int = int(playlist_str)\n",
      "        except ValueError:  # Validate playlist using conversion dict.\n",
      "            to_return = self.str_to_playlist.get(playlist_str.lower(), None)\n",
      "        else:\n",
      "            to_return = playlist_int if playlist_int in self.PLAYLIST_ID_SET else None\n",
      "        return to_return\n",
      "\n",
      "    def get_tier_colour(self, tier_n: int) -> int:\n",
      "        \"\"\"\n",
      "        :param tier_n: The tier number.\n",
      "        :return: A hex code for the colour of the rank embed.\n",
      "        \"\"\"\n",
      "        colour_key = (tier_n + 2) // 3  # For unranked: (0 + 2) // 3 == 0\n",
      "        return int(self.divmod_colours[colour_key], 16)  # 0x-values stored as string.\n",
      "\n",
      "    def get_tier_icon(self, tier_n: int) -> str:\n",
      "        \"\"\"\n",
      "        :param tier_n: The tier number.\n",
      "        :return: A string with the image link.\n",
      "        \"\"\"\n",
      "        return self.icons[tier_n]\n",
      "\n",
      "    def get_tier_name(self, tier_n: int) -> str:\n",
      "        \"\"\"\n",
      "        :param tier_n: tier number\n",
      "        :return: tier name\n",
      "        \"\"\"\n",
      "        key, div = divmod((tier_n + 2), 3)\n",
      "        if key in (0, 8):\n",
      "            to_return = self.divmod_tiers[key]\n",
      "        else:\n",
      "            to_return = \" \".join((self.divmod_tiers[key], self.roman_nums[div + 1]))\n",
      "        return to_return\n",
      "\n",
      "    def get_playlist_name(self, playlist_id: int, mode: int = 2) -> str:\n",
      "        \"\"\"\n",
      "        :param playlist_id:\n",
      "        :param mode:\n",
      "        :return:\n",
      "        \"\"\"\n",
      "        assert 1 <= mode <= 3, \"The mode int must be 1, 2, or 3.\"\n",
      "        mode_str = self.MODE_DICT[mode]\n",
      "        return self.int_to_plist_str[mode_str][playlist_id]\n",
      "\n",
      "    def tier_div_str(self, skills_item: dict) -> str:\n",
      "        \"\"\"\n",
      "        :param skills_item: An item (playlist) of the \"player_skills\" list in the PlayerSkills API response dict.\n",
      "        :return: A string depicting that playlist's tier and division (if applicable).\n",
      "        \"\"\"\n",
      "        tier_n = skills_item[\"tier\"]\n",
      "        div = skills_item[\"division\"] + 1\n",
      "        tier = self.get_tier_name(tier_n)\n",
      "        return \"{} Div. {}\".format(tier, div) if tier_n not in (0, 19) else tier\n",
      "\n",
      "    def reward_level_str(self, response: dict) -> str:\n",
      "        \"\"\"\n",
      "        :param response: The PlayerSkills API response dict\n",
      "        :return: A player's Season Rewards level summarised into a string\n",
      "        \"\"\"\n",
      "        rewards = response[\"season_rewards\"]\n",
      "        level, wins = rewards[\"level\"], rewards[\"wins\"]\n",
      "        if level:\n",
      "            level_str = self.divmod_tiers[level]\n",
      "            bonus_str = \" (+{})\".format(wins) if level != 7 else \"\"\n",
      "            to_return = \"{}{}\".format(level_str, bonus_str)\n",
      "        else:\n",
      "            to_return = \"*None*\"\n",
      "        return to_return\n",
      "\n",
      "Output: {'json_data': [], 'json_data._json_key_to_int': ['<builtin>.int'], '<builtin>.int': [], 'os.path.realpath': [], 'json_data.GetJsonData': ['os.path.dirname', 'os.path.realpath'], 'os.path.dirname': [], 'json_data.GetJsonData.__init__': ['json_data._json_key_to_int', 'json.load', '<builtin>.open'], '<builtin>.open': [], 'json.load': [], 'json_data.GetJsonData.get_input_platform': [], 'json_data.GetJsonData.get_input_playlist': ['<builtin>.int'], 'json_data.GetJsonData.get_tier_colour': ['<builtin>.int'], 'json_data.GetJsonData.get_tier_icon': [], 'json_data.GetJsonData.get_tier_name': ['<builtin>.divmod'], '<builtin>.divmod': [], 'json_data.GetJsonData.get_playlist_name': [], 'json_data.GetJsonData.tier_div_str': ['json_data.GetJsonData.get_tier_name'], 'json_data.GetJsonData.reward_level_str': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\FixedThink_RocketCogs\\lafusee\\json_data.py\n",
      "[('json_data GetJsonData', 'os path dirname'), ('json_data GetJsonData', 'os path realpath'), ('json_data GetJsonData __init__', 'json_data _json_key_to_int'), ('json_data GetJsonData __init__', 'json load'), ('json_data GetJsonData tier_div_str', 'json_data GetJsonData get_tier_name')]\n",
      "52\n",
      "found files: []\n",
      "# Default library.\n",
      "import datetime as dt\n",
      "import sqlite3  # Only to make the db on init.\n",
      "from typing import List, Optional, Tuple, Set\n",
      "\n",
      "# Requirements.\n",
      "import aiosqlite\n",
      "\n",
      "\n",
      "# TODO: some todo about typehints that #s will take care of.\n",
      "class DbQueries:\n",
      "    \"\"\"Query the reputation database\"\"\"\n",
      "    CREATE_TABLE = \"CREATE TABLE `reputations` (`from_user` INTEGER, `from_name` TEXT, `to_user` INTEGER, \" \\\n",
      "                   \"`to_name` TEXT, `stamp` TEXT, `message` TEXT);\"\n",
      "    CREATE_INDEX = \"CREATE INDEX get_users_reps ON reputations(to_user);\"\n",
      "    TABLE_CHECK = \"SELECT count(*) FROM sqlite_master WHERE type='table' AND name='reputations';\"\n",
      "    INSERT_REP = \"INSERT OR REPLACE INTO `reputations` VALUES (:f_id, :f_n, :t_id, :t_n, :stamp, :msg);\"\n",
      "    SELECT_REP_PAIR = \"SELECT * from reputations WHERE from_user = ? AND to_user = ? AND stamp > ?\"\n",
      "    SELECT_REP_COUNT = \"SELECT COUNT(*) as rep_count, COUNT(DISTINCT from_user) as u_count, \" \\\n",
      "                       \"MAX(stamp) as most_recent FROM reputations WHERE to_user = ?;\"\n",
      "    SELECT_LEADERBOARD = \"SELECT to_user, COUNT(to_user) as rep_count FROM reputations \" \\\n",
      "                         \"GROUP BY to_user ORDER BY rep_count DESC, MAX(stamp) DESC;\"\n",
      "    CHECK_SIMPLE = \"SELECT to_user from reputations GROUP BY to_user HAVING COUNT(*) >= ?;\"\n",
      "    CHECK_DOUBLE = \"SELECT to_user from reputations WHERE stamp > ? GROUP BY to_user HAVING COUNT(*) >= ?\\n\" \\\n",
      "                   \"INTERSECT\\n\" + CHECK_SIMPLE\n",
      "    GET_RECENT_REPS = \"SELECT COUNT(*) from reputations WHERE to_user = ? AND stamp > ?\"\n",
      "\n",
      "    def __init__(self, db_path):\n",
      "        self.path = db_path\n",
      "        self.init_table()\n",
      "\n",
      "    def init_table(self) -> None:\n",
      "        \"\"\"Check if the table exists. If not, create it.\n",
      "        Note: this method uses sqlite3 rather than aiosqlite\"\"\"\n",
      "        connection = sqlite3.connect(self.path)\n",
      "        cursor = connection.cursor()\n",
      "        cursor.execute(self.TABLE_CHECK)\n",
      "        resp = cursor.fetchall()\n",
      "        is_table = bool(resp[0][0])\n",
      "        if is_table is False:\n",
      "            print(\"Making the reputations table...\")\n",
      "            cursor.execute(self.CREATE_TABLE)\n",
      "            cursor.execute(self.CREATE_INDEX)  # To ensure quick rep lookup.\n",
      "            connection.commit()\n",
      "        connection.close()\n",
      "        return\n",
      "\n",
      "    async def all_eligible_users(self, decay_threshold: int, role_threshold: int,\n",
      "                                 decay_period: Optional[int]) -> Set[int]:\n",
      "        \"\"\"\n",
      "        :param decay_threshold: The minimum amount of reps a user must receive within decay_period to keep the role.\n",
      "        :param role_threshold: The minimum amount of reps a user needs to receive the reputation role.\n",
      "        :param decay_period: The time period in which a user must receive decay_threshold reps to keep the role.\n",
      "        :return: A list of all user ids who are eligible for the reputation role.\n",
      "        \"\"\"\n",
      "        if decay_period:\n",
      "            stamp = dt.datetime.utcnow() - dt.timedelta(seconds=decay_period)\n",
      "            id_list = await self.exec_sql(self.CHECK_DOUBLE, params=[stamp, decay_threshold, role_threshold])\n",
      "        else:\n",
      "            id_list = await self.exec_sql(self.CHECK_SIMPLE, params=[role_threshold])\n",
      "        return {x[0] for x in id_list}\n",
      "\n",
      "    async def insert_rep(self, from_id: int, from_name: str, to_id: int, to_name: str, rep_dt: dt.datetime,\n",
      "                         rep_msg: str = None, cooldown: int = None) -> bool:\n",
      "        \"\"\"\n",
      "        :param from_id: UserID of the user that gives the rep.\n",
      "        :param from_name: username#1234 of the user that gives the rep.\n",
      "        :param to_id: UserID of the user that is being rep'd.\n",
      "        :param to_name: username#1234 of the user that is being rep'd.\n",
      "        :param rep_dt: The datetime that the reputation message was sent.\n",
      "        :param rep_msg: (Optional) The message accompanied with the rep.\n",
      "        :param cooldown: (Optional) The amount of seconds that need to have passed since the last time\n",
      "               from_id rep'd to_id.\n",
      "        :return: A boolean which determines whether a reputation was eligible to be inserted or not.\n",
      "        \"\"\"\n",
      "        if cooldown:\n",
      "            compare_stamp = rep_dt - dt.timedelta(seconds=cooldown)\n",
      "            check_rows = await self.exec_sql(self.SELECT_REP_PAIR, [from_id, to_id, compare_stamp])\n",
      "            can_insert = not check_rows  # Boolean, if check_rows is empty then the rep can be inserted.\n",
      "        else:\n",
      "            can_insert = True\n",
      "        if can_insert:\n",
      "            stamp = str(rep_dt)\n",
      "            params = {\"f_id\": from_id, \"f_n\": from_name, \"t_id\": to_id, \"t_n\": to_name, \"stamp\": stamp, \"msg\": rep_msg}\n",
      "            await self.exec_sql(self.INSERT_REP, params=params, commit=True)\n",
      "        return can_insert\n",
      "\n",
      "    async def user_rep_count(self, user_id: int) -> Tuple[int, int, Optional[str]]:\n",
      "        \"\"\"\n",
      "        :param user_id: The userID of the user whose reputation count should be checked.\n",
      "        :return: The tuple with the amount of reputations received, given by distinct count of users,\n",
      "                 and the datetime string of the last reputation given.\n",
      "        \"\"\"\n",
      "        resp = await self.exec_sql(self.SELECT_REP_COUNT, params=[user_id])\n",
      "        assert resp, \"No response from user_rep_count!\"  # Should always return a response.\n",
      "        return resp[0]\n",
      "\n",
      "    async def rep_leaderboard(self) -> Optional[List[Tuple[int, int]]]:\n",
      "        \"\"\"\n",
      "        :return: A list of tuples with the amount of reputations by userID, sorted on reputation count.\n",
      "\n",
      "        Get the full leaderboard for reputations\n",
      "        \"\"\"\n",
      "        leaderboard = await self.exec_sql(self.SELECT_LEADERBOARD)\n",
      "        return leaderboard if leaderboard else None\n",
      "\n",
      "    async def recent_reps(self, user_id: int, start_time: dt.datetime) -> int:\n",
      "        \"\"\"\n",
      "        :param user_id: The userID of the user whose recent reps should be checked.\n",
      "        :param start_time: The timestamp after which all reputations should be counted\n",
      "        :return: An integer with the amount of reputations received by the user after start_time\n",
      "        \"\"\"\n",
      "        resp = await self.exec_sql(self.GET_RECENT_REPS, params=[user_id, start_time])\n",
      "        assert resp, \"No response from recent_reps!\"\n",
      "        return resp[0][0]\n",
      "\n",
      "    # Utilities.\n",
      "    async def exec_sql(self, query, params=None, commit=False) -> list:\n",
      "        \"\"\"Make an asynchronous query to the reputation database\"\"\"\n",
      "        async with aiosqlite.connect(self.path) as db:\n",
      "            async with db.execute(query, parameters=params) as cursor:\n",
      "                rows = await cursor.fetchall()\n",
      "            if commit:\n",
      "                await db.commit()\n",
      "        return rows\n",
      "\n",
      "Output: {'db_queries': [], 'db_queries.DbQueries.__init__': ['db_queries.DbQueries.init_table'], 'db_queries.DbQueries.init_table': ['<builtin>.print', 'sqlite3.connect', '<builtin>.bool'], 'sqlite3.connect': [], '<builtin>.bool': [], '<builtin>.print': [], 'db_queries.DbQueries.all_eligible_users': ['datetime.timedelta', 'db_queries.DbQueries.exec_sql', 'datetime.datetime.utcnow'], 'datetime.datetime.utcnow': [], 'datetime.timedelta': [], 'db_queries.DbQueries.exec_sql': ['aiosqlite.connect'], 'db_queries.DbQueries.insert_rep': ['datetime.timedelta', 'db_queries.DbQueries.exec_sql', '<builtin>.str'], '<builtin>.str': [], 'db_queries.DbQueries.user_rep_count': ['db_queries.DbQueries.exec_sql'], 'db_queries.DbQueries.rep_leaderboard': ['db_queries.DbQueries.exec_sql'], 'db_queries.DbQueries.recent_reps': ['db_queries.DbQueries.exec_sql'], 'aiosqlite.connect': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\FixedThink_RocketCogs\\reputation\\db_queries.py\n",
      "[('db_queries DbQueries __init__', 'db_queries DbQueries init_table'), ('db_queries DbQueries init_table', 'sqlite3 connect'), ('db_queries DbQueries all_eligible_users', 'datetime timedelta'), ('db_queries DbQueries all_eligible_users', 'db_queries DbQueries exec_sql'), ('db_queries DbQueries all_eligible_users', 'datetime datetime utcnow'), ('db_queries DbQueries exec_sql', 'aiosqlite connect'), ('db_queries DbQueries insert_rep', 'datetime timedelta'), ('db_queries DbQueries insert_rep', 'db_queries DbQueries exec_sql'), ('db_queries DbQueries user_rep_count', 'db_queries DbQueries exec_sql'), ('db_queries DbQueries rep_leaderboard', 'db_queries DbQueries exec_sql'), ('db_queries DbQueries recent_reps', 'db_queries DbQueries exec_sql')]\n",
      "0\n",
      "found files: []\n",
      "from typing import Optional, Tuple\n",
      "\n",
      "\n",
      "def _use_plist(check_d: dict, ignore_special: bool = False) -> bool:\n",
      "    \"\"\"\n",
      "    :param check_d: Dict of a playlist-specific player skills.\n",
      "    :param ignore_special: Whether to count special playlists or not\n",
      "    :return: A boolean determining whether the playlist should be considered.\n",
      "    \"\"\"\n",
      "    to_check = check_d[\"playlist\"]\n",
      "    # return to_check != 0 if not ignore_special else 0 < to_check < 20\n",
      "    return (to_check not in (0, 34)) if not ignore_special else 0 < to_check < 20\n",
      "\n",
      "\n",
      "def best_playlist(player_skills: list, ignore_special: bool = False) -> Tuple[int, Optional[int], set]:\n",
      "    \"\"\"\n",
      "    :param player_skills: A list with a player's skills (extracted from the skills response dict).\n",
      "    :param ignore_special: Whether to count special playlists or not\n",
      "    :return: A tuple containing the player's best rank, playlist, and what lists they've played in.\n",
      "    \"\"\"\n",
      "    # Check which playlists have data and which ones not.\n",
      "    played_lists = {d[\"playlist\"] for d in player_skills}\n",
      "    # Get highest ranked playlist (only if there's data for any ranked playlist).\n",
      "    if any(n != 0 for n in played_lists):\n",
      "        best_playlist_dict = max((d for d in player_skills if _use_plist(d, ignore_special)),\n",
      "                                 key=lambda x: (x[\"tier\"], x[\"division\"], x[\"mu\"]))\n",
      "        best_tier = best_playlist_dict.get(\"tier\")\n",
      "        best_list_id = best_playlist_dict.get(\"playlist\")\n",
      "    else:\n",
      "        best_tier = 0\n",
      "        best_list_id = None\n",
      "    return best_tier, best_list_id, played_lists\n",
      "\n",
      "\n",
      "def com(ctx, command, tick: bool = True) -> str:\n",
      "    \"\"\"\n",
      "    :param ctx: The context manager as provided by the command. Used for the prefix.\n",
      "    :param command: The command for which the command link should be made.\n",
      "    :param tick: (Optional) Whether to surround the command with backticks (`). Defaults to False.\n",
      "    :return: A string in with a readable command link (excluding any code blocks).\n",
      "\n",
      "    Make a string to refer to another command\n",
      "    \"\"\"\n",
      "    return \"{t}{p}{com}{t}\".format(p=ctx.prefix, com=command.qualified_name, t=\"`\" if tick else \"\")\n",
      "\n",
      "\n",
      "def float_sr(skills_item: dict) -> float:\n",
      "    \"\"\"\n",
      "    :param skills_item: An item (playlist) of the \"player_skills\" list in the PlayerSkills API response dict.\n",
      "    :return: Skill rating in float format.\n",
      "    \"\"\"\n",
      "    return skills_item[\"mu\"] * 20 + 100\n",
      "\n",
      "Output: {'static_functions': [], 'static_functions._use_plist': [], 'static_functions.best_playlist': ['static_functions._use_plist', '<builtin>.max', '<builtin>.any'], '<builtin>.any': [], 'static_functions.best_playlist.<lambda1>': [], '<builtin>.max': [], 'static_functions.com': [], 'static_functions.float_sr': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\FixedThink_RocketCogs\\lafusee\\static_functions.py\n",
      "[('static_functions best_playlist', 'static_functions _use_plist')]\n",
      "403\n",
      "found files: []\n",
      "# Used by Red.\n",
      "import aiohttp\n",
      "\n",
      "# Local files.\n",
      "from .exceptions import SteamCallError\n",
      "\n",
      "\n",
      "class SteamCalls:\n",
      "    \"\"\"Class for querying the Steam API asynchronically\"\"\"\n",
      "    # t = token, v = vanity url.\n",
      "    API_VANITY = \"http://api.steampowered.com/ISteamUser/ResolveVanityURL/v1/?key={t}&vanityurl={v}\"\n",
      "    STEAM_NO_MATCH = \":x: Error: That Steam vanity ID does not seem to exist. Please check your input.\"\n",
      "    STEAM_TOKEN_NONE = \":x: Error: No token set for the Steam API.\"\n",
      "    # Constants based on status codes.\n",
      "    STEAM_BAD_REQUEST = \":x: Error: The request done to the Steam API was improper.\" \\\n",
      "                        \"\\nSee the console for more info. `(Status: 400)`\"\n",
      "    STEAM_TOKEN_INVALID = \":x: Error: The Steam API token is invalid. `(Status: 403)`\"\n",
      "    SERVER_ERROR = \":satellite: The Steam API is experiencing issues. Please try the command again. `(Status: {})`\"\n",
      "    # Other request-based errors.\n",
      "    TIMEOUT_ERROR = \":hourglass: The request to the Steam API timed out. This means that the API might be down. \" \\\n",
      "                    \"Try to use the 17-digit number instead of the vanity ID, or try again later.\"\n",
      "    UNKNOWN_STATUS_ERROR = \"Something went wrong whilst querying the Steam API.\\nStatus: {}\\n Query: {}\"\n",
      "\n",
      "    def __init__(self, config):\n",
      "        # Load config in order to always have an updated token.\n",
      "        self.config = config\n",
      "        self.session = aiohttp.ClientSession()\n",
      "\n",
      "    async def _call_steam_api(self, request_url: str) -> dict:\n",
      "        \"\"\"Given an url, call the API using the configured token\n",
      "\n",
      "        Returns a list if valid, False if invalid, and None if there is no token.\n",
      "        Also returns a error if there is one.\"\"\"\n",
      "        try:\n",
      "            async with self.session.get(request_url) as response:\n",
      "                resp = response\n",
      "                resp_status = resp.status\n",
      "                if resp_status == 200:\n",
      "                    resp_json = await resp.json()\n",
      "                else:\n",
      "                    resp_json = None\n",
      "        except aiohttp.client_exceptions.ServerTimeoutError:\n",
      "            raise SteamCallError(self.TIMEOUT_ERROR)\n",
      "        if resp_json is not None:\n",
      "            to_return = resp_json.get(\"response\")\n",
      "        else:  # No valid response.\n",
      "            if resp_status == 403:\n",
      "                raise SteamCallError(self.STEAM_TOKEN_INVALID)\n",
      "            elif resp_status == 400:\n",
      "                print(\"Invalid request URL: {}\".format(request_url))\n",
      "                raise SteamCallError(self.STEAM_BAD_REQUEST)\n",
      "            elif resp_status in {500, 502, 503}:\n",
      "                raise SteamCallError(self.SERVER_ERROR.format(resp_status))\n",
      "            raise Exception(self.UNKNOWN_STATUS_ERROR.format(resp_status, request_url))\n",
      "        return to_return\n",
      "\n",
      "    async def vanity_to_id64(self, vanity_id: str) -> str:\n",
      "        \"\"\"Convert a Steam vanity id into an id64, so that it can be used in the Psyonix API\n",
      "\n",
      "        Structure of a normal API response if there's a match:\n",
      "        {response: {steamid: str, success: 1}}\n",
      "\n",
      "        Structure of an API response if there's no match:\n",
      "        {response: {message: \"No match\", success: 42}}\n",
      "        \"\"\"\n",
      "        token = await self.config.steam_token()\n",
      "        if token is None:\n",
      "            raise SteamCallError(self.STEAM_TOKEN_NONE)\n",
      "        request_url = self.API_VANITY.format(t=token, v=vanity_id)\n",
      "        resp_dict = await self._call_steam_api(request_url)\n",
      "        id64 = resp_dict.get(\"steamid\")\n",
      "        if not id64:  # No match found for steamid.\n",
      "            raise SteamCallError(self.STEAM_NO_MATCH)\n",
      "        return id64\n",
      "\n",
      "Output: {'steam_calls': [], 'steam_calls.SteamCalls.__init__': ['aiohttp.ClientSession'], 'aiohttp.ClientSession': [], 'steam_calls.SteamCalls._call_steam_api': ['exceptions.SteamCallError', '<builtin>.Exception', '<builtin>.print'], 'exceptions.SteamCallError': [], '<builtin>.print': [], '<builtin>.Exception': [], 'steam_calls.SteamCalls.vanity_to_id64': ['exceptions.SteamCallError', 'steam_calls.SteamCalls._call_steam_api']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\FixedThink_RocketCogs\\lafusee\\steam_calls.py\n",
      "[('steam_calls SteamCalls __init__', 'aiohttp ClientSession'), ('steam_calls SteamCalls _call_steam_api', 'exceptions SteamCallError'), ('steam_calls SteamCalls vanity_to_id64', 'exceptions SteamCallError'), ('steam_calls SteamCalls vanity_to_id64', 'steam_calls SteamCalls _call_steam_api')]\n",
      "0\n",
      "found files: []\n",
      "# Default libraries.\n",
      "import re\n",
      "from collections import OrderedDict\n",
      "from json import dumps  # Only used for debug output formatting.\n",
      "from typing import List, Literal, Optional\n",
      "\n",
      "# Used by Red.\n",
      "import discord\n",
      "import redbot.core.utils.menus as red_menu\n",
      "from redbot.core import checks, Config, data_manager\n",
      "from redbot.core import commands\n",
      "from redbot.core.bot import Red\n",
      "\n",
      "from .db_queries import DbQueries\n",
      "# Local files.\n",
      "from .exceptions import CustomNotice, LaFuseeError, AccountInputError, TokenError, PsyonixCallError\n",
      "from .json_data import GetJsonData\n",
      "from .psyonix_calls import PsyonixCalls\n",
      "from .static_functions import best_playlist, com, float_sr\n",
      "from .steam_calls import SteamCalls\n",
      "\n",
      "\n",
      "class LaFusee(commands.Cog):\n",
      "    \"\"\"Rocket League rank commands\"\"\"\n",
      "    # TODO: Give notice about spaces when someone with xbox puts in their ID wrongly. (or fix with *).\n",
      "    # Constants.\n",
      "    PSY_TOKEN_LEN = 40\n",
      "    STEAM_TOKEN_LEN = 32\n",
      "    PLAYLIST_IDS = (0, 10, 11, 12, 13, 27, 28, 29, 30)\n",
      "\n",
      "    # Emotes used in constants.\n",
      "    BIN = \":put_litter_in_its_place: \"\n",
      "    ERROR = \":x: Error: \"\n",
      "    DONE = \":white_check_mark: \"\n",
      "    # Token command notices.\n",
      "    TOKEN_ADDED = \"Successfully set the token for the {} API.\"\n",
      "    TOKEN_DELETED = \"Successfully cleared the token for the {} API.\"\n",
      "    TOKEN_NONE = ERROR + \"No token set.\"\n",
      "    TOKEN_NOT_SET = TOKEN_NONE + \"Which makes deleting it a little complicated.\"\n",
      "    TOKEN_LEN_ERROR = ERROR + \"The token you put in is not as long as the accepted token size ({}).\"\n",
      "    TOKEN_HEX_ERROR = ERROR + \"Your input does not seem to be hexadecimal.\"\n",
      "    TOKEN_NOT_PRIVATE = \":warning: Because of safety reasons, please send the bot this command in DMs. Input ignored.\"\n",
      "    TOKEN_INVALID = ERROR + \"Token is invalid.\"\n",
      "    # Rank role configuration constants.\n",
      "    R_CONF_DISABLED = BIN + \"Successfully disabled the rank role functionality for this server.\"\n",
      "    R_CONF_ENABLED = DONE + \"Successfully enabled the rank role functionality for this server.\"\n",
      "    R_SPECIAL_IGNORE = DONE + \"The rank role check will now ignore the special playlists.\"\n",
      "    R_SPECIAL_UNIGNORE = BIN + \"The rank role check will no longer ignore the special playlists.\"\n",
      "    R_CONF_SUCCESS = DONE + \"Successfully added all roles!\"\n",
      "    R_CONF_NOT_ENABLED = \"Don't forget to enable the RL rank role functionality by doing {}\"\n",
      "    R_CONF_INVALID_MODE = ERROR + \"Invalid mode.\"\n",
      "    R_CONF_INCOMPLETE = \"You can either add each missing role individually using {}, \" \\\n",
      "                        \"or rerun this command when all roles are set up.\"\n",
      "    R_GENERATE_NO_PERMS = ERROR + \"I do not have sufficient permissions to add roles\"\n",
      "    R_GENERATE_PROGRESS = \"{n} out of 22 roles done.\"\n",
      "    R_DETECT_SUCCESS = DONE + \"Detected `{role_id}` for {tier_str}\"\n",
      "    R_DETECT_FAIL = \":x: Did not find a role for {tier_str}\"\n",
      "    R_DETECT_TOTAL = \"**Total matches:** {match_count} out of 22\\n{note}\\n\\n{rest}\"\n",
      "    # Account registration + rank role update constants.\n",
      "    LINKED_UNRANKED = \"Your linked account is (currently) unranked in every playlist.\"\n",
      "    RANK_ROLE_ADDED = \"You received the {r_role} role.\"\n",
      "    RANK_ROLE_REMOVED = \"Your rank roles are removed.\"\n",
      "    RANK_ROLE_INTACT = \"You already seem to have the right rank role ({r_role}), so your roles are not changed.\"\n",
      "    RANK_ROLE_UPDATED = \"Your rank role is successfully updated to {r_role}.\"\n",
      "    RANK_ROLE_NULL = \"You did not have any rank roles, so none were deleted either\"\n",
      "    RANK_ROLE_DISABLED = ERROR + \"You cannot obtain a rank role on this server!\"\n",
      "    RANK_ROLE_UPDATE_UNRANKED = ERROR + LINKED_UNRANKED + \"\\nThus, your rank roles could not be updated.\"\n",
      "    LINK_SUCCESS = DONE + \"Successfully linked your {} ID with this account!\"\n",
      "    LINK_ROLE_UNRANKED = LINKED_UNRANKED + \"\\nThus, you cannot receive a rank role.\"\n",
      "    LINK_REMOVED = BIN + \"Successfully unlinked your {} ID from this account.\"\n",
      "    LINK_AND_RANKROLE_REMOVED = LINK_REMOVED + \"\\nIf you had any rank roles, these were removed as well.\"  # 1 {}\n",
      "    LINK_REMOVE_ROLE_NOTE = \"Keep in mind that you __don't__ have to unlink your account to update any rank roles.\\n\"\n",
      "    LINK_REMOVE_PROMPT = \"**Are you sure you want to unlink your account?**\\n{}\" \\\n",
      "                         \"If so, resend this command, but with `yes` at the end, to unlink your {} ID. \" \\\n",
      "                         \"No action needed otherwise. {}\"  # 3 {}.\n",
      "    # General user link errors.\n",
      "    USER_NOT_REGISTERED = ERROR + \"This user has not registered their account!\"\n",
      "    ALREADY_REGISTERED = \":no_entry_sign: You have already linked your account!\\n\" \\\n",
      "                         \"To change your account, first *unlink* the current account with {}, then link a new one.\"\n",
      "    AUTHOR_NOT_REGISTERED = ERROR + \"You do not have a registered account.\"\n",
      "    AUTHOR_REGISTER_PROMPT = AUTHOR_NOT_REGISTERED + \"\\nUse {} to register one.\"\n",
      "    # Platform-tag validation constants.\n",
      "    ID64_NON_NUMERIC = ERROR + \"`/profiles/` links must have a fully numeric ID!\"\n",
      "    SWITCH_UNSUPPORTED = ERROR + \"Psyonix does not (yet) support rank queries for the Nintendo Switch.\\n\" \\\n",
      "                                 \"When they do, this command will support it as soon as possible.\"\n",
      "    PLATFORM_EXAMPLES = \"Try one of these: PC, PS4, XBOX\"\n",
      "    PLATFORM_INVALID = ERROR + \"That platform does not exist.\\n\" + PLATFORM_EXAMPLES\n",
      "    # Playlist validation constants.\n",
      "    PLAYLIST_INVALID = ERROR + \"Invalid playlist input.\"\n",
      "    PLAYLIST_NOT_PLAYED = ERROR + \"{plist} is never played on this account.\"\n",
      "    # Help message constants.\n",
      "    GROUP_FOOTER = \"Tip: adding 'me' or 'user' behind a stat command name shows your own stats, \" \\\n",
      "                   \"or lets you view the stats of another Discord user.\"\n",
      "    PLAYLIST_INPUT = \"Playlists are accepted in multiple formats, including:\\n\" \\\n",
      "                     \"`casual`  `duel`  `doubles`  `solostandard`  `hoops`  `rumble`  `dropshot`  `snowday\\n\" \\\n",
      "                     \"1s`  `2s`  `ss`  `3s`  `hs`  `rb`  `ds`  `sd`\"\n",
      "    PROFILE_INPUT = \"**PC**  Use your vanity ID (__not__ display name!), the long number, \" \\\n",
      "                    \"or just link to your profile.\\n**PS4**  Use your player tag (may be case-sensitive).\\n\" \\\n",
      "                    \"**XBOX**  Use your player tag. If it has spaces, surround it with quotes.\"\n",
      "    INFO_FOOTER = \"If any input is invalid though it should be valid, please reach out to the developer!\"\n",
      "    # Assertion error constants.\n",
      "    ASSERT_INT = \"LaFusee: Invalid int for tier: {n} is not an integer between 0 and 22 inclusive.\"\n",
      "    ASSERT_ROLE_CONFIG = \"LaFusee: The role for tier {n} is not configured.\"\n",
      "    ASSERT_ROLE_EXISTS = \"LaFusee: The role with ID {r_id} ({tier_n}) does not exist.\"\n",
      "    # Embed row constants. Padding character (\\u2800) is a Braille space, and spacing is an en space (\\u2002).\n",
      "    E_ROW_ONLY_MMR = \"`{:\\u2800<{}}`\\u2002**{:0.2f}**\"\n",
      "    E_ROW_RANKED = \"`{ls:\\u2800<{p}}`\\u2002**{n:0.2f}**\\u2002({bold}{tier_div}{bold})\"\n",
      "    E_ROW_NO_MATCHES = \"`{:\\u2800<{}}`\\u2002*No matches played*\"\n",
      "    # Other constants.\n",
      "    STEAM_PROFILE_URL = \"https://steamcommunity.com/profiles/{}\"\n",
      "    STEAM_APP_URL = \"steam://url/SteamIDPage/{}\"\n",
      "\n",
      "    def __init__(self, bot: Red):\n",
      "        super().__init__()\n",
      "        self.bot = bot\n",
      "        self.FOLDER = str(data_manager.cog_data_path(self))\n",
      "        self.PATH_DB = self.FOLDER + \"/account_registrations.db\"\n",
      "        self.config = Config.get_conf(self, identifier=80590423, force_registration=True)\n",
      "        self.config.register_global(psy_token=None, steam_token=None)\n",
      "        # Structure of rankrole_dict: {tier_n: role_id}\n",
      "        self.config.register_guild(rankrole_enabled=False, rankrole_dict={}, ignore_special=False)\n",
      "        self.psy_api = PsyonixCalls(self.config)\n",
      "        self.steam_api = SteamCalls(self.config)\n",
      "        self.link_db = DbQueries(self.PATH_DB)\n",
      "        self.json_conv = GetJsonData()\n",
      "\n",
      "    # Events\n",
      "    async def cog_command_error(self, ctx, error):\n",
      "        if isinstance(error, LaFuseeError):\n",
      "            await ctx.send(str(error))\n",
      "        else:\n",
      "            await ctx.bot.on_command_error(ctx, error, unhandled_by_cog=True)\n",
      "\n",
      "    # Configuration commands.\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @commands.group(name=\"rlset\", invoke_without_command=True)\n",
      "    async def _rl_setup(self, ctx):\n",
      "        \"\"\"Configure the cog's configuration for this server\"\"\"\n",
      "        await ctx.send_help()\n",
      "\n",
      "    @checks.mod_or_permissions(administrator=True)\n",
      "    @_rl_setup.group(name=\"api\", invoke_without_command=True)\n",
      "    async def _api_setup(self, ctx):\n",
      "        \"\"\"Configure the API keys needed for the RL commands\"\"\"\n",
      "        await ctx.send_help()\n",
      "\n",
      "    @_api_setup.command()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def set_psyonix_token(self, ctx, token):\n",
      "        \"\"\"Configures the token required to query the Psyonix API\n",
      "\n",
      "        Only the hexadecimal code is needed.\"\"\"\n",
      "        await self.check_token_fmt(ctx, token, self.PSY_TOKEN_LEN)\n",
      "        str_token = \"Token {}\".format(token)\n",
      "        await self.config.psy_token.set(str_token)\n",
      "        await ctx.send(self.TOKEN_ADDED.format(\"Psyonix\"))\n",
      "\n",
      "    @_api_setup.command()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def delete_psyonix_token(self, ctx):\n",
      "        \"\"\"Removes the currently set token from the config\"\"\"\n",
      "        token = await self.config.psy_token()\n",
      "        if token is None:\n",
      "            raise TokenError(self.TOKEN_NOT_SET)\n",
      "        await self.config.psy_token.clear()\n",
      "        await ctx.send(self.TOKEN_DELETED.format(\"Psyonix\"))\n",
      "\n",
      "    @_api_setup.command()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def set_steam_token(self, ctx, token):\n",
      "        \"\"\"Configures the token required to query the Steam API\n",
      "\n",
      "        Only the hexadecimal code is needed.\"\"\"\n",
      "        await self.check_token_fmt(ctx, token, self.STEAM_TOKEN_LEN)\n",
      "        await self.config.steam_token.set(str(token))\n",
      "        await ctx.send(self.TOKEN_ADDED.format(\"Steam\"))\n",
      "\n",
      "    @_api_setup.command()\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def delete_steam_token(self, ctx):\n",
      "        \"\"\"Removes the currently set token from the config\"\"\"\n",
      "        token = await self.config.steam_token()\n",
      "        if token is not None:\n",
      "            await self.config.steam_token.clear()\n",
      "            notice = self.TOKEN_DELETED.format(\"Steam\")\n",
      "        else:\n",
      "            notice = self.TOKEN_NOT_SET\n",
      "        await ctx.send(notice)\n",
      "\n",
      "    @_rl_setup.command(name=\"toggle_roles\")\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def toggle_rl_role(self, ctx):\n",
      "        \"\"\"Toggles the RL rank role functionality\"\"\"\n",
      "        is_enabled = await self.config.guild(ctx.guild).rankrole_enabled()\n",
      "        if is_enabled:\n",
      "            to_send = self.R_CONF_DISABLED\n",
      "        else:\n",
      "            to_send = self.R_CONF_ENABLED\n",
      "        # Set rankrole_enabled as the inverse of is_enabled (as this command is a toggle).\n",
      "        await self.config.guild(ctx.guild).rankrole_enabled.set(not is_enabled)\n",
      "        await ctx.send(to_send)\n",
      "\n",
      "    @_rl_setup.command(name=\"toggle_special\")\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def toggle_ignore_special(self, ctx):\n",
      "        \"\"\"Toggle whether the rank role should ignore the special playlists\"\"\"\n",
      "        is_enabled = await self.config.guild(ctx.guild).ignore_special()\n",
      "        if is_enabled:\n",
      "            to_send = self.R_SPECIAL_UNIGNORE\n",
      "        else:\n",
      "            to_send = self.R_SPECIAL_IGNORE\n",
      "        # Set rankrole_enabled as the inverse of is_enabled (as this command is a toggle).\n",
      "        await self.config.guild(ctx.guild).ignore_special.set(not is_enabled)\n",
      "        await ctx.send(to_send)\n",
      "\n",
      "    @_rl_setup.command(name=\"set_roles\")\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def set_rl_roles(self, ctx, mode: str):\n",
      "        \"\"\"Toggles the RL rank role functionality\n",
      "\n",
      "        There are two possible modes:\n",
      "        **generate** - creates new rank roles and automatically saves them\n",
      "        **detect** - detects existing roles based on their name.\n",
      "\n",
      "        For `detect`, the role names must have proper capitalisation and roman numerals, like \\\"Diamond III\\\".\"\"\"\n",
      "        gld = ctx.guild\n",
      "        low_mode = mode.lower()\n",
      "        if low_mode == \"generate\":\n",
      "            role_dict = {}\n",
      "            if gld.me.guild_permissions.manage_roles is False:\n",
      "                to_say = self.R_GENERATE_NO_PERMS\n",
      "            else:\n",
      "                for i in reversed(range(1, 20)):  # Reversed because of hierarchy.\n",
      "                    role_colour = discord.Colour(self.json_conv.get_tier_colour(i))\n",
      "                    role_name = self.json_conv.get_tier_name(i)\n",
      "                    new_role = await gld.create_role(name=role_name, colour=role_colour, hoist=True)\n",
      "                    role_dict[i] = new_role.id\n",
      "                    progress_n = 20 - i\n",
      "                    if progress_n % 5 == 0:\n",
      "                        await ctx.send(self.R_GENERATE_PROGRESS.format(n=progress_n))\n",
      "                to_say = self.R_CONF_SUCCESS\n",
      "            await self.config.guild(gld).rankrole_dict.set(role_dict)\n",
      "        elif low_mode == \"detect\":\n",
      "            role_dict = {}\n",
      "            say_list = []\n",
      "            matches = 0\n",
      "            for i in range(1, 23):\n",
      "                tier_str = self.json_conv.get_tier_name(i)\n",
      "                role = discord.utils.get(gld.roles, name=tier_str)\n",
      "                if role:\n",
      "                    matches += 1\n",
      "                    role_id = role.id\n",
      "                    role_dict[i] = role_id\n",
      "                    say_list.append(self.R_DETECT_SUCCESS.format(role_id=role_id, tier_str=tier_str))\n",
      "                else:  # No role found.\n",
      "                    role_dict[i] = None\n",
      "                    say_list.append(self.R_DETECT_FAIL.format(tier_str=tier_str))\n",
      "            if matches < 22:\n",
      "                comment = self.R_CONF_INCOMPLETE.format(\"`SoonTM`\")  # TODO: add manual command.\n",
      "            elif await self.config.guild(gld).rankrole_enabled() is False:\n",
      "                comment = self.R_CONF_NOT_ENABLED.format(com(ctx, self.toggle_rl_role))\n",
      "            else:\n",
      "                comment = self.R_CONF_SUCCESS\n",
      "            to_say = self.R_DETECT_TOTAL.format(match_count=matches, note=comment, rest=\"\\n\".join(say_list))\n",
      "            await self.config.guild(gld).rankrole_dict.set(role_dict)\n",
      "        else:\n",
      "            to_say = self.R_CONF_INVALID_MODE\n",
      "        await ctx.send(to_say)\n",
      "\n",
      "    # Main command group.\n",
      "    @commands.group(name=\"rl\", invoke_without_command=True)\n",
      "    async def _rl(self, ctx):\n",
      "        \"\"\"Commands related to Rocket League stats\"\"\"\n",
      "        rankrole_enabled = await self.config.guild(ctx.guild).rankrole_enabled()\n",
      "        embed = discord.Embed(title=\"Rocket League stats: Overview\", colour=discord.Colour.red())\n",
      "        embed.description = \"Need help with input? Try {}\".format(com(ctx, self.rl_help))\n",
      "        # View stats.\n",
      "        stat_lines = (\"Compact ranks: {}\".format(com(ctx, self._lfg_embed)),\n",
      "                      \"General stats: {}\".format(com(ctx, self._rocket_embed)),\n",
      "                      \"Playlist stats: {}\".format(com(ctx, self._plist_embed)))\n",
      "        embed.add_field(name=\"View stats\", value=\"\\n\".join(stat_lines))\n",
      "        # Link account etc.\n",
      "        link_lines = (\"Link account: {}\".format(com(ctx, self.register_tag)),\n",
      "                      \"Remove link: {}\".format(com(ctx, self.de_register_tag)),\n",
      "                      \"Update rank role: {}\".format(com(ctx, self.update_rank_role)))\n",
      "        t_slice = None if rankrole_enabled else 2\n",
      "        embed.add_field(name=\"Linking your account\", value=\"\\n\".join(link_lines[:t_slice]))\n",
      "        embed.set_footer(text=self.GROUP_FOOTER)\n",
      "        await ctx.send(embed=embed)\n",
      "\n",
      "    @_rl.command(name=\"howto\")\n",
      "    async def rl_help(self, ctx):\n",
      "        \"\"\"Show information about input for the ranking commands\"\"\"\n",
      "        embed = discord.Embed(title=\"Rocket League stats: Input help\", colour=discord.Colour.red())\n",
      "        embed.add_field(name=\"Platform input\", value=self.PLATFORM_EXAMPLES, inline=False)\n",
      "        embed.add_field(name=\"Profile input\", value=self.PROFILE_INPUT)\n",
      "        embed.add_field(name=\"Playlist input\", value=self.PLAYLIST_INPUT)\n",
      "        embed.set_footer(text=self.INFO_FOOTER)\n",
      "        await ctx.send(embed=embed)\n",
      "\n",
      "    # Registration commands.\n",
      "    @_rl.command(name=\"link\")\n",
      "    async def register_tag(self, ctx, platform, profile_id):\n",
      "        \"\"\"Register your gamer account for use in other commands\"\"\"\n",
      "        author = ctx.author\n",
      "        gld = ctx.guild\n",
      "        rankrole_enabled = await self.config.guild(gld).rankrole_enabled()\n",
      "        db_platform, db_id = await self.link_db.select_user(author.id)\n",
      "        if db_platform or db_id:\n",
      "            overwrite_error = self.ALREADY_REGISTERED.format(com(ctx, self.de_register_tag))\n",
      "            if rankrole_enabled:\n",
      "                overwrite_error += \"\\nTo update your rank role, try {}.\\n\".format(com(ctx, self.update_rank_role))\n",
      "            raise CustomNotice(overwrite_error)\n",
      "        url_platform, url_id = await self.platform_id_bundle(platform, profile_id)\n",
      "        msg = await ctx.send(\"Linking your account...\")\n",
      "        try:  # Check their rankings to see if their platform + ID pair gives an error.\n",
      "            response = await self.psy_api.player_skills(url_platform, url_id)\n",
      "        except PsyonixCallError as e:\n",
      "            edit_say = str(e)\n",
      "        else:\n",
      "            await self.link_db.insert_user(author.id, str(author), url_platform, url_id)\n",
      "            cap_platform = url_platform.capitalize()\n",
      "            link_say = self.LINK_SUCCESS.format(cap_platform)\n",
      "            if rankrole_enabled is False:\n",
      "                edit_say = link_say\n",
      "            else:  # Rank roles are enabled.\n",
      "                # Check their highest roles, and give a role if this is not unranked.\n",
      "                player_skills = response.get(\"player_skills\")  # Value is a list.\n",
      "                ignore_special = await self.config.guild(ctx.guild).ignore_special()\n",
      "                best_tier, best_list_id, played_lists = best_playlist(player_skills, ignore_special)\n",
      "                if best_tier == 0:  # Unranked, so no actual highest rank.\n",
      "                    role_say = self.LINK_ROLE_UNRANKED  # Keep roles in the event one's ranks got inactive.\n",
      "                else:  # Does have a rank.\n",
      "                    role_say = await self.update_member_rankroles(gld, author, best_tier)\n",
      "                edit_say = \"\\n\".join((link_say, role_say))\n",
      "        await msg.edit(content=edit_say)\n",
      "\n",
      "    @_rl.command(name=\"update\")\n",
      "    async def update_rank_role(self, ctx):\n",
      "        \"\"\"Update your rank role based on the current best rank of your linked account\"\"\"\n",
      "        gld = ctx.guild\n",
      "        rankrole_enabled = await self.config.guild(gld).rankrole_enabled()\n",
      "        if rankrole_enabled is False:\n",
      "            raise CustomNotice(self.RANK_ROLE_DISABLED)\n",
      "        author = ctx.author\n",
      "        url_platform, url_id = await self.link_db.select_user(author.id)\n",
      "        if url_platform is None and url_id is None:\n",
      "            raise CustomNotice(self.AUTHOR_NOT_REGISTERED)\n",
      "        response = await self.psy_api.player_skills(url_platform, url_id)\n",
      "        player_skills = response.get(\"player_skills\")  # Value is a list.\n",
      "        ignore_special = await self.config.guild(ctx.guild).ignore_special()\n",
      "        best_tier, best_list_id, played_lists = best_playlist(player_skills, ignore_special)\n",
      "        if best_tier == 0:  # Unranked, so no actual highest rank.\n",
      "            to_say = self.RANK_ROLE_UPDATE_UNRANKED  # Keep roles in the event one's ranks got inactive.\n",
      "        else:  # Does have a rank.\n",
      "            role_say = await self.update_member_rankroles(ctx.guild, author, best_tier)\n",
      "            to_say = \"{}{}\".format(self.DONE, role_say)\n",
      "        await ctx.send(to_say)\n",
      "\n",
      "    @_rl.command(name=\"unlink\")\n",
      "    async def de_register_tag(self, ctx, confirmation: bool = False):\n",
      "        \"\"\"De-register your gamer account for use in other commands\"\"\"\n",
      "        gld = ctx.guild\n",
      "        author = ctx.author\n",
      "        author_id = author.id\n",
      "\n",
      "        url_platform, url_id = await self.link_db.select_user(author_id)\n",
      "        if url_platform is None and url_id is None:\n",
      "            to_say = self.AUTHOR_NOT_REGISTERED\n",
      "        else:\n",
      "            cap_platform = url_platform.capitalize()\n",
      "            rankrole_enabled = await self.config.guild(gld).rankrole_enabled()\n",
      "            if not confirmation:\n",
      "                role_note = self.LINK_REMOVE_ROLE_NOTE if rankrole_enabled else \"\"\n",
      "                to_say = self.LINK_REMOVE_PROMPT.format(role_note, cap_platform, author.mention)\n",
      "            else:\n",
      "                await self.link_db.delete_user(author_id)\n",
      "                if rankrole_enabled is False:\n",
      "                    to_say = self.LINK_REMOVED.format(cap_platform)\n",
      "                else:\n",
      "                    # Remove any leftover rank roles.\n",
      "                    await self.update_member_rankroles(gld, author)\n",
      "                    to_say = self.LINK_AND_RANKROLE_REMOVED.format(cap_platform)\n",
      "        await ctx.send(to_say)\n",
      "\n",
      "    # Rank lookup commands.\n",
      "    @_rl.group(name=\"lfg\", invoke_without_command=True)\n",
      "    async def _lfg_embed(self, ctx, platform: str, profile_id: str):\n",
      "        \"\"\"Show a player's ranks in LFG embed format\"\"\"\n",
      "        url_platform, url_id = await self.platform_id_bundle(platform, profile_id)\n",
      "        response = await self.psy_api.player_skills(url_platform, url_id, ensure_played=True)\n",
      "        embeds = self.make_lfg_embed(response, url_platform)\n",
      "        await red_menu.menu(ctx, embeds, red_menu.DEFAULT_CONTROLS, timeout=30.0)\n",
      "\n",
      "    @_lfg_embed.command(name=\"user\", aliases=[\"me\"])\n",
      "    async def lfg_user(self, ctx, user: discord.Member = None):\n",
      "        \"\"\"Show the LFG embed of a member on this server\n",
      "\n",
      "        If no user is provided, it will show your own.\"\"\"\n",
      "        if user is None:\n",
      "            user = ctx.author\n",
      "        url_platform, url_id = await self.link_db.select_user(user.id)\n",
      "        self.check_registration_complete(url_platform, url_id, user, ctx)  # Valid registration or error raised.\n",
      "        response = await self.psy_api.player_skills(url_platform, url_id, ensure_played=True)\n",
      "        embeds = self.make_lfg_embed(response, url_platform, user)\n",
      "        await red_menu.menu(ctx, embeds, red_menu.DEFAULT_CONTROLS, timeout=30.0)\n",
      "\n",
      "    @_rl.group(name=\"stats\", aliases=[\"rocket\"], invoke_without_command=True)\n",
      "    async def _rocket_embed(self, ctx, platform: str, profile_id: str):\n",
      "        \"\"\"Show a player's stats in standard embed format\"\"\"\n",
      "        url_platform, url_id = await self.platform_id_bundle(platform, profile_id)\n",
      "        response = await self.psy_api.player_skills(url_platform, url_id, ensure_played=True)\n",
      "        gas_od = await self.psy_api.player_stat_values(url_platform, url_id)\n",
      "        await ctx.send(embed=self.make_rocket_embed(response, gas_od, url_platform))\n",
      "\n",
      "    @_rocket_embed.command(name=\"user\", aliases=[\"me\"])\n",
      "    async def rocket_user(self, ctx, user: discord.Member = None):\n",
      "        \"\"\"Show the rocket embed of a member on this server\n",
      "\n",
      "        If no user is provided, it will show your own.\"\"\"\n",
      "        if user is None:\n",
      "            user = ctx.author\n",
      "        url_platform, url_id = await self.link_db.select_user(user.id)\n",
      "        self.check_registration_complete(url_platform, url_id, user, ctx)  # Valid registration or error raised.\n",
      "        response = await self.psy_api.player_skills(url_platform, url_id, ensure_played=True)\n",
      "        gas_od = await self.psy_api.player_stat_values(url_platform, url_id)\n",
      "        await ctx.send(embed=self.make_rocket_embed(response, gas_od, url_platform, user))\n",
      "\n",
      "    @_rl.group(name=\"lstats\", aliases=[\"liststats\", \"list\"], invoke_without_command=True)\n",
      "    async def _plist_embed(self, ctx, platform: str, profile_id: str, playlist: str):\n",
      "        \"\"\"Show a player's stats of a specific playlist\"\"\"\n",
      "        # Validate playlist input.\n",
      "        list_id = self.json_conv.get_input_playlist(playlist)\n",
      "        if list_id is None:  # Can be 0, so None should be explicit.\n",
      "            raise CustomNotice(self.PLAYLIST_INVALID)\n",
      "        url_platform, url_id = await self.platform_id_bundle(platform, profile_id)  # Get platform / ID.\n",
      "        response = await self.psy_api.player_skills(url_platform, url_id, ensure_played=True)  # Get player skills.\n",
      "        content, embed = self.make_plist_embed(response, list_id, url_platform)\n",
      "        await ctx.send(content, embed=embed)\n",
      "\n",
      "    @_plist_embed.command(name=\"user\", aliases=[\"me\"])\n",
      "    async def plist_user(self, ctx, playlist: str, user: discord.Member = None):\n",
      "        \"\"\"Show a server member's stats of a specific playlist\n",
      "\n",
      "        If no user is provided, it will show your own.\"\"\"\n",
      "        # Validate playlist input.\n",
      "        list_id = self.json_conv.get_input_playlist(playlist)\n",
      "        if list_id is None:  # Can be 0, so None should be explicit.\n",
      "            raise CustomNotice(self.PLAYLIST_INVALID)\n",
      "        if user is None:\n",
      "            user = ctx.author\n",
      "        url_platform, url_id = await self.link_db.select_user(user.id)  # Get user from DB.\n",
      "        self.check_registration_complete(url_platform, url_id, user, ctx)  # Valid registration or error raised.\n",
      "        response = await self.psy_api.player_skills(url_platform, url_id, ensure_played=True)\n",
      "        content, embed = self.make_plist_embed(response, list_id, url_platform, user)\n",
      "        await ctx.send(content, embed=embed)\n",
      "\n",
      "    # Extra commands.\n",
      "    @commands.command(name=\"steamadd\", aliases=[\"add\"])\n",
      "    async def send_steam_link(self, ctx, profile_id: str = None):\n",
      "        \"\"\"Send a direct link to your steam account in chat\n",
      "\n",
      "        This allows others to open up your account directly in the steam client.\n",
      "        If no account is provided, it will try to use your linked account.\"\"\"\n",
      "        if not profile_id:\n",
      "            url_platform, url_id = await self.link_db.select_user(ctx.author.id)\n",
      "            if None in (url_platform, url_id):\n",
      "                raise CustomNotice(self.AUTHOR_REGISTER_PROMPT.format(com(ctx, self.register_tag)))\n",
      "        else:\n",
      "            url_platform, url_id = await self.platform_id_bundle(\"steam\", profile_id)\n",
      "        await ctx.send(self.STEAM_APP_URL.format(url_id))\n",
      "\n",
      "    # Debug commands.\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    @commands.group(name=\"rltest\", invoke_without_command=True)\n",
      "    async def _tests(self, ctx):\n",
      "        \"\"\"Debug commands for the RL module\"\"\"\n",
      "        await ctx.send_help()\n",
      "\n",
      "    @_tests.command(name=\"skills\")\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def skills_test(self, ctx, platform, profile_id):\n",
      "        \"\"\"Used for seeing the response of a PlayerSkills query\"\"\"\n",
      "        url_platform, url_id = await self.platform_id_bundle(platform, profile_id)\n",
      "        response = await self.psy_api.player_skills(url_platform, url_id)\n",
      "        str_list = []\n",
      "        for k, v in response.items():\n",
      "            str_row = \"`{}`: {}\".format(k, v)\n",
      "            str_list.append(str_row)\n",
      "        await ctx.send(\"\\n\".join(str_list))\n",
      "\n",
      "    @_tests.command(name=\"titles\")\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def titles_test(self, ctx, platform, profile_id):\n",
      "        \"\"\"Used for seeing the response of a PlayerTitles query\"\"\"\n",
      "        url_platform, url_id = await self.platform_id_bundle(platform, profile_id)\n",
      "        response = await self.psy_api.player_titles(url_platform, url_id)\n",
      "        await ctx.send(response)\n",
      "\n",
      "    @_tests.command(name=\"raw\")\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def raw_skills(self, ctx, platform, profile_id):\n",
      "        \"\"\"Used for seeing the response of a PlayerSkills query\"\"\"\n",
      "        url_platform, url_id = await self.platform_id_bundle(platform, profile_id)\n",
      "        response = await self.psy_api.player_skills(url_platform, url_id)\n",
      "        await ctx.send(\"```json\\n{}```\".format(dumps(response, sort_keys=True, indent=1)))\n",
      "\n",
      "    @_tests.command(name=\"gas\")\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def gas_test(self, ctx, platform, profile_id):\n",
      "        \"\"\"Test the loop query for gas-stats\"\"\"\n",
      "        url_platform, url_id = await self.platform_id_bundle(platform, profile_id)\n",
      "        gas_od = await self.psy_api.player_stat_values(url_platform, url_id)\n",
      "        await ctx.send(\"\\n\".join(f\"{k.title()}: {v}\" for k, v in gas_od.items()))\n",
      "\n",
      "    @_tests.command(name=\"vanity\")\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def test_vanity(self, ctx, vanity_id):\n",
      "        \"\"\"Used for testing the Steam API vanity id conversion\"\"\"\n",
      "        response = await self.steam_api.vanity_to_id64(vanity_id)\n",
      "        await ctx.send(response)\n",
      "\n",
      "    @_tests.command(name=\"user_bundle\")\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def test_platform_id_bundle(self, ctx, platform, profile_id):\n",
      "        \"\"\"Used for testing the platform - gamerID bundle\"\"\"\n",
      "        url_platform, url_id = await self.platform_id_bundle(platform, profile_id)\n",
      "        await ctx.send(\"{} - {}\".format(url_platform, url_id))\n",
      "\n",
      "    @_tests.command(name=\"re\")\n",
      "    @checks.admin_or_permissions(administrator=True)\n",
      "    async def test_regex_split(self, ctx, steam_url):\n",
      "        \"\"\"Used for testing regex for the platform bundle\"\"\"\n",
      "        id_split = re.split(r'/id/', steam_url, maxsplit=1)\n",
      "        profiles_split = re.split(r'/profiles/', steam_url, maxsplit=1)\n",
      "\n",
      "        if len(id_split) == 2:  # Means that a split took place.\n",
      "            to_say = id_split[-1].rstrip(\"/\")\n",
      "        elif len(profiles_split) == 2:\n",
      "            to_say = profiles_split[-1].rstrip(\"/\")\n",
      "        else:\n",
      "            to_say = \"`{}` could not be split\".format(steam_url)\n",
      "        await ctx.send(to_say)\n",
      "\n",
      "    # Utilities\n",
      "    async def red_delete_data_for_user(\n",
      "        self,\n",
      "        *,\n",
      "        requester: Literal[\"discord_deleted_user\", \"owner\", \"user\", \"user_strict\"],\n",
      "        author_id: int,\n",
      "    ):\n",
      "        \"\"\"Delete someone's linked account (only info stored)\n",
      "\n",
      "        This does not take care of any rank roles that the user may have.\"\"\"\n",
      "        url_platform, url_id = await self.link_db.select_user(author_id)\n",
      "        if url_platform or url_id:  # Nothing linked.\n",
      "            await self.link_db.delete_user(author_id)\n",
      "\n",
      "    async def check_token_fmt(self, ctx: commands.Context, token: str, expected_token_length: int) -> None:\n",
      "        \"\"\"Check if a token is hexadecimal and a proper length. Return None if so, raise error otherwise\"\"\"\n",
      "        msg = ctx.message\n",
      "        if not isinstance(msg.channel, discord.abc.PrivateChannel):\n",
      "            try:\n",
      "                await msg.delete()  # Delete message immediately if not sent in DMs.\n",
      "            except discord.errors.Forbidden:\n",
      "                print(\"No perms to delete message\")\n",
      "            raise TokenError(self.TOKEN_NOT_PRIVATE)\n",
      "        if len(token) != expected_token_length:\n",
      "            raise TokenError(self.TOKEN_LEN_ERROR.format(expected_token_length))\n",
      "        try:\n",
      "            int(token, 16)  # Token is a valid hexadecimal string.\n",
      "        except ValueError:\n",
      "            raise TokenError(self.TOKEN_HEX_ERROR)\n",
      "\n",
      "    def check_registration_complete(self, url_platform, url_id, user: discord.User, ctx: commands.Context = None):\n",
      "        \"\"\"Check if registration is complete, raise error otherwise\"\"\"\n",
      "        if None in (url_platform, url_id):  # User is not properly registered.\n",
      "            if ctx and user == ctx.author:\n",
      "                raise CustomNotice(self.AUTHOR_REGISTER_PROMPT.format(com(ctx, self.register_tag)))\n",
      "            raise CustomNotice(self.USER_NOT_REGISTERED)\n",
      "\n",
      "    async def update_member_rankroles(self, gld: discord.Guild, mem: discord.Member, add_tier: int = None) -> str:\n",
      "        \"\"\"Update the rank roles of a user\n",
      "\n",
      "        add_tier must be either an int between 0-22 inclusive, or None.\n",
      "        If add_tier is None, all rank roles will be removed.\n",
      "        Otherwise, the add_tier will be kept, or added in case the member did not have it.\"\"\"\n",
      "        assert add_tier is None or (type(add_tier) == int and 0 <= add_tier <= 22), self.ASSERT_INT.format(n=add_tier)\n",
      "        rankrole_dict = await self.config.guild(gld).rankrole_dict()\n",
      "        rankrole_ids = {r_id for r_id in rankrole_dict.values() if r_id is not None}\n",
      "\n",
      "        roles = mem.roles\n",
      "        member_r_roles = [r for r in roles if r.id in rankrole_ids]\n",
      "\n",
      "        if add_tier is None or add_tier == 0:  # All member rank roles should be deleted.\n",
      "            if len(member_r_roles) > 0:\n",
      "                await mem.remove_roles(*member_r_roles)\n",
      "                to_return = self.RANK_ROLE_REMOVED\n",
      "            else:\n",
      "                to_return = self.RANK_ROLE_NULL\n",
      "        else:\n",
      "            exempt_role_id = rankrole_dict.get(str(add_tier), None)\n",
      "            assert exempt_role_id is not None, self.ASSERT_ROLE_CONFIG.format(n=add_tier)\n",
      "            role_to_add = discord.utils.get(gld.roles, id=exempt_role_id)\n",
      "            assert role_to_add is not None, self.ASSERT_ROLE_EXISTS.format(r_id=exempt_role_id, tier_n=add_tier)\n",
      "\n",
      "            tier_name = self.json_conv.get_tier_name(add_tier)\n",
      "            if len(member_r_roles) == 0:  # No current rank roles.\n",
      "                await mem.add_roles(role_to_add)\n",
      "                to_return = self.RANK_ROLE_ADDED.format(r_role=tier_name)\n",
      "            elif member_r_roles == [role_to_add]:\n",
      "                # Author already has the exact rank role he should have, and no other rank roles.\n",
      "                to_return = self.RANK_ROLE_INTACT.format(r_role=tier_name)\n",
      "            else:\n",
      "                if role_to_add in member_r_roles:\n",
      "                    # Keep the role supposed to be added, remove the rest later.\n",
      "                    to_remove = [r for r in member_r_roles if r != role_to_add]\n",
      "                else:\n",
      "                    await mem.add_roles(role_to_add)  # Add the role, remove the current ones later.\n",
      "                    to_remove = member_r_roles\n",
      "                await mem.remove_roles(*to_remove)\n",
      "                to_return = self.RANK_ROLE_UPDATED.format(r_role=tier_name)\n",
      "        return to_return\n",
      "\n",
      "    async def platform_id_bundle(self, platform_in: str, id_in: str):\n",
      "        \"\"\"Verify the input of a platform and gamer id\n",
      "\n",
      "        By default, number input for id_in (for Steam) will be treated as an ID3/ID64.\n",
      "        In order to use vanity id that consists solely of digits, it must be prefixed with /id/\"\"\"\n",
      "        platform_out = self.json_conv.get_input_platform(platform_in)\n",
      "        if not platform_out:\n",
      "            raise AccountInputError(self.PLATFORM_INVALID)\n",
      "        if platform_out == \"switch\":\n",
      "            raise AccountInputError(self.SWITCH_UNSUPPORTED)\n",
      "        # Valid platform.\n",
      "        if platform_out == \"steam\":\n",
      "            if id_in.lstrip(\"-\").isdigit():\n",
      "                id_out = self.int_to_steam_id64(int(id_in))\n",
      "            elif re.match(r\"^\\[U:1:\\d{1,10}\\]$\", id_in):  # Convert value inside steamID3 to ID64.\n",
      "                id_out = self.int_to_steam_id64(int(id_in.lstrip(\"[U:1:\").rstrip(\"]\")))\n",
      "            else:  # Do regex checks for /id/ and /profiles/.\n",
      "                re_split_a = re.split(r'/profiles/', id_in, maxsplit=1)\n",
      "                re_split_b = re.split(r'/id/', id_in, maxsplit=1)\n",
      "                if len(re_split_a) == 2:  # Successful split, so a match.\n",
      "                    clean_id = re_split_a[-1].rstrip(\"/\")\n",
      "                    try:\n",
      "                        id_out = self.int_to_steam_id64(int(clean_id))\n",
      "                    except ValueError:\n",
      "                        raise AccountInputError(self.ID64_NON_NUMERIC)\n",
      "                elif len(re_split_b) == 2:\n",
      "                    clean_id = re_split_b[-1].rstrip(\"/\")\n",
      "                    id_out = await self.steam_api.vanity_to_id64(clean_id)\n",
      "                else:\n",
      "                    id_out = await self.steam_api.vanity_to_id64(id_in)\n",
      "        else:\n",
      "            id_out = id_in\n",
      "        return platform_out, id_out\n",
      "\n",
      "    @staticmethod\n",
      "    def int_to_steam_id64(id_64: int) -> int:\n",
      "        \"\"\"Converts a SteamID64 to the one that the Psyonix API recognises\n",
      "\n",
      "        The reason for this is that Valve accepts multiple ID64s for the same account.\n",
      "        As a consequence, Discord Steam links use an ID64 that is not recognised by the Rocket League API.\"\"\"\n",
      "        return (id_64 % (2 ** 32)) + 76561197960265728\n",
      "\n",
      "    def rank_summary_str(self, player_skills: Optional[list], best_list_id: int, unplayed_lists: set,\n",
      "                         drop_casual: bool = False) -> (str, str):\n",
      "        \"\"\"\n",
      "        :param player_skills: list that is extracted from the API response dict, or None if there are no stats.\n",
      "        :param best_list_id: The number of the playlist in which the user has the highest ranking.\n",
      "        :param unplayed_lists: A set of the playlists which the user has not played in.\n",
      "        :param drop_casual: (Optional) Whether to drop casual ranking. Defaults to False.\n",
      "        :return: A string with a player's summarised rank in a given playlist\n",
      "        \"\"\"\n",
      "        desc_rows = {}\n",
      "        pad = 8\n",
      "        mode_int = 2\n",
      "        for i in player_skills:\n",
      "            rating = float_sr(i)\n",
      "            playlist_id = i[\"playlist\"]\n",
      "            list_name = self.json_conv.get_playlist_name(playlist_id, mode_int)\n",
      "            if playlist_id == 0 and drop_casual:\n",
      "                playlist_str = None\n",
      "            elif playlist_id == 0:\n",
      "                playlist_str = self.E_ROW_ONLY_MMR.format(list_name, pad, rating)\n",
      "            else:\n",
      "                tier_div = self.json_conv.tier_div_str(i)\n",
      "                bold = \"**\" if playlist_id == best_list_id else \"\"  # Embolden best playlist.\n",
      "                playlist_str = self.E_ROW_RANKED.format(ls=list_name, p=pad, n=rating, bold=bold, tier_div=tier_div)\n",
      "            if playlist_str:\n",
      "                desc_rows[playlist_id] = playlist_str\n",
      "        for n in unplayed_lists:\n",
      "            list_name = self.json_conv.get_playlist_name(n, mode_int)\n",
      "            desc_rows[n] = self.E_ROW_NO_MATCHES.format(list_name, pad)\n",
      "        # Split list into normal and special (to make menu-embed possible).\n",
      "        normal_lists, special_lists = [], []\n",
      "        for k, v in sorted(desc_rows.items()):\n",
      "            normal_lists.append(v) if k < 20 else special_lists.append(v)\n",
      "        return \"\\n\".join(normal_lists), \"\\n\".join(special_lists)\n",
      "\n",
      "    def make_lfg_embed(self, response: dict, url_platform: str, user: discord.Member = None) -> List[discord.Embed]:\n",
      "        \"\"\"Make the embed for the LFG commands\"\"\"\n",
      "        player_name = response[\"user_name\"]\n",
      "        player_skills = response.get(\"player_skills\")  # Note: value is a list!\n",
      "        assert player_skills, \"lfg -> No player skills! Check the presence of player skills first.\"\n",
      "        best_tier, best_list_id, played_lists = best_playlist(player_skills)\n",
      "        unplayed_lists = {n for n in self.PLAYLIST_IDS if n not in played_lists}\n",
      "        # Create rows for each playlist.\n",
      "        summary_tuple = self.rank_summary_str(player_skills, best_list_id, unplayed_lists)\n",
      "        # Get author URL. Profile links only exist for Steam.\n",
      "        player_url = self.STEAM_PROFILE_URL.format(response[\"user_id\"]) \\\n",
      "            if url_platform == \"steam\" else discord.Embed.Empty\n",
      "        # Create embed, and use the highest tier's colour.\n",
      "        return_list = []\n",
      "        for summary in summary_tuple:\n",
      "            embed = discord.Embed()\n",
      "            embed.colour = self.json_conv.get_tier_colour(best_tier)\n",
      "            embed.set_author(name=\"Rocket League Stats - {}\".format(player_name), url=player_url)\n",
      "            embed.description = summary\n",
      "            if user:\n",
      "                embed.set_footer(text=f\"ID: {user.id}\", icon_url=user.avatar_url_as(static_format=\"png\"))\n",
      "            return_list.append(embed)\n",
      "        return return_list\n",
      "\n",
      "    def make_rocket_embed(self, response: dict, gas_od: OrderedDict, url_platform: str,\n",
      "                          user: discord.Member = None) -> discord.Embed:\n",
      "        \"\"\"Make the embed for the general stat commands\"\"\"\n",
      "        player_name = response[\"user_name\"]\n",
      "        player_skills = response.get(\"player_skills\")  # Note: value is a list!\n",
      "        assert player_skills, \"rocket -> No player skills! Check the presence of player skills first.\"\n",
      "        best_tier, best_list_id, played_lists = best_playlist(player_skills)\n",
      "        unplayed_lists = {n for n in self.PLAYLIST_IDS if n not in played_lists}\n",
      "        # Create rows for each playlist.\n",
      "        summary_tuple = self.rank_summary_str(player_skills, best_list_id, unplayed_lists, drop_casual=True)\n",
      "        # Get stats for casual (unranked) separately.\n",
      "        casual_rating = None\n",
      "        if 0 not in unplayed_lists:  # Thus, casual is played.\n",
      "            zero_dict = next(d for d in player_skills if d[\"playlist\"] == 0)\n",
      "            casual_rating = float_sr(zero_dict)\n",
      "        casual_str = \"\\nCasual SR: **{}**\".format(f\"{casual_rating:0.2f}\" if casual_rating else \"*N/A*\")\n",
      "        # Make strings for GAS.\n",
      "        gas_list = [f\"{k.title()}: **{v}**\" for k, v in gas_od.items()]\n",
      "        # Get author URL. Profile links only exist for Steam.\n",
      "        player_url = self.STEAM_PROFILE_URL.format(response[\"user_id\"]) \\\n",
      "            if url_platform == \"steam\" else discord.Embed.Empty\n",
      "        # Create embed, and use the highest tier's colour.\n",
      "        embed = discord.Embed()\n",
      "        embed.colour = self.json_conv.get_tier_colour(best_tier)\n",
      "        embed.description = \"Reward level: {}\".format(self.json_conv.reward_level_str(response))\n",
      "        embed.set_thumbnail(url=self.json_conv.get_tier_icon(best_tier))\n",
      "        embed.set_author(name=\"Rocket League Stats - {}\".format(player_name), url=player_url)\n",
      "        if user:\n",
      "            embed.set_footer(text=f\"ID: {user.id}\", icon_url=user.avatar_url_as(static_format=\"png\"))\n",
      "        # Add stat fields.\n",
      "        embed.add_field(name=\"General\", value=\"\\n\".join((*gas_list, casual_str)))\n",
      "        embed.add_field(name=\"Competitive\", value=\"\\n\".join(summary_tuple))\n",
      "        return embed\n",
      "\n",
      "    def make_plist_embed(self, response: dict, list_id: int, url_platform: str,\n",
      "                         user: discord.Member = None) -> (Optional[str], Optional[discord.Embed]):\n",
      "        \"\"\"Create a playlist-specific embed\n",
      "\n",
      "        Returns message content (if applicable) and an embed (if there is one).\"\"\"\n",
      "        player_skills = response.get(\"player_skills\")\n",
      "        assert player_skills, \"plist -> No player skills! Check the presence of player skills first.\"\n",
      "        list_name = self.json_conv.get_playlist_name(list_id, mode=3)\n",
      "        p_dict = next((d for d in player_skills if d[\"playlist\"] == list_id), None)  # No fixed order.\n",
      "        if not p_dict:\n",
      "            content, embed = self.PLAYLIST_NOT_PLAYED.format(plist=list_name), None\n",
      "        elif list_id == 0:\n",
      "            content, embed = (\"**{} stats**\\nRating: {}\\nMu/MMR: {}\\nSigma:{}\"\n",
      "                              .format(list_name, float_sr(p_dict), p_dict[\"mu\"], p_dict[\"sigma\"])), None\n",
      "        else:  # Embed can be made.\n",
      "            player_name = response[\"user_name\"]\n",
      "            # Unpack rating values.\n",
      "            tier_div = self.json_conv.tier_div_str(p_dict)\n",
      "            sr = float_sr(p_dict)\n",
      "            matches = p_dict[\"matches_played\"]\n",
      "            streak = p_dict[\"win_streak\"]\n",
      "            tier_n = p_dict[\"tier\"]  # Needed for thumb and colour.\n",
      "            # Get author URL. Profile links only exist for Steam.\n",
      "            player_url = self.STEAM_PROFILE_URL.format(response[\"user_id\"]) \\\n",
      "                if url_platform == \"steam\" else discord.Embed.Empty\n",
      "            # Create embed.\n",
      "            content, embed = None, discord.Embed(description=tier_div)\n",
      "            embed.colour = self.json_conv.get_tier_colour(tier_n)\n",
      "            embed.set_thumbnail(url=self.json_conv.get_tier_icon(tier_n))\n",
      "            embed.set_author(name=\"{} stats - {}\".format(list_name, player_name), url=player_url)\n",
      "            embed.add_field(name=\"Rating\", value=f\"{sr:0.2f}\")\n",
      "            embed.add_field(name=\"Matches played\", value=\"{} (Streak: {})\".format(matches, streak))\n",
      "            misc = \"Mu/MMR: {} | Sigma: {}\".format(p_dict[\"mu\"], p_dict[\"sigma\"])\n",
      "            if user:\n",
      "                embed.set_footer(text=f\"ID: {user.id} | {misc}\", icon_url=user.avatar_url_as(static_format=\"png\"))\n",
      "            else:\n",
      "                embed.set_footer(text=misc)\n",
      "        return content, embed\n",
      "\n",
      "Output: {'lafusee': [], 'lafusee.LaFusee.__init__': ['redbot.core.Config.get_conf', 'json_data.GetJsonData', 'redbot.core.data_manager.cog_data_path', '<builtin>.super', '<builtin>.str', 'db_queries.DbQueries', 'steam_calls.SteamCalls', 'psyonix_calls.PsyonixCalls'], '<builtin>.super': [], 'redbot.core.data_manager.cog_data_path': [], '<builtin>.str': [], 'redbot.core.Config.get_conf': [], 'psyonix_calls.PsyonixCalls': [], 'steam_calls.SteamCalls': [], 'db_queries.DbQueries': [], 'json_data.GetJsonData': [], 'lafusee.LaFusee.cog_command_error': ['<builtin>.isinstance', '<builtin>.str'], '<builtin>.isinstance': [], 'redbot.core.checks.admin_or_permissions': [], 'lafusee.LaFusee': ['redbot.core.checks.admin_or_permissions', 'redbot.core.commands.group', 'redbot.core.checks.mod_or_permissions', 'redbot.core.commands.command'], 'redbot.core.commands.group': [], 'lafusee.LaFusee._rl_setup': [], 'redbot.core.checks.mod_or_permissions': [], 'lafusee.LaFusee._api_setup': [], 'lafusee.LaFusee.set_psyonix_token': ['lafusee.LaFusee.check_token_fmt'], 'lafusee.LaFusee.check_token_fmt': ['<builtin>.isinstance', '<builtin>.print', '<builtin>.len', 'exceptions.TokenError', '<builtin>.int'], 'lafusee.LaFusee.delete_psyonix_token': ['exceptions.TokenError'], 'exceptions.TokenError': [], 'lafusee.LaFusee.set_steam_token': ['<builtin>.str', 'lafusee.LaFusee.check_token_fmt'], 'lafusee.LaFusee.delete_steam_token': [], 'lafusee.LaFusee.toggle_rl_role': [], 'lafusee.LaFusee.toggle_ignore_special': [], 'lafusee.LaFusee.set_rl_roles': ['<builtin>.range', '<builtin>.reversed', 'discord.utils.get', 'discord.Colour', 'static_functions.com'], '<builtin>.range': [], '<builtin>.reversed': [], 'discord.Colour': [], 'discord.utils.get': [], 'static_functions.com': [], 'lafusee.LaFusee._rl': ['discord.Colour.red', 'static_functions.com', 'discord.Embed'], 'discord.Colour.red': [], 'discord.Embed': [], 'lafusee.LaFusee.rl_help': ['discord.Colour.red', 'discord.Embed'], 'lafusee.LaFusee.register_tag': ['lafusee.LaFusee.update_member_rankroles', 'lafusee.LaFusee.platform_id_bundle', '<builtin>.str', 'static_functions.com', 'exceptions.CustomNotice', 'static_functions.best_playlist'], 'exceptions.CustomNotice': [], 'lafusee.LaFusee.platform_id_bundle': ['lafusee.LaFusee.int_to_steam_id64', '<builtin>.len', 're.match', 'exceptions.AccountInputError', 're.split', '<builtin>.int'], 'static_functions.best_playlist': [], 'lafusee.LaFusee.update_member_rankroles': ['discord.utils.get', '<builtin>.str', '<builtin>.type', '<builtin>.len'], 'lafusee.LaFusee.update_rank_role': ['static_functions.best_playlist', 'lafusee.LaFusee.update_member_rankroles', 'exceptions.CustomNotice'], 'lafusee.LaFusee.de_register_tag': ['lafusee.LaFusee.update_member_rankroles'], 'lafusee.LaFusee._lfg_embed': ['lafusee.LaFusee.platform_id_bundle', 'lafusee.LaFusee.make_lfg_embed', 'redbot.core.utils.menus.menu'], 'lafusee.LaFusee.make_lfg_embed': ['discord.Embed', 'lafusee.LaFusee.rank_summary_str', 'static_functions.best_playlist'], 'redbot.core.utils.menus.menu': [], 'lafusee.LaFusee.lfg_user': ['lafusee.LaFusee.make_lfg_embed', 'lafusee.LaFusee.check_registration_complete', 'redbot.core.utils.menus.menu'], 'lafusee.LaFusee.check_registration_complete': ['exceptions.CustomNotice', 'static_functions.com'], 'lafusee.LaFusee._rocket_embed': ['lafusee.LaFusee.platform_id_bundle', 'lafusee.LaFusee.make_rocket_embed'], 'lafusee.LaFusee.make_rocket_embed': ['discord.Embed', 'static_functions.float_sr', 'lafusee.LaFusee.rank_summary_str', '<builtin>.next', 'static_functions.best_playlist'], 'lafusee.LaFusee.rocket_user': ['lafusee.LaFusee.check_registration_complete', 'lafusee.LaFusee.make_rocket_embed'], 'lafusee.LaFusee._plist_embed': ['lafusee.LaFusee.platform_id_bundle', 'lafusee.LaFusee.make_plist_embed', 'exceptions.CustomNotice'], 'lafusee.LaFusee.make_plist_embed': ['discord.Embed', '<builtin>.next', 'static_functions.float_sr'], 'lafusee.LaFusee.plist_user': ['lafusee.LaFusee.check_registration_complete', 'lafusee.LaFusee.make_plist_embed', 'exceptions.CustomNotice'], 'redbot.core.commands.command': [], 'lafusee.LaFusee.send_steam_link': ['lafusee.LaFusee.platform_id_bundle', 'exceptions.CustomNotice', 'static_functions.com'], 'lafusee.LaFusee._tests': [], 'lafusee.LaFusee.skills_test': ['lafusee.LaFusee.platform_id_bundle'], 'lafusee.LaFusee.titles_test': ['lafusee.LaFusee.platform_id_bundle'], 'lafusee.LaFusee.raw_skills': ['lafusee.LaFusee.platform_id_bundle', 'json.dumps'], 'json.dumps': [], 'lafusee.LaFusee.gas_test': ['lafusee.LaFusee.platform_id_bundle'], 'lafusee.LaFusee.test_vanity': [], 'lafusee.LaFusee.test_platform_id_bundle': ['lafusee.LaFusee.platform_id_bundle'], 'lafusee.LaFusee.test_regex_split': ['re.split', '<builtin>.len'], 're.split': [], '<builtin>.len': [], 'lafusee.LaFusee.red_delete_data_for_user': [], '<builtin>.print': [], '<builtin>.int': [], '<builtin>.type': [], 'exceptions.AccountInputError': [], 'lafusee.LaFusee.int_to_steam_id64': [], 're.match': [], 'lafusee.LaFusee.rank_summary_str': ['static_functions.float_sr', '<builtin>.sorted'], 'static_functions.float_sr': [], '<builtin>.sorted': [], '<builtin>.next': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\FixedThink_RocketCogs\\lafusee\\lafusee.py\n",
      "[('lafusee LaFusee __init__', 'redbot core Config get_conf'), ('lafusee LaFusee __init__', 'json_data GetJsonData'), ('lafusee LaFusee __init__', 'redbot core data_manager cog_data_path'), ('lafusee LaFusee __init__', 'db_queries DbQueries'), ('lafusee LaFusee __init__', 'steam_calls SteamCalls'), ('lafusee LaFusee __init__', 'psyonix_calls PsyonixCalls'), ('lafusee LaFusee', 'redbot core checks admin_or_permissions'), ('lafusee LaFusee', 'redbot core commands group'), ('lafusee LaFusee', 'redbot core checks mod_or_permissions'), ('lafusee LaFusee', 'redbot core commands command'), ('lafusee LaFusee set_psyonix_token', 'lafusee LaFusee check_token_fmt'), ('lafusee LaFusee check_token_fmt', 'exceptions TokenError'), ('lafusee LaFusee delete_psyonix_token', 'exceptions TokenError'), ('lafusee LaFusee set_steam_token', 'lafusee LaFusee check_token_fmt'), ('lafusee LaFusee set_rl_roles', 'discord utils get'), ('lafusee LaFusee set_rl_roles', 'discord Colour'), ('lafusee LaFusee set_rl_roles', 'static_functions com'), ('lafusee LaFusee _rl', 'discord Colour red'), ('lafusee LaFusee _rl', 'static_functions com'), ('lafusee LaFusee _rl', 'discord Embed'), ('lafusee LaFusee rl_help', 'discord Colour red'), ('lafusee LaFusee rl_help', 'discord Embed'), ('lafusee LaFusee register_tag', 'lafusee LaFusee update_member_rankroles'), ('lafusee LaFusee register_tag', 'lafusee LaFusee platform_id_bundle'), ('lafusee LaFusee register_tag', 'static_functions com'), ('lafusee LaFusee register_tag', 'exceptions CustomNotice'), ('lafusee LaFusee register_tag', 'static_functions best_playlist'), ('lafusee LaFusee platform_id_bundle', 'lafusee LaFusee int_to_steam_id64'), ('lafusee LaFusee platform_id_bundle', 're match'), ('lafusee LaFusee platform_id_bundle', 'exceptions AccountInputError')]\n",
      "0\n",
      "found files: []\n",
      "# Default library.\n",
      "import asyncio\n",
      "from collections import OrderedDict\n",
      "from typing import Dict, List, Optional\n",
      "\n",
      "# Used by Red.\n",
      "import aiohttp\n",
      "\n",
      "# Local imports.\n",
      "from .exceptions import PsyonixCallError\n",
      "\n",
      "\n",
      "class PsyonixCalls:\n",
      "    \"\"\"Class for querying the Psyonix API asynchronically\"\"\"\n",
      "    ERROR = \":x: Error: \"\n",
      "\n",
      "    API_URL = \"https://api.rocketleague.com/api/v1/{p}/\"  # p=platform, uid=gamer-id\n",
      "    API_GAS = API_URL + \"leaderboard/stats/{t}/{uid}\"  # {} * 3, t=GAS-type\n",
      "    API_RANK = API_URL + \"playerskills/{uid}\"  # {} * 2\n",
      "    API_TITLES = API_URL + \"playertitles/{uid}\"  # {} * 2\n",
      "\n",
      "    GAS_LIST = [\"goals\", \"assists\", \"saves\", \"wins\", \"mvps\", \"shots\"]\n",
      "    PSY_TOKEN_NONE = ERROR + \"No token set for the Psyonix API.\"\n",
      "    # Constants based on status codes.\n",
      "    PLAYER_ERROR = ERROR + \"That ID is not associated with an account that has played Rocket League.\\n\" \\\n",
      "                           \"Please make sure the right account is used. `(Status: 400)`\"\n",
      "    PSY_TOKEN_INVALID = ERROR + \"The Psyonix API token is invalid. `(Status: 401)`\"\n",
      "    SERVER_ERROR = \":satellite: The Rocket League API is experiencing issues. \" \\\n",
      "                   \"Please try the command again in 30 seconds. `(Status: {})`\"\n",
      "    LOOP_NOT_ALL_200 = ERROR + \"One or more stats in the loop returned a non-200 status!\"\n",
      "    # Other request-based errors.\n",
      "    TIMEOUT_ERROR = \":hourglass: The request to the Rocket League API timed out. \" \\\n",
      "                    \"This means that the API might be down. Try again later.\"\n",
      "    UNKNOWN_STATUS_ERROR = ERROR + \"Something went wrong whilst querying the Psyonix API.\\n\" \\\n",
      "                                   \"See the console for the query in question. `(Uncaught status: {})`\"\n",
      "    # Other errors.\n",
      "    NO_MATCHES = ERROR + \"This account has purchased Rocket League, but has no online matches on record!\"\n",
      "\n",
      "    def __init__(self, config):\n",
      "        # Load config in order to always have an updated token.\n",
      "        self.config = config\n",
      "        self.session = aiohttp.ClientSession()\n",
      "\n",
      "    async def _fetch(self, request_url, headers) -> (Optional[List[dict]], int):\n",
      "        \"\"\"Send a get request to the Psyonix API, and fetch the response\"\"\"\n",
      "        async with self.session.get(request_url, headers=headers) as response:\n",
      "            resp = response\n",
      "            resp_status = resp.status\n",
      "            if resp_status == 200:  # Valid response.\n",
      "                resp_json = await resp.json()\n",
      "            else:\n",
      "                resp_json = None\n",
      "        return resp_json, resp_status\n",
      "\n",
      "    async def _call_psyonix_api(self, request_url: str) -> dict:\n",
      "        \"\"\"Given an url, call the API using the configured token\n",
      "\n",
      "        Returns a list if valid, False if invalid, and None if there is no token.\n",
      "        Also returns a error if there is one.\"\"\"\n",
      "        token = await self.config.psy_token()\n",
      "        if token is None:\n",
      "            raise PsyonixCallError(self.PSY_TOKEN_NONE)\n",
      "        headers = {\"Authorization\": token}\n",
      "        try:\n",
      "            resp_json, resp_status = await self._fetch(request_url, headers)\n",
      "        except aiohttp.client_exceptions.ServerTimeoutError:\n",
      "            raise PsyonixCallError(self.TIMEOUT_ERROR)\n",
      "        if resp_status == 200:  # TODO: test if resp_json is not None is needed.\n",
      "            if isinstance(resp_json, list):\n",
      "                resp_json = resp_json[0]\n",
      "            to_return = resp_json\n",
      "        else:\n",
      "            if resp_status == 401:\n",
      "                raise PsyonixCallError(self.PSY_TOKEN_INVALID)\n",
      "            if resp_status == 400:\n",
      "                raise PsyonixCallError(self.PLAYER_ERROR)\n",
      "            if resp_status in {500, 502}:\n",
      "                raise PsyonixCallError(self.SERVER_ERROR.format(resp_status))\n",
      "            print(request_url)\n",
      "            raise PsyonixCallError(self.UNKNOWN_STATUS_ERROR.format(resp_status))\n",
      "        return to_return\n",
      "\n",
      "    async def player_skills(self, platform: str, valid_id,\n",
      "                            ensure_played: bool = False) -> Optional[dict]:  # TODO: Check if optional\n",
      "        \"\"\"Composes the PlayerSkills query call, and returns its response\n",
      "\n",
      "        if ensure_played is True, there will be a notice if the player_skills value is an empty list.\n",
      "\n",
      "        Structure of a normal API response:\n",
      "        {user_name: str, player_skills: [list of playlist_dict], user_id: str, season_rewards: {wins: int, level: int}}\n",
      "\n",
      "        Structure of playlist_dict:\n",
      "        {division: int, matches_played: int, mu: float, playlist: int, sigma: float,\n",
      "        skill: int, tier: int, tier_max: int, win_steak: int}\n",
      "\n",
      "        Note: the original response has the dict wrapped in a list, but the call method removes it.\n",
      "        \"\"\"\n",
      "        request_url = self.API_RANK.format(p=platform, uid=valid_id)\n",
      "        to_return = await self._call_psyonix_api(request_url)\n",
      "        skills: List[Dict[str, Optional[float]]] = to_return.get(\"player_skills\") if to_return else None\n",
      "        if ensure_played and not skills:\n",
      "            raise PsyonixCallError(self.NO_MATCHES)\n",
      "        elif skills:  # Skills exist, replace nulls with 0. TODO: Maybe build in exception for raw.\n",
      "            for d in skills:\n",
      "                for k, v in d.items():\n",
      "                    if v is None:\n",
      "                        d[k] = 0\n",
      "        return to_return\n",
      "\n",
      "    async def player_titles(self, platform: str, valid_id) -> Optional[dict]:\n",
      "        \"\"\"Composes the PlayerTitles query call, and returns its response\n",
      "\n",
      "        Structure of a normal API response:\n",
      "        {titles: [list of titles]}\n",
      "        \"\"\"\n",
      "        request_url = self.API_TITLES.format(p=platform, uid=valid_id)\n",
      "        response = await self._call_psyonix_api(request_url)\n",
      "        return response.get(\"titles\")\n",
      "\n",
      "    async def player_stat_values(self, platform: str, valid_id) -> OrderedDict:\n",
      "        \"\"\"Get all the six stats for a player: wins, MVPs, goals, assists, saves, and shots\n",
      "\n",
      "        Structure of a normal API response (per individual stat):\n",
      "        {user_id: str, stat_type: str, value: str}\n",
      "        \"\"\"\n",
      "        token = await self.config.psy_token()\n",
      "        if token is None:\n",
      "            raise PsyonixCallError(self.PSY_TOKEN_NONE)\n",
      "        headers = {\"Authorization\": token}\n",
      "        tasks = []\n",
      "        for i in self.GAS_LIST:\n",
      "            url = self.API_GAS.format(p=platform, t=i, uid=valid_id)\n",
      "            task = asyncio.ensure_future(self._fetch(url, headers))\n",
      "            tasks.append(task)\n",
      "        responses = await asyncio.gather(*tasks)  # Structure: List[Tuple[List[dict]]]\n",
      "        if any(status != 200 for d, status in responses):  # One or more values does not have status 200.\n",
      "            print(responses)\n",
      "            raise PsyonixCallError(self.LOOP_NOT_ALL_200)\n",
      "        # Unpack gas-values to an OrderedDict.\n",
      "        return OrderedDict((d[\"stat_type\"], int(d[\"value\"])) for (d,), status in responses)\n",
      "\n",
      "Output: {'psyonix_calls': [], 'psyonix_calls.PsyonixCalls.__init__': ['aiohttp.ClientSession'], 'aiohttp.ClientSession': [], 'psyonix_calls.PsyonixCalls._fetch': [], 'psyonix_calls.PsyonixCalls._call_psyonix_api': ['<builtin>.print', 'psyonix_calls.PsyonixCalls._fetch', 'exceptions.PsyonixCallError', '<builtin>.isinstance'], 'exceptions.PsyonixCallError': [], '<builtin>.isinstance': [], '<builtin>.print': [], 'psyonix_calls.PsyonixCalls.player_skills': ['psyonix_calls.PsyonixCalls._call_psyonix_api', 'exceptions.PsyonixCallError'], 'psyonix_calls.PsyonixCalls.player_titles': ['psyonix_calls.PsyonixCalls._call_psyonix_api'], 'psyonix_calls.PsyonixCalls.player_stat_values': ['psyonix_calls.PsyonixCalls._fetch', '<builtin>.int', 'exceptions.PsyonixCallError', 'asyncio.ensure_future', '<builtin>.any', 'collections.OrderedDict', '<builtin>.print', 'asyncio.gather'], 'asyncio.ensure_future': [], 'asyncio.gather': [], '<builtin>.any': [], '<builtin>.int': [], 'collections.OrderedDict': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\FixedThink_RocketCogs\\lafusee\\psyonix_calls.py\n",
      "[('psyonix_calls PsyonixCalls __init__', 'aiohttp ClientSession'), ('psyonix_calls PsyonixCalls _call_psyonix_api', 'psyonix_calls PsyonixCalls _fetch'), ('psyonix_calls PsyonixCalls _call_psyonix_api', 'exceptions PsyonixCallError'), ('psyonix_calls PsyonixCalls player_skills', 'psyonix_calls PsyonixCalls _call_psyonix_api'), ('psyonix_calls PsyonixCalls player_skills', 'exceptions PsyonixCallError'), ('psyonix_calls PsyonixCalls player_titles', 'psyonix_calls PsyonixCalls _call_psyonix_api'), ('psyonix_calls PsyonixCalls player_stat_values', 'psyonix_calls PsyonixCalls _fetch'), ('psyonix_calls PsyonixCalls player_stat_values', 'exceptions PsyonixCallError'), ('psyonix_calls PsyonixCalls player_stat_values', 'asyncio ensure_future'), ('psyonix_calls PsyonixCalls player_stat_values', 'collections OrderedDict'), ('psyonix_calls PsyonixCalls player_stat_values', 'asyncio gather')]\n",
      "0\n",
      "found files: []\n",
      "# Default library.\n",
      "import datetime\n",
      "import sqlite3  # Only to make the db on init.\n",
      "\n",
      "# Requirements.\n",
      "import aiosqlite\n",
      "\n",
      "\n",
      "class DbQueries:\n",
      "    \"\"\"Query the account registrations\"\"\"\n",
      "    CREATE_TABLE = \"CREATE TABLE `registrations` (`userID` INTEGER, `username` TEXT, `timestamp` TEXT, \" \\\n",
      "                   \"`platform` INTEGER, `gamer_id` TEXT, PRIMARY KEY(`userID`));\"\n",
      "    TABLE_CHECK = \"SELECT count(*) FROM sqlite_master WHERE type='table' AND name='registrations';\"\n",
      "    DELETE_LINK = \"DELETE FROM `registrations` WHERE userID = ?\"\n",
      "    INSERT_LINK = \"INSERT OR REPLACE INTO `registrations` VALUES (?, ?, ?, ?, ?);\"\n",
      "    SELECT_LINK = \"SELECT `platform`, `gamer_id` FROM `registrations` WHERE userID = ?\"\n",
      "\n",
      "    def __init__(self, db_path):\n",
      "        self.path = db_path\n",
      "        self.init_table()\n",
      "\n",
      "    def init_table(self) -> None:\n",
      "        \"\"\"Check if the table exists. If not, create it.\n",
      "\n",
      "        Note: this method uses sqlite3 rather than aiosqlite\"\"\"\n",
      "        connection = sqlite3.connect(self.path)\n",
      "        cursor = connection.cursor()\n",
      "        cursor.execute(self.TABLE_CHECK)\n",
      "        resp = cursor.fetchall()\n",
      "        is_table = bool(resp[0][0])\n",
      "        if is_table is False:\n",
      "            print(\"Making the registrations table...\")\n",
      "            cursor.execute(self.CREATE_TABLE)\n",
      "            connection.commit()\n",
      "        connection.close()\n",
      "        return\n",
      "\n",
      "    # Query methods.\n",
      "    async def delete_user(self, user_id) -> None:\n",
      "        \"\"\"Delete the link information for a user\"\"\"\n",
      "        await self.exec_sql(self.DELETE_LINK, [user_id], commit=True)\n",
      "        return\n",
      "\n",
      "    async def insert_user(self, user_id, username, platform, gamer_id) -> None:\n",
      "        \"\"\"Insert the link information for a user\"\"\"\n",
      "        stamp = str(datetime.datetime.utcnow())\n",
      "        await self.exec_sql(self.INSERT_LINK, [user_id, username, stamp, platform, gamer_id], commit=True)\n",
      "        return\n",
      "\n",
      "    async def select_user(self, user_id) -> tuple:\n",
      "        \"\"\"Get the platform and gamer_id of a user in the DB. Returns (False, False) if there's no match\"\"\"\n",
      "        resp = await self.exec_sql(self.SELECT_LINK, [user_id])\n",
      "        if len(resp) == 0:  # No match\n",
      "            platform, gamer_id = (None, None)\n",
      "        else:\n",
      "            platform, gamer_id = resp[0]\n",
      "        return platform, gamer_id\n",
      "\n",
      "    # Utilities.\n",
      "    async def exec_sql(self, query, params=None, commit=False) -> list:\n",
      "        \"\"\"Make an SQL query to the userID - gamer ID Database\"\"\"\n",
      "        async with aiosqlite.connect(self.path) as db:\n",
      "            async with db.execute(query, parameters=params) as cursor:\n",
      "                rows = await cursor.fetchall()\n",
      "            if commit:\n",
      "                await db.commit()\n",
      "        return rows\n",
      "\n",
      "Output: {'db_queries': [], 'db_queries.DbQueries.__init__': ['db_queries.DbQueries.init_table'], 'db_queries.DbQueries.init_table': ['sqlite3.connect', '<builtin>.bool', '<builtin>.print'], 'sqlite3.connect': [], '<builtin>.bool': [], '<builtin>.print': [], 'db_queries.DbQueries.delete_user': ['db_queries.DbQueries.exec_sql'], 'db_queries.DbQueries.exec_sql': ['aiosqlite.connect'], 'db_queries.DbQueries.insert_user': ['datetime.datetime.utcnow', 'db_queries.DbQueries.exec_sql', '<builtin>.str'], 'datetime.datetime.utcnow': [], '<builtin>.str': [], 'db_queries.DbQueries.select_user': ['db_queries.DbQueries.exec_sql', '<builtin>.len'], '<builtin>.len': [], 'aiosqlite.connect': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\FixedThink_RocketCogs\\lafusee\\db_queries.py\n",
      "[('db_queries DbQueries __init__', 'db_queries DbQueries init_table'), ('db_queries DbQueries init_table', 'sqlite3 connect'), ('db_queries DbQueries delete_user', 'db_queries DbQueries exec_sql'), ('db_queries DbQueries exec_sql', 'aiosqlite connect'), ('db_queries DbQueries insert_user', 'datetime datetime utcnow'), ('db_queries DbQueries insert_user', 'db_queries DbQueries exec_sql'), ('db_queries DbQueries select_user', 'db_queries DbQueries exec_sql')]\n",
      "0\n",
      "found files: []\n",
      "from redbot.core.commands import CommandError\n",
      "\n",
      "\n",
      "class LaFuseeError(CommandError):\n",
      "    \"\"\"Generic error for the RL commands cog\"\"\"\n",
      "\n",
      "\n",
      "class CustomNotice(LaFuseeError):\n",
      "    \"\"\"Generic custom command error\"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "class AccountInputError(LaFuseeError):\n",
      "    \"\"\"Used when a platform-id couple yields an error\"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "class PsyonixCallError(LaFuseeError):\n",
      "    \"\"\"Used when a call to the Psyonix API yields an error\"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "class SteamCallError(LaFuseeError):\n",
      "    \"\"\"Used when a call to the Psyonix API yields an error\"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "class TokenError(LaFuseeError):\n",
      "    \"\"\"Errors related to setting and using tokens\"\"\"\n",
      "    pass\n",
      "\n",
      "Output: {'exceptions': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\FixedThink_RocketCogs\\lafusee\\exceptions.py\n",
      "[]\n",
      "********************pycgContent*************************\n",
      "[[('reputation Reputation __init__', 'redbot core Config get_conf'), ('reputation Reputation __init__', 'redbot core data_manager cog_data_path'), ('reputation Reputation __init__', 'reputation Reputation periodical_decay_check'), ('reputation Reputation __init__', 'asyncio ensure_future'), ('reputation Reputation __init__', 'db_queries DbQueries'), ('reputation Reputation periodical_decay_check', 'asyncio sleep'), ('reputation Reputation periodical_decay_check', 'reputation Reputation guild_role_check'), ('reputation Reputation guild_role_check', 'reputation Reputation give_reputation_role'), ('reputation Reputation guild_role_check', 'reputation Reputation get_reputation_role_obj'), ('reputation Reputation', 'redbot core commands group'), ('reputation Reputation', 'redbot core commands guild_only'), ('reputation Reputation', 'redbot core checks admin_or_permissions'), ('reputation Reputation', 'redbot core commands command'), ('reputation Reputation view_current_config', 'discord Embed'), ('reputation Reputation view_current_config', 'datetime timedelta'), ('reputation Reputation view_current_config', 'discord utils get'), ('reputation Reputation view_current_config', 'reputation Reputation get_shadow_role_obj'), ('reputation Reputation view_current_config', 'reputation Reputation get_reputation_role_obj'), ('reputation Reputation view_current_config', 'discord Colour lighter_grey'), ('reputation Reputation get_reputation_role_obj', 'discord utils get'), ('reputation Reputation get_shadow_role_obj', 'discord utils get'), ('reputation Reputation role_opt_out', 'reputation Reputation get_reputation_role_obj'), ('reputation Reputation role_opt_out', 'reputation Reputation user_role_check'), ('reputation Reputation user_role_check', 'datetime timedelta'), ('reputation Reputation user_role_check', 'reputation Reputation get_reputation_role_obj'), ('reputation Reputation user_role_check', 'reputation Reputation give_reputation_role'), ('reputation Reputation set_rep_cooldown', 'datetime timedelta'), ('reputation Reputation set_rep_decay', 'datetime timedelta'), ('reputation Reputation manual_guild_check', 'reputation Reputation guild_role_check'), ('reputation Reputation manual_guild_check', 'reputation Reputation plural_s')], [('json_data GetJsonData', 'os path dirname'), ('json_data GetJsonData', 'os path realpath'), ('json_data GetJsonData __init__', 'json_data _json_key_to_int'), ('json_data GetJsonData __init__', 'json load'), ('json_data GetJsonData tier_div_str', 'json_data GetJsonData get_tier_name')], [('db_queries DbQueries __init__', 'db_queries DbQueries init_table'), ('db_queries DbQueries init_table', 'sqlite3 connect'), ('db_queries DbQueries all_eligible_users', 'datetime timedelta'), ('db_queries DbQueries all_eligible_users', 'db_queries DbQueries exec_sql'), ('db_queries DbQueries all_eligible_users', 'datetime datetime utcnow'), ('db_queries DbQueries exec_sql', 'aiosqlite connect'), ('db_queries DbQueries insert_rep', 'datetime timedelta'), ('db_queries DbQueries insert_rep', 'db_queries DbQueries exec_sql'), ('db_queries DbQueries user_rep_count', 'db_queries DbQueries exec_sql'), ('db_queries DbQueries rep_leaderboard', 'db_queries DbQueries exec_sql'), ('db_queries DbQueries recent_reps', 'db_queries DbQueries exec_sql')], [('static_functions best_playlist', 'static_functions _use_plist')], [('steam_calls SteamCalls __init__', 'aiohttp ClientSession'), ('steam_calls SteamCalls _call_steam_api', 'exceptions SteamCallError'), ('steam_calls SteamCalls vanity_to_id64', 'exceptions SteamCallError'), ('steam_calls SteamCalls vanity_to_id64', 'steam_calls SteamCalls _call_steam_api')], [('lafusee LaFusee __init__', 'redbot core Config get_conf'), ('lafusee LaFusee __init__', 'json_data GetJsonData'), ('lafusee LaFusee __init__', 'redbot core data_manager cog_data_path'), ('lafusee LaFusee __init__', 'db_queries DbQueries'), ('lafusee LaFusee __init__', 'steam_calls SteamCalls'), ('lafusee LaFusee __init__', 'psyonix_calls PsyonixCalls'), ('lafusee LaFusee', 'redbot core checks admin_or_permissions'), ('lafusee LaFusee', 'redbot core commands group'), ('lafusee LaFusee', 'redbot core checks mod_or_permissions'), ('lafusee LaFusee', 'redbot core commands command'), ('lafusee LaFusee set_psyonix_token', 'lafusee LaFusee check_token_fmt'), ('lafusee LaFusee check_token_fmt', 'exceptions TokenError'), ('lafusee LaFusee delete_psyonix_token', 'exceptions TokenError'), ('lafusee LaFusee set_steam_token', 'lafusee LaFusee check_token_fmt'), ('lafusee LaFusee set_rl_roles', 'discord utils get'), ('lafusee LaFusee set_rl_roles', 'discord Colour'), ('lafusee LaFusee set_rl_roles', 'static_functions com'), ('lafusee LaFusee _rl', 'discord Colour red'), ('lafusee LaFusee _rl', 'static_functions com'), ('lafusee LaFusee _rl', 'discord Embed'), ('lafusee LaFusee rl_help', 'discord Colour red'), ('lafusee LaFusee rl_help', 'discord Embed'), ('lafusee LaFusee register_tag', 'lafusee LaFusee update_member_rankroles'), ('lafusee LaFusee register_tag', 'lafusee LaFusee platform_id_bundle'), ('lafusee LaFusee register_tag', 'static_functions com'), ('lafusee LaFusee register_tag', 'exceptions CustomNotice'), ('lafusee LaFusee register_tag', 'static_functions best_playlist'), ('lafusee LaFusee platform_id_bundle', 'lafusee LaFusee int_to_steam_id64'), ('lafusee LaFusee platform_id_bundle', 're match'), ('lafusee LaFusee platform_id_bundle', 'exceptions AccountInputError')], [('psyonix_calls PsyonixCalls __init__', 'aiohttp ClientSession'), ('psyonix_calls PsyonixCalls _call_psyonix_api', 'psyonix_calls PsyonixCalls _fetch'), ('psyonix_calls PsyonixCalls _call_psyonix_api', 'exceptions PsyonixCallError'), ('psyonix_calls PsyonixCalls player_skills', 'psyonix_calls PsyonixCalls _call_psyonix_api'), ('psyonix_calls PsyonixCalls player_skills', 'exceptions PsyonixCallError'), ('psyonix_calls PsyonixCalls player_titles', 'psyonix_calls PsyonixCalls _call_psyonix_api'), ('psyonix_calls PsyonixCalls player_stat_values', 'psyonix_calls PsyonixCalls _fetch'), ('psyonix_calls PsyonixCalls player_stat_values', 'exceptions PsyonixCallError'), ('psyonix_calls PsyonixCalls player_stat_values', 'asyncio ensure_future'), ('psyonix_calls PsyonixCalls player_stat_values', 'collections OrderedDict'), ('psyonix_calls PsyonixCalls player_stat_values', 'asyncio gather')], [('db_queries DbQueries __init__', 'db_queries DbQueries init_table'), ('db_queries DbQueries init_table', 'sqlite3 connect'), ('db_queries DbQueries delete_user', 'db_queries DbQueries exec_sql'), ('db_queries DbQueries exec_sql', 'aiosqlite connect'), ('db_queries DbQueries insert_user', 'datetime datetime utcnow'), ('db_queries DbQueries insert_user', 'db_queries DbQueries exec_sql'), ('db_queries DbQueries select_user', 'db_queries DbQueries exec_sql')]]\n",
      "********************doctrings*************************\n",
      "['', 'json key to int [SEP] Converts the keys of a (JSON) dictionary to integers', '', \"use plist best playlist com float sr [SEP] :param check_d: Dict of a playlist-specific player skills. :param ignore_special: Whether to count s :param player_skills: A list with a player's skills (extracted from the skills response dict). :para :param ctx: The context manager as provided by t\", '', '', '', '']\n",
      "embed index dataset: 20\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\FLHonker_Self-Driving-Car-RL\\\\map_commented.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\FLHonker_Self-Driving-Car-RL\\\\ai.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\FLHonker_Self-Driving-Car-RL\\\\map.py']\n",
      "# Self Driving Car\n",
      "\n",
      "# Importing the libraries\n",
      "import numpy as np\n",
      "from random import random, randint\n",
      "import matplotlib.pyplot as plt\n",
      "import time\n",
      "\n",
      "# Importing the Kivy packages\n",
      "from kivy.app import App\n",
      "from kivy.uix.widget import Widget\n",
      "from kivy.uix.button import Button\n",
      "from kivy.graphics import Color, Ellipse, Line\n",
      "from kivy.config import Config\n",
      "from kivy.properties import NumericProperty, ReferenceListProperty, ObjectProperty\n",
      "from kivy.vector import Vector\n",
      "from kivy.clock import Clock\n",
      "\n",
      "# Importing the Dqn object from our AI in ia.py\n",
      "from ai import Dqn\n",
      "\n",
      "# Adding this line if we don't want the right click to put a red point\n",
      "Config.set('input', 'mouse', 'mouse,multitouch_on_demand')\n",
      "\n",
      "# Introducing last_x and last_y, used to keep the last point in memory when we draw the sand on the map\n",
      "last_x = 0\n",
      "last_y = 0\n",
      "n_points = 0 # the total number of points in the last drawing\n",
      "length = 0 # the length of the last drawing\n",
      "\n",
      "# Getting our AI, which we call \"brain\", and that contains our neural network that represents our Q-function\n",
      "brain = Dqn(5,3,0.9) # 5 sensors, 3 actions, gama = 0.9\n",
      "action2rotation = [0,20,-20] # action = 0 => no rotation, action = 1 => rotate 20 degres, action = 2 => rotate -20 degres\n",
      "last_reward = 0 # initializing the last reward\n",
      "scores = [] # initializing the mean score curve (sliding window of the rewards) with respect to time\n",
      "\n",
      "# Initializing the map\n",
      "first_update = True # using this trick to initialize the map only once\n",
      "def init():\n",
      "    global sand # sand is an array that has as many cells as our graphic interface has pixels. Each cell has a one if there is sand, 0 otherwise.\n",
      "    global goal_x # x-coordinate of the goal (where the car has to go, that is the airport or the downtown)\n",
      "    global goal_y # y-coordinate of the goal (where the car has to go, that is the airport or the downtown)\n",
      "    sand = np.zeros((longueur,largeur)) # initializing the sand array with only zeros\n",
      "    goal_x = 20 # the goal to reach is at the upper left of the map (the x-coordinate is 20 and not 0 because the car gets bad reward if it touches the wall)\n",
      "    goal_y = largeur - 20 # the goal to reach is at the upper left of the map (y-coordinate)\n",
      "    first_update = False # trick to initialize the map only once\n",
      "\n",
      "# Initializing the last distance\n",
      "last_distance = 0\n",
      "\n",
      "# Creating the car class (to understand \"NumericProperty\" and \"ReferenceListProperty\", see kivy tutorials: https://kivy.org/docs/tutorials/pong.html)\n",
      "\n",
      "class Car(Widget):\n",
      "\n",
      "    angle = NumericProperty(0) # initializing the angle of the car (angle between the x-axis of the map and the axis of the car)\n",
      "    rotation = NumericProperty(0) # initializing the last rotation of the car (after playing the action, the car does a rotation of 0, 20 or -20 degrees)\n",
      "    velocity_x = NumericProperty(0) # initializing the x-coordinate of the velocity vector\n",
      "    velocity_y = NumericProperty(0) # initializing the y-coordinate of the velocity vector\n",
      "    velocity = ReferenceListProperty(velocity_x, velocity_y) # velocity vector\n",
      "    sensor1_x = NumericProperty(0) # initializing the x-coordinate of the first sensor (the one that looks forward)\n",
      "    sensor1_y = NumericProperty(0) # initializing the y-coordinate of the first sensor (the one that looks forward)\n",
      "    sensor1 = ReferenceListProperty(sensor1_x, sensor1_y) # first sensor vector\n",
      "    sensor2_x = NumericProperty(0) # initializing the x-coordinate of the second sensor (the one that looks 30 degrees to the left)\n",
      "    sensor2_y = NumericProperty(0) # initializing the y-coordinate of the second sensor (the one that looks 30 degrees to the left)\n",
      "    sensor2 = ReferenceListProperty(sensor2_x, sensor2_y) # second sensor vector\n",
      "    sensor3_x = NumericProperty(0) # initializing the x-coordinate of the third sensor (the one that looks 30 degrees to the right)\n",
      "    sensor3_y = NumericProperty(0) # initializing the y-coordinate of the third sensor (the one that looks 30 degrees to the right)\n",
      "    sensor3 = ReferenceListProperty(sensor3_x, sensor3_y) # third sensor vector\n",
      "    signal1 = NumericProperty(0) # initializing the signal received by sensor 1\n",
      "    signal2 = NumericProperty(0) # initializing the signal received by sensor 2\n",
      "    signal3 = NumericProperty(0) # initializing the signal received by sensor 3\n",
      "\n",
      "    def move(self, rotation):\n",
      "        self.pos = Vector(*self.velocity) + self.pos # updating the position of the car according to its last position and velocity\n",
      "        self.rotation = rotation # getting the rotation of the car\n",
      "        self.angle = self.angle + self.rotation # updating the angle\n",
      "        self.sensor1 = Vector(30, 0).rotate(self.angle) + self.pos # updating the position of sensor 1\n",
      "        self.sensor2 = Vector(30, 0).rotate((self.angle+30)%360) + self.pos # updating the position of sensor 2\n",
      "        self.sensor3 = Vector(30, 0).rotate((self.angle-30)%360) + self.pos # updating the position of sensor 3\n",
      "        self.signal1 = int(np.sum(sand[int(self.sensor1_x)-10:int(self.sensor1_x)+10, int(self.sensor1_y)-10:int(self.sensor1_y)+10]))/400. # getting the signal received by sensor 1 (density of sand around sensor 1)\n",
      "        self.signal2 = int(np.sum(sand[int(self.sensor2_x)-10:int(self.sensor2_x)+10, int(self.sensor2_y)-10:int(self.sensor2_y)+10]))/400. # getting the signal received by sensor 2 (density of sand around sensor 2)\n",
      "        self.signal3 = int(np.sum(sand[int(self.sensor3_x)-10:int(self.sensor3_x)+10, int(self.sensor3_y)-10:int(self.sensor3_y)+10]))/400. # getting the signal received by sensor 3 (density of sand around sensor 3)\n",
      "        if self.sensor1_x > longueur-10 or self.sensor1_x<10 or self.sensor1_y>largeur-10 or self.sensor1_y<10: # if sensor 1 is out of the map (the car is facing one edge of the map)\n",
      "            self.signal1 = 1. # sensor 1 detects full sand\n",
      "        if self.sensor2_x > longueur-10 or self.sensor2_x<10 or self.sensor2_y>largeur-10 or self.sensor2_y<10: # if sensor 2 is out of the map (the car is facing one edge of the map)\n",
      "            self.signal2 = 1. # sensor 2 detects full sand\n",
      "        if self.sensor3_x > longueur-10 or self.sensor3_x<10 or self.sensor3_y>largeur-10 or self.sensor3_y<10: # if sensor 3 is out of the map (the car is facing one edge of the map)\n",
      "            self.signal3 = 1. # sensor 3 detects full sand\n",
      "\n",
      "class Ball1(Widget): # sensor 1 (see kivy tutorials: kivy https://kivy.org/docs/tutorials/pong.html)\n",
      "    pass\n",
      "class Ball2(Widget): # sensor 2 (see kivy tutorials: kivy https://kivy.org/docs/tutorials/pong.html)\n",
      "    pass\n",
      "class Ball3(Widget): # sensor 3 (see kivy tutorials: kivy https://kivy.org/docs/tutorials/pong.html)\n",
      "    pass\n",
      "\n",
      "# Creating the game class (to understand \"ObjectProperty\", see kivy tutorials: kivy https://kivy.org/docs/tutorials/pong.html)\n",
      "\n",
      "class Game(Widget):\n",
      "\n",
      "    car = ObjectProperty(None) # getting the car object from our kivy file\n",
      "    ball1 = ObjectProperty(None) # getting the sensor 1 object from our kivy file\n",
      "    ball2 = ObjectProperty(None) # getting the sensor 2 object from our kivy file\n",
      "    ball3 = ObjectProperty(None) # getting the sensor 3 object from our kivy file\n",
      "\n",
      "    def serve_car(self): # starting the car when we launch the application\n",
      "        self.car.center = self.center # the car will start at the center of the map\n",
      "        self.car.velocity = Vector(6, 0) # the car will start to go horizontally to the right with a speed of 6\n",
      "\n",
      "    def update(self, dt): # the big update function that updates everything that needs to be updated at each discrete time t when reaching a new state (getting new signals from the sensors)\n",
      "\n",
      "        global brain # specifying the global variables (the brain of the car, that is our AI)\n",
      "        global last_reward # specifying the global variables (the last reward)\n",
      "        global scores # specifying the global variables (the means of the rewards)\n",
      "        global last_distance # specifying the global variables (the last distance from the car to the goal)\n",
      "        global goal_x # specifying the global variables (x-coordinate of the goal)\n",
      "        global goal_y # specifying the global variables (y-coordinate of the goal)\n",
      "        global longueur # specifying the global variables (width of the map)\n",
      "        global largeur # specifying the global variables (height of the map)\n",
      "\n",
      "        longueur = self.width # width of the map (horizontal edge)\n",
      "        largeur = self.height # height of the map (vertical edge)\n",
      "        if first_update: # trick to initialize the map only once\n",
      "            init()\n",
      "\n",
      "        xx = goal_x - self.car.x # difference of x-coordinates between the goal and the car\n",
      "        yy = goal_y - self.car.y # difference of y-coordinates between the goal and the car\n",
      "        orientation = Vector(*self.car.velocity).angle((xx,yy))/180. # direction of the car with respect to the goal (if the car is heading perfectly towards the goal, then orientation = 0)\n",
      "        last_signal = [self.car.signal1, self.car.signal2, self.car.signal3, orientation, -orientation] # our input state vector, composed of the three signals received by the three sensors, plus the orientation and -orientation\n",
      "        action = brain.update(last_reward, last_signal) # playing the action from our ai (the object brain of the dqn class)\n",
      "        scores.append(brain.score()) # appending the score (mean of the last 100 rewards to the reward window)\n",
      "        rotation = action2rotation[action] # converting the action played (0, 1 or 2) into the rotation angle (0, 20 or -20)\n",
      "        self.car.move(rotation) # moving the car according to this last rotation angle\n",
      "        distance = np.sqrt((self.car.x - goal_x)**2 + (self.car.y - goal_y)**2) # getting the new distance between the car and the goal right after the car moved\n",
      "        self.ball1.pos = self.car.sensor1 # updating the position of the first sensor (ball1) right after the car moved\n",
      "        self.ball2.pos = self.car.sensor2 # updating the position of the second sensor (ball2) right after the car moved\n",
      "        self.ball3.pos = self.car.sensor3 # updating the position of the third sensor (ball3) right after the car moved\n",
      "\n",
      "        if sand[int(self.car.x),int(self.car.y)] > 0: # if the car is on the sand\n",
      "            self.car.velocity = Vector(1, 0).rotate(self.car.angle) # it is slowed down (speed = 1)\n",
      "            last_reward = -1 # and reward = -1\n",
      "        else: # otherwise\n",
      "            self.car.velocity = Vector(6, 0).rotate(self.car.angle) # it goes to a normal speed (speed = 6)\n",
      "            last_reward = -0.2 # and it gets bad reward (-0.2)\n",
      "            if distance < last_distance: # however if it getting close to the goal\n",
      "                last_reward = 0.1 # it still gets slightly positive reward 0.1\n",
      "\n",
      "        if self.car.x < 10: # if the car is in the left edge of the frame\n",
      "            self.car.x = 10 # it is not slowed down\n",
      "            last_reward = -1 # but it gets bad reward -1\n",
      "        if self.car.x > self.width-10: # if the car is in the right edge of the frame\n",
      "            self.car.x = self.width-10 # it is not slowed down\n",
      "            last_reward = -1 # but it gets bad reward -1\n",
      "        if self.car.y < 10: # if the car is in the bottom edge of the frame\n",
      "            self.car.y = 10 # it is not slowed down\n",
      "            last_reward = -1 # but it gets bad reward -1\n",
      "        if self.car.y > self.height-10: # if the car is in the upper edge of the frame\n",
      "            self.car.y = self.height-10 # it is not slowed down\n",
      "            last_reward = -1 # but it gets bad reward -1\n",
      "\n",
      "        if distance < 100: # when the car reaches its goal\n",
      "            goal_x = self.width - goal_x # the goal becomes the bottom right corner of the map (the downtown), and vice versa (updating of the x-coordinate of the goal)\n",
      "            goal_y = self.height - goal_y # the goal becomes the bottom right corner of the map (the downtown), and vice versa (updating of the y-coordinate of the goal)\n",
      "\n",
      "        # Updating the last distance from the car to the goal\n",
      "        last_distance = distance\n",
      "\n",
      "# Painting for graphic interface (see kivy tutorials: https://kivy.org/docs/tutorials/firstwidget.html)\n",
      "\n",
      "class MyPaintWidget(Widget):\n",
      "\n",
      "    def on_touch_down(self, touch): # putting some sand when we do a left click\n",
      "        global length,n_points,last_x,last_y\n",
      "        with self.canvas:\n",
      "            Color(0.8,0.7,0)\n",
      "            d=10.\n",
      "            touch.ud['line'] = Line(points = (touch.x, touch.y), width = 10)\n",
      "            last_x = int(touch.x)\n",
      "            last_y = int(touch.y)\n",
      "            n_points = 0\n",
      "            length = 0\n",
      "            sand[int(touch.x),int(touch.y)] = 1\n",
      "\n",
      "    def on_touch_move(self, touch): # putting some sand when we move the mouse while pressing left\n",
      "        global length,n_points,last_x,last_y\n",
      "        if touch.button=='left':\n",
      "            touch.ud['line'].points += [touch.x, touch.y]\n",
      "            x = int(touch.x)\n",
      "            y = int(touch.y)\n",
      "            length += np.sqrt(max((x - last_x)**2 + (y - last_y)**2, 2))\n",
      "            n_points += 1.\n",
      "            density = n_points/(length)\n",
      "            touch.ud['line'].width = int(20*density + 1)\n",
      "            sand[int(touch.x) - 10 : int(touch.x) + 10, int(touch.y) - 10 : int(touch.y) + 10] = 1\n",
      "            last_x = x\n",
      "            last_y = y\n",
      "\n",
      "# API and switches interface (see kivy tutorials: https://kivy.org/docs/tutorials/pong.html)\n",
      "\n",
      "class CarApp(App):\n",
      "\n",
      "    def build(self): # building the app\n",
      "        parent = Game()\n",
      "        parent.serve_car()\n",
      "        Clock.schedule_interval(parent.update, 1.0 / 60.0)\n",
      "        self.painter = MyPaintWidget()\n",
      "        clearbtn = Button(text='clear')\n",
      "        savebtn = Button(text='save',pos=(parent.width,0))\n",
      "        loadbtn = Button(text='load',pos=(2*parent.width,0))\n",
      "        clearbtn.bind(on_release=self.clear_canvas)\n",
      "        savebtn.bind(on_release=self.save)\n",
      "        loadbtn.bind(on_release=self.load)\n",
      "        parent.add_widget(self.painter)\n",
      "        parent.add_widget(clearbtn)\n",
      "        parent.add_widget(savebtn)\n",
      "        parent.add_widget(loadbtn)\n",
      "        return parent\n",
      "\n",
      "    def clear_canvas(self, obj): # clear button\n",
      "        global sand\n",
      "        self.painter.canvas.clear()\n",
      "        sand = np.zeros((longueur,largeur))\n",
      "\n",
      "    def save(self, obj): # save button\n",
      "        print(\"saving brain...\")\n",
      "        brain.save()\n",
      "        plt.plot(scores)\n",
      "        plt.show()\n",
      "\n",
      "    def load(self, obj): # load button\n",
      "        print(\"loading last saved brain...\")\n",
      "        brain.load()\n",
      "\n",
      "# Running the app\n",
      "if __name__ == '__main__':\n",
      "    CarApp().run()\n",
      "\n",
      "Output: {'map_commented': ['ai.Dqn.__init__', 'kivy.app.App.__init__', 'kivy.config.Config.set', 'kivy.app.App.run'], 'kivy.config.Config.set': [], 'ai.Dqn.__init__': ['torch.nn.Module.parameters', 'ai.ReplayMemory.__init__', 'torch.optim.Adam', 'torch.Tensor', 'ai.Network.__init__'], 'map_commented.init': ['numpy.zeros'], 'numpy.zeros': [], 'kivy.properties.NumericProperty': [], 'map_commented.Car': ['kivy.properties.NumericProperty', 'kivy.properties.ReferenceListProperty'], 'kivy.properties.ReferenceListProperty': [], 'map_commented.Car.move': ['kivy.vector.Vector', '<builtin>.int', 'numpy.sum'], 'kivy.vector.Vector': [], '<builtin>.int': [], 'numpy.sum': [], 'kivy.properties.ObjectProperty': [], 'map_commented.Game': ['kivy.properties.ObjectProperty'], 'map_commented.Game.serve_car': ['kivy.vector.Vector'], 'map_commented.Game.update': ['kivy.vector.Vector', 'numpy.sqrt', 'ai.Dqn.update', 'ai.Dqn.score', '<builtin>.int', 'map_commented.init'], 'ai.Dqn.update': ['ai.Dqn.learn', 'torch.LongTensor', '<builtin>.len', 'ai.ReplayMemory.sample', 'torch.Tensor', '<builtin>.int', 'ai.ReplayMemory.push', 'ai.Dqn.select_action'], 'ai.Dqn.score': ['<builtin>.sum', '<builtin>.len'], 'numpy.sqrt': [], 'map_commented.MyPaintWidget.on_touch_down': ['kivy.graphics.Line', '<builtin>.int', 'kivy.graphics.Color'], 'kivy.graphics.Color': [], 'kivy.graphics.Line': [], 'map_commented.MyPaintWidget.on_touch_move': ['numpy.sqrt', '<builtin>.int', '<builtin>.max'], '<builtin>.max': [], 'map_commented.CarApp.build': ['kivy.uix.button.Button', 'kivy.uix.widget.Widget.__init__', 'kivy.uix.widget.Widget.add_widget', 'map_commented.Game.serve_car', 'kivy.clock.Clock.schedule_interval'], 'kivy.uix.widget.Widget.__init__': [], 'kivy.clock.Clock.schedule_interval': [], 'kivy.uix.button.Button': [], 'kivy.uix.widget.Widget.add_widget': [], 'map_commented.CarApp.clear_canvas': ['numpy.zeros', 'kivy.uix.widget.Widget.canvas.clear'], 'kivy.uix.widget.Widget.canvas.clear': [], 'map_commented.CarApp.save': ['matplotlib.pyplot.plot', '<builtin>.print', 'matplotlib.pyplot.show', 'ai.Dqn.save'], '<builtin>.print': [], 'ai.Dqn.save': ['torch.save', 'torch.nn.Module.state_dict'], 'matplotlib.pyplot.plot': [], 'matplotlib.pyplot.show': [], 'map_commented.CarApp.load': ['<builtin>.print', 'ai.Dqn.load'], 'ai.Dqn.load': ['torch.load', '<builtin>.print', 'torch.nn.Module.load_state_dict', 'os.path.isfile'], 'kivy.app.App.__init__': [], 'kivy.app.App.run': [], 'ai': [], 'ai.Network.__init__': ['torch.nn.Linear', '<builtin>.super'], '<builtin>.super': [], 'torch.nn.Linear': [], 'ai.Network.forward': ['torch.nn.functional.relu'], 'torch.nn.functional.relu': [], 'ai.ReplayMemory.__init__': [], 'ai.ReplayMemory.push': ['<builtin>.len'], '<builtin>.len': [], 'ai.ReplayMemory.sample': ['<builtin>.map', '<builtin>.zip', 'random.sample'], 'random.sample': [], '<builtin>.zip': [], 'ai.ReplayMemory.sample.<lambda1>': ['torch.autograd.Variable', 'torch.cat'], 'torch.cat': [], 'torch.autograd.Variable': [], '<builtin>.map': [], 'torch.nn.Module.parameters': [], 'torch.optim.Adam': [], 'torch.Tensor': [], 'ai.Dqn.select_action': ['torch.autograd.Variable', 'torch.nn.functional.softmax', 'ai.Network.__init__'], 'torch.nn.functional.softmax': [], 'ai.Dqn.learn': ['torch.nn.functional.smooth_l1_loss', 'torch.nn.Module.gather', 'torch.nn.Module.detach', 'ai.Network.__init__'], 'torch.nn.Module.gather': [], 'torch.nn.Module.detach': [], 'torch.nn.functional.smooth_l1_loss': [], 'torch.LongTensor': [], '<builtin>.sum': [], 'torch.nn.Module.state_dict': [], 'torch.save': [], 'os.path.isfile': [], 'torch.load': [], 'torch.nn.Module.load_state_dict': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\FLHonker_Self-Driving-Car-RL\\map_commented.py\n",
      "[('map_commented', 'ai Dqn __init__'), ('map_commented', 'kivy app App __init__'), ('map_commented', 'kivy config Config set'), ('map_commented', 'kivy app App run'), ('ai Dqn __init__', 'torch nn Module parameters'), ('ai Dqn __init__', 'ai ReplayMemory __init__'), ('ai Dqn __init__', 'torch optim Adam'), ('ai Dqn __init__', 'torch Tensor'), ('ai Dqn __init__', 'ai Network __init__'), ('map_commented init', 'numpy zeros'), ('map_commented Car', 'kivy properties NumericProperty'), ('map_commented Car', 'kivy properties ReferenceListProperty'), ('map_commented Car move', 'kivy vector Vector'), ('map_commented Car move', 'numpy sum'), ('map_commented Game', 'kivy properties ObjectProperty'), ('map_commented Game serve_car', 'kivy vector Vector'), ('map_commented Game update', 'kivy vector Vector'), ('map_commented Game update', 'numpy sqrt'), ('map_commented Game update', 'ai Dqn update'), ('map_commented Game update', 'ai Dqn score'), ('map_commented Game update', 'map_commented init'), ('ai Dqn update', 'ai Dqn learn'), ('ai Dqn update', 'torch LongTensor'), ('ai Dqn update', 'ai ReplayMemory sample'), ('ai Dqn update', 'torch Tensor'), ('ai Dqn update', 'ai ReplayMemory push'), ('ai Dqn update', 'ai Dqn select_action'), ('map_commented MyPaintWidget on_touch_down', 'kivy graphics Line'), ('map_commented MyPaintWidget on_touch_down', 'kivy graphics Color'), ('map_commented MyPaintWidget on_touch_move', 'numpy sqrt')]\n",
      "0\n",
      "found files: []\n",
      "# AI for Self Driving Car\n",
      "\n",
      "# Importing the libraries\n",
      "\n",
      "import numpy as np\n",
      "import random\n",
      "import os\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "import torch.optim as optim\n",
      "import torch.autograd as autograd\n",
      "from torch.autograd import Variable\n",
      "\n",
      "# Creating the architecture of the Neural Network\n",
      "\n",
      "class Network(nn.Module):\n",
      "    \n",
      "    def __init__(self, input_size, nb_action):\n",
      "        super(Network, self).__init__()\n",
      "        self.input_size = input_size\n",
      "        self.nb_action = nb_action\n",
      "        self.fc1 = nn.Linear(input_size, 30)\n",
      "        self.fc2 = nn.Linear(30, nb_action)\n",
      "    \n",
      "    def forward(self, state):\n",
      "        x = F.relu(self.fc1(state))\n",
      "        q_values = self.fc2(x)\n",
      "        return q_values\n",
      "\n",
      "# Implementing Experience Replay\n",
      "\n",
      "class ReplayMemory(object):\n",
      "    \n",
      "    def __init__(self, capacity):\n",
      "        self.capacity = capacity\n",
      "        self.memory = []\n",
      "    \n",
      "    def push(self, event):\n",
      "        self.memory.append(event)\n",
      "        if len(self.memory) > self.capacity:\n",
      "            del self.memory[0]\n",
      "    \n",
      "    def sample(self, batch_size):\n",
      "        samples = zip(*random.sample(self.memory, batch_size))\n",
      "        return map(lambda x: Variable(torch.cat(x, 0)), samples)\n",
      "\n",
      "# Implementing Deep Q Learning\n",
      "\n",
      "class Dqn():\n",
      "    \n",
      "    def __init__(self, input_size, nb_action, gamma):\n",
      "        self.gamma = gamma\n",
      "        self.reward_window = []\n",
      "        self.model = Network(input_size, nb_action)\n",
      "        self.memory = ReplayMemory(100000)\n",
      "        self.optimizer = optim.Adam(self.model.parameters(), lr = 0.001)\n",
      "        self.last_state = torch.Tensor(input_size).unsqueeze(0)\n",
      "        self.last_action = 0\n",
      "        self.last_reward = 0\n",
      "    \n",
      "    def select_action(self, state):\n",
      "        probs = F.softmax(self.model(Variable(state, volatile = True))*100) # T=100\n",
      "        action = probs.multinomial(1)\n",
      "        return action.data[0,0]\n",
      "    \n",
      "    def learn(self, batch_state, batch_next_state, batch_reward, batch_action):\n",
      "        outputs = self.model(batch_state).gather(1, batch_action.unsqueeze(1)).squeeze(1)\n",
      "        next_outputs = self.model(batch_next_state).detach().max(1)[0]\n",
      "        target = self.gamma*next_outputs + batch_reward\n",
      "        td_loss = F.smooth_l1_loss(outputs, target)\n",
      "        self.optimizer.zero_grad()\n",
      "        td_loss.backward()  # retain_variables = True\n",
      "        self.optimizer.step()\n",
      "    \n",
      "    def update(self, reward, new_signal):\n",
      "        new_state = torch.Tensor(new_signal).float().unsqueeze(0)\n",
      "        self.memory.push((self.last_state, new_state, torch.LongTensor([int(self.last_action)]), torch.Tensor([self.last_reward])))\n",
      "        action = self.select_action(new_state)\n",
      "        if len(self.memory.memory) > 100:\n",
      "            batch_state, batch_next_state, batch_action, batch_reward = self.memory.sample(100)\n",
      "            self.learn(batch_state, batch_next_state, batch_reward, batch_action)\n",
      "        self.last_action = action\n",
      "        self.last_state = new_state\n",
      "        self.last_reward = reward\n",
      "        self.reward_window.append(reward)\n",
      "        if len(self.reward_window) > 1000:\n",
      "            del self.reward_window[0]\n",
      "        return action\n",
      "    \n",
      "    def score(self):\n",
      "        return sum(self.reward_window)/(len(self.reward_window)+1.)\n",
      "    \n",
      "    def save(self):\n",
      "        torch.save({'state_dict': self.model.state_dict(),\n",
      "                    'optimizer' : self.optimizer.state_dict(),\n",
      "                   }, 'last_brain.pth')\n",
      "    \n",
      "    def load(self):\n",
      "        if os.path.isfile('last_brain.pth'):\n",
      "            print(\"=> loading checkpoint... \")\n",
      "            checkpoint = torch.load('last_brain.pth')\n",
      "            self.model.load_state_dict(checkpoint['state_dict'])\n",
      "            self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
      "            print(\"done !\")\n",
      "        else:\n",
      "            print(\"no checkpoint found...\")\n",
      "Output: {'ai': [], 'ai.Network.__init__': ['<builtin>.super', 'torch.nn.Linear'], '<builtin>.super': [], 'torch.nn.Linear': [], 'ai.Network.forward': ['torch.nn.functional.relu'], 'torch.nn.functional.relu': [], 'ai.ReplayMemory.__init__': [], 'ai.ReplayMemory.push': ['<builtin>.len'], '<builtin>.len': [], 'ai.ReplayMemory.sample': ['<builtin>.zip', 'random.sample', '<builtin>.map'], 'random.sample': [], '<builtin>.zip': [], 'ai.ReplayMemory.sample.<lambda1>': ['torch.cat', 'torch.autograd.Variable'], 'torch.cat': [], 'torch.autograd.Variable': [], '<builtin>.map': [], 'ai.Dqn.__init__': ['ai.Network.__init__', 'torch.Tensor', 'ai.ReplayMemory.__init__', 'torch.nn.Module.parameters', 'torch.optim.Adam'], 'torch.nn.Module.parameters': [], 'torch.optim.Adam': [], 'torch.Tensor': [], 'ai.Dqn.select_action': ['ai.Network.__init__', 'torch.autograd.Variable', 'torch.nn.functional.softmax'], 'torch.nn.functional.softmax': [], 'ai.Dqn.learn': ['torch.nn.functional.smooth_l1_loss', 'torch.nn.Module.detach', 'ai.Network.__init__', 'torch.nn.Module.gather'], 'torch.nn.Module.gather': [], 'torch.nn.Module.detach': [], 'torch.nn.functional.smooth_l1_loss': [], 'ai.Dqn.update': ['ai.Dqn.select_action', 'ai.ReplayMemory.push', 'ai.Dqn.learn', 'torch.Tensor', '<builtin>.len', 'ai.ReplayMemory.sample', 'torch.LongTensor', '<builtin>.int'], '<builtin>.int': [], 'torch.LongTensor': [], 'ai.Dqn.score': ['<builtin>.sum', '<builtin>.len'], '<builtin>.sum': [], 'ai.Dqn.save': ['torch.save', 'torch.nn.Module.state_dict'], 'torch.nn.Module.state_dict': [], 'torch.save': [], 'ai.Dqn.load': ['torch.nn.Module.load_state_dict', 'os.path.isfile', 'torch.load', '<builtin>.print'], 'os.path.isfile': [], '<builtin>.print': [], 'torch.load': [], 'torch.nn.Module.load_state_dict': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\FLHonker_Self-Driving-Car-RL\\ai.py\n",
      "[('ai Network __init__', 'torch nn Linear'), ('ai Network forward', 'torch nn functional relu'), ('ai ReplayMemory sample', 'random sample'), ('ai ReplayMemory sample <lambda1>', 'torch cat'), ('ai ReplayMemory sample <lambda1>', 'torch autograd Variable'), ('ai Dqn __init__', 'ai Network __init__'), ('ai Dqn __init__', 'torch Tensor'), ('ai Dqn __init__', 'ai ReplayMemory __init__'), ('ai Dqn __init__', 'torch nn Module parameters'), ('ai Dqn __init__', 'torch optim Adam'), ('ai Dqn select_action', 'ai Network __init__'), ('ai Dqn select_action', 'torch autograd Variable'), ('ai Dqn select_action', 'torch nn functional softmax'), ('ai Dqn learn', 'torch nn functional smooth_l1_loss'), ('ai Dqn learn', 'torch nn Module detach'), ('ai Dqn learn', 'ai Network __init__'), ('ai Dqn learn', 'torch nn Module gather'), ('ai Dqn update', 'ai Dqn select_action'), ('ai Dqn update', 'ai ReplayMemory push'), ('ai Dqn update', 'ai Dqn learn'), ('ai Dqn update', 'torch Tensor'), ('ai Dqn update', 'ai ReplayMemory sample'), ('ai Dqn update', 'torch LongTensor'), ('ai Dqn save', 'torch save'), ('ai Dqn save', 'torch nn Module state_dict'), ('ai Dqn load', 'torch nn Module load_state_dict'), ('ai Dqn load', 'os path isfile'), ('ai Dqn load', 'torch load')]\n",
      "0\n",
      "found files: []\n",
      "# Self Driving Car\n",
      "\n",
      "# Importing the libraries\n",
      "import numpy as np\n",
      "from random import random, randint\n",
      "import matplotlib.pyplot as plt\n",
      "import time\n",
      "\n",
      "# Importing the Kivy packages\n",
      "from kivy.app import App\n",
      "from kivy.uix.widget import Widget\n",
      "from kivy.uix.button import Button\n",
      "from kivy.graphics import Color, Ellipse, Line\n",
      "from kivy.config import Config\n",
      "from kivy.properties import NumericProperty, ReferenceListProperty, ObjectProperty\n",
      "from kivy.vector import Vector\n",
      "from kivy.clock import Clock\n",
      "\n",
      "# Importing the Dqn object from our AI in ai.py\n",
      "from ai import Dqn\n",
      "\n",
      "# Adding this line if we don't want the right click to put a red point\n",
      "Config.set('input', 'mouse', 'mouse,multitouch_on_demand')\n",
      "\n",
      "# Introducing last_x and last_y, used to keep the last point in memory when we draw the sand on the map\n",
      "last_x = 0\n",
      "last_y = 0\n",
      "n_points = 0\n",
      "length = 0\n",
      "\n",
      "# Getting our AI, which we call \"brain\", and that contains our neural network that represents our Q-function\n",
      "brain = Dqn(5,3,0.9)\n",
      "action2rotation = [0,20,-20]\n",
      "last_reward = 0\n",
      "scores = []\n",
      "\n",
      "# Initializing the map\n",
      "first_update = True\n",
      "def init():\n",
      "    global sand\n",
      "    global goal_x\n",
      "    global goal_y\n",
      "    global first_update\n",
      "    sand = np.zeros((longueur,largeur))\n",
      "    goal_x = 20\n",
      "    goal_y = largeur - 20\n",
      "    first_update = False\n",
      "\n",
      "# Initializing the last distance\n",
      "last_distance = 0\n",
      "\n",
      "# Creating the car class\n",
      "\n",
      "class Car(Widget):\n",
      "    \n",
      "    angle = NumericProperty(0)\n",
      "    rotation = NumericProperty(0)\n",
      "    velocity_x = NumericProperty(0)\n",
      "    velocity_y = NumericProperty(0)\n",
      "    velocity = ReferenceListProperty(velocity_x, velocity_y)\n",
      "    sensor1_x = NumericProperty(0)\n",
      "    sensor1_y = NumericProperty(0)\n",
      "    sensor1 = ReferenceListProperty(sensor1_x, sensor1_y)\n",
      "    sensor2_x = NumericProperty(0)\n",
      "    sensor2_y = NumericProperty(0)\n",
      "    sensor2 = ReferenceListProperty(sensor2_x, sensor2_y)\n",
      "    sensor3_x = NumericProperty(0)\n",
      "    sensor3_y = NumericProperty(0)\n",
      "    sensor3 = ReferenceListProperty(sensor3_x, sensor3_y)\n",
      "    signal1 = NumericProperty(0)\n",
      "    signal2 = NumericProperty(0)\n",
      "    signal3 = NumericProperty(0)\n",
      "\n",
      "    def move(self, rotation):\n",
      "        self.pos = Vector(*self.velocity) + self.pos\n",
      "        self.rotation = rotation\n",
      "        self.angle = self.angle + self.rotation\n",
      "        self.sensor1 = Vector(30, 0).rotate(self.angle) + self.pos\n",
      "        self.sensor2 = Vector(30, 0).rotate((self.angle+30)%360) + self.pos\n",
      "        self.sensor3 = Vector(30, 0).rotate((self.angle-30)%360) + self.pos\n",
      "        self.signal1 = int(np.sum(sand[int(self.sensor1_x)-10:int(self.sensor1_x)+10, int(self.sensor1_y)-10:int(self.sensor1_y)+10]))/400.\n",
      "        self.signal2 = int(np.sum(sand[int(self.sensor2_x)-10:int(self.sensor2_x)+10, int(self.sensor2_y)-10:int(self.sensor2_y)+10]))/400.\n",
      "        self.signal3 = int(np.sum(sand[int(self.sensor3_x)-10:int(self.sensor3_x)+10, int(self.sensor3_y)-10:int(self.sensor3_y)+10]))/400.\n",
      "        if self.sensor1_x>longueur-10 or self.sensor1_x<10 or self.sensor1_y>largeur-10 or self.sensor1_y<10:\n",
      "            self.signal1 = 1.\n",
      "        if self.sensor2_x>longueur-10 or self.sensor2_x<10 or self.sensor2_y>largeur-10 or self.sensor2_y<10:\n",
      "            self.signal2 = 1.\n",
      "        if self.sensor3_x>longueur-10 or self.sensor3_x<10 or self.sensor3_y>largeur-10 or self.sensor3_y<10:\n",
      "            self.signal3 = 1.\n",
      "\n",
      "class Ball1(Widget):\n",
      "    pass\n",
      "class Ball2(Widget):\n",
      "    pass\n",
      "class Ball3(Widget):\n",
      "    pass\n",
      "\n",
      "# Creating the game class\n",
      "\n",
      "class Game(Widget):\n",
      "\n",
      "    car = ObjectProperty(None)\n",
      "    ball1 = ObjectProperty(None)\n",
      "    ball2 = ObjectProperty(None)\n",
      "    ball3 = ObjectProperty(None)\n",
      "\n",
      "    def serve_car(self):\n",
      "        self.car.center = self.center\n",
      "        self.car.velocity = Vector(6, 0)\n",
      "\n",
      "    def update(self, dt):\n",
      "\n",
      "        global brain\n",
      "        global last_reward\n",
      "        global scores\n",
      "        global last_distance\n",
      "        global goal_x\n",
      "        global goal_y\n",
      "        global longueur\n",
      "        global largeur\n",
      "\n",
      "        longueur = self.width\n",
      "        largeur = self.height\n",
      "        if first_update:\n",
      "            init()\n",
      "\n",
      "        xx = goal_x - self.car.x\n",
      "        yy = goal_y - self.car.y\n",
      "        orientation = Vector(*self.car.velocity).angle((xx,yy))/180.\n",
      "        last_signal = [self.car.signal1, self.car.signal2, self.car.signal3, orientation, -orientation]\n",
      "        action = brain.update(last_reward, last_signal)\n",
      "        scores.append(brain.score())\n",
      "        rotation = action2rotation[action]\n",
      "        self.car.move(rotation)\n",
      "        distance = np.sqrt((self.car.x - goal_x)**2 + (self.car.y - goal_y)**2)\n",
      "        self.ball1.pos = self.car.sensor1\n",
      "        self.ball2.pos = self.car.sensor2\n",
      "        self.ball3.pos = self.car.sensor3\n",
      "\n",
      "        if sand[int(self.car.x),int(self.car.y)] > 0:\n",
      "            self.car.velocity = Vector(1, 0).rotate(self.car.angle)\n",
      "            last_reward = -1\n",
      "        else: # otherwise\n",
      "            self.car.velocity = Vector(6, 0).rotate(self.car.angle)\n",
      "            last_reward = -0.2\n",
      "            if distance < last_distance:\n",
      "                last_reward = 0.1\n",
      "\n",
      "        if self.car.x < 10:\n",
      "            self.car.x = 10\n",
      "            last_reward = -1\n",
      "        if self.car.x > self.width - 10:\n",
      "            self.car.x = self.width - 10\n",
      "            last_reward = -1\n",
      "        if self.car.y < 10:\n",
      "            self.car.y = 10\n",
      "            last_reward = -1\n",
      "        if self.car.y > self.height - 10:\n",
      "            self.car.y = self.height - 10\n",
      "            last_reward = -1\n",
      "\n",
      "        if distance < 100:\n",
      "            goal_x = self.width-goal_x\n",
      "            goal_y = self.height-goal_y\n",
      "        last_distance = distance\n",
      "\n",
      "# Adding the painting tools\n",
      "\n",
      "class MyPaintWidget(Widget):\n",
      "\n",
      "    def on_touch_down(self, touch):\n",
      "        global length, n_points, last_x, last_y\n",
      "        with self.canvas:\n",
      "            Color(0.8,0.7,0)\n",
      "            d = 10.\n",
      "            touch.ud['line'] = Line(points = (touch.x, touch.y), width = 10)\n",
      "            last_x = int(touch.x)\n",
      "            last_y = int(touch.y)\n",
      "            n_points = 0\n",
      "            length = 0\n",
      "            sand[int(touch.x),int(touch.y)] = 1\n",
      "\n",
      "    def on_touch_move(self, touch):\n",
      "        global length, n_points, last_x, last_y\n",
      "        if touch.button == 'left':\n",
      "            touch.ud['line'].points += [touch.x, touch.y]\n",
      "            x = int(touch.x)\n",
      "            y = int(touch.y)\n",
      "            length += np.sqrt(max((x - last_x)**2 + (y - last_y)**2, 2))\n",
      "            n_points += 1.\n",
      "            density = n_points/(length)\n",
      "            touch.ud['line'].width = int(20 * density + 1)\n",
      "            sand[int(touch.x) - 10 : int(touch.x) + 10, int(touch.y) - 10 : int(touch.y) + 10] = 1\n",
      "            last_x = x\n",
      "            last_y = y\n",
      "\n",
      "# Adding the API Buttons (clear, save and load)\n",
      "\n",
      "class CarApp(App):\n",
      "\n",
      "    def build(self):\n",
      "        parent = Game()\n",
      "        parent.serve_car()\n",
      "        Clock.schedule_interval(parent.update, 1.0/60.0)\n",
      "        self.painter = MyPaintWidget()\n",
      "        clearbtn = Button(text = 'clear')\n",
      "        savebtn = Button(text = 'save', pos = (parent.width, 0))\n",
      "        loadbtn = Button(text = 'load', pos = (2 * parent.width, 0))\n",
      "        clearbtn.bind(on_release = self.clear_canvas)\n",
      "        savebtn.bind(on_release = self.save)\n",
      "        loadbtn.bind(on_release = self.load)\n",
      "        parent.add_widget(self.painter)\n",
      "        parent.add_widget(clearbtn)\n",
      "        parent.add_widget(savebtn)\n",
      "        parent.add_widget(loadbtn)\n",
      "        return parent\n",
      "\n",
      "    def clear_canvas(self, obj):\n",
      "        global sand\n",
      "        self.painter.canvas.clear()\n",
      "        sand = np.zeros((longueur,largeur))\n",
      "\n",
      "    def save(self, obj):\n",
      "        print(\"saving brain...\")\n",
      "        brain.save()\n",
      "        plt.plot(scores)\n",
      "        plt.show()\n",
      "\n",
      "    def load(self, obj):\n",
      "        print(\"loading last saved brain...\")\n",
      "        brain.load()\n",
      "\n",
      "# Running the whole thing\n",
      "if __name__ == '__main__':\n",
      "    CarApp().run()\n",
      "\n",
      "Output: {'map': ['ai.Dqn.__init__', 'kivy.app.App.__init__', 'kivy.app.App.run', 'kivy.config.Config.set'], 'kivy.config.Config.set': [], 'ai.Dqn.__init__': ['ai.Network.__init__', 'ai.ReplayMemory.__init__', 'torch.nn.Module.parameters', 'torch.Tensor', 'torch.optim.Adam'], 'map.init': ['numpy.zeros'], 'numpy.zeros': [], 'kivy.properties.NumericProperty': [], 'map.Car': ['kivy.properties.ReferenceListProperty', 'kivy.properties.NumericProperty'], 'kivy.properties.ReferenceListProperty': [], 'map.Car.move': ['numpy.sum', '<builtin>.int', 'kivy.vector.Vector'], 'kivy.vector.Vector': [], '<builtin>.int': [], 'numpy.sum': [], 'kivy.properties.ObjectProperty': [], 'map.Game': ['kivy.properties.ObjectProperty'], 'map.Game.serve_car': ['kivy.vector.Vector'], 'map.Game.update': ['ai.Dqn.score', '<builtin>.int', 'ai.Dqn.update', 'kivy.vector.Vector', 'map.init', 'numpy.sqrt'], 'ai.Dqn.update': ['ai.ReplayMemory.push', 'ai.Dqn.learn', '<builtin>.int', 'torch.LongTensor', 'torch.Tensor', 'ai.Dqn.select_action', 'ai.ReplayMemory.sample', '<builtin>.len'], 'ai.Dqn.score': ['<builtin>.sum', '<builtin>.len'], 'numpy.sqrt': [], 'map.MyPaintWidget.on_touch_down': ['kivy.graphics.Line', '<builtin>.int', 'kivy.graphics.Color'], 'kivy.graphics.Color': [], 'kivy.graphics.Line': [], 'map.MyPaintWidget.on_touch_move': ['numpy.sqrt', '<builtin>.max', '<builtin>.int'], '<builtin>.max': [], 'map.CarApp.build': ['kivy.uix.button.Button', 'kivy.clock.Clock.schedule_interval', 'kivy.uix.widget.Widget.add_widget', 'map.Game.serve_car', 'kivy.uix.widget.Widget.__init__'], 'kivy.uix.widget.Widget.__init__': [], 'kivy.clock.Clock.schedule_interval': [], 'kivy.uix.button.Button': [], 'kivy.uix.widget.Widget.add_widget': [], 'map.CarApp.clear_canvas': ['numpy.zeros', 'kivy.uix.widget.Widget.canvas.clear'], 'kivy.uix.widget.Widget.canvas.clear': [], 'map.CarApp.save': ['ai.Dqn.save', 'matplotlib.pyplot.show', 'matplotlib.pyplot.plot', '<builtin>.print'], '<builtin>.print': [], 'ai.Dqn.save': ['torch.save', 'torch.nn.Module.state_dict'], 'matplotlib.pyplot.plot': [], 'matplotlib.pyplot.show': [], 'map.CarApp.load': ['<builtin>.print', 'ai.Dqn.load'], 'ai.Dqn.load': ['<builtin>.print', 'torch.load', 'os.path.isfile', 'torch.nn.Module.load_state_dict'], 'kivy.app.App.__init__': [], 'kivy.app.App.run': [], 'ai': [], 'ai.Network.__init__': ['<builtin>.super', 'torch.nn.Linear'], '<builtin>.super': [], 'torch.nn.Linear': [], 'ai.Network.forward': ['torch.nn.functional.relu'], 'torch.nn.functional.relu': [], 'ai.ReplayMemory.__init__': [], 'ai.ReplayMemory.push': ['<builtin>.len'], '<builtin>.len': [], 'ai.ReplayMemory.sample': ['random.sample', '<builtin>.map', '<builtin>.zip'], 'random.sample': [], '<builtin>.zip': [], 'ai.ReplayMemory.sample.<lambda1>': ['torch.autograd.Variable', 'torch.cat'], 'torch.cat': [], 'torch.autograd.Variable': [], '<builtin>.map': [], 'torch.nn.Module.parameters': [], 'torch.optim.Adam': [], 'torch.Tensor': [], 'ai.Dqn.select_action': ['ai.Network.__init__', 'torch.nn.functional.softmax', 'torch.autograd.Variable'], 'torch.nn.functional.softmax': [], 'ai.Dqn.learn': ['torch.nn.Module.detach', 'ai.Network.__init__', 'torch.nn.functional.smooth_l1_loss', 'torch.nn.Module.gather'], 'torch.nn.Module.gather': [], 'torch.nn.Module.detach': [], 'torch.nn.functional.smooth_l1_loss': [], 'torch.LongTensor': [], '<builtin>.sum': [], 'torch.nn.Module.state_dict': [], 'torch.save': [], 'os.path.isfile': [], 'torch.load': [], 'torch.nn.Module.load_state_dict': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\FLHonker_Self-Driving-Car-RL\\map.py\n",
      "[('map', 'ai Dqn __init__'), ('map', 'kivy app App __init__'), ('map', 'kivy app App run'), ('map', 'kivy config Config set'), ('ai Dqn __init__', 'ai Network __init__'), ('ai Dqn __init__', 'ai ReplayMemory __init__'), ('ai Dqn __init__', 'torch nn Module parameters'), ('ai Dqn __init__', 'torch Tensor'), ('ai Dqn __init__', 'torch optim Adam'), ('map init', 'numpy zeros'), ('map Car', 'kivy properties ReferenceListProperty'), ('map Car', 'kivy properties NumericProperty'), ('map Car move', 'numpy sum'), ('map Car move', 'kivy vector Vector'), ('map Game', 'kivy properties ObjectProperty'), ('map Game serve_car', 'kivy vector Vector'), ('map Game update', 'ai Dqn score'), ('map Game update', 'ai Dqn update'), ('map Game update', 'kivy vector Vector'), ('map Game update', 'map init'), ('map Game update', 'numpy sqrt'), ('ai Dqn update', 'ai ReplayMemory push'), ('ai Dqn update', 'ai Dqn learn'), ('ai Dqn update', 'torch LongTensor'), ('ai Dqn update', 'torch Tensor'), ('ai Dqn update', 'ai Dqn select_action'), ('ai Dqn update', 'ai ReplayMemory sample'), ('map MyPaintWidget on_touch_down', 'kivy graphics Line'), ('map MyPaintWidget on_touch_down', 'kivy graphics Color'), ('map MyPaintWidget on_touch_move', 'numpy sqrt')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('map_commented', 'ai Dqn __init__'), ('map_commented', 'kivy app App __init__'), ('map_commented', 'kivy config Config set'), ('map_commented', 'kivy app App run'), ('ai Dqn __init__', 'torch nn Module parameters'), ('ai Dqn __init__', 'ai ReplayMemory __init__'), ('ai Dqn __init__', 'torch optim Adam'), ('ai Dqn __init__', 'torch Tensor'), ('ai Dqn __init__', 'ai Network __init__'), ('map_commented init', 'numpy zeros'), ('map_commented Car', 'kivy properties NumericProperty'), ('map_commented Car', 'kivy properties ReferenceListProperty'), ('map_commented Car move', 'kivy vector Vector'), ('map_commented Car move', 'numpy sum'), ('map_commented Game', 'kivy properties ObjectProperty'), ('map_commented Game serve_car', 'kivy vector Vector'), ('map_commented Game update', 'kivy vector Vector'), ('map_commented Game update', 'numpy sqrt'), ('map_commented Game update', 'ai Dqn update'), ('map_commented Game update', 'ai Dqn score'), ('map_commented Game update', 'map_commented init'), ('ai Dqn update', 'ai Dqn learn'), ('ai Dqn update', 'torch LongTensor'), ('ai Dqn update', 'ai ReplayMemory sample'), ('ai Dqn update', 'torch Tensor'), ('ai Dqn update', 'ai ReplayMemory push'), ('ai Dqn update', 'ai Dqn select_action'), ('map_commented MyPaintWidget on_touch_down', 'kivy graphics Line'), ('map_commented MyPaintWidget on_touch_down', 'kivy graphics Color'), ('map_commented MyPaintWidget on_touch_move', 'numpy sqrt')], [('ai Network __init__', 'torch nn Linear'), ('ai Network forward', 'torch nn functional relu'), ('ai ReplayMemory sample', 'random sample'), ('ai ReplayMemory sample <lambda1>', 'torch cat'), ('ai ReplayMemory sample <lambda1>', 'torch autograd Variable'), ('ai Dqn __init__', 'ai Network __init__'), ('ai Dqn __init__', 'torch Tensor'), ('ai Dqn __init__', 'ai ReplayMemory __init__'), ('ai Dqn __init__', 'torch nn Module parameters'), ('ai Dqn __init__', 'torch optim Adam'), ('ai Dqn select_action', 'ai Network __init__'), ('ai Dqn select_action', 'torch autograd Variable'), ('ai Dqn select_action', 'torch nn functional softmax'), ('ai Dqn learn', 'torch nn functional smooth_l1_loss'), ('ai Dqn learn', 'torch nn Module detach'), ('ai Dqn learn', 'ai Network __init__'), ('ai Dqn learn', 'torch nn Module gather'), ('ai Dqn update', 'ai Dqn select_action'), ('ai Dqn update', 'ai ReplayMemory push'), ('ai Dqn update', 'ai Dqn learn'), ('ai Dqn update', 'torch Tensor'), ('ai Dqn update', 'ai ReplayMemory sample'), ('ai Dqn update', 'torch LongTensor'), ('ai Dqn save', 'torch save'), ('ai Dqn save', 'torch nn Module state_dict'), ('ai Dqn load', 'torch nn Module load_state_dict'), ('ai Dqn load', 'os path isfile'), ('ai Dqn load', 'torch load')], [('map', 'ai Dqn __init__'), ('map', 'kivy app App __init__'), ('map', 'kivy app App run'), ('map', 'kivy config Config set'), ('ai Dqn __init__', 'ai Network __init__'), ('ai Dqn __init__', 'ai ReplayMemory __init__'), ('ai Dqn __init__', 'torch nn Module parameters'), ('ai Dqn __init__', 'torch Tensor'), ('ai Dqn __init__', 'torch optim Adam'), ('map init', 'numpy zeros'), ('map Car', 'kivy properties ReferenceListProperty'), ('map Car', 'kivy properties NumericProperty'), ('map Car move', 'numpy sum'), ('map Car move', 'kivy vector Vector'), ('map Game', 'kivy properties ObjectProperty'), ('map Game serve_car', 'kivy vector Vector'), ('map Game update', 'ai Dqn score'), ('map Game update', 'ai Dqn update'), ('map Game update', 'kivy vector Vector'), ('map Game update', 'map init'), ('map Game update', 'numpy sqrt'), ('ai Dqn update', 'ai ReplayMemory push'), ('ai Dqn update', 'ai Dqn learn'), ('ai Dqn update', 'torch LongTensor'), ('ai Dqn update', 'torch Tensor'), ('ai Dqn update', 'ai Dqn select_action'), ('ai Dqn update', 'ai ReplayMemory sample'), ('map MyPaintWidget on_touch_down', 'kivy graphics Line'), ('map MyPaintWidget on_touch_down', 'kivy graphics Color'), ('map MyPaintWidget on_touch_move', 'numpy sqrt')]]\n",
      "********************doctrings*************************\n",
      "['init', '', 'init']\n",
      "embed index dataset: 21\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\chatbot\\\\05_seq2seq_bilstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\sentiment-analysis\\\\02_bilstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\spacy_examples\\\\split_sentences.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\entity-tagging\\\\torch_lstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\sentiment-analysis\\\\01_lstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\text-generation\\\\01_char_lstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\chatbot\\\\04_seq2seq_birnn.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\entity-tagging\\\\10_bert.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\sentiment-analysis\\\\tf_transformer.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\pos-tagging\\\\tf_bilstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\spacy_examples\\\\dependency_parsing.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\word-segmentation\\\\02_bilstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\spacy_examples\\\\ner_visualization.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\examples-with-transformers\\\\torch_lm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\text-classification\\\\gender_classification_naive_bayes.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\entity-tagging\\\\tf_lstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\named-entity-recognition\\\\02_bilstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\entity-tagging\\\\tf_bilstm_crf.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\chatbot\\\\06_seq2seq_bigru.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\question-answering\\\\04_dynamic_memory.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\entity-tagging\\\\tf_lstm_crf.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\word-segmentation\\\\03_cnn.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\pos-tagging\\\\torch_lstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\pos-tagging\\\\tf_bilstm_crf.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\text-generation\\\\02_word_lstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\non-deep-learning\\\\tf-idf.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\question-answering\\\\attention_gru_cell.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\spacy_examples\\\\pos_tagging.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\named-entity-recognition\\\\03_bilstm_crf.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\pos-tagging\\\\tf_lstm_crf.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\spacy_examples\\\\dep_visualization.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\stemming\\\\01_seq2seq_rnn.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\entity-tagging\\\\torch_bilstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\language-detection\\\\01_nsec_langdetect.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\entity-tagging\\\\tf_bilstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\pos-tagging\\\\torch_bilstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\spacy_examples\\\\tokenization.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\named-entity-recognition\\\\01_lstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\sentence-similarity\\\\sentence_bert.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\word-segmentation\\\\01_lstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\spacy_examples\\\\remove_stopwords.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\text-mining\\\\text-cleaning.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\pos-tagging\\\\tf_lstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\chatbot\\\\01_seq2seq_rnn.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\question-answering\\\\dataloader.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\spam_detection\\\\basic_nn.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\text-summarization\\\\ts-bart.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\language-detection\\\\00_langdetect.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\pos-tagging\\\\10_bert.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\chatbot\\\\03_seq2seq_gru.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\spacy_examples\\\\lemmatization.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\spam_detection\\\\tf_transformer.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\spacy_examples\\\\singular_plural.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\chatbot\\\\02_seq2seq_lstm.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\naetherm_NLP\\\\spacy_examples\\\\stemming.py']\n",
      "import tensorflow as tf\n",
      "import tensorflow_addons as tfa\n",
      "from sklearn.utils import shuffle\n",
      "import re\n",
      "import time\n",
      "import collections\n",
      "\n",
      "tf.compat.v1.disable_v2_behavior()\n",
      "\n",
      "HIDDEN_LAYER = 256\n",
      "NUM_LAYERS = 2\n",
      "EMBEDDING_SIZE = 128\n",
      "LEARNING_RATE = 1e-2\n",
      "BATCH_SIZE = 16\n",
      "NUM_EPOCHS = 20\n",
      "\n",
      "\n",
      "def generate_dataset(words, n_words, atleast=1):\n",
      "  count = [['PAD', 0], ['GO', 1], ['EOS', 2], ['UNK', 3]]\n",
      "  counter = collections.Counter(words).most_common(n_words)\n",
      "  counter = [i for i in counter if i[1] >= atleast]\n",
      "  count.extend(counter)\n",
      "  dictionary = dict()\n",
      "  for word, _ in count:\n",
      "    dictionary[word] = len(dictionary)\n",
      "  data = list()\n",
      "  unk_count = 0\n",
      "  for word in words:\n",
      "    index = dictionary.get(word, 0)\n",
      "    if index == 0:\n",
      "      unk_count += 1\n",
      "    data.append(index)\n",
      "  count[0][1] = unk_count\n",
      "  reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
      "  return data, count, dictionary, reversed_dictionary\n",
      "\n",
      "\n",
      "lines = open('movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
      "conv_lines = open('movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
      "\n",
      "id2line = {}\n",
      "for line in lines:\n",
      "  _line = line.split(' +++$+++ ')\n",
      "  if len(_line) == 5:\n",
      "    id2line[_line[0]] = _line[4]\n",
      "\n",
      "convs = []\n",
      "for line in conv_lines[:-1]:\n",
      "  _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\")\n",
      "  convs.append(_line.split(','))\n",
      "\n",
      "questions = []\n",
      "answers = []\n",
      "\n",
      "for conv in convs:\n",
      "  for i in range(len(conv) - 1):\n",
      "    questions.append(id2line[conv[i]])\n",
      "    answers.append(id2line[conv[i + 1]])\n",
      "\n",
      "\n",
      "def cleanup_and_expand_text(text):\n",
      "  text = text.lower()\n",
      "  text = re.sub(r\"i'm\", \"i am\", text)\n",
      "  text = re.sub(r\"he's\", \"he is\", text)\n",
      "  text = re.sub(r\"she's\", \"she is\", text)\n",
      "  text = re.sub(r\"it's\", \"it is\", text)\n",
      "  text = re.sub(r\"that's\", \"that is\", text)\n",
      "  text = re.sub(r\"what's\", \"that is\", text)\n",
      "  text = re.sub(r\"where's\", \"where is\", text)\n",
      "  text = re.sub(r\"how's\", \"how is\", text)\n",
      "  text = re.sub(r\"\\'ll\", \" will\", text)\n",
      "  text = re.sub(r\"\\'ve\", \" have\", text)\n",
      "  text = re.sub(r\"\\'re\", \" are\", text)\n",
      "  text = re.sub(r\"\\'d\", \" would\", text)\n",
      "  text = re.sub(r\"\\'re\", \" are\", text)\n",
      "  text = re.sub(r\"won't\", \"will not\", text)\n",
      "  text = re.sub(r\"can't\", \"cannot\", text)\n",
      "  text = re.sub(r\"n't\", \" not\", text)\n",
      "  text = re.sub(r\"n'\", \"ng\", text)\n",
      "  text = re.sub(r\"'bout\", \"about\", text)\n",
      "  text = re.sub(r\"'til\", \"until\", text)\n",
      "  text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
      "  return ' '.join([i.strip() for i in filter(None, text.split())])\n",
      "\n",
      "\n",
      "clean_questions = []\n",
      "for question in questions:\n",
      "  clean_questions.append(cleanup_and_expand_text(question))\n",
      "\n",
      "clean_answers = []\n",
      "for answer in answers:\n",
      "  clean_answers.append(cleanup_and_expand_text(answer))\n",
      "\n",
      "min_line_length = 2\n",
      "max_line_length = 5\n",
      "short_questions_temp = []\n",
      "short_answers_temp = []\n",
      "\n",
      "i = 0\n",
      "for question in clean_questions:\n",
      "  if min_line_length <= len(question.split()) <= max_line_length:\n",
      "    short_questions_temp.append(question)\n",
      "    short_answers_temp.append(clean_answers[i])\n",
      "  i += 1\n",
      "\n",
      "short_questions = []\n",
      "short_answers = []\n",
      "\n",
      "i = 0\n",
      "for answer in short_answers_temp:\n",
      "  if min_line_length <= len(answer.split()) <= max_line_length:\n",
      "    short_answers.append(answer)\n",
      "    short_questions.append(short_questions_temp[i])\n",
      "  i += 1\n",
      "\n",
      "question_test = short_questions[500:550]\n",
      "answer_test = short_answers[500:550]\n",
      "short_questions = short_questions[:500]\n",
      "short_answers = short_answers[:500]\n",
      "\n",
      "# Generate the question dataset -> the input\n",
      "concat_from = ' '.join(short_questions + question_test).split()\n",
      "vocabulary_size_from = len(list(set(concat_from)))\n",
      "data_from, count_from, dictionary_from, rev_dictionary_from = generate_dataset(concat_from, vocabulary_size_from)\n",
      "\n",
      "# Generate the answer dataset -> the target\n",
      "concat_to = ' '.join(short_answers + answer_test).split()\n",
      "vocabulary_size_to = len(list(set(concat_to)))\n",
      "data_to, count_to, dictionary_to, rev_dictionary_to = generate_dataset(concat_to, vocabulary_size_to)\n",
      "\n",
      "# Shortcuts to functional tags\n",
      "GO = dictionary_from['GO']\n",
      "PAD = dictionary_from['PAD']\n",
      "EOS = dictionary_from['EOS']\n",
      "UNK = dictionary_from['UNK']\n",
      "\n",
      "for i in range(len(short_answers)):\n",
      "  short_answers[i] += ' EOS'\n",
      "\n",
      "print(\"questions: {}\".format(questions[:2]))\n",
      "print(\"answers: {}\".format(answers[:2]))\n",
      "\n",
      "print(\"short_questions: {}\".format(short_questions[:2]))\n",
      "print(\"short_answers: {}\".format(short_answers[:2]))\n",
      "\n",
      "\n",
      "# Helper method for transforming dataset to indices\n",
      "def str_idx(corpus, dic):\n",
      "  X = []\n",
      "  for i in corpus:\n",
      "    ints = []\n",
      "    for k in i.split():\n",
      "      ints.append(dic.get(k, UNK))\n",
      "    X.append(ints)\n",
      "  return X\n",
      "\n",
      "\n",
      "class LSTMChatbot(object):\n",
      "  def __init__(self, hidden_size, num_layers, embedded_size,\n",
      "               from_dict_size, to_dict_size, learning_rate, batch_size):\n",
      "    super(LSTMChatbot, self).__init__()\n",
      "    \n",
      "    def cells(h_size, reuse=False):\n",
      "      return tf.compat.v1.nn.rnn_cell.LSTMCell(h_size, reuse=reuse)\n",
      "    \n",
      "    self.X = tf.compat.v1.placeholder(tf.int32, [None, None])\n",
      "    self.Y = tf.compat.v1.placeholder(tf.int32, [None, None])\n",
      "    self.X_seq_len = tf.compat.v1.placeholder(tf.int32, [None])\n",
      "    self.Y_seq_len = tf.compat.v1.placeholder(tf.int32, [None])\n",
      "    batch_size = tf.shape(input=self.X)[0]\n",
      "    \n",
      "    encoder_embeddings = tf.Variable(tf.random.uniform([from_dict_size, embedded_size], -1, 1))\n",
      "    encoder_embedded = tf.nn.embedding_lookup(params=encoder_embeddings, ids=self.X)\n",
      "    main = tf.strided_slice(self.X, [0, 0], [batch_size, -1], [1, 1])\n",
      "    decoder_input = tf.concat([tf.fill([batch_size, 1], GO), main], 1)\n",
      "    decoder_embedded = tf.nn.embedding_lookup(params=encoder_embeddings, ids=decoder_input)\n",
      "    \n",
      "    # Multi layer architecture ->\n",
      "    for l in range(num_layers):\n",
      "      (o_fw, o_bw), (s_fw, s_bw) = tf.compat.v1.nn.bidirectional_dynamic_rnn(\n",
      "        cell_fw=cells(hidden_size // 2),\n",
      "        cell_bw=cells(hidden_size // 2),\n",
      "        inputs=encoder_embedded,\n",
      "        sequence_length=self.X_seq_len,\n",
      "        scope='birnn_L{}'.format(l),\n",
      "        dtype=tf.float32\n",
      "      )\n",
      "      encoder_embedded = tf.concat((o_fw, o_bw), axis=2)\n",
      "    \n",
      "    s_c_bi = tf.concat((s_fw.c, s_bw.c), axis=-1)\n",
      "    s_h_bi = tf.concat((s_fw.h, s_bw.h), axis=-1)\n",
      "    bi_lstm_state = tf.compat.v1.nn.rnn_cell.LSTMStateTuple(c=s_c_bi, h=s_h_bi)\n",
      "    s_last = tuple([bi_lstm_state] * num_layers)\n",
      "    \n",
      "    with tf.compat.v1.variable_scope(\"decoder\"):\n",
      "      rnn_cells_dec = tf.compat.v1.nn.rnn_cell.MultiRNNCell([cells(hidden_size) for _ in range(num_layers)])\n",
      "      outputs, _ = tf.compat.v1.nn.dynamic_rnn(rnn_cells_dec, decoder_embedded,\n",
      "                                               sequence_length=self.X_seq_len,\n",
      "                                               initial_state=s_last,\n",
      "                                               dtype=tf.float32)\n",
      "    self.logits = tf.compat.v1.layers.dense(outputs, to_dict_size)\n",
      "    masks = tf.sequence_mask(self.Y_seq_len, tf.reduce_max(input_tensor=self.Y_seq_len), dtype=tf.float32)\n",
      "    self.cost = tfa.seq2seq.sequence_loss(logits=self.logits,\n",
      "                                          targets=self.Y,\n",
      "                                          weights=masks)\n",
      "    self.optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
      "    y_t = tf.argmax(input=self.logits, axis=2)\n",
      "    y_t = tf.cast(y_t, tf.int32)\n",
      "    self.prediction = tf.boolean_mask(tensor=y_t, mask=masks)\n",
      "    mask_label = tf.boolean_mask(tensor=self.Y, mask=masks)\n",
      "    correct_pred = tf.equal(self.prediction, mask_label)\n",
      "    self.accuracy = tf.reduce_mean(input_tensor=tf.cast(correct_pred, tf.float32))\n",
      "\n",
      "\n",
      "# Start the session (this is < TF 2.0)\n",
      "tf.compat.v1.reset_default_graph()\n",
      "sess = tf.compat.v1.InteractiveSession()\n",
      "model = LSTMChatbot(\n",
      "  HIDDEN_LAYER,\n",
      "  NUM_LAYERS,\n",
      "  EMBEDDING_SIZE,\n",
      "  len(dictionary_from),\n",
      "  len(dictionary_to),\n",
      "  LEARNING_RATE,\n",
      "  BATCH_SIZE)\n",
      "sess.run(tf.compat.v1.global_variables_initializer())\n",
      "\n",
      "# Transform input and output to indices\n",
      "X = str_idx(short_questions, dictionary_from)\n",
      "Y = str_idx(short_answers, dictionary_to)\n",
      "X_test = str_idx(question_test, dictionary_from)\n",
      "Y_test = str_idx(answer_test, dictionary_from)\n",
      "\n",
      "# For batching the input and target we will need the max. length of each\n",
      "maxlen_question = max([len(x) for x in X]) * 2\n",
      "maxlen_answer = max([len(y) for y in Y]) * 2\n",
      "# For simplicity let's use the longest length\n",
      "maxlen = max(maxlen_question, maxlen_answer)\n",
      "\n",
      "\n",
      "# Batching input and target sequences according to the max. length of each\n",
      "def pad_sentence_batch(sentence_batch, pad_int, maxlen):\n",
      "  padded_seqs = []\n",
      "  seq_lens = []\n",
      "  max_sentence_len = maxlen\n",
      "  for sentence in sentence_batch:\n",
      "    padded_seqs.append(sentence + [pad_int] * (max_sentence_len - len(sentence)))\n",
      "    seq_lens.append(maxlen)\n",
      "  return padded_seqs, seq_lens\n",
      "\n",
      "\n",
      "# Training\n",
      "for i in range(NUM_EPOCHS):\n",
      "  start_time = time.time()\n",
      "  total_loss, total_accuracy = 0, 0\n",
      "  X, Y = shuffle(X, Y)\n",
      "  for k in range(0, len(short_questions), BATCH_SIZE):\n",
      "    index = min(k + BATCH_SIZE, len(short_questions))\n",
      "    batch_x, seq_x = pad_sentence_batch(X[k: index], PAD, maxlen)\n",
      "    batch_y, seq_y = pad_sentence_batch(Y[k: index], PAD, maxlen)\n",
      "    predicted, accuracy, loss, _ = sess.run(\n",
      "      [\n",
      "        tf.argmax(input=model.logits, axis=2),\n",
      "        model.accuracy,\n",
      "        model.cost,\n",
      "        model.optimizer\n",
      "      ],\n",
      "      feed_dict={\n",
      "        model.X: batch_x,\n",
      "        model.Y: batch_y,\n",
      "        model.X_seq_len: seq_x,\n",
      "        model.Y_seq_len: seq_y\n",
      "      }\n",
      "    )\n",
      "    total_loss += loss\n",
      "    total_accuracy += accuracy\n",
      "    print('REAL ANSWER:', ' '.join([rev_dictionary_to[n] for n in batch_y[0] if n not in [0, 1, 2, 3]]))\n",
      "    print('PREDICTED ANSWER:', ' '.join([rev_dictionary_to[n] for n in predicted[0] if n not in [0, 1, 2, 3]]), '\\n')\n",
      "  total_loss /= (len(short_questions) / BATCH_SIZE)\n",
      "  total_accuracy /= (len(short_questions) / BATCH_SIZE)\n",
      "  diff_time = time.time() - start_time\n",
      "  print('[%f seconds] epoch: %d, avg loss: %f, avg accuracy: %f' % (diff_time, i + 1, total_loss, total_accuracy))\n",
      "\n",
      "# Testing\n",
      "batch_x, seq_x = pad_sentence_batch(X_test[:BATCH_SIZE], PAD, maxlen)\n",
      "batch_y, seq_y = pad_sentence_batch(Y_test[:BATCH_SIZE], PAD, maxlen)\n",
      "predicted = sess.run(tf.argmax(input=model.logits, axis=2), feed_dict={model.X: batch_x, model.X_seq_len: seq_x})\n",
      "\n",
      "# Results\n",
      "print(\"########################\")\n",
      "print(\"# TESTING\")\n",
      "print(\"########################\")\n",
      "for i in range(len(batch_x)):\n",
      "  print('row %d' % (i + 1))\n",
      "  print('QUESTION:', ' '.join([rev_dictionary_from[n] for n in batch_x[i] if n not in [0, 1, 2, 3]]))\n",
      "  print('REAL ANSWER:', ' '.join([rev_dictionary_to[n] for n in batch_y[i] if n not in [0, 1, 2, 3]]))\n",
      "  print('PREDICTED ANSWER:', ' '.join([rev_dictionary_to[n] for n in predicted[i] if n not in [0, 1, 2, 3]]), '\\n')\n",
      "\n",
      "Output: {'05_seq2seq_bilstm': ['05_seq2seq_bilstm.pad_sentence_batch', '<builtin>.list', 'tensorflow.compat.v1.global_variables_initializer', '<builtin>.set', '<builtin>.print', 'tensorflow.compat.v1.reset_default_graph', 'tensorflow.compat.v1.disable_v2_behavior', '<builtin>.len', 'sklearn.utils.shuffle', '05_seq2seq_bilstm.cleanup_and_expand_text', '05_seq2seq_bilstm.str_idx', 'tensorflow.compat.v1.InteractiveSession', '05_seq2seq_bilstm.LSTMChatbot.__init__', '05_seq2seq_bilstm.generate_dataset', 'time.time', '<builtin>.open', 'tensorflow.argmax', '<builtin>.max', '<builtin>.min', '<builtin>.range'], 'tensorflow.compat.v1.disable_v2_behavior': [], '05_seq2seq_bilstm.generate_dataset': ['<builtin>.list', 'collections.Counter', '<builtin>.zip', '<builtin>.len', '<builtin>.dict'], 'collections.Counter': [], '<builtin>.dict': [], '<builtin>.len': [], '<builtin>.list': [], '<builtin>.zip': [], '<builtin>.open': [], '<builtin>.range': [], '05_seq2seq_bilstm.cleanup_and_expand_text': ['<builtin>.filter', 're.sub'], 're.sub': [], '<builtin>.filter': [], '<builtin>.set': [], '<builtin>.print': [], '05_seq2seq_bilstm.str_idx': [], '05_seq2seq_bilstm.LSTMChatbot.__init__': ['tensorflow.cast', 'tensorflow.compat.v1.variable_scope', 'tensorflow.reduce_mean', 'tensorflow.sequence_mask', 'tensorflow.compat.v1.nn.bidirectional_dynamic_rnn', 'tensorflow.strided_slice', 'tensorflow.boolean_mask', 'tensorflow_addons.seq2seq.sequence_loss', '<builtin>.super', '<builtin>.range', 'tensorflow.concat', 'tensorflow.random.uniform', '<builtin>.tuple', 'tensorflow.compat.v1.nn.rnn_cell.MultiRNNCell', 'tensorflow.compat.v1.train.AdamOptimizer', 'tensorflow.Variable', 'tensorflow.compat.v1.nn.dynamic_rnn', 'tensorflow.nn.embedding_lookup', 'tensorflow.compat.v1.layers.dense', 'tensorflow.reduce_max', '05_seq2seq_bilstm.LSTMChatbot.__init__.cells', 'tensorflow.argmax', 'tensorflow.shape', 'tensorflow.fill', 'tensorflow.equal', 'tensorflow.compat.v1.placeholder', 'tensorflow.compat.v1.nn.rnn_cell.LSTMStateTuple'], '<builtin>.super': [], '05_seq2seq_bilstm.LSTMChatbot.__init__.cells': ['tensorflow.compat.v1.nn.rnn_cell.LSTMCell'], 'tensorflow.compat.v1.nn.rnn_cell.LSTMCell': [], 'tensorflow.compat.v1.placeholder': [], 'tensorflow.shape': [], 'tensorflow.random.uniform': [], 'tensorflow.Variable': [], 'tensorflow.nn.embedding_lookup': [], 'tensorflow.strided_slice': [], 'tensorflow.fill': [], 'tensorflow.concat': [], 'tensorflow.compat.v1.nn.bidirectional_dynamic_rnn': [], 'tensorflow.compat.v1.nn.rnn_cell.LSTMStateTuple': [], '<builtin>.tuple': [], 'tensorflow.compat.v1.variable_scope': [], 'tensorflow.compat.v1.nn.rnn_cell.MultiRNNCell': [], 'tensorflow.compat.v1.nn.dynamic_rnn': [], 'tensorflow.compat.v1.layers.dense': [], 'tensorflow.reduce_max': [], 'tensorflow.sequence_mask': [], 'tensorflow_addons.seq2seq.sequence_loss': [], 'tensorflow.compat.v1.train.AdamOptimizer': [], 'tensorflow.argmax': [], 'tensorflow.cast': [], 'tensorflow.boolean_mask': [], 'tensorflow.equal': [], 'tensorflow.reduce_mean': [], 'tensorflow.compat.v1.reset_default_graph': [], 'tensorflow.compat.v1.InteractiveSession': [], 'tensorflow.compat.v1.global_variables_initializer': [], '<builtin>.max': [], '05_seq2seq_bilstm.pad_sentence_batch': ['<builtin>.len'], 'time.time': [], 'sklearn.utils.shuffle': [], '<builtin>.min': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\chatbot\\05_seq2seq_bilstm.py\n",
      "[('05_seq2seq_bilstm', '05_seq2seq_bilstm pad_sentence_batch'), ('05_seq2seq_bilstm', 'tensorflow compat v1 global_variables_initializer'), ('05_seq2seq_bilstm', 'tensorflow compat v1 reset_default_graph'), ('05_seq2seq_bilstm', 'tensorflow compat v1 disable_v2_behavior'), ('05_seq2seq_bilstm', 'sklearn utils shuffle'), ('05_seq2seq_bilstm', '05_seq2seq_bilstm cleanup_and_expand_text'), ('05_seq2seq_bilstm', '05_seq2seq_bilstm str_idx'), ('05_seq2seq_bilstm', 'tensorflow compat v1 InteractiveSession'), ('05_seq2seq_bilstm', '05_seq2seq_bilstm LSTMChatbot __init__'), ('05_seq2seq_bilstm', '05_seq2seq_bilstm generate_dataset'), ('05_seq2seq_bilstm', 'time time'), ('05_seq2seq_bilstm', 'tensorflow argmax'), ('05_seq2seq_bilstm generate_dataset', 'collections Counter'), ('05_seq2seq_bilstm cleanup_and_expand_text', 're sub'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow cast'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow compat v1 variable_scope'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow reduce_mean'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow sequence_mask'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow compat v1 nn bidirectional_dynamic_rnn'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow strided_slice'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow boolean_mask'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow_addons seq2seq sequence_loss'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow concat'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow random uniform'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow compat v1 nn rnn_cell MultiRNNCell'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow compat v1 train AdamOptimizer'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow Variable'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow compat v1 nn dynamic_rnn'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow nn embedding_lookup'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow compat v1 layers dense')]\n",
      "0\n",
      "found files: []\n",
      "import tensorflow_datasets as tfds\n",
      "import tensorflow as tf\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "BUFFER_SIZE = 10000\n",
      "BATCH_SIZE = 64\n",
      "HIDDEN_SIZE = 64\n",
      "LR = 1e-4\n",
      "\n",
      "\n",
      "def plot_graphs(history, metric):\n",
      "  plt.plot(history.history[metric])\n",
      "  plt.plot(history.history['val_' + metric], '')\n",
      "  plt.xlabel(\"Epochs\")\n",
      "  plt.ylabel(metric)\n",
      "  plt.legend([metric, 'val_' + metric])\n",
      "  plt.show()\n",
      "\n",
      "\n",
      "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True)\n",
      "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
      "\n",
      "encoder = info.features['text'].encoder\n",
      "\n",
      "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
      "train_dataset = train_dataset.padded_batch(BATCH_SIZE)\n",
      "\n",
      "test_dataset = test_dataset.padded_batch(BATCH_SIZE)\n",
      "\n",
      "model = tf.keras.Sequential([\n",
      "  tf.keras.layers.Embedding(encoder.vocab_size, HIDDEN_SIZE),\n",
      "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(HIDDEN_SIZE)),\n",
      "  tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
      "  tf.keras.layers.Dense(1)\n",
      "])\n",
      "\n",
      "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
      "              optimizer=tf.keras.optimizers.Adam(LR),\n",
      "              metrics=['accuracy'])\n",
      "\n",
      "history = model.fit(train_dataset, epochs=10,\n",
      "                    validation_data=test_dataset,\n",
      "                    validation_steps=30)\n",
      "\n",
      "test_loss, test_acc = model.evaluate(test_dataset)\n",
      "\n",
      "print('Test Loss: {}'.format(test_loss))\n",
      "print('Test Accuracy: {}'.format(test_acc))\n",
      "\n",
      "\n",
      "Output: {'02_bilstm': ['tensorflow_datasets.load', 'tensorflow.keras.optimizers.Adam', 'tensorflow.keras.layers.LSTM', 'tensorflow.keras.losses.BinaryCrossentropy', 'tensorflow.keras.layers.Bidirectional', '<builtin>.print', 'tensorflow.keras.Sequential', 'tensorflow.keras.layers.Embedding', 'tensorflow.keras.layers.Dense'], '02_bilstm.plot_graphs': ['matplotlib.pyplot.xlabel', 'matplotlib.pyplot.legend', 'matplotlib.pyplot.plot', 'matplotlib.pyplot.ylabel', 'matplotlib.pyplot.show'], 'matplotlib.pyplot.plot': [], 'matplotlib.pyplot.xlabel': [], 'matplotlib.pyplot.ylabel': [], 'matplotlib.pyplot.legend': [], 'matplotlib.pyplot.show': [], 'tensorflow_datasets.load': [], 'tensorflow.keras.layers.Embedding': [], 'tensorflow.keras.layers.LSTM': [], 'tensorflow.keras.layers.Bidirectional': [], 'tensorflow.keras.layers.Dense': [], 'tensorflow.keras.Sequential': [], 'tensorflow.keras.losses.BinaryCrossentropy': [], 'tensorflow.keras.optimizers.Adam': [], '<builtin>.print': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\sentiment-analysis\\02_bilstm.py\n",
      "[('02_bilstm', 'tensorflow_datasets load'), ('02_bilstm', 'tensorflow keras optimizers Adam'), ('02_bilstm', 'tensorflow keras layers LSTM'), ('02_bilstm', 'tensorflow keras losses BinaryCrossentropy'), ('02_bilstm', 'tensorflow keras layers Bidirectional'), ('02_bilstm', 'tensorflow keras Sequential'), ('02_bilstm', 'tensorflow keras layers Embedding'), ('02_bilstm', 'tensorflow keras layers Dense'), ('02_bilstm plot_graphs', 'matplotlib pyplot xlabel'), ('02_bilstm plot_graphs', 'matplotlib pyplot legend'), ('02_bilstm plot_graphs', 'matplotlib pyplot plot'), ('02_bilstm plot_graphs', 'matplotlib pyplot ylabel'), ('02_bilstm plot_graphs', 'matplotlib pyplot show')]\n",
      "0\n",
      "found files: []\n",
      "import time\n",
      "import nltk\n",
      "import spacy\n",
      "\n",
      "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
      "nlp = spacy.load(\"en_core_web_sm\")\n",
      "\n",
      "def read_file(filename):\n",
      "    file = open(filename, \"r\", encoding=\"utf-8\") \n",
      "    return file.read()\n",
      "\n",
      "def preprocess_text(text):\n",
      "    text = text.replace(\"\\n\", \" \")\n",
      "    return text\n",
      "\n",
      "def split_sentences_nltk(text):\n",
      "    sentences = tokenizer.tokenize(text)\n",
      "    return sentences\n",
      "\n",
      "def split_sentences_spacy(text):\n",
      "    doc = nlp(text)\n",
      "    return [sentence.text for sentence in doc.sents]\n",
      "\n",
      "def split_sentences(text):\n",
      "    return split_sentences_nltk(text)\n",
      "\n",
      "def main():\n",
      "    random_text = read_file(\"./random_text.txt\")\n",
      "    random_text = preprocess_text(random_text)\n",
      "    sentences = split_sentences(random_text)\n",
      "    print(sentences)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    start = time.time()\n",
      "    main()\n",
      "\n",
      "Output: {'split_sentences': ['time.time', 'spacy.load', 'nltk.data.load', 'split_sentences.main'], 'nltk.data.load': [], 'spacy.load': [], 'split_sentences.read_file': ['<builtin>.open'], '<builtin>.open': [], 'split_sentences.preprocess_text': [], 'split_sentences.split_sentences_nltk': [], 'split_sentences.split_sentences_spacy': [], 'split_sentences.split_sentences': ['split_sentences.split_sentences_nltk'], 'split_sentences.main': ['split_sentences.read_file', '<builtin>.print', 'split_sentences.preprocess_text', 'split_sentences.split_sentences'], '<builtin>.print': [], 'time.time': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\spacy_examples\\split_sentences.py\n",
      "[('split_sentences', 'time time'), ('split_sentences', 'spacy load'), ('split_sentences', 'nltk data load'), ('split_sentences', 'split_sentences main'), ('split_sentences split_sentences', 'split_sentences split_sentences_nltk'), ('split_sentences main', 'split_sentences read_file'), ('split_sentences main', 'split_sentences preprocess_text'), ('split_sentences main', 'split_sentences split_sentences')]\n",
      "0\n",
      "found files: []\n",
      "import re\n",
      "import numpy as np\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "import torch.optim as optim\n",
      "\n",
      "from tqdm import tqdm\n",
      "\n",
      "\n",
      "EPOCHS=20\n",
      "\n",
      "def parse(file):\n",
      "    with open(file) as fopen:\n",
      "        texts = fopen.read().split('\\n')\n",
      "    left, right = [], []\n",
      "    for text in texts:\n",
      "        if '-DOCSTART-' in text or not len(text):\n",
      "            continue\n",
      "        splitted = text.split()\n",
      "        left.append(splitted[0])\n",
      "        right.append(splitted[-1])\n",
      "    return left, right\n",
      "    \n",
      "left_train, right_train = parse('eng.train')\n",
      "left_test, right_test = parse('eng.testa')\n",
      "\n",
      "def process_string(string):\n",
      "    string = re.sub('[^A-Za-z0-9\\-\\/ ]+', ' ', string).split()\n",
      "    return ' '.join([to_title(y.strip()) for y in string])\n",
      "\n",
      "def to_title(string):\n",
      "    if string.isupper():\n",
      "        string = string.title()\n",
      "    return string\n",
      "    \n",
      "word2idx = {'PAD': 0,'NUM':1,'UNK':2}\n",
      "tag2idx = {'PAD': 0}\n",
      "char2idx = {'PAD': 0}\n",
      "word_idx = 3\n",
      "tag_idx = 1\n",
      "char_idx = 1\n",
      "\n",
      "def parse_XY(texts, labels):\n",
      "    global word2idx, tag2idx, char2idx, word_idx, tag_idx, char_idx\n",
      "    X, Y = [], []\n",
      "    for no, text in enumerate(texts):\n",
      "        text = text.lower()\n",
      "        tag = labels[no]\n",
      "        for c in text:\n",
      "            if c not in char2idx:\n",
      "                char2idx[c] = char_idx\n",
      "                char_idx += 1\n",
      "        if tag not in tag2idx:\n",
      "            tag2idx[tag] = tag_idx\n",
      "            tag_idx += 1\n",
      "        Y.append(tag2idx[tag])\n",
      "        if text not in word2idx:\n",
      "            word2idx[text] = word_idx\n",
      "            word_idx += 1\n",
      "        X.append(word2idx[text])\n",
      "    return X, np.array(Y)\n",
      "    \n",
      "train_X, train_Y = parse_XY(left_train, right_train)\n",
      "test_X, test_Y = parse_XY(left_test, right_test)\n",
      "\n",
      "idx2word = {idx: tag for tag, idx in word2idx.items()}\n",
      "idx2tag = {i: w for w, i in tag2idx.items()}\n",
      "\n",
      "seq_len = 50\n",
      "def iter_seq(x):\n",
      "    return np.array([x[i: i+seq_len] for i in range(0, len(x)-seq_len, 1)])\n",
      "\n",
      "def to_train_seq(*args):\n",
      "    return [iter_seq(x) for x in args]\n",
      "\n",
      "def generate_char_seq(batch):\n",
      "    x = [[len(idx2word[i]) for i in k] for k in batch]\n",
      "    maxlen = max([j for i in x for j in i])\n",
      "    temp = np.zeros((batch.shape[0],batch.shape[1],maxlen),dtype=np.int32)\n",
      "    for i in range(batch.shape[0]):\n",
      "        for k in range(batch.shape[1]):\n",
      "            for no, c in enumerate(idx2word[batch[i,k]]):\n",
      "                temp[i,k,-1-no] = char2idx[c]\n",
      "    return temp\n",
      "    \n",
      "\n",
      "X_seq, Y_seq = to_train_seq(train_X, train_Y)\n",
      "X_char_seq = generate_char_seq(X_seq)\n",
      "X_seq.shape\n",
      "\n",
      "X_seq_test, Y_seq_test = to_train_seq(test_X, test_Y)\n",
      "X_char_seq_test = generate_char_seq(X_seq_test)\n",
      "X_seq_test.shape\n",
      "\n",
      "train_X, train_Y, train_char = X_seq, Y_seq, X_char_seq\n",
      "test_X, test_Y, test_char = X_seq_test, Y_seq_test, X_char_seq_test\n",
      "\n",
      "\n",
      "from numpy.random import seed\n",
      "seed(1)\n",
      "torch.manual_seed(1)\n",
      "output_dim = 64\n",
      "\n",
      "\n",
      "class LSTMModel(nn.Module):\n",
      "\n",
      "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
      "        super(LSTMModel, self).__init__()\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
      "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
      "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
      "\n",
      "    def forward(self, sentence):\n",
      "        embeds = self.word_embeddings(sentence)\n",
      "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
      "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
      "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
      "        return tag_scores\n",
      "\n",
      "model = LSTMModel(output_dim, output_dim, len(word2idx), len(tag2idx))\n",
      "loss_function = nn.NLLLoss()\n",
      "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
      "\n",
      "for epoch in range(EPOCHS):\n",
      "    for s, t in zip(train_X, train_Y):\n",
      "        model.zero_grad()\n",
      "        tag_scores = model(torch.tensor(s, dtype=torch.int32))\n",
      "        loss = loss_function(tag_scores, torch.from_numpy(t))\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "Output: {'torch_lstm': ['numpy.random.seed', 'torch.nn.Module.zero_grad', 'torch.tensor', 'torch.manual_seed', 'torch.nn.NLLLoss', '<builtin>.range', 'torch_lstm.parse_XY', 'torch.nn.Module.parameters', 'torch_lstm.parse', '<builtin>.zip', 'torch_lstm.generate_char_seq', 'torch.from_numpy', 'torch_lstm.LSTMModel.__init__', 'torch.optim.Adam', '<builtin>.len', 'torch_lstm.to_train_seq'], 'torch_lstm.parse': ['<builtin>.len', '<builtin>.open'], '<builtin>.open': [], '<builtin>.len': [], 'torch_lstm.process_string': ['torch_lstm.to_title', 're.sub'], 're.sub': [], 'torch_lstm.to_title': [], 'torch_lstm.parse_XY': ['<builtin>.enumerate', 'numpy.array'], '<builtin>.enumerate': [], 'numpy.array': [], 'torch_lstm.iter_seq': ['<builtin>.len', 'numpy.array', '<builtin>.range'], '<builtin>.range': [], 'torch_lstm.to_train_seq': ['torch_lstm.iter_seq'], 'torch_lstm.generate_char_seq': ['numpy.zeros', '<builtin>.range', '<builtin>.enumerate', '<builtin>.max', '<builtin>.len'], '<builtin>.max': [], 'numpy.zeros': [], 'numpy.random.seed': [], 'torch.manual_seed': [], 'torch_lstm.LSTMModel.__init__': ['<builtin>.super', 'torch.nn.LSTM', 'torch.nn.Embedding', 'torch.nn.Linear'], '<builtin>.super': [], 'torch.nn.Embedding': [], 'torch.nn.LSTM': [], 'torch.nn.Linear': [], 'torch_lstm.LSTMModel.forward': ['<builtin>.len', 'torch.nn.functional.log_softmax'], 'torch.nn.functional.log_softmax': [], 'torch.nn.NLLLoss': [], 'torch.nn.Module.parameters': [], 'torch.optim.Adam': [], '<builtin>.zip': [], 'torch.nn.Module.zero_grad': [], 'torch.tensor': [], 'torch.from_numpy': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\entity-tagging\\torch_lstm.py\n",
      "[('torch_lstm', 'numpy random seed'), ('torch_lstm', 'torch nn Module zero_grad'), ('torch_lstm', 'torch tensor'), ('torch_lstm', 'torch manual_seed'), ('torch_lstm', 'torch nn NLLLoss'), ('torch_lstm', 'torch_lstm parse_XY'), ('torch_lstm', 'torch nn Module parameters'), ('torch_lstm', 'torch_lstm parse'), ('torch_lstm', 'torch_lstm generate_char_seq'), ('torch_lstm', 'torch from_numpy'), ('torch_lstm', 'torch_lstm LSTMModel __init__'), ('torch_lstm', 'torch optim Adam'), ('torch_lstm', 'torch_lstm to_train_seq'), ('torch_lstm process_string', 'torch_lstm to_title'), ('torch_lstm process_string', 're sub'), ('torch_lstm parse_XY', 'numpy array'), ('torch_lstm iter_seq', 'numpy array'), ('torch_lstm to_train_seq', 'torch_lstm iter_seq'), ('torch_lstm generate_char_seq', 'numpy zeros'), ('torch_lstm LSTMModel __init__', 'torch nn LSTM'), ('torch_lstm LSTMModel __init__', 'torch nn Embedding'), ('torch_lstm LSTMModel __init__', 'torch nn Linear'), ('torch_lstm LSTMModel forward', 'torch nn functional log_softmax')]\n",
      "0\n",
      "found files: []\n",
      "\n",
      "import tensorflow_datasets as tfds\n",
      "import tensorflow as tf\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "BUFFER_SIZE = 10000\n",
      "BATCH_SIZE = 64\n",
      "HIDDEN_SIZE = 64\n",
      "LR = 1e-4\n",
      "\n",
      "\n",
      "def plot_graphs(history, metric):\n",
      "  plt.plot(history.history[metric])\n",
      "  plt.plot(history.history['val_'+metric], '')\n",
      "  plt.xlabel(\"Epochs\")\n",
      "  plt.ylabel(metric)\n",
      "  plt.legend([metric, 'val_'+metric])\n",
      "  plt.show()\n",
      "  \n",
      "\n",
      "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True)\n",
      "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
      "\n",
      "encoder = info.features['text'].encoder\n",
      "\n",
      "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
      "train_dataset = train_dataset.padded_batch(BATCH_SIZE)\n",
      "\n",
      "test_dataset = test_dataset.padded_batch(BATCH_SIZE)\n",
      "\n",
      "model = tf.keras.Sequential([\n",
      "    tf.keras.layers.Embedding(encoder.vocab_size, HIDDEN_SIZE),\n",
      "    tf.keras.layers.LSTM(HIDDEN_SIZE),\n",
      "    tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'),\n",
      "    tf.keras.layers.Dense(1)\n",
      "])\n",
      "\n",
      "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
      "              optimizer=tf.keras.optimizers.Adam(LR),\n",
      "              metrics=['accuracy'])\n",
      "\n",
      "history = model.fit(train_dataset, epochs=10,\n",
      "                    validation_data=test_dataset,\n",
      "                    validation_steps=30)\n",
      "\n",
      "test_loss, test_acc = model.evaluate(test_dataset)\n",
      "\n",
      "print('Test Loss: {}'.format(test_loss))\n",
      "print('Test Accuracy: {}'.format(test_acc))\n",
      "\n",
      "\n",
      "Output: {'01_lstm': ['tensorflow.keras.layers.Embedding', 'tensorflow.keras.losses.BinaryCrossentropy', '<builtin>.print', 'tensorflow.keras.optimizers.Adam', 'tensorflow_datasets.load', 'tensorflow.keras.layers.LSTM', 'tensorflow.keras.layers.Dense', 'tensorflow.keras.Sequential'], '01_lstm.plot_graphs': ['matplotlib.pyplot.xlabel', 'matplotlib.pyplot.show', 'matplotlib.pyplot.legend', 'matplotlib.pyplot.plot', 'matplotlib.pyplot.ylabel'], 'matplotlib.pyplot.plot': [], 'matplotlib.pyplot.xlabel': [], 'matplotlib.pyplot.ylabel': [], 'matplotlib.pyplot.legend': [], 'matplotlib.pyplot.show': [], 'tensorflow_datasets.load': [], 'tensorflow.keras.layers.Embedding': [], 'tensorflow.keras.layers.LSTM': [], 'tensorflow.keras.layers.Dense': [], 'tensorflow.keras.Sequential': [], 'tensorflow.keras.losses.BinaryCrossentropy': [], 'tensorflow.keras.optimizers.Adam': [], '<builtin>.print': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\sentiment-analysis\\01_lstm.py\n",
      "[('01_lstm', 'tensorflow keras layers Embedding'), ('01_lstm', 'tensorflow keras losses BinaryCrossentropy'), ('01_lstm', 'tensorflow keras optimizers Adam'), ('01_lstm', 'tensorflow_datasets load'), ('01_lstm', 'tensorflow keras layers LSTM'), ('01_lstm', 'tensorflow keras layers Dense'), ('01_lstm', 'tensorflow keras Sequential'), ('01_lstm plot_graphs', 'matplotlib pyplot xlabel'), ('01_lstm plot_graphs', 'matplotlib pyplot show'), ('01_lstm plot_graphs', 'matplotlib pyplot legend'), ('01_lstm plot_graphs', 'matplotlib pyplot plot'), ('01_lstm plot_graphs', 'matplotlib pyplot ylabel')]\n",
      "0\n",
      "found files: []\n",
      "import tensorflow as tf\n",
      "\n",
      "import numpy as np\n",
      "import os\n",
      "import time\n",
      "\n",
      "# Read, then decode for py2 compat.\n",
      "\n",
      "PATH_TO_FILE = \"bible.txt\"\n",
      "\n",
      "text = open(PATH_TO_FILE, 'rb').read().decode(encoding='utf-8')\n",
      "# length of text is the number of characters in it\n",
      "print ('Length of text: {} characters'.format(len(text)))\n",
      "\n",
      "# Take a look at the first 250 characters in text\n",
      "print(text[:250])\n",
      "\n",
      "# The unique characters in the file\n",
      "vocab = sorted(set(text))\n",
      "print ('{} unique characters'.format(len(vocab)))\n",
      "\n",
      "# Creating a mapping from unique characters to indices\n",
      "char2idx = {u:i for i, u in enumerate(vocab)}\n",
      "idx2char = np.array(vocab)\n",
      "\n",
      "text_as_int = np.array([char2idx[c] for c in text])\n",
      "\n",
      "# The maximum length sentence we want for a single input in characters\n",
      "seq_length = 100\n",
      "examples_per_epoch = len(text)//(seq_length+1)\n",
      "\n",
      "# Create training examples / targets\n",
      "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
      "\n",
      "for i in char_dataset.take(5):\n",
      "  print(idx2char[i.numpy()])\n",
      "  \n",
      "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
      "\n",
      "for item in sequences.take(5):\n",
      "  print(repr(''.join(idx2char[item.numpy()])))\n",
      "  \n",
      "def split_input_target(chunk):\n",
      "  input_text = chunk[:-1]\n",
      "  target_text = chunk[1:]\n",
      "  return input_text, target_text\n",
      "\n",
      "dataset = sequences.map(split_input_target)\n",
      "\n",
      "# Batch size\n",
      "BATCH_SIZE = 64\n",
      "\n",
      "# Buffer size to shuffle the dataset\n",
      "# (TF data is designed to work with possibly infinite sequences,\n",
      "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
      "# it maintains a buffer in which it shuffles elements).\n",
      "BUFFER_SIZE = 10000\n",
      "\n",
      "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
      "\n",
      "\n",
      "# Length of the vocabulary in chars\n",
      "vocab_size = len(vocab)\n",
      "\n",
      "# The embedding dimension\n",
      "embedding_dim = 256\n",
      "\n",
      "# Number of RNN units\n",
      "rnn_units = 1024\n",
      "\n",
      "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
      "  model = tf.keras.Sequential([\n",
      "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
      "                              batch_input_shape=[batch_size, None]),\n",
      "    tf.keras.layers.LSTM(rnn_units,\n",
      "                         return_sequences=True,\n",
      "                         stateful=True,\n",
      "                         recurrent_initializer='glorot_uniform'),\n",
      "    tf.keras.layers.Dense(vocab_size)\n",
      "  ])\n",
      "  return model\n",
      "  \n",
      "model = build_model(\n",
      "    vocab_size = len(vocab),\n",
      "    embedding_dim=embedding_dim,\n",
      "    rnn_units=rnn_units,\n",
      "    batch_size=BATCH_SIZE)\n",
      "    \n",
      "for input_example_batch, target_example_batch in dataset.take(1):\n",
      "  example_batch_predictions = model(input_example_batch)\n",
      "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
      "  \n",
      "model.summary()\n",
      "\n",
      "\n",
      "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
      "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
      "\n",
      "def loss(labels, logits):\n",
      "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
      "\n",
      "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
      "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
      "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n",
      "\n",
      "model.compile(optimizer='adam', loss=loss)\n",
      "\n",
      "EPOCHS=10\n",
      "\n",
      "# Directory where the checkpoints will be saved\n",
      "checkpoint_dir = './training_checkpoints'\n",
      "# Name of the checkpoint files\n",
      "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
      "\n",
      "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
      "    filepath=checkpoint_prefix,\n",
      "    save_weights_only=True)\n",
      "\n",
      "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n",
      "\n",
      "\n",
      "\n",
      "Output: {'01_char_lstm': ['tensorflow.data.Dataset.from_tensor_slices', '<builtin>.len', '<builtin>.enumerate', '<builtin>.set', 'tensorflow.keras.callbacks.ModelCheckpoint', '<builtin>.print', 'numpy.array', 'tensorflow.random.categorical', 'os.path.join', '<builtin>.sorted', 'tensorflow.squeeze', '<builtin>.open', '<builtin>.repr', '01_char_lstm.build_model', '01_char_lstm.loss'], '<builtin>.open': [], '<builtin>.len': [], '<builtin>.print': [], '<builtin>.set': [], '<builtin>.sorted': [], '<builtin>.enumerate': [], 'numpy.array': [], 'tensorflow.data.Dataset.from_tensor_slices': [], '<builtin>.repr': [], '01_char_lstm.split_input_target': [], '01_char_lstm.build_model': ['tensorflow.keras.layers.Dense', 'tensorflow.keras.layers.Embedding', 'tensorflow.keras.layers.LSTM', 'tensorflow.keras.Sequential'], 'tensorflow.keras.layers.Embedding': [], 'tensorflow.keras.layers.LSTM': [], 'tensorflow.keras.layers.Dense': [], 'tensorflow.keras.Sequential': [], 'tensorflow.random.categorical': [], 'tensorflow.squeeze': [], '01_char_lstm.loss': ['tensorflow.keras.losses.sparse_categorical_crossentropy'], 'tensorflow.keras.losses.sparse_categorical_crossentropy': [], 'os.path.join': [], 'tensorflow.keras.callbacks.ModelCheckpoint': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\text-generation\\01_char_lstm.py\n",
      "[('01_char_lstm', 'tensorflow data Dataset from_tensor_slices'), ('01_char_lstm', 'tensorflow keras callbacks ModelCheckpoint'), ('01_char_lstm', 'numpy array'), ('01_char_lstm', 'tensorflow random categorical'), ('01_char_lstm', 'os path join'), ('01_char_lstm', 'tensorflow squeeze'), ('01_char_lstm', '01_char_lstm build_model'), ('01_char_lstm', '01_char_lstm loss'), ('01_char_lstm build_model', 'tensorflow keras layers Dense'), ('01_char_lstm build_model', 'tensorflow keras layers Embedding'), ('01_char_lstm build_model', 'tensorflow keras layers LSTM'), ('01_char_lstm build_model', 'tensorflow keras Sequential'), ('01_char_lstm loss', 'tensorflow keras losses sparse_categorical_crossentropy')]\n",
      "0\n",
      "found files: []\n",
      "import tensorflow as tf\n",
      "import tensorflow_addons as tfa\n",
      "from sklearn.utils import shuffle\n",
      "import re\n",
      "import time\n",
      "import collections\n",
      "\n",
      "tf.compat.v1.disable_v2_behavior()\n",
      "\n",
      "HIDDEN_LAYER = 256\n",
      "NUM_LAYERS = 2\n",
      "EMBEDDING_SIZE = 128\n",
      "LEARNING_RATE = 1e-2\n",
      "BATCH_SIZE = 16\n",
      "NUM_EPOCHS = 20\n",
      "\n",
      "\n",
      "def generate_dataset(words, n_words, atleast=1):\n",
      "  count = [['PAD', 0], ['GO', 1], ['EOS', 2], ['UNK', 3]]\n",
      "  counter = collections.Counter(words).most_common(n_words)\n",
      "  counter = [i for i in counter if i[1] >= atleast]\n",
      "  count.extend(counter)\n",
      "  dictionary = dict()\n",
      "  for word, _ in count:\n",
      "    dictionary[word] = len(dictionary)\n",
      "  data = list()\n",
      "  unk_count = 0\n",
      "  for word in words:\n",
      "    index = dictionary.get(word, 0)\n",
      "    if index == 0:\n",
      "      unk_count += 1\n",
      "    data.append(index)\n",
      "  count[0][1] = unk_count\n",
      "  reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
      "  return data, count, dictionary, reversed_dictionary\n",
      "\n",
      "\n",
      "lines = open('movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
      "conv_lines = open('movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
      "\n",
      "id2line = {}\n",
      "for line in lines:\n",
      "  _line = line.split(' +++$+++ ')\n",
      "  if len(_line) == 5:\n",
      "    id2line[_line[0]] = _line[4]\n",
      "\n",
      "convs = []\n",
      "for line in conv_lines[:-1]:\n",
      "  _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\").replace(\" \", \"\")\n",
      "  convs.append(_line.split(','))\n",
      "\n",
      "questions = []\n",
      "answers = []\n",
      "\n",
      "for conv in convs:\n",
      "  for i in range(len(conv) - 1):\n",
      "    questions.append(id2line[conv[i]])\n",
      "    answers.append(id2line[conv[i + 1]])\n",
      "\n",
      "\n",
      "def cleanup_and_expand_text(text):\n",
      "  text = text.lower()\n",
      "  text = re.sub(r\"i'm\", \"i am\", text)\n",
      "  text = re.sub(r\"he's\", \"he is\", text)\n",
      "  text = re.sub(r\"she's\", \"she is\", text)\n",
      "  text = re.sub(r\"it's\", \"it is\", text)\n",
      "  text = re.sub(r\"that's\", \"that is\", text)\n",
      "  text = re.sub(r\"what's\", \"that is\", text)\n",
      "  text = re.sub(r\"where's\", \"where is\", text)\n",
      "  text = re.sub(r\"how's\", \"how is\", text)\n",
      "  text = re.sub(r\"\\'ll\", \" will\", text)\n",
      "  text = re.sub(r\"\\'ve\", \" have\", text)\n",
      "  text = re.sub(r\"\\'re\", \" are\", text)\n",
      "  text = re.sub(r\"\\'d\", \" would\", text)\n",
      "  text = re.sub(r\"\\'re\", \" are\", text)\n",
      "  text = re.sub(r\"won't\", \"will not\", text)\n",
      "  text = re.sub(r\"can't\", \"cannot\", text)\n",
      "  text = re.sub(r\"n't\", \" not\", text)\n",
      "  text = re.sub(r\"n'\", \"ng\", text)\n",
      "  text = re.sub(r\"'bout\", \"about\", text)\n",
      "  text = re.sub(r\"'til\", \"until\", text)\n",
      "  text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
      "  return ' '.join([i.strip() for i in filter(None, text.split())])\n",
      "\n",
      "\n",
      "clean_questions = []\n",
      "for question in questions:\n",
      "  clean_questions.append(cleanup_and_expand_text(question))\n",
      "\n",
      "clean_answers = []\n",
      "for answer in answers:\n",
      "  clean_answers.append(cleanup_and_expand_text(answer))\n",
      "\n",
      "min_line_length = 2\n",
      "max_line_length = 5\n",
      "short_questions_temp = []\n",
      "short_answers_temp = []\n",
      "\n",
      "i = 0\n",
      "for question in clean_questions:\n",
      "  if min_line_length <= len(question.split()) <= max_line_length:\n",
      "    short_questions_temp.append(question)\n",
      "    short_answers_temp.append(clean_answers[i])\n",
      "  i += 1\n",
      "\n",
      "short_questions = []\n",
      "short_answers = []\n",
      "\n",
      "i = 0\n",
      "for answer in short_answers_temp:\n",
      "  if min_line_length <= len(answer.split()) <= max_line_length:\n",
      "    short_answers.append(answer)\n",
      "    short_questions.append(short_questions_temp[i])\n",
      "  i += 1\n",
      "\n",
      "question_test = short_questions[500:550]\n",
      "answer_test = short_answers[500:550]\n",
      "short_questions = short_questions[:500]\n",
      "short_answers = short_answers[:500]\n",
      "\n",
      "# Generate the question dataset -> the input\n",
      "concat_from = ' '.join(short_questions + question_test).split()\n",
      "vocabulary_size_from = len(list(set(concat_from)))\n",
      "data_from, count_from, dictionary_from, rev_dictionary_from = generate_dataset(concat_from, vocabulary_size_from)\n",
      "\n",
      "# Generate the answer dataset -> the target\n",
      "concat_to = ' '.join(short_answers + answer_test).split()\n",
      "vocabulary_size_to = len(list(set(concat_to)))\n",
      "data_to, count_to, dictionary_to, rev_dictionary_to = generate_dataset(concat_to, vocabulary_size_to)\n",
      "\n",
      "# Shortcuts to functional tags\n",
      "GO = dictionary_from['GO']\n",
      "PAD = dictionary_from['PAD']\n",
      "EOS = dictionary_from['EOS']\n",
      "UNK = dictionary_from['UNK']\n",
      "\n",
      "for i in range(len(short_answers)):\n",
      "  short_answers[i] += ' EOS'\n",
      "\n",
      "print(\"questions: {}\".format(questions[:2]))\n",
      "print(\"answers: {}\".format(answers[:2]))\n",
      "\n",
      "print(\"short_questions: {}\".format(short_questions[:2]))\n",
      "print(\"short_answers: {}\".format(short_answers[:2]))\n",
      "\n",
      "\n",
      "# Helper method for transforming dataset to indices\n",
      "def str_idx(corpus, dic):\n",
      "  X = []\n",
      "  for i in corpus:\n",
      "    ints = []\n",
      "    for k in i.split():\n",
      "      ints.append(dic.get(k, UNK))\n",
      "    X.append(ints)\n",
      "  return X\n",
      "\n",
      "\n",
      "class RNNChatbot(object):\n",
      "  def __init__(self, hidden_size, num_layers, embedded_size,\n",
      "               from_dict_size, to_dict_size, learning_rate, batch_size):\n",
      "    super(RNNChatbot, self).__init__()\n",
      "    \n",
      "    def cells(h_size, reuse=False):\n",
      "      return tf.compat.v1.nn.rnn_cell.BasicRNNCell(h_size, reuse=reuse)\n",
      "    \n",
      "    self.X = tf.compat.v1.placeholder(tf.int32, [None, None])\n",
      "    self.Y = tf.compat.v1.placeholder(tf.int32, [None, None])\n",
      "    self.X_seq_len = tf.compat.v1.placeholder(tf.int32, [None])\n",
      "    self.Y_seq_len = tf.compat.v1.placeholder(tf.int32, [None])\n",
      "    batch_size = tf.shape(input=self.X)[0]\n",
      "    \n",
      "    encoder_embeddings = tf.Variable(tf.random.uniform([from_dict_size, embedded_size], -1, 1))\n",
      "    encoder_embedded = tf.nn.embedding_lookup(params=encoder_embeddings, ids=self.X)\n",
      "    main = tf.strided_slice(self.X, [0, 0], [batch_size, -1], [1, 1])\n",
      "    decoder_input = tf.concat([tf.fill([batch_size, 1], GO), main], 1)\n",
      "    decoder_embedded = tf.nn.embedding_lookup(params=encoder_embeddings, ids=decoder_input)\n",
      "    \n",
      "    # Multi layer architecture ->\n",
      "    for l in range(num_layers):\n",
      "      (o_fw, o_bw), (s_fw, s_bw) = tf.compat.v1.nn.bidirectional_dynamic_rnn(\n",
      "        cell_fw=cells(hidden_size // 2),\n",
      "        cell_bw=cells(hidden_size // 2),\n",
      "        inputs=encoder_embedded,\n",
      "        sequence_length=self.X_seq_len,\n",
      "        scope='birnn_L{}'.format(l),\n",
      "        dtype=tf.float32\n",
      "      )\n",
      "      encoder_embedded = tf.concat((o_fw, o_bw), axis=2)\n",
      "    \n",
      "    s_bi = tf.concat((s_fw, s_bw), axis=-1)\n",
      "    s_last = tuple([s_bi] * num_layers)\n",
      "    \n",
      "    with tf.compat.v1.variable_scope(\"decoder\"):\n",
      "      rnn_cells_dec = tf.compat.v1.nn.rnn_cell.MultiRNNCell([cells(hidden_size) for _ in range(num_layers)])\n",
      "      outputs, _ = tf.compat.v1.nn.dynamic_rnn(rnn_cells_dec, decoder_embedded,\n",
      "                                               sequence_length=self.X_seq_len,\n",
      "                                               initial_state=s_last,\n",
      "                                               dtype=tf.float32)\n",
      "    self.logits = tf.compat.v1.layers.dense(outputs, to_dict_size)\n",
      "    masks = tf.sequence_mask(self.Y_seq_len, tf.reduce_max(input_tensor=self.Y_seq_len), dtype=tf.float32)\n",
      "    self.cost = tfa.seq2seq.sequence_loss(logits=self.logits,\n",
      "                                          targets=self.Y,\n",
      "                                          weights=masks)\n",
      "    self.optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost)\n",
      "    y_t = tf.argmax(input=self.logits, axis=2)\n",
      "    y_t = tf.cast(y_t, tf.int32)\n",
      "    self.prediction = tf.boolean_mask(tensor=y_t, mask=masks)\n",
      "    mask_label = tf.boolean_mask(tensor=self.Y, mask=masks)\n",
      "    correct_pred = tf.equal(self.prediction, mask_label)\n",
      "    self.accuracy = tf.reduce_mean(input_tensor=tf.cast(correct_pred, tf.float32))\n",
      "\n",
      "\n",
      "# Start the session (this is < TF 2.0)\n",
      "tf.compat.v1.reset_default_graph()\n",
      "sess = tf.compat.v1.InteractiveSession()\n",
      "model = RNNChatbot(\n",
      "  HIDDEN_LAYER,\n",
      "  NUM_LAYERS,\n",
      "  EMBEDDING_SIZE,\n",
      "  len(dictionary_from),\n",
      "  len(dictionary_to),\n",
      "  LEARNING_RATE,\n",
      "  BATCH_SIZE)\n",
      "sess.run(tf.compat.v1.global_variables_initializer())\n",
      "\n",
      "# Transform input and output to indices\n",
      "X = str_idx(short_questions, dictionary_from)\n",
      "Y = str_idx(short_answers, dictionary_to)\n",
      "X_test = str_idx(question_test, dictionary_from)\n",
      "Y_test = str_idx(answer_test, dictionary_from)\n",
      "\n",
      "# For batching the input and target we will need the max. length of each\n",
      "maxlen_question = max([len(x) for x in X]) * 2\n",
      "maxlen_answer = max([len(y) for y in Y]) * 2\n",
      "# For simplicity let's use the longest length\n",
      "maxlen = max(maxlen_question, maxlen_answer)\n",
      "\n",
      "\n",
      "# Batching input and target sequences according to the max. length of each\n",
      "def pad_sentence_batch(sentence_batch, pad_int, maxlen):\n",
      "  padded_seqs = []\n",
      "  seq_lens = []\n",
      "  max_sentence_len = maxlen\n",
      "  for sentence in sentence_batch:\n",
      "    padded_seqs.append(sentence + [pad_int] * (max_sentence_len - len(sentence)))\n",
      "    seq_lens.append(maxlen)\n",
      "  return padded_seqs, seq_lens\n",
      "\n",
      "\n",
      "# Training\n",
      "for i in range(NUM_EPOCHS):\n",
      "  start_time = time.time()\n",
      "  total_loss, total_accuracy = 0, 0\n",
      "  X, Y = shuffle(X, Y)\n",
      "  for k in range(0, len(short_questions), BATCH_SIZE):\n",
      "    index = min(k + BATCH_SIZE, len(short_questions))\n",
      "    batch_x, seq_x = pad_sentence_batch(X[k: index], PAD, maxlen)\n",
      "    batch_y, seq_y = pad_sentence_batch(Y[k: index], PAD, maxlen)\n",
      "    predicted, accuracy, loss, _ = sess.run(\n",
      "      [\n",
      "        tf.argmax(input=model.logits, axis=2),\n",
      "        model.accuracy,\n",
      "        model.cost,\n",
      "        model.optimizer\n",
      "      ],\n",
      "      feed_dict={\n",
      "        model.X: batch_x,\n",
      "        model.Y: batch_y,\n",
      "        model.X_seq_len: seq_x,\n",
      "        model.Y_seq_len: seq_y\n",
      "      }\n",
      "    )\n",
      "    total_loss += loss\n",
      "    total_accuracy += accuracy\n",
      "    print('REAL ANSWER:', ' '.join([rev_dictionary_to[n] for n in batch_y[0] if n not in [0, 1, 2, 3]]))\n",
      "    print('PREDICTED ANSWER:', ' '.join([rev_dictionary_to[n] for n in predicted[0] if n not in [0, 1, 2, 3]]), '\\n')\n",
      "  total_loss /= (len(short_questions) / BATCH_SIZE)\n",
      "  total_accuracy /= (len(short_questions) / BATCH_SIZE)\n",
      "  diff_time = time.time() - start_time\n",
      "  print('[%f seconds] epoch: %d, avg loss: %f, avg accuracy: %f' % (diff_time, i + 1, total_loss, total_accuracy))\n",
      "\n",
      "# Testing\n",
      "batch_x, seq_x = pad_sentence_batch(X_test[:BATCH_SIZE], PAD, maxlen)\n",
      "batch_y, seq_y = pad_sentence_batch(Y_test[:BATCH_SIZE], PAD, maxlen)\n",
      "predicted = sess.run(tf.argmax(input=model.logits, axis=2), feed_dict={model.X: batch_x, model.X_seq_len: seq_x})\n",
      "\n",
      "# Results\n",
      "print(\"########################\")\n",
      "print(\"# TESTING\")\n",
      "print(\"########################\")\n",
      "for i in range(len(batch_x)):\n",
      "  print('row %d' % (i + 1))\n",
      "  print('QUESTION:', ' '.join([rev_dictionary_from[n] for n in batch_x[i] if n not in [0, 1, 2, 3]]))\n",
      "  print('REAL ANSWER:', ' '.join([rev_dictionary_to[n] for n in batch_y[i] if n not in [0, 1, 2, 3]]))\n",
      "  print('PREDICTED ANSWER:', ' '.join([rev_dictionary_to[n] for n in predicted[i] if n not in [0, 1, 2, 3]]), '\\n')\n",
      "\n",
      "Output: {'04_seq2seq_birnn': ['<builtin>.open', '04_seq2seq_birnn.cleanup_and_expand_text', 'tensorflow.compat.v1.InteractiveSession', '<builtin>.range', 'sklearn.utils.shuffle', 'tensorflow.compat.v1.reset_default_graph', '04_seq2seq_birnn.str_idx', '04_seq2seq_birnn.generate_dataset', 'tensorflow.argmax', '<builtin>.max', '<builtin>.len', 'tensorflow.compat.v1.global_variables_initializer', '<builtin>.print', 'tensorflow.compat.v1.disable_v2_behavior', '04_seq2seq_birnn.RNNChatbot.__init__', '<builtin>.set', '<builtin>.list', '<builtin>.min', 'time.time', '04_seq2seq_birnn.pad_sentence_batch'], 'tensorflow.compat.v1.disable_v2_behavior': [], '04_seq2seq_birnn.generate_dataset': ['<builtin>.list', '<builtin>.len', '<builtin>.dict', '<builtin>.zip', 'collections.Counter'], 'collections.Counter': [], '<builtin>.dict': [], '<builtin>.len': [], '<builtin>.list': [], '<builtin>.zip': [], '<builtin>.open': [], '<builtin>.range': [], '04_seq2seq_birnn.cleanup_and_expand_text': ['<builtin>.filter', 're.sub'], 're.sub': [], '<builtin>.filter': [], '<builtin>.set': [], '<builtin>.print': [], '04_seq2seq_birnn.str_idx': [], '04_seq2seq_birnn.RNNChatbot.__init__': ['tensorflow.cast', '<builtin>.tuple', 'tensorflow.compat.v1.layers.dense', 'tensorflow_addons.seq2seq.sequence_loss', '04_seq2seq_birnn.RNNChatbot.__init__.cells', '<builtin>.range', 'tensorflow.boolean_mask', 'tensorflow.compat.v1.placeholder', 'tensorflow.nn.embedding_lookup', 'tensorflow.concat', 'tensorflow.shape', 'tensorflow.compat.v1.train.AdamOptimizer', 'tensorflow.reduce_mean', 'tensorflow.argmax', 'tensorflow.Variable', 'tensorflow.compat.v1.variable_scope', 'tensorflow.strided_slice', 'tensorflow.compat.v1.nn.rnn_cell.MultiRNNCell', 'tensorflow.random.uniform', '<builtin>.super', 'tensorflow.equal', 'tensorflow.sequence_mask', 'tensorflow.fill', 'tensorflow.compat.v1.nn.bidirectional_dynamic_rnn', 'tensorflow.reduce_max', 'tensorflow.compat.v1.nn.dynamic_rnn'], '<builtin>.super': [], '04_seq2seq_birnn.RNNChatbot.__init__.cells': ['tensorflow.compat.v1.nn.rnn_cell.BasicRNNCell'], 'tensorflow.compat.v1.nn.rnn_cell.BasicRNNCell': [], 'tensorflow.compat.v1.placeholder': [], 'tensorflow.shape': [], 'tensorflow.random.uniform': [], 'tensorflow.Variable': [], 'tensorflow.nn.embedding_lookup': [], 'tensorflow.strided_slice': [], 'tensorflow.fill': [], 'tensorflow.concat': [], 'tensorflow.compat.v1.nn.bidirectional_dynamic_rnn': [], '<builtin>.tuple': [], 'tensorflow.compat.v1.variable_scope': [], 'tensorflow.compat.v1.nn.rnn_cell.MultiRNNCell': [], 'tensorflow.compat.v1.nn.dynamic_rnn': [], 'tensorflow.compat.v1.layers.dense': [], 'tensorflow.reduce_max': [], 'tensorflow.sequence_mask': [], 'tensorflow_addons.seq2seq.sequence_loss': [], 'tensorflow.compat.v1.train.AdamOptimizer': [], 'tensorflow.argmax': [], 'tensorflow.cast': [], 'tensorflow.boolean_mask': [], 'tensorflow.equal': [], 'tensorflow.reduce_mean': [], 'tensorflow.compat.v1.reset_default_graph': [], 'tensorflow.compat.v1.InteractiveSession': [], 'tensorflow.compat.v1.global_variables_initializer': [], '<builtin>.max': [], '04_seq2seq_birnn.pad_sentence_batch': ['<builtin>.len'], 'time.time': [], 'sklearn.utils.shuffle': [], '<builtin>.min': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\chatbot\\04_seq2seq_birnn.py\n",
      "[('04_seq2seq_birnn', '04_seq2seq_birnn cleanup_and_expand_text'), ('04_seq2seq_birnn', 'tensorflow compat v1 InteractiveSession'), ('04_seq2seq_birnn', 'sklearn utils shuffle'), ('04_seq2seq_birnn', 'tensorflow compat v1 reset_default_graph'), ('04_seq2seq_birnn', '04_seq2seq_birnn str_idx'), ('04_seq2seq_birnn', '04_seq2seq_birnn generate_dataset'), ('04_seq2seq_birnn', 'tensorflow argmax'), ('04_seq2seq_birnn', 'tensorflow compat v1 global_variables_initializer'), ('04_seq2seq_birnn', 'tensorflow compat v1 disable_v2_behavior'), ('04_seq2seq_birnn', '04_seq2seq_birnn RNNChatbot __init__'), ('04_seq2seq_birnn', 'time time'), ('04_seq2seq_birnn', '04_seq2seq_birnn pad_sentence_batch'), ('04_seq2seq_birnn generate_dataset', 'collections Counter'), ('04_seq2seq_birnn cleanup_and_expand_text', 're sub'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow cast'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow compat v1 layers dense'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow_addons seq2seq sequence_loss'), ('04_seq2seq_birnn RNNChatbot __init__', '04_seq2seq_birnn RNNChatbot __init__ cells'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow boolean_mask'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow compat v1 placeholder'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow nn embedding_lookup'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow concat'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow shape'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow compat v1 train AdamOptimizer'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow reduce_mean'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow argmax'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow Variable'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow compat v1 variable_scope'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow strided_slice'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow compat v1 nn rnn_cell MultiRNNCell')]\n",
      "0\n",
      "found files: []\n",
      "\n",
      "\"\"\"\n",
      "Based on the BERT model, further described in:\n",
      "'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'\n",
      "\n",
      "Source: https://arxiv.org/abs/1810.04805v2\n",
      "\"\"\"\n",
      "\n",
      "# If using the cased variant set those variables to ^cased too\n",
      "BERT_VOCAB = 'uncased_L-12_H-768_A-12/vocab.txt'\n",
      "BERT_INIT_CHKPNT = 'uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
      "BERT_CONFIG = 'uncased_L-12_H-768_A-12/bert_config.json'\n",
      "USE_LOWER = True\n",
      "\n",
      "num_epochs = 5\n",
      "batch_size = 8\n",
      "warmup_proportion = 0.1\n",
      "# Learning Rate\n",
      "LR = 2e-5\n",
      "\n",
      "seq_len = 50\n",
      "\n",
      "import os\n",
      "import sys\n",
      "import time\n",
      "import regex as re\n",
      "\n",
      "from tqdm import tqdm\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "import tensorflow.keras as keras\n",
      "\n",
      "import bert\n",
      "from bert import run_classifier\n",
      "from bert import optimization\n",
      "from bert import tokenization\n",
      "from bert import modeling\n",
      "\n",
      "\n",
      "#\n",
      "# The parsing from the given training and test set files.\n",
      "# If you want to change the task from Entity- to POS-Tagging just exchange the\n",
      "# marked line\n",
      "#\n",
      "\n",
      "\n",
      "# Read and parse train and test sets\n",
      "def parse(file):\n",
      "    with open(file, 'r', encoding='utf-8') as fin:\n",
      "        texts = fin.readlines()\n",
      "    x, y = [], []\n",
      "    for t in texts:\n",
      "        # Skip uninformative lines\n",
      "        if \"-DOCSTART-\" in t or len(t) <= 1:\n",
      "            continue\n",
      "        split_ = t.split()\n",
      "        x.append(split_[0])\n",
      "        y.append(split_[-1])\n",
      "    return x, y\n",
      "\n",
      "\n",
      "x_train, y_train = parse('eng.train')\n",
      "x_test, y_test = parse('eng.testa')\n",
      "\n",
      "\n",
      "#\n",
      "# Just some length padding and extraction of all tags\n",
      "#\n",
      "\n",
      "\n",
      "def iter_seq(X):\n",
      "    return np.array([X[i:i + seq_len] for i in range(0, len(X) - seq_len, 1)])\n",
      "\n",
      "\n",
      "def to_train_seq(*args):\n",
      "    return [iter_seq(x) for x in args]\n",
      "\n",
      "\n",
      "x_train, y_train = to_train_seq(x_train, y_train)\n",
      "x_test, y_test = to_train_seq(x_test, y_test)\n",
      "\n",
      "tag2idx = {\"PAD\": 0}\n",
      "\n",
      "for no, u in enumerate(np.unique(y_train)):\n",
      "    tag2idx[u] = no + 1\n",
      "print(\"generated tagset: {}\".format(tag2idx))\n",
      "\n",
      "tokenization.validate_case_matches_checkpoint(USE_LOWER, BERT_INIT_CHKPNT)\n",
      "tokenizer = tokenization.FullTokenizer(\n",
      "  vocab_file=BERT_VOCAB,\n",
      "  do_lower_case=USE_LOWER\n",
      ")\n",
      "\n",
      "\n",
      "def parseXY(x, y):\n",
      "    X, Y = [], []\n",
      "    for i in tqdm(range(len(x))):\n",
      "        left = x[i]\n",
      "        right = y[i]\n",
      "        \n",
      "        # The beginning of a sentence, CLS stands thereby for CLASSIFICATION\n",
      "        bert_tokens = ['[CLS]']\n",
      "        # The padding\n",
      "        y_ = ['PAD']\n",
      "        \n",
      "        for no, orig_token in enumerate(left):\n",
      "            y_.append(right[no])\n",
      "            t = tokenizer.tokenize(orig_token)\n",
      "            bert_tokens.extend(t)\n",
      "            y_.extend(['PAD'] * (len(t) - 1))\n",
      "        # The SEP is required for the separation of sentences\n",
      "        bert_tokens.append(\"[SEP]\")\n",
      "        \n",
      "        y_.append(\"PAD\")\n",
      "        X.append(tokenizer.convert_tokens_to_ids(bert_tokens))\n",
      "        Y.append([tag2idx[i] for i in y_])\n",
      "    \n",
      "    return X, Y\n",
      "\n",
      "\n",
      "train_X, train_Y = parseXY(x_train, y_train)\n",
      "test_X, test_Y = parseXY(x_test, y_test)\n",
      "\n",
      "train_X = keras.preprocessing.sequence.pad_sequences(train_X, padding='post')\n",
      "train_Y = keras.preprocessing.sequence.pad_sequences(train_Y, padding='post')\n",
      "\n",
      "test_X = keras.preprocessing.sequence.pad_sequences(test_X, padding='post')\n",
      "test_Y = keras.preprocessing.sequence.pad_sequences(test_Y, padding='post')\n",
      "\n",
      "num_train_steps = int(len(train_X) / batch_size * num_epochs)\n",
      "num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
      "\n",
      "bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG)\n",
      "\n",
      "\n",
      "#\n",
      "# The model\n",
      "#\n",
      "class BERTEntityTagger(object):\n",
      "  \n",
      "    def __init__(\n",
      "      self,\n",
      "      dimension_output,\n",
      "      learning_rate=2e-5\n",
      "    ):\n",
      "        self.X = tf.placeholder(tf.int32, shape=[None, None])\n",
      "        self.Y = tf.placeholder(tf.int32, shape=[None, None])\n",
      "        \n",
      "        self.maxlen = tf.shape(self.X)[1]\n",
      "        # We can evaluate the length this way because PAD is 0\n",
      "        self.lengths = tf.count_nonzero(self.X, 1)\n",
      "        \n",
      "        #\n",
      "        # The procedure of finetuning bert is:\n",
      "        # - Create the default BERT model\n",
      "        # - Fetch the output layer and pass it to a dense layer, with output dim #TAGS\n",
      "        #\n",
      "        model = modeling.BertModel(\n",
      "          config=bert_config,\n",
      "          is_training=True,\n",
      "          input_ids=self.X,\n",
      "          use_one_hot_embeddings=False\n",
      "        )\n",
      "        output_layer = model.get_sequence_output()\n",
      "        \n",
      "        logits = tf.layers.dense(output_layer, dimension_output)\n",
      "        \n",
      "        #\n",
      "        # This is specific for training, as one can see we are using CRF\n",
      "        #\n",
      "        y_t = self.Y\n",
      "        \n",
      "        llh, transitions = tf.contrib.crf.crf_log_likelihood(logits, y_t, self.lengths)\n",
      "        \n",
      "        self.loss = tf.reduce_mean(-llh)\n",
      "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss)\n",
      "        \n",
      "        mask = tf.sequence_mask(self.lengths, maxlen=self.maxlen)\n",
      "        self.tags_seq, _ = tf.contrib.crf.crf_decode(logits, transitions, self.lengths)\n",
      "        self.tags_seq = tf.identity(self.tags_seq, name='logits')\n",
      "        \n",
      "        y_t = tf.cast(y_t, tf.int32)\n",
      "        self.prediction = tf.boolean_mask(self.tags_seq, mask)\n",
      "        \n",
      "        mask_label = tf.boolean_mask(y_t, mask)\n",
      "        \n",
      "        correct_prediction = tf.equal(self.prediction, mask_label)\n",
      "        \n",
      "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
      "\n",
      "\n",
      "#\n",
      "# TRAINING\n",
      "#\n",
      "dimension_output = len(tag2idx)\n",
      "\n",
      "tf.reset_default_graph()\n",
      "sess = tf.InteractiveSession()\n",
      "\n",
      "model = BERTEntityTagger(dimension_output, learning_rate=LR)\n",
      "\n",
      "sess.run(tf.global_variables_initializer())\n",
      "var_lists = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='bert')\n",
      "\n",
      "# load the pretrained model\n",
      "saver = tf.train.Saver(var_list=var_lists)\n",
      "saver.restore(sess, BERT_INIT_CHKPNT)\n",
      "\n",
      "for e in range(num_epochs):\n",
      "    start_time = time.time()\n",
      "    \n",
      "    #\n",
      "    # Training\n",
      "    #\n",
      "    train_acc, train_loss, test_acc, test_loss = 0.0, 0.0, 0.0, 0.0\n",
      "    \n",
      "    progress = tqdm(range(0, len(train_X), batch_size), desc='training loop')\n",
      "    \n",
      "    for i in progress:\n",
      "        batch_x = train_X[i:min(i + batch_size, train_X.shape[0])]\n",
      "        batch_y = train_Y[i:min(i + batch_size, train_X.shape[0])]\n",
      "        \n",
      "        acc, loss, _ = sess.run(\n",
      "          [model.accuracy, model.loss, model.optimizer],\n",
      "          feed_dict={model.X: batch_x, model.Y: batch_y}\n",
      "        )\n",
      "        \n",
      "        assert not np.isnan(loss)\n",
      "        \n",
      "        train_loss += loss\n",
      "        train_acc += acc\n",
      "        progress.set_postfix(loss=loss, accuracy=acc)\n",
      "    \n",
      "    #\n",
      "    # Testing\n",
      "    #\n",
      "    progress = tqdm(range(0, len(test_X), batch_size), desc='test loop')\n",
      "    \n",
      "    for i in progress:\n",
      "        batch_x = test_X[i:min(i + batch_size, test_X.shape[0])]\n",
      "        batch_y = test_Y[i:min(i + batch_size, test_X.shape[0])]\n",
      "        \n",
      "        acc, loss = sess.run(\n",
      "          [model.accuracy, model.loss],\n",
      "          feed_dict={model.X: batch_x, model.Y: batch_y}\n",
      "        )\n",
      "        \n",
      "        assert not np.isnan(loss)\n",
      "        \n",
      "        test_loss += loss\n",
      "        test_acc += acc\n",
      "        progress.set_postfix(loss=loss, accuracy=acc)\n",
      "    \n",
      "    train_loss /= len(train_X) / batch_size\n",
      "    train_acc /= len(train_X) / batch_size\n",
      "    test_loss /= len(test_X) / batch_size\n",
      "    test_acc /= len(test_X) / batch_size\n",
      "    \n",
      "    print(\"Whole epoch took {} s\".format(time.time() - start_time))\n",
      "    \n",
      "    print(\"epoch {} values: {} training loss; {} training acc; {} test loss; {} test acc\".format(\n",
      "      e, train_loss, train_acc, test_loss, test_acc\n",
      "    ))\n",
      "\n",
      "Output: {'10_bert': ['<builtin>.enumerate', '10_bert.to_train_seq', 'tensorflow.reset_default_graph', '10_bert.parseXY', 'tensorflow.InteractiveSession', 'tensorflow.global_variables_initializer', 'tensorflow.get_collection', 'tensorflow.train.Saver', 'bert.tokenization.FullTokenizer', '<builtin>.print', 'numpy.isnan', 'tqdm.tqdm', '10_bert.BERTEntityTagger.__init__', 'tensorflow.keras.preprocessing.sequence.pad_sequences', '<builtin>.len', 'bert.tokenization.validate_case_matches_checkpoint', '10_bert.parse', '<builtin>.range', 'bert.modeling.BertConfig.from_json_file', '<builtin>.int', 'time.time', 'numpy.unique', '<builtin>.min'], '10_bert.parse': ['<builtin>.len', '<builtin>.open'], '<builtin>.open': [], '<builtin>.len': [], '10_bert.iter_seq': ['<builtin>.len', '<builtin>.range', 'numpy.array'], '<builtin>.range': [], 'numpy.array': [], '10_bert.to_train_seq': ['10_bert.iter_seq'], 'numpy.unique': [], '<builtin>.enumerate': [], '<builtin>.print': [], 'bert.tokenization.validate_case_matches_checkpoint': [], 'bert.tokenization.FullTokenizer': [], '10_bert.parseXY': ['<builtin>.enumerate', '<builtin>.len', '<builtin>.range', 'tqdm.tqdm'], 'tqdm.tqdm': [], 'tensorflow.keras.preprocessing.sequence.pad_sequences': [], '<builtin>.int': [], 'bert.modeling.BertConfig.from_json_file': [], '10_bert.BERTEntityTagger.__init__': ['tensorflow.shape', 'tensorflow.contrib.crf.crf_log_likelihood', 'tensorflow.layers.dense', 'tensorflow.reduce_mean', 'tensorflow.train.AdamOptimizer', 'tensorflow.boolean_mask', 'tensorflow.contrib.crf.crf_decode', 'tensorflow.equal', 'bert.modeling.BertModel', 'tensorflow.sequence_mask', 'tensorflow.identity', 'tensorflow.count_nonzero', 'tensorflow.placeholder', 'tensorflow.cast'], 'tensorflow.placeholder': [], 'tensorflow.shape': [], 'tensorflow.count_nonzero': [], 'bert.modeling.BertModel': [], 'tensorflow.layers.dense': [], 'tensorflow.contrib.crf.crf_log_likelihood': [], 'tensorflow.reduce_mean': [], 'tensorflow.train.AdamOptimizer': [], 'tensorflow.sequence_mask': [], 'tensorflow.contrib.crf.crf_decode': [], 'tensorflow.identity': [], 'tensorflow.cast': [], 'tensorflow.boolean_mask': [], 'tensorflow.equal': [], 'tensorflow.reset_default_graph': [], 'tensorflow.InteractiveSession': [], 'tensorflow.global_variables_initializer': [], 'tensorflow.get_collection': [], 'tensorflow.train.Saver': [], 'time.time': [], '<builtin>.min': [], 'numpy.isnan': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\entity-tagging\\10_bert.py\n",
      "[('10_bert', '10_bert to_train_seq'), ('10_bert', 'tensorflow reset_default_graph'), ('10_bert', '10_bert parseXY'), ('10_bert', 'tensorflow InteractiveSession'), ('10_bert', 'tensorflow global_variables_initializer'), ('10_bert', 'tensorflow get_collection'), ('10_bert', 'tensorflow train Saver'), ('10_bert', 'bert tokenization FullTokenizer'), ('10_bert', 'numpy isnan'), ('10_bert', 'tqdm tqdm'), ('10_bert', '10_bert BERTEntityTagger __init__'), ('10_bert', 'tensorflow keras preprocessing sequence pad_sequences'), ('10_bert', 'bert tokenization validate_case_matches_checkpoint'), ('10_bert', '10_bert parse'), ('10_bert', 'bert modeling BertConfig from_json_file'), ('10_bert', 'time time'), ('10_bert', 'numpy unique'), ('10_bert iter_seq', 'numpy array'), ('10_bert to_train_seq', '10_bert iter_seq'), ('10_bert parseXY', 'tqdm tqdm'), ('10_bert BERTEntityTagger __init__', 'tensorflow shape'), ('10_bert BERTEntityTagger __init__', 'tensorflow contrib crf crf_log_likelihood'), ('10_bert BERTEntityTagger __init__', 'tensorflow layers dense'), ('10_bert BERTEntityTagger __init__', 'tensorflow reduce_mean'), ('10_bert BERTEntityTagger __init__', 'tensorflow train AdamOptimizer'), ('10_bert BERTEntityTagger __init__', 'tensorflow boolean_mask'), ('10_bert BERTEntityTagger __init__', 'tensorflow contrib crf crf_decode'), ('10_bert BERTEntityTagger __init__', 'tensorflow equal'), ('10_bert BERTEntityTagger __init__', 'bert modeling BertModel'), ('10_bert BERTEntityTagger __init__', 'tensorflow sequence_mask')]\n",
      "0\n",
      "found files: []\n",
      "import nltk, random\n",
      "import numpy as np\n",
      "nltk.download('movie_reviews')\n",
      "from nltk.corpus import movie_reviews\n",
      "import tensorflow as tf\n",
      "from tensorflow import keras\n",
      "from tensorflow.keras import layers\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "\n",
      "documents = [\n",
      "    (' '.join(movie_reviews.words(fileid)), category)\n",
      "    for category in movie_reviews.categories()\n",
      "    for fileid in movie_reviews.fileids(category)]\n",
      "random.shuffle(documents)  #in-place shuffle\n",
      "\n",
      "train_set, test_set = train_test_split(documents, test_size=0.1, random_state=12)\n",
      "\n",
      "vocab_size = 10000\n",
      "maxlen = 200  # Only consider the last 200 words of each movie review\n",
      "embed_dim = 32\n",
      "num_heads = 2\n",
      "ff_dim = 32\n",
      "batch_size = 128\n",
      "epochs = 10\n",
      "\n",
      "## texts vs. labels\n",
      "texts = np.array([t for (t, l) in train_set])\n",
      "labels = np.array([1 if l == 'pos' else 0 for (t, l) in train_set])\n",
      "## tokenizer\n",
      "tokenizer = keras.preprocessing.text.Tokenizer(num_words=vocab_size)\n",
      "## fit tokenizer\n",
      "tokenizer.fit_on_texts(texts)\n",
      "## text to sequences\n",
      "texts_to_int = tokenizer.texts_to_sequences(texts)\n",
      "## pad sequences\n",
      "texts_to_int_pad = keras.preprocessing.sequence.pad_sequences(texts_to_int, maxlen=maxlen, truncating='pre', padding='pre')\n",
      "               \n",
      "x_train = texts_to_int_pad\n",
      "\n",
      "y_train = labels\n",
      "\n",
      "\n",
      "## Perform same vectorization on testing set\n",
      "x_val_text = np.array([t for (t,l) in test_set])\n",
      "\n",
      "x_val = keras.preprocessing.sequence.pad_sequences(\n",
      "    tokenizer.texts_to_sequences(x_val_text),\n",
      "    maxlen=maxlen,\n",
      "    truncating='pre',\n",
      "    padding='pre'\n",
      ")\n",
      "    \n",
      "y_val = np.array([1 if l == 'pos' else 0 for (t, l) in test_set])\n",
      "\n",
      "\n",
      "class Transformer(layers.Layer):\n",
      "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
      "        super(Transformer, self).__init__()\n",
      "        self.att = layers.MultiHeadAttention(num_heads=num_heads,\n",
      "                                             key_dim=embed_dim)\n",
      "        self.ffn = keras.Sequential([\n",
      "            layers.Dense(ff_dim, activation=\"relu\"),\n",
      "            layers.Dense(embed_dim),\n",
      "        ])\n",
      "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
      "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
      "        self.dropout1 = layers.Dropout(rate)\n",
      "        self.dropout2 = layers.Dropout(rate)\n",
      "\n",
      "    def call(self, inputs, training):\n",
      "        attn_output = self.att(inputs, inputs)\n",
      "        attn_output = self.dropout1(attn_output, training=training)\n",
      "        out1 = self.layernorm1(inputs + attn_output)\n",
      "        ffn_output = self.ffn(out1)\n",
      "        ffn_output = self.dropout2(ffn_output, training=training)\n",
      "        return self.layernorm2(out1 + ffn_output)\n",
      "        \n",
      "        \n",
      "class TokenAndPositionEmbedding(layers.Layer):\n",
      "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
      "        super(TokenAndPositionEmbedding, self).__init__()\n",
      "        self.token_emb = layers.Embedding(input_dim=vocab_size,\n",
      "                                          output_dim=embed_dim)\n",
      "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
      "\n",
      "    def call(self, x):\n",
      "        maxlen = tf.shape(x)[-1]\n",
      "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
      "        positions = self.pos_emb(positions)\n",
      "        x = self.token_emb(x)\n",
      "        return x + positions\n",
      "        \n",
      "\n",
      "## Using Sequential API\n",
      "model = keras.Sequential([\n",
      "    layers.Input(shape=(maxlen, )),\n",
      "    TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim),\n",
      "    Transformer(embed_dim, num_heads, ff_dim),\n",
      "    layers.GlobalAveragePooling1D(),\n",
      "    layers.Dropout(0.1),\n",
      "    layers.Dense(ff_dim, activation='relu'),\n",
      "    layers.Dropout(0.1),\n",
      "    layers.Dense(1, activation='sigmoid')\n",
      "])\n",
      "\n",
      "model.compile(\n",
      "    optimizer=\"adam\",\n",
      "    loss=\"binary_crossentropy\",\n",
      "    metrics=[\"accuracy\"])\n",
      "\n",
      "history = model.fit(\n",
      "    x_train,\n",
      "    y_train,\n",
      "    batch_size=batch_size,\n",
      "    epochs=epochs,\n",
      "    validation_data=(x_val, y_val))\n",
      "\n",
      "Output: {'tf_transformer': ['tf_transformer.Transformer.__init__', 'nltk.corpus.movie_reviews.words', 'tensorflow.keras.layers.Dense', 'tensorflow.keras.preprocessing.text.Tokenizer', 'random.shuffle', 'nltk.corpus.movie_reviews.fileids', 'tensorflow.keras.layers.GlobalAveragePooling1D', 'nltk.corpus.movie_reviews.categories', 'tensorflow.keras.preprocessing.sequence.pad_sequences', 'tensorflow.keras.Sequential', 'tf_transformer.TokenAndPositionEmbedding.__init__', 'tensorflow.keras.layers.Dropout', 'numpy.array', 'nltk.download', 'tensorflow.keras.layers.Input', 'sklearn.model_selection.train_test_split'], 'nltk.download': [], 'nltk.corpus.movie_reviews.words': [], 'nltk.corpus.movie_reviews.categories': [], 'nltk.corpus.movie_reviews.fileids': [], 'random.shuffle': [], 'sklearn.model_selection.train_test_split': [], 'numpy.array': [], 'tensorflow.keras.preprocessing.text.Tokenizer': [], 'tensorflow.keras.preprocessing.sequence.pad_sequences': [], 'tf_transformer.Transformer.__init__': ['tensorflow.keras.layers.Dense', 'tensorflow.keras.Sequential', '<builtin>.super', 'tensorflow.keras.layers.MultiHeadAttention', 'tensorflow.keras.layers.Dropout', 'tensorflow.keras.layers.LayerNormalization'], '<builtin>.super': [], 'tensorflow.keras.layers.MultiHeadAttention': [], 'tensorflow.keras.layers.Dense': [], 'tensorflow.keras.Sequential': [], 'tensorflow.keras.layers.LayerNormalization': [], 'tensorflow.keras.layers.Dropout': [], 'tf_transformer.Transformer.call': [], 'tf_transformer.TokenAndPositionEmbedding.__init__': ['<builtin>.super', 'tensorflow.keras.layers.Embedding'], 'tensorflow.keras.layers.Embedding': [], 'tf_transformer.TokenAndPositionEmbedding.call': ['tensorflow.shape', 'tensorflow.range'], 'tensorflow.shape': [], 'tensorflow.range': [], 'tensorflow.keras.layers.Input': [], 'tensorflow.keras.layers.GlobalAveragePooling1D': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\sentiment-analysis\\tf_transformer.py\n",
      "[('tf_transformer', 'tf_transformer Transformer __init__'), ('tf_transformer', 'nltk corpus movie_reviews words'), ('tf_transformer', 'tensorflow keras layers Dense'), ('tf_transformer', 'tensorflow keras preprocessing text Tokenizer'), ('tf_transformer', 'random shuffle'), ('tf_transformer', 'nltk corpus movie_reviews fileids'), ('tf_transformer', 'tensorflow keras layers GlobalAveragePooling1D'), ('tf_transformer', 'nltk corpus movie_reviews categories'), ('tf_transformer', 'tensorflow keras preprocessing sequence pad_sequences'), ('tf_transformer', 'tensorflow keras Sequential'), ('tf_transformer', 'tf_transformer TokenAndPositionEmbedding __init__'), ('tf_transformer', 'tensorflow keras layers Dropout'), ('tf_transformer', 'numpy array'), ('tf_transformer', 'nltk download'), ('tf_transformer', 'tensorflow keras layers Input'), ('tf_transformer', 'sklearn model_selection train_test_split'), ('tf_transformer Transformer __init__', 'tensorflow keras layers Dense'), ('tf_transformer Transformer __init__', 'tensorflow keras Sequential'), ('tf_transformer Transformer __init__', 'tensorflow keras layers MultiHeadAttention'), ('tf_transformer Transformer __init__', 'tensorflow keras layers Dropout'), ('tf_transformer Transformer __init__', 'tensorflow keras layers LayerNormalization'), ('tf_transformer TokenAndPositionEmbedding __init__', 'tensorflow keras layers Embedding'), ('tf_transformer TokenAndPositionEmbedding call', 'tensorflow shape'), ('tf_transformer TokenAndPositionEmbedding call', 'tensorflow range')]\n",
      "0\n",
      "found files: []\n",
      "# First, download the required data\n",
      "# !wget https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.train\n",
      "# !wget https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.testa\n",
      "\n",
      "import re\n",
      "import numpy as np\n",
      "import tensorflow\n",
      "from tensorflow.keras import backend as K\n",
      "from tensorflow.keras import Sequential, Model, Input\n",
      "from tensorflow.keras.layers import InputSpec, Layer\n",
      "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
      "from tensorflow.keras.utils import plot_model\n",
      "from tqdm import tqdm\n",
      "\n",
      "def parse(file):\n",
      "    with open(file) as fopen:\n",
      "        texts = fopen.read().split('\\n')\n",
      "    left, right = [], []\n",
      "    for text in texts:\n",
      "        if '-DOCSTART-' in text or not len(text):\n",
      "            continue\n",
      "        splitted = text.split()\n",
      "        left.append(splitted[0])\n",
      "        right.append(splitted[1])\n",
      "    return left, right\n",
      "    \n",
      "left_train, right_train = parse('eng.train')\n",
      "left_test, right_test = parse('eng.testa')\n",
      "\n",
      "def process_string(string):\n",
      "    string = re.sub('[^A-Za-z0-9\\-\\/ ]+', ' ', string).split()\n",
      "    return ' '.join([to_title(y.strip()) for y in string])\n",
      "\n",
      "def to_title(string):\n",
      "    if string.isupper():\n",
      "        string = string.title()\n",
      "    return string\n",
      "    \n",
      "word2idx = {'PAD': 0,'NUM':1,'UNK':2}\n",
      "tag2idx = {'PAD': 0}\n",
      "char2idx = {'PAD': 0}\n",
      "word_idx = 3\n",
      "tag_idx = 1\n",
      "char_idx = 1\n",
      "\n",
      "def parse_XY(texts, labels):\n",
      "    global word2idx, tag2idx, char2idx, word_idx, tag_idx, char_idx\n",
      "    X, Y = [], []\n",
      "    for no, text in enumerate(texts):\n",
      "        text = text.lower()\n",
      "        tag = labels[no]\n",
      "        for c in text:\n",
      "            if c not in char2idx:\n",
      "                char2idx[c] = char_idx\n",
      "                char_idx += 1\n",
      "        if tag not in tag2idx:\n",
      "            tag2idx[tag] = tag_idx\n",
      "            tag_idx += 1\n",
      "        Y.append(tag2idx[tag])\n",
      "        if text not in word2idx:\n",
      "            word2idx[text] = word_idx\n",
      "            word_idx += 1\n",
      "        X.append(word2idx[text])\n",
      "    return X, tensorflow.keras.utils.to_categorical(np.array(Y))\n",
      "    \n",
      "train_X, train_Y = parse_XY(left_train, right_train)\n",
      "test_X, test_Y = parse_XY(left_test, right_test)\n",
      "\n",
      "idx2word = {idx: tag for tag, idx in word2idx.items()}\n",
      "idx2tag = {i: w for w, i in tag2idx.items()}\n",
      "\n",
      "seq_len = 50\n",
      "def iter_seq(x):\n",
      "    return np.array([x[i: i+seq_len] for i in range(0, len(x)-seq_len, 1)])\n",
      "\n",
      "def to_train_seq(*args):\n",
      "    return [iter_seq(x) for x in args]\n",
      "\n",
      "def generate_char_seq(batch):\n",
      "    x = [[len(idx2word[i]) for i in k] for k in batch]\n",
      "    maxlen = max([j for i in x for j in i])\n",
      "    temp = np.zeros((batch.shape[0],batch.shape[1],maxlen),dtype=np.int32)\n",
      "    for i in range(batch.shape[0]):\n",
      "        for k in range(batch.shape[1]):\n",
      "            for no, c in enumerate(idx2word[batch[i,k]]):\n",
      "                temp[i,k,-1-no] = char2idx[c]\n",
      "    return temp\n",
      "    \n",
      "\n",
      "X_seq, Y_seq = to_train_seq(train_X, train_Y)\n",
      "X_char_seq = generate_char_seq(X_seq)\n",
      "X_seq.shape\n",
      "\n",
      "X_seq_test, Y_seq_test = to_train_seq(test_X, test_Y)\n",
      "X_char_seq_test = generate_char_seq(X_seq_test)\n",
      "X_seq_test.shape\n",
      "\n",
      "train_X, train_Y, train_char = X_seq, Y_seq, X_char_seq\n",
      "test_X, test_Y, test_char = X_seq_test, Y_seq_test, X_char_seq_test\n",
      "\n",
      "\n",
      "from numpy.random import seed\n",
      "seed(1)\n",
      "tensorflow.random.set_seed(2)\n",
      "output_dim = 64\n",
      "\n",
      "\n",
      "model = Sequential()\n",
      "\n",
      "# Add Embedding layer\n",
      "model.add(Embedding(input_dim=len(word2idx), output_dim=output_dim, input_length=len(train_X[0])))\n",
      "\n",
      "# Add bidirectional LSTM\n",
      "model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
      "\n",
      "# Add LSTM\n",
      "model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
      "\n",
      "# Add timeDistributed Layer\n",
      "model.add(TimeDistributed(Dense(len(tag2idx), activation=\"relu\")))\n",
      "\n",
      "# Compile model\n",
      "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
      "model.summary()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def train_model(X, y, model):\n",
      "    loss = list()\n",
      "    for i in range(25):\n",
      "        # fit model for one epoch on this sequence\n",
      "        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.2)\n",
      "        loss.append(hist.history['loss'][0])\n",
      "    return loss\n",
      "    \n",
      "train_model(train_X, train_Y, model)\n",
      "\n",
      "Output: {'tf_bilstm': ['tensorflow.keras.layers.TimeDistributed', 'tf_bilstm.parse_XY', 'tensorflow.random.set_seed', 'tf_bilstm.generate_char_seq', 'tensorflow.keras.layers.Dense', 'tensorflow.keras.layers.Embedding', 'tf_bilstm.parse', 'tensorflow.keras.Sequential', 'tf_bilstm.to_train_seq', 'tensorflow.keras.layers.Bidirectional', '<builtin>.len', 'tf_bilstm.train_model', 'tensorflow.keras.layers.LSTM', 'numpy.random.seed'], 'tf_bilstm.parse': ['<builtin>.open', '<builtin>.len'], '<builtin>.open': [], '<builtin>.len': [], 'tf_bilstm.process_string': ['re.sub', 'tf_bilstm.to_title'], 're.sub': [], 'tf_bilstm.to_title': [], 'tf_bilstm.parse_XY': ['tensorflow.keras.utils.to_categorical', 'numpy.array', '<builtin>.enumerate'], '<builtin>.enumerate': [], 'numpy.array': [], 'tensorflow.keras.utils.to_categorical': [], 'tf_bilstm.iter_seq': ['<builtin>.len', 'numpy.array', '<builtin>.range'], '<builtin>.range': [], 'tf_bilstm.to_train_seq': ['tf_bilstm.iter_seq'], 'tf_bilstm.generate_char_seq': ['numpy.zeros', '<builtin>.max', '<builtin>.range', '<builtin>.len', '<builtin>.enumerate'], '<builtin>.max': [], 'numpy.zeros': [], 'numpy.random.seed': [], 'tensorflow.random.set_seed': [], 'tensorflow.keras.Sequential': [], 'tensorflow.keras.layers.Embedding': [], 'tensorflow.keras.layers.LSTM': [], 'tensorflow.keras.layers.Bidirectional': [], 'tensorflow.keras.layers.Dense': [], 'tensorflow.keras.layers.TimeDistributed': [], 'tf_bilstm.train_model': ['<builtin>.list', '<builtin>.range'], '<builtin>.list': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\pos-tagging\\tf_bilstm.py\n",
      "[('tf_bilstm', 'tensorflow keras layers TimeDistributed'), ('tf_bilstm', 'tf_bilstm parse_XY'), ('tf_bilstm', 'tensorflow random set_seed'), ('tf_bilstm', 'tf_bilstm generate_char_seq'), ('tf_bilstm', 'tensorflow keras layers Dense'), ('tf_bilstm', 'tensorflow keras layers Embedding'), ('tf_bilstm', 'tf_bilstm parse'), ('tf_bilstm', 'tensorflow keras Sequential'), ('tf_bilstm', 'tf_bilstm to_train_seq'), ('tf_bilstm', 'tensorflow keras layers Bidirectional'), ('tf_bilstm', 'tf_bilstm train_model'), ('tf_bilstm', 'tensorflow keras layers LSTM'), ('tf_bilstm', 'numpy random seed'), ('tf_bilstm process_string', 're sub'), ('tf_bilstm process_string', 'tf_bilstm to_title'), ('tf_bilstm parse_XY', 'tensorflow keras utils to_categorical'), ('tf_bilstm parse_XY', 'numpy array'), ('tf_bilstm iter_seq', 'numpy array'), ('tf_bilstm to_train_seq', 'tf_bilstm iter_seq'), ('tf_bilstm generate_char_seq', 'numpy zeros')]\n",
      "0\n",
      "found files: []\n",
      "import spacy\n",
      "\n",
      "sentences = ['Started his hearted any civilly.',\n",
      "    'So me by marianne admitted speaking.',\n",
      "    'Men bred fine call ask.',\n",
      "    'Cease one miles truth day above seven.',\n",
      "    'Suspicion sportsmen provision suffering mrs saw engrossed something.'\n",
      "    'Snug soon he on plan in be dine some. ']\n",
      "nlp = spacy.load('en_core_web_sm')\n",
      "\n",
      "def get_dependency_parse(sentence):\n",
      "    doc = nlp(sentence)\n",
      "    for token in doc:\n",
      "        print(token.text, \"\\t\", token.dep_, \"\\t\", spacy.explain(token.dep_))\n",
      "\n",
      "def main():\n",
      "    for i in range(len(sentences)):\n",
      "        print(\"---\")\n",
      "        get_dependency_parse(sentences[i])\n",
      "\n",
      "if (__name__ == \"__main__\"):\n",
      "    main()\n",
      "\n",
      "Output: {'dependency_parsing': ['dependency_parsing.main', 'spacy.load'], 'spacy.load': [], 'dependency_parsing.get_dependency_parse': ['spacy.explain', '<builtin>.print'], 'spacy.explain': [], '<builtin>.print': [], 'dependency_parsing.main': ['<builtin>.len', '<builtin>.print', 'dependency_parsing.get_dependency_parse', '<builtin>.range'], '<builtin>.len': [], '<builtin>.range': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\spacy_examples\\dependency_parsing.py\n",
      "[('dependency_parsing', 'dependency_parsing main'), ('dependency_parsing', 'spacy load'), ('dependency_parsing get_dependency_parse', 'spacy explain'), ('dependency_parsing main', 'dependency_parsing get_dependency_parse')]\n",
      "0\n",
      "found files: []\n",
      "\n",
      "import os\n",
      "import sys\n",
      "import argparse\n",
      "import time\n",
      "import tqdm\n",
      "from collections import Counter\n",
      "\n",
      "import numpy as np\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "import torch.optim as optim\n",
      "\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn import metrics\n",
      "\n",
      "\n",
      "EMBEDDING_DIM = 256\n",
      "HIDDEN_DIM = 128\n",
      "NUM_TAGS = 2\n",
      "TRAINING_DATA = \"./oscar.atom.txt\"\n",
      "LR = 1e-3\n",
      "NUM_EPOCHS = 10\n",
      "\n",
      "\n",
      "def get_length_of_file_in_lines(text_file):\n",
      "  file_len = 0\n",
      "  with open(text_file, encoding='utf-8') as fin:\n",
      "    for l in fin:\n",
      "      file_len += 1\n",
      "  return file_len\n",
      "\n",
      "\n",
      "def lazy_scan_vocabulary(text_file, padding_idx=0, min_count=1):\n",
      "  \"\"\"\n",
      "  Responsible for loading the whole vocabulary of the given training set.\n",
      "  \"\"\"\n",
      "  max_line_length = -1\n",
      "  total_length = 0\n",
      "  counter = Counter()\n",
      "\n",
      "  with open(text_file, encoding='utf-8') as fin:\n",
      "    for line in tqdm.tqdm(fin, desc=\"Analyzing vocabulary\"):\n",
      "      text = line.rstrip()\n",
      "\n",
      "      if len(line) > max_line_length:\n",
      "        max_line_length = len(line)\n",
      "\n",
      "      c2 = Counter(vocab for vocab in text)\n",
      "\n",
      "      total_length += 1\n",
      "\n",
      "      counter.update(c2)\n",
      "\n",
      "  idx2char = []\n",
      "  char2idx = {}\n",
      "  idx2char.append(\"@@@PADDING@@@\")\n",
      "  char2idx[\"@@@PADDING@@@\"] = padding_idx\n",
      "  idx2char.append(\"@@@UNKNOWN@@@\")\n",
      "  char2idx[\"@@@UNKNOWN@@@\"] = padding_idx+1\n",
      "  idx2char.extend([vocab for vocab in sorted(counter, key=lambda x:-counter[x])])\n",
      "  char2idx.update({vocab:idx for idx, vocab in enumerate(idx2char)})\n",
      "\n",
      "  return idx2char, char2idx, max_line_length, total_length\n",
      "\n",
      "\n",
      "def space_tag(sent, nonspace=0, space=1):\n",
      "  \"\"\"\n",
      "  :param sent: str\n",
      "      Input sentence\n",
      "  :param nonspace: Object\n",
      "      Non-space tag. Default is 0, int type\n",
      "  :param space: Object\n",
      "      Space tag. Default is 1, int type\n",
      "  It returns\n",
      "  ----------\n",
      "  chars : list of character\n",
      "  tags : list of tag\n",
      "  (example)\n",
      "      sent  = 'Test sentence for demonstration purposes.'\n",
      "      chars = list('Testsentencefordemonstrationpurposes.')\n",
      "      tags  = [{0,1},...]\n",
      "  \"\"\"\n",
      "\n",
      "  sent = sent.strip()\n",
      "  chars = list(sent.replace(' ',''))\n",
      "  tags = [nonspace]*(len(chars) - 1) + [space]\n",
      "  idx = 0\n",
      "\n",
      "  for c in sent:\n",
      "    if c == ' ':\n",
      "      tags[idx-1] = space\n",
      "    else:\n",
      "      idx += 1\n",
      "\n",
      "  return chars, tags\n",
      "\n",
      "\n",
      "def to_idx(item, mapper, unknown=\"@@@UNKNOWN@@@\"):\n",
      "  \"\"\"\n",
      "  :param item: Object\n",
      "      Object to be encoded\n",
      "  :param mapper: dict\n",
      "      Dictionary from item to idx\n",
      "  :param unknown: int\n",
      "      Index of unknown item. If None, use len(mapper)\n",
      "  It returns\n",
      "  ----------\n",
      "  idx : int\n",
      "      Index of item\n",
      "  \"\"\"\n",
      "\n",
      "  if item in mapper.keys():\n",
      "    return mapper[item]\n",
      "  return mapper[\"@@@UNKNOWN@@@\"]\n",
      "\n",
      "  if unknown is None:\n",
      "    unknown = len(mapper)\n",
      "  return mapper.get(item, unknown)\n",
      "\n",
      "\n",
      "def to_item(idx, idx_to_char, unknown='@@@UNKNOWN@@@'):\n",
      "  \"\"\"\n",
      "  :param idx: int\n",
      "      Index of item\n",
      "  :param idx_to_char: list of Object\n",
      "      Mapper from index to item object\n",
      "  :param unknown: Object\n",
      "      Return value when the idx is outbound of idx_to_char\n",
      "      Default is 'Unk', str type\n",
      "  It returns\n",
      "  ----------\n",
      "  object : object\n",
      "      Item that corresponding idx\n",
      "  \"\"\"\n",
      "\n",
      "  if 0 <= idx < len(idx_to_char):\n",
      "    return idx_to_char[idx]\n",
      "  return unknown\n",
      "\n",
      "\n",
      "def sent_to_xy(sent, char_to_idx, cnn_mode=False):\n",
      "  \"\"\"\n",
      "  :param sent: str\n",
      "      Input sentence\n",
      "  :param char_to_idx: dict\n",
      "      Dictionary from character to index\n",
      "  It returns\n",
      "  ----------\n",
      "  idxs : torch.LongTensor\n",
      "      Encoded character sequence\n",
      "  tags : torch.LongTensor\n",
      "      Space tag sequence\n",
      "  \"\"\"\n",
      "\n",
      "  chars, tags = space_tag(sent)\n",
      "  if cnn_mode:\n",
      "    idxs = torch.LongTensor(\n",
      "      [[to_idx(c, char_to_idx) for c in chars]])\n",
      "  else:\n",
      "    idxs = torch.LongTensor(\n",
      "      [to_idx(c, char_to_idx) for c in chars])\n",
      "  tags = torch.LongTensor([tags])\n",
      "  return idxs, tags\n",
      "\n",
      "\n",
      "class BILSTMModel(nn.Module):\n",
      "\n",
      "  def __init__(\n",
      "    self,\n",
      "    embedding_dim,\n",
      "    hidden_dim,\n",
      "    vocab_size,\n",
      "    tags_size,\n",
      "    num_layers=1,\n",
      "    bias=True,\n",
      "    dropout=0.1,\n",
      "    bidirectional=True):\n",
      "    super(BILSTMModel, self).__init__()\n",
      "\n",
      "    self.hidden_dim = hidden_dim\n",
      "    self.num_layers = num_layers\n",
      "    self.bidirectional = bidirectional\n",
      "\n",
      "    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
      "    self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
      "      num_layers=num_layers,\n",
      "      bias=bias,\n",
      "      dropout=dropout,\n",
      "      bidirectional=bidirectional)\n",
      "    self.hidden2tag = nn.Linear(hidden_dim * (1 + self.bidirectional), tags_size)\n",
      "    self.hidden = self.init_hidden() # hidden, cell\n",
      "\n",
      "  def forward(self, char_idxs):\n",
      "    self.hidden = self.init_hidden() # hidden, cell\n",
      "    embeds = self.embeddings(char_idxs)\n",
      "    lstm_out, self.hidden = self.lstm(\n",
      "      embeds.view(len(char_idxs), 1, -1), self.hidden)\n",
      "    tag_space = self.hidden2tag(lstm_out.view(char_idxs.size()[0], -1))\n",
      "    tag_scores = F.log_softmax(tag_space, dim=1)\n",
      "\n",
      "    return tag_scores\n",
      "\n",
      "  def init_hidden(self):\n",
      "    # (num_layers, minibatch_size, hidden_dim)\n",
      "    return (torch.zeros(1 + self.bidirectional, 1, self.hidden_dim),\n",
      "            torch.zeros(1 + self.bidirectional, 1, self.hidden_dim))\n",
      "\n",
      "\n",
      "idx2char, char2idx, max_line_length, total_length = lazy_scan_vocabulary(TRAINING_DATA)\n",
      "vocab_size = len(idx2char) + 1\n",
      "print(f\"vocab size: {vocab_size}\")\n",
      "\n",
      "model = BILSTMModel(EMBEDDING_DIM, HIDDEN_DIM, vocab_size, NUM_TAGS)\n",
      "\n",
      "\n",
      "def train(model, char2idx, idx2char, total_length, use_gpu=False):\n",
      "  print(\"Un train\")\n",
      "  batch_size = 1\n",
      "\n",
      "  is_cuda = use_gpu and torch.cuda.is_available()\n",
      "  device = torch.device(\"cuda\" if is_cuda else \"cpu\")\n",
      "\n",
      "  loss_function = nn.CrossEntropyLoss().to(device)\n",
      "  optimizer = optim.Adam(model.parameters(), lr=LR)\n",
      "\n",
      "  # Create training and testing data\n",
      "\n",
      "\n",
      "  def get_batches(filename, indexer, cnn_mode, max_seq_length=2040, min_seq_length=4, batch_size=1):\n",
      "    with open(filename, 'r', encoding='utf-8') as fin:\n",
      "      for line in fin:\n",
      "        line = line.strip()\n",
      "\n",
      "        if min_seq_length < len(line) < max_seq_length:\n",
      "          x, y = sent_to_xy(line, indexer, cnn_mode)\n",
      "\n",
      "          yield (x, y)\n",
      "\n",
      "\n",
      "  for e in range(NUM_EPOCHS-1):\n",
      "    start_time = time.time()\n",
      "    print(\"Epoch %d/%d\" % (e, NUM_EPOCHS-1))\n",
      "\n",
      "    # Training\n",
      "    train_acc, train_loss = 0.0, 0.0\n",
      "    trained_sample_length = 0\n",
      "\n",
      "    pbar = tqdm.tqdm(\n",
      "      get_batches(TRAINING_DATA, char2idx, False), desc=\"Training\", total=total_length\n",
      "    )\n",
      "    for x, y in pbar:\n",
      "      batch_x = x\n",
      "      batch_y = y\n",
      "\n",
      "      batch_x = batch_x.to(device)\n",
      "      batch_y = batch_y.to(device)\n",
      "\n",
      "      model.zero_grad()\n",
      "\n",
      "      model.hidden = model.init_hidden()\n",
      "      tag_scores = model(batch_x)\n",
      "      tag_scores = tag_scores.squeeze()\n",
      "      tags = batch_y.squeeze()\n",
      "\n",
      "      try:\n",
      "        loss = loss_function(tag_scores, tags)\n",
      "\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "\n",
      "        if is_cuda:\n",
      "          loss_value = loss.cpu().data.numpy()\n",
      "          ts_value = tag_scores.cpu().data.numpy()\n",
      "        else:\n",
      "          loss_value = loss.data.numpy()\n",
      "          ts_value = tag_scores.data.numpy()\n",
      "        acc = (np.argmax(ts_value, -1) == np.asarray(tags)).sum().item() / len(tags)\n",
      "\n",
      "        # Sanity check\n",
      "        #assert not np.isnan(loss.numpy())\n",
      "        train_loss += loss_value\n",
      "        train_acc += acc\n",
      "        pbar.set_postfix(loss=loss, accuracy=acc)\n",
      "\n",
      "        trained_sample_length += 1\n",
      "\n",
      "      except:\n",
      "        print(\"tag_scores: {}\".format(tag_scores))\n",
      "        print(\"tags: {}\".format(tags))\n",
      "\n",
      "\n",
      "    print(\"Training: Loss={}, Acc={}\".format(train_loss/trained_sample_length, train_acc/trained_sample_length))\n",
      "\n",
      "\n",
      "train(model, char2idx, idx2char, total_length, False)\n",
      "Output: {'02_bilstm': ['02_bilstm.train', '02_bilstm.lazy_scan_vocabulary', '02_bilstm.BILSTMModel.__init__', '<builtin>.print', '<builtin>.len'], '02_bilstm.get_length_of_file_in_lines': ['<builtin>.open'], '<builtin>.open': [], '02_bilstm.lazy_scan_vocabulary': ['collections.Counter', '<builtin>.enumerate', '<builtin>.open', 'tqdm.tqdm', '<builtin>.sorted', '<builtin>.len'], 'collections.Counter': [], 'tqdm.tqdm': [], '<builtin>.len': [], '02_bilstm.lazy_scan_vocabulary.<lambda1>': [], '<builtin>.sorted': [], '<builtin>.enumerate': [], '02_bilstm.space_tag': ['<builtin>.list', '<builtin>.len'], '<builtin>.list': [], '02_bilstm.to_idx': ['<builtin>.len'], '02_bilstm.to_item': ['<builtin>.len'], '02_bilstm.sent_to_xy': ['02_bilstm.space_tag', 'torch.LongTensor', '02_bilstm.to_idx'], 'torch.LongTensor': [], '02_bilstm.BILSTMModel.__init__': ['torch.nn.Embedding', 'torch.nn.LSTM', '<builtin>.super', 'torch.nn.Linear', '02_bilstm.BILSTMModel.init_hidden'], '<builtin>.super': [], 'torch.nn.Embedding': [], 'torch.nn.LSTM': [], 'torch.nn.Linear': [], '02_bilstm.BILSTMModel.init_hidden': ['torch.zeros'], '02_bilstm.BILSTMModel.forward': ['torch.nn.functional.log_softmax', '<builtin>.len', '02_bilstm.BILSTMModel.init_hidden'], 'torch.nn.functional.log_softmax': [], 'torch.zeros': [], '<builtin>.print': [], '02_bilstm.train': ['torch.nn.Module.parameters', 'torch.optim.Adam', '<builtin>.range', 'tqdm.tqdm', '02_bilstm.BILSTMModel.init_hidden', 'torch.device', '<builtin>.print', 'torch.nn.Module.zero_grad', '02_bilstm.BILSTMModel.__init__', 'numpy.argmax', 'numpy.asarray', '02_bilstm.train.get_batches', 'torch.nn.CrossEntropyLoss', 'torch.cuda.is_available', '<builtin>.len', 'time.time'], 'torch.cuda.is_available': [], 'torch.device': [], 'torch.nn.CrossEntropyLoss': [], 'torch.nn.Module.parameters': [], 'torch.optim.Adam': [], '02_bilstm.train.get_batches': ['02_bilstm.sent_to_xy', '<builtin>.len', '<builtin>.open'], '<builtin>.range': [], 'time.time': [], 'torch.nn.Module.zero_grad': [], 'numpy.argmax': [], 'numpy.asarray': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\word-segmentation\\02_bilstm.py\n",
      "[('02_bilstm', '02_bilstm train'), ('02_bilstm', '02_bilstm lazy_scan_vocabulary'), ('02_bilstm', '02_bilstm BILSTMModel __init__'), ('02_bilstm lazy_scan_vocabulary', 'collections Counter'), ('02_bilstm lazy_scan_vocabulary', 'tqdm tqdm'), ('02_bilstm sent_to_xy', '02_bilstm space_tag'), ('02_bilstm sent_to_xy', 'torch LongTensor'), ('02_bilstm sent_to_xy', '02_bilstm to_idx'), ('02_bilstm BILSTMModel __init__', 'torch nn Embedding'), ('02_bilstm BILSTMModel __init__', 'torch nn LSTM'), ('02_bilstm BILSTMModel __init__', 'torch nn Linear'), ('02_bilstm BILSTMModel __init__', '02_bilstm BILSTMModel init_hidden'), ('02_bilstm BILSTMModel init_hidden', 'torch zeros'), ('02_bilstm BILSTMModel forward', 'torch nn functional log_softmax'), ('02_bilstm BILSTMModel forward', '02_bilstm BILSTMModel init_hidden'), ('02_bilstm train', 'torch nn Module parameters'), ('02_bilstm train', 'torch optim Adam'), ('02_bilstm train', 'tqdm tqdm'), ('02_bilstm train', '02_bilstm BILSTMModel init_hidden'), ('02_bilstm train', 'torch device'), ('02_bilstm train', 'torch nn Module zero_grad'), ('02_bilstm train', '02_bilstm BILSTMModel __init__'), ('02_bilstm train', 'numpy argmax'), ('02_bilstm train', 'numpy asarray'), ('02_bilstm train', '02_bilstm train get_batches'), ('02_bilstm train', 'torch nn CrossEntropyLoss'), ('02_bilstm train', 'torch cuda is_available'), ('02_bilstm train', 'time time'), ('02_bilstm train get_batches', '02_bilstm sent_to_xy')]\n",
      "475\n",
      "found files: []\n",
      "import spacy\n",
      "from spacy import displacy\n",
      "from pathlib import Path\n",
      "\n",
      "nlp = spacy.load('en_core_web_sm')\n",
      "\n",
      "def visualize(doc):\n",
      "    colors = {\"ORG\": \"green\", \"PERSON\":\"yellow\"}\n",
      "    options = {\"colors\": colors}\n",
      "    displacy.serve(doc, style='ent', options=options)\n",
      "\n",
      "def save_as_html(doc, path):\n",
      "    html = displacy.render(doc, style=\"ent\")\n",
      "    html_file= open(path, \"w\", encoding=\"utf-8\")\n",
      "    html_file.write(html)\n",
      "    html_file.close()\n",
      "\n",
      "def main():\n",
      "    text = \"\"\"SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars.\"\"\"\n",
      "    doc = nlp(text)\n",
      "    doc.user_data[\"title\"] = \"Random Text\"\n",
      "    visualize(doc)\n",
      "    save_as_html(doc, \"./ner_vis.html\")\n",
      "\n",
      "if (__name__ == \"__main__\"):\n",
      "    main()\n",
      "\n",
      "\n",
      "Output: {'ner_visualization': ['ner_visualization.main', 'spacy.load'], 'spacy.load': [], 'ner_visualization.visualize': ['spacy.displacy.serve'], 'spacy.displacy.serve': [], 'ner_visualization.save_as_html': ['<builtin>.open', 'spacy.displacy.render'], 'spacy.displacy.render': [], '<builtin>.open': [], 'ner_visualization.main': ['ner_visualization.save_as_html', 'ner_visualization.visualize']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\spacy_examples\\ner_visualization.py\n",
      "[('ner_visualization', 'ner_visualization main'), ('ner_visualization', 'spacy load'), ('ner_visualization visualize', 'spacy displacy serve'), ('ner_visualization save_as_html', 'spacy displacy render'), ('ner_visualization main', 'ner_visualization save_as_html'), ('ner_visualization main', 'ner_visualization visualize')]\n",
      "0\n",
      "found files: []\n",
      "import math\n",
      "import copy\n",
      "from typing import Tuple\n",
      "import torch\n",
      "from torch import nn, Tensor\n",
      "import torch.nn.functional as F\n",
      "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
      "from torch.utils.data import dataset\n",
      "from torchtext.datasets import WikiText103\n",
      "from torchtext.data.utils import get_tokenizer\n",
      "from torchtext.vocab import build_vocab_from_iterator\n",
      "\n",
      "\n",
      "EMBEDDING_DIM = 200\n",
      "HIDDEN_DIM = 200\n",
      "NUM_LAYERS = 2\n",
      "NUM_HEADS = 2\n",
      "DROPOUT = 0.2\n",
      "BATCH_SIZE = 20\n",
      "BATCH_SIZE = 10\n",
      "BPTT = 35\n",
      "EPOCHS = 3\n",
      "LEARNING_RATE = 5.0\n",
      "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "LOG_INTERVAL = 200\n",
      "WEIGHT_INIT_RANGE = 0.1\n",
      "\n",
      "\n",
      "class TransformerModel(nn.Module):\n",
      "\n",
      "    def __init__(self, num_token, d_model, num_head, d_hid, num_layers, dropout = 0.5):\n",
      "        super().__init__()\n",
      "        self.model_type = 'Transformer'\n",
      "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
      "        encoder_layers = TransformerEncoderLayer(d_model, num_head, d_hid, dropout)\n",
      "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)\n",
      "        self.encoder = nn.Embedding(num_token, d_model)\n",
      "        self.d_model = d_model\n",
      "        self.decoder = nn.Linear(d_model, num_token)\n",
      "\n",
      "        self.init_weights()\n",
      "\n",
      "    def init_weights(self):\n",
      "        self.encoder.weight.data.uniform_(-WEIGHT_INIT_RANGE, WEIGHT_INIT_RANGE)\n",
      "        self.decoder.bias.data.zero_()\n",
      "        self.decoder.weight.data.uniform_(-WEIGHT_INIT_RANGE, WEIGHT_INIT_RANGE)\n",
      "\n",
      "    def forward(self, src, src_mask):\n",
      "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
      "        src = self.pos_encoder(src)\n",
      "        output = self.transformer_encoder(src, src_mask)\n",
      "        output = self.decoder(output)\n",
      "        return output\n",
      "\n",
      "\n",
      "def generate_square_subsequent_mask(sz):\n",
      "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
      "\n",
      "\n",
      "class PositionalEncoding(nn.Module):\n",
      "\n",
      "    def __init__(self, d_model, dropout = 0.1, max_len = 5000):\n",
      "        super().__init__()\n",
      "        self.dropout = nn.Dropout(p=dropout)\n",
      "\n",
      "        position = torch.arange(max_len).unsqueeze(1)\n",
      "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
      "        pe = torch.zeros(max_len, 1, d_model)\n",
      "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
      "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
      "        self.register_buffer('pe', pe)\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = x + self.pe[:x.size(0)]\n",
      "        return self.dropout(x)\n",
      "\n",
      "\n",
      "train_iter = WikiText103(split='train')\n",
      "tokenizer = get_tokenizer('basic_english')\n",
      "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
      "vocab.set_default_index(vocab['<unk>']) \n",
      "\n",
      "def data_processing(raw_text_iter):\n",
      "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
      "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
      "\n",
      "train_iter, val_iter, test_iter = WikiText103()\n",
      "train_data = data_processing(train_iter)\n",
      "val_data = data_processing(val_iter)\n",
      "test_data = data_processing(test_iter)\n",
      "\n",
      "def gen_all_batches(data):\n",
      "    seq_len = data.size(0) // BATCH_SIZE\n",
      "    data = data[:seq_len * BATCH_SIZE]\n",
      "    data = data.view(BATCH_SIZE, seq_len).t().contiguous()\n",
      "    return data.to(DEVICE)\n",
      "\n",
      "train_data = gen_all_batches(train_data)\n",
      "val_data = gen_all_batches(val_data)\n",
      "test_data = gen_all_batches(test_data)\n",
      "\n",
      "def get_batch(source, i):\n",
      "    seq_len = min(BPTT, len(source) - 1 - i)\n",
      "    data = source[i:i+seq_len]\n",
      "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
      "    return data, target\n",
      "\n",
      "num_tokens = len(vocab)\n",
      "\n",
      "model = TransformerModel(num_tokens, EMBEDDING_DIM, NUM_HEADS, HIDDEN_DIM, NUM_LAYERS, DROPOUT).to(DEVICE)\n",
      "model_loss = nn.CrossEntropyLoss()\n",
      "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
      "\n",
      "def train(model):\n",
      "    model.train()\n",
      "    total_loss = 0.\n",
      "    src_mask = generate_square_subsequent_mask(BPTT).to(DEVICE)\n",
      "\n",
      "    num_batches = len(train_data) // BPTT\n",
      "    for batch, i in enumerate(range(0, train_data.size(0) - 1, BPTT)):\n",
      "        data, targets = get_batch(train_data, i)\n",
      "        BATCH_SIZE = data.size(0)\n",
      "        if BATCH_SIZE != BPTT:\n",
      "            src_mask = src_mask[:BATCH_SIZE, :BATCH_SIZE]\n",
      "        output = model(data, src_mask)\n",
      "        loss = model_loss(output.view(-1, num_tokens), targets)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "        loss.backward()\n",
      "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
      "        optimizer.step()\n",
      "\n",
      "        total_loss += loss.item()\n",
      "        if batch % LOG_INTERVAL == 0 and batch > 0:\n",
      "            cur_loss = total_loss / LOG_INTERVAL\n",
      "            ppl = math.exp(cur_loss)\n",
      "            print(f'>> epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
      "            total_loss = 0\n",
      "\n",
      "def evaluate(model, eval_data):\n",
      "    model.eval()\n",
      "    total_loss = 0.0\n",
      "    src_mask = generate_square_subsequent_mask(BPTT).to(DEVICE)\n",
      "    with torch.no_grad():\n",
      "        for i in range(0, eval_data.size(0) - 1, BPTT):\n",
      "            data, targets = get_batch(eval_data, i)\n",
      "            BATCH_SIZE = data.size(0)\n",
      "            if BATCH_SIZE != BPTT:\n",
      "                src_mask = src_mask[:BATCH_SIZE, :BATCH_SIZE]\n",
      "            output = model(data, src_mask)\n",
      "            output_flat = output.view(-1, num_tokens)\n",
      "            total_loss += BATCH_SIZE * model_loss(output_flat, targets).item()\n",
      "    return total_loss / (len(eval_data) - 1)\n",
      "\n",
      "best_val_loss = float('inf')\n",
      "best_model = None\n",
      "\n",
      "for epoch in range(1, EPOCHS + 1):\n",
      "    train(model)\n",
      "    val_loss = evaluate(model, val_data)\n",
      "    val_ppl = math.exp(val_loss)\n",
      "    print(f'>> end of epoch {epoch:3d} | valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
      "\n",
      "    if val_loss < best_val_loss:\n",
      "        best_val_loss = val_loss\n",
      "        best_model = copy.deepcopy(model)\n",
      "\n",
      "\n",
      "test_loss = evaluate(best_model, test_data)\n",
      "test_ppl = math.exp(test_loss)\n",
      "print(f'>> test loss {test_loss:5.2f} | test ppl {test_ppl:8.2f}')\n",
      "Output: {'torch_lm': ['torch_lm.evaluate', 'torch.nn.Module.to', 'math.exp', 'torchtext.vocab.build_vocab_from_iterator', 'torch.nn.CrossEntropyLoss', '<builtin>.map', '<builtin>.float', 'torchtext.datasets.WikiText103', '<builtin>.print', 'torch_lm.gen_all_batches', 'torch.optim.SGD', '<builtin>.range', 'torch_lm.data_processing', 'torchtext.data.utils.get_tokenizer', 'torch.device', 'torch_lm.TransformerModel.__init__', 'copy.deepcopy', 'torch_lm.train', 'torch.cuda.is_available', '<builtin>.len'], 'torch.cuda.is_available': [], 'torch.device': [], 'torch_lm.TransformerModel.__init__': ['torch.nn.Embedding', '<builtin>.super', 'torch.nn.Linear', 'torch.nn.TransformerEncoderLayer', 'torch_lm.TransformerModel.init_weights', 'torch.nn.TransformerEncoder', 'torch_lm.PositionalEncoding.__init__'], '<builtin>.super': [], 'torch_lm.PositionalEncoding.__init__': ['torch.zeros', '<builtin>.super', 'torch.nn.Module.register_buffer', 'torch.nn.Dropout', 'torch.exp', 'torch.sin', 'math.log', 'torch.cos', 'torch.arange'], 'torch.nn.TransformerEncoderLayer': [], 'torch.nn.TransformerEncoder': [], 'torch.nn.Embedding': [], 'torch.nn.Linear': [], 'torch_lm.TransformerModel.init_weights': [], 'torch_lm.TransformerModel.forward': ['math.sqrt', 'torch_lm.PositionalEncoding.__init__'], 'math.sqrt': [], 'torch_lm.generate_square_subsequent_mask': ['torch.triu', '<builtin>.float', 'torch.ones'], 'torch.ones': [], '<builtin>.float': [], 'torch.triu': [], 'torch.nn.Dropout': [], 'torch.arange': [], 'math.log': [], 'torch.exp': [], 'torch.zeros': [], 'torch.sin': [], 'torch.cos': [], 'torch.nn.Module.register_buffer': [], 'torch_lm.PositionalEncoding.forward': [], 'torchtext.datasets.WikiText103': [], 'torchtext.data.utils.get_tokenizer': [], '<builtin>.map': [], 'torchtext.vocab.build_vocab_from_iterator': [], 'torch_lm.data_processing': ['torch.cat', 'torch.tensor', '<builtin>.tuple', '<builtin>.filter'], 'torch.tensor': [], 'torch_lm.data_processing.<lambda1>': [], '<builtin>.filter': [], '<builtin>.tuple': [], 'torch.cat': [], 'torch_lm.gen_all_batches': [], 'torch_lm.get_batch': ['<builtin>.min', '<builtin>.len'], '<builtin>.len': [], '<builtin>.min': [], 'torch.nn.Module.to': [], 'torch.nn.CrossEntropyLoss': [], 'torch.optim.SGD': [], 'torch_lm.train': ['torch.nn.utils.clip_grad_norm_', 'torch_lm.generate_square_subsequent_mask', '<builtin>.range', '<builtin>.print', '<builtin>.enumerate', 'torch_lm.get_batch', 'math.exp', '<builtin>.len'], '<builtin>.range': [], '<builtin>.enumerate': [], 'torch.nn.utils.clip_grad_norm_': [], 'math.exp': [], '<builtin>.print': [], 'torch_lm.evaluate': ['torch.no_grad', 'torch_lm.generate_square_subsequent_mask', '<builtin>.range', 'torch_lm.get_batch', '<builtin>.len'], 'torch.no_grad': [], 'copy.deepcopy': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\examples-with-transformers\\torch_lm.py\n",
      "[('torch_lm', 'torch_lm evaluate'), ('torch_lm', 'torch nn Module to'), ('torch_lm', 'math exp'), ('torch_lm', 'torchtext vocab build_vocab_from_iterator'), ('torch_lm', 'torch nn CrossEntropyLoss'), ('torch_lm', 'torchtext datasets WikiText103'), ('torch_lm', 'torch_lm gen_all_batches'), ('torch_lm', 'torch optim SGD'), ('torch_lm', 'torch_lm data_processing'), ('torch_lm', 'torchtext data utils get_tokenizer'), ('torch_lm', 'torch device'), ('torch_lm', 'torch_lm TransformerModel __init__'), ('torch_lm', 'copy deepcopy'), ('torch_lm', 'torch_lm train'), ('torch_lm', 'torch cuda is_available'), ('torch_lm TransformerModel __init__', 'torch nn Embedding'), ('torch_lm TransformerModel __init__', 'torch nn Linear'), ('torch_lm TransformerModel __init__', 'torch nn TransformerEncoderLayer'), ('torch_lm TransformerModel __init__', 'torch_lm TransformerModel init_weights'), ('torch_lm TransformerModel __init__', 'torch nn TransformerEncoder'), ('torch_lm TransformerModel __init__', 'torch_lm PositionalEncoding __init__'), ('torch_lm PositionalEncoding __init__', 'torch zeros'), ('torch_lm PositionalEncoding __init__', 'torch nn Module register_buffer'), ('torch_lm PositionalEncoding __init__', 'torch nn Dropout'), ('torch_lm PositionalEncoding __init__', 'torch exp'), ('torch_lm PositionalEncoding __init__', 'torch sin'), ('torch_lm PositionalEncoding __init__', 'math log'), ('torch_lm PositionalEncoding __init__', 'torch cos'), ('torch_lm PositionalEncoding __init__', 'torch arange'), ('torch_lm TransformerModel forward', 'math sqrt')]\n",
      "0\n",
      "found files: []\n",
      "import nltk\n",
      "from nltk.corpus import names\n",
      "import random\n",
      "\n",
      "SET_SPLIT = 300\n",
      "\n",
      "names = (\n",
      "    [(name, 'male') for name in names.words('male.txt')] +\n",
      "    [(name, 'female') for name in names.words('female.txt')])\n",
      "    \n",
      "random.shuffle(names)\n",
      "\n",
      "def single_features(word):\n",
      "    return {\n",
      "        'last_letter': word[-1]\n",
      "    }\n",
      "    \n",
      "feature_sets = [(single_features(n), gender) for (n, gender) in names]\n",
      "print(len(feature_sets))\n",
      "\n",
      "\n",
      "classifier = nltk.NaiveBayesClassifier.train(feature_sets[SET_SPLIT:])\n",
      "\n",
      "print(classifier.classify(single_features('Markus')))\n",
      "print(classifier.classify(single_features('Laura')))\n",
      "\n",
      "print(nltk.classify.accuracy(classifier, feature_sets[:SET_SPLIT]))\n",
      "\n",
      "\n",
      "def more_features(word):\n",
      "    return {\n",
      "        'last_letter': word[-1],\n",
      "        'second_last_letter': word[-2],\n",
      "        'rest': word[:-2]\n",
      "    }\n",
      "    \n",
      "feature_sets = [(more_features(n), gender) for (n, gender) in names]\n",
      "print(len(feature_sets))\n",
      "\n",
      "\n",
      "classifier = nltk.NaiveBayesClassifier.train(feature_sets[SET_SPLIT:])\n",
      "\n",
      "print(classifier.classify(more_features('Markus')))\n",
      "print(classifier.classify(more_features('Laura')))\n",
      "\n",
      "print(nltk.classify.accuracy(classifier, feature_sets[:SET_SPLIT]))\n",
      "\n",
      "Output: {'gender_classification_naive_bayes': ['nltk.classify.accuracy', 'gender_classification_naive_bayes.more_features', 'gender_classification_naive_bayes.single_features', 'random.shuffle', '<builtin>.len', 'nltk.NaiveBayesClassifier.train', 'nltk.corpus.names.words', '<builtin>.print'], 'nltk.corpus.names.words': [], 'random.shuffle': [], 'gender_classification_naive_bayes.single_features': [], '<builtin>.len': [], '<builtin>.print': [], 'nltk.NaiveBayesClassifier.train': [], 'nltk.classify.accuracy': [], 'gender_classification_naive_bayes.more_features': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\naetherm_NLP\\text-classification\\gender_classification_naive_bayes.py\n",
      "[('gender_classification_naive_bayes', 'nltk classify accuracy'), ('gender_classification_naive_bayes', 'gender_classification_naive_bayes more_features'), ('gender_classification_naive_bayes', 'gender_classification_naive_bayes single_features'), ('gender_classification_naive_bayes', 'random shuffle'), ('gender_classification_naive_bayes', 'nltk NaiveBayesClassifier train'), ('gender_classification_naive_bayes', 'nltk corpus names words')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('05_seq2seq_bilstm', '05_seq2seq_bilstm pad_sentence_batch'), ('05_seq2seq_bilstm', 'tensorflow compat v1 global_variables_initializer'), ('05_seq2seq_bilstm', 'tensorflow compat v1 reset_default_graph'), ('05_seq2seq_bilstm', 'tensorflow compat v1 disable_v2_behavior'), ('05_seq2seq_bilstm', 'sklearn utils shuffle'), ('05_seq2seq_bilstm', '05_seq2seq_bilstm cleanup_and_expand_text'), ('05_seq2seq_bilstm', '05_seq2seq_bilstm str_idx'), ('05_seq2seq_bilstm', 'tensorflow compat v1 InteractiveSession'), ('05_seq2seq_bilstm', '05_seq2seq_bilstm LSTMChatbot __init__'), ('05_seq2seq_bilstm', '05_seq2seq_bilstm generate_dataset'), ('05_seq2seq_bilstm', 'time time'), ('05_seq2seq_bilstm', 'tensorflow argmax'), ('05_seq2seq_bilstm generate_dataset', 'collections Counter'), ('05_seq2seq_bilstm cleanup_and_expand_text', 're sub'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow cast'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow compat v1 variable_scope'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow reduce_mean'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow sequence_mask'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow compat v1 nn bidirectional_dynamic_rnn'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow strided_slice'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow boolean_mask'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow_addons seq2seq sequence_loss'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow concat'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow random uniform'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow compat v1 nn rnn_cell MultiRNNCell'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow compat v1 train AdamOptimizer'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow Variable'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow compat v1 nn dynamic_rnn'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow nn embedding_lookup'), ('05_seq2seq_bilstm LSTMChatbot __init__', 'tensorflow compat v1 layers dense')], [('02_bilstm', 'tensorflow_datasets load'), ('02_bilstm', 'tensorflow keras optimizers Adam'), ('02_bilstm', 'tensorflow keras layers LSTM'), ('02_bilstm', 'tensorflow keras losses BinaryCrossentropy'), ('02_bilstm', 'tensorflow keras layers Bidirectional'), ('02_bilstm', 'tensorflow keras Sequential'), ('02_bilstm', 'tensorflow keras layers Embedding'), ('02_bilstm', 'tensorflow keras layers Dense'), ('02_bilstm plot_graphs', 'matplotlib pyplot xlabel'), ('02_bilstm plot_graphs', 'matplotlib pyplot legend'), ('02_bilstm plot_graphs', 'matplotlib pyplot plot'), ('02_bilstm plot_graphs', 'matplotlib pyplot ylabel'), ('02_bilstm plot_graphs', 'matplotlib pyplot show')], [('split_sentences', 'time time'), ('split_sentences', 'spacy load'), ('split_sentences', 'nltk data load'), ('split_sentences', 'split_sentences main'), ('split_sentences split_sentences', 'split_sentences split_sentences_nltk'), ('split_sentences main', 'split_sentences read_file'), ('split_sentences main', 'split_sentences preprocess_text'), ('split_sentences main', 'split_sentences split_sentences')], [('torch_lstm', 'numpy random seed'), ('torch_lstm', 'torch nn Module zero_grad'), ('torch_lstm', 'torch tensor'), ('torch_lstm', 'torch manual_seed'), ('torch_lstm', 'torch nn NLLLoss'), ('torch_lstm', 'torch_lstm parse_XY'), ('torch_lstm', 'torch nn Module parameters'), ('torch_lstm', 'torch_lstm parse'), ('torch_lstm', 'torch_lstm generate_char_seq'), ('torch_lstm', 'torch from_numpy'), ('torch_lstm', 'torch_lstm LSTMModel __init__'), ('torch_lstm', 'torch optim Adam'), ('torch_lstm', 'torch_lstm to_train_seq'), ('torch_lstm process_string', 'torch_lstm to_title'), ('torch_lstm process_string', 're sub'), ('torch_lstm parse_XY', 'numpy array'), ('torch_lstm iter_seq', 'numpy array'), ('torch_lstm to_train_seq', 'torch_lstm iter_seq'), ('torch_lstm generate_char_seq', 'numpy zeros'), ('torch_lstm LSTMModel __init__', 'torch nn LSTM'), ('torch_lstm LSTMModel __init__', 'torch nn Embedding'), ('torch_lstm LSTMModel __init__', 'torch nn Linear'), ('torch_lstm LSTMModel forward', 'torch nn functional log_softmax')], [('01_lstm', 'tensorflow keras layers Embedding'), ('01_lstm', 'tensorflow keras losses BinaryCrossentropy'), ('01_lstm', 'tensorflow keras optimizers Adam'), ('01_lstm', 'tensorflow_datasets load'), ('01_lstm', 'tensorflow keras layers LSTM'), ('01_lstm', 'tensorflow keras layers Dense'), ('01_lstm', 'tensorflow keras Sequential'), ('01_lstm plot_graphs', 'matplotlib pyplot xlabel'), ('01_lstm plot_graphs', 'matplotlib pyplot show'), ('01_lstm plot_graphs', 'matplotlib pyplot legend'), ('01_lstm plot_graphs', 'matplotlib pyplot plot'), ('01_lstm plot_graphs', 'matplotlib pyplot ylabel')], [('01_char_lstm', 'tensorflow data Dataset from_tensor_slices'), ('01_char_lstm', 'tensorflow keras callbacks ModelCheckpoint'), ('01_char_lstm', 'numpy array'), ('01_char_lstm', 'tensorflow random categorical'), ('01_char_lstm', 'os path join'), ('01_char_lstm', 'tensorflow squeeze'), ('01_char_lstm', '01_char_lstm build_model'), ('01_char_lstm', '01_char_lstm loss'), ('01_char_lstm build_model', 'tensorflow keras layers Dense'), ('01_char_lstm build_model', 'tensorflow keras layers Embedding'), ('01_char_lstm build_model', 'tensorflow keras layers LSTM'), ('01_char_lstm build_model', 'tensorflow keras Sequential'), ('01_char_lstm loss', 'tensorflow keras losses sparse_categorical_crossentropy')], [('04_seq2seq_birnn', '04_seq2seq_birnn cleanup_and_expand_text'), ('04_seq2seq_birnn', 'tensorflow compat v1 InteractiveSession'), ('04_seq2seq_birnn', 'sklearn utils shuffle'), ('04_seq2seq_birnn', 'tensorflow compat v1 reset_default_graph'), ('04_seq2seq_birnn', '04_seq2seq_birnn str_idx'), ('04_seq2seq_birnn', '04_seq2seq_birnn generate_dataset'), ('04_seq2seq_birnn', 'tensorflow argmax'), ('04_seq2seq_birnn', 'tensorflow compat v1 global_variables_initializer'), ('04_seq2seq_birnn', 'tensorflow compat v1 disable_v2_behavior'), ('04_seq2seq_birnn', '04_seq2seq_birnn RNNChatbot __init__'), ('04_seq2seq_birnn', 'time time'), ('04_seq2seq_birnn', '04_seq2seq_birnn pad_sentence_batch'), ('04_seq2seq_birnn generate_dataset', 'collections Counter'), ('04_seq2seq_birnn cleanup_and_expand_text', 're sub'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow cast'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow compat v1 layers dense'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow_addons seq2seq sequence_loss'), ('04_seq2seq_birnn RNNChatbot __init__', '04_seq2seq_birnn RNNChatbot __init__ cells'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow boolean_mask'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow compat v1 placeholder'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow nn embedding_lookup'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow concat'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow shape'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow compat v1 train AdamOptimizer'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow reduce_mean'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow argmax'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow Variable'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow compat v1 variable_scope'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow strided_slice'), ('04_seq2seq_birnn RNNChatbot __init__', 'tensorflow compat v1 nn rnn_cell MultiRNNCell')], [('10_bert', '10_bert to_train_seq'), ('10_bert', 'tensorflow reset_default_graph'), ('10_bert', '10_bert parseXY'), ('10_bert', 'tensorflow InteractiveSession'), ('10_bert', 'tensorflow global_variables_initializer'), ('10_bert', 'tensorflow get_collection'), ('10_bert', 'tensorflow train Saver'), ('10_bert', 'bert tokenization FullTokenizer'), ('10_bert', 'numpy isnan'), ('10_bert', 'tqdm tqdm'), ('10_bert', '10_bert BERTEntityTagger __init__'), ('10_bert', 'tensorflow keras preprocessing sequence pad_sequences'), ('10_bert', 'bert tokenization validate_case_matches_checkpoint'), ('10_bert', '10_bert parse'), ('10_bert', 'bert modeling BertConfig from_json_file'), ('10_bert', 'time time'), ('10_bert', 'numpy unique'), ('10_bert iter_seq', 'numpy array'), ('10_bert to_train_seq', '10_bert iter_seq'), ('10_bert parseXY', 'tqdm tqdm'), ('10_bert BERTEntityTagger __init__', 'tensorflow shape'), ('10_bert BERTEntityTagger __init__', 'tensorflow contrib crf crf_log_likelihood'), ('10_bert BERTEntityTagger __init__', 'tensorflow layers dense'), ('10_bert BERTEntityTagger __init__', 'tensorflow reduce_mean'), ('10_bert BERTEntityTagger __init__', 'tensorflow train AdamOptimizer'), ('10_bert BERTEntityTagger __init__', 'tensorflow boolean_mask'), ('10_bert BERTEntityTagger __init__', 'tensorflow contrib crf crf_decode'), ('10_bert BERTEntityTagger __init__', 'tensorflow equal'), ('10_bert BERTEntityTagger __init__', 'bert modeling BertModel'), ('10_bert BERTEntityTagger __init__', 'tensorflow sequence_mask')], [('tf_transformer', 'tf_transformer Transformer __init__'), ('tf_transformer', 'nltk corpus movie_reviews words'), ('tf_transformer', 'tensorflow keras layers Dense'), ('tf_transformer', 'tensorflow keras preprocessing text Tokenizer'), ('tf_transformer', 'random shuffle'), ('tf_transformer', 'nltk corpus movie_reviews fileids'), ('tf_transformer', 'tensorflow keras layers GlobalAveragePooling1D'), ('tf_transformer', 'nltk corpus movie_reviews categories'), ('tf_transformer', 'tensorflow keras preprocessing sequence pad_sequences'), ('tf_transformer', 'tensorflow keras Sequential'), ('tf_transformer', 'tf_transformer TokenAndPositionEmbedding __init__'), ('tf_transformer', 'tensorflow keras layers Dropout'), ('tf_transformer', 'numpy array'), ('tf_transformer', 'nltk download'), ('tf_transformer', 'tensorflow keras layers Input'), ('tf_transformer', 'sklearn model_selection train_test_split'), ('tf_transformer Transformer __init__', 'tensorflow keras layers Dense'), ('tf_transformer Transformer __init__', 'tensorflow keras Sequential'), ('tf_transformer Transformer __init__', 'tensorflow keras layers MultiHeadAttention'), ('tf_transformer Transformer __init__', 'tensorflow keras layers Dropout'), ('tf_transformer Transformer __init__', 'tensorflow keras layers LayerNormalization'), ('tf_transformer TokenAndPositionEmbedding __init__', 'tensorflow keras layers Embedding'), ('tf_transformer TokenAndPositionEmbedding call', 'tensorflow shape'), ('tf_transformer TokenAndPositionEmbedding call', 'tensorflow range')], [('tf_bilstm', 'tensorflow keras layers TimeDistributed'), ('tf_bilstm', 'tf_bilstm parse_XY'), ('tf_bilstm', 'tensorflow random set_seed'), ('tf_bilstm', 'tf_bilstm generate_char_seq'), ('tf_bilstm', 'tensorflow keras layers Dense'), ('tf_bilstm', 'tensorflow keras layers Embedding'), ('tf_bilstm', 'tf_bilstm parse'), ('tf_bilstm', 'tensorflow keras Sequential'), ('tf_bilstm', 'tf_bilstm to_train_seq'), ('tf_bilstm', 'tensorflow keras layers Bidirectional'), ('tf_bilstm', 'tf_bilstm train_model'), ('tf_bilstm', 'tensorflow keras layers LSTM'), ('tf_bilstm', 'numpy random seed'), ('tf_bilstm process_string', 're sub'), ('tf_bilstm process_string', 'tf_bilstm to_title'), ('tf_bilstm parse_XY', 'tensorflow keras utils to_categorical'), ('tf_bilstm parse_XY', 'numpy array'), ('tf_bilstm iter_seq', 'numpy array'), ('tf_bilstm to_train_seq', 'tf_bilstm iter_seq'), ('tf_bilstm generate_char_seq', 'numpy zeros')], [('dependency_parsing', 'dependency_parsing main'), ('dependency_parsing', 'spacy load'), ('dependency_parsing get_dependency_parse', 'spacy explain'), ('dependency_parsing main', 'dependency_parsing get_dependency_parse')], [('02_bilstm', '02_bilstm train'), ('02_bilstm', '02_bilstm lazy_scan_vocabulary'), ('02_bilstm', '02_bilstm BILSTMModel __init__'), ('02_bilstm lazy_scan_vocabulary', 'collections Counter'), ('02_bilstm lazy_scan_vocabulary', 'tqdm tqdm'), ('02_bilstm sent_to_xy', '02_bilstm space_tag'), ('02_bilstm sent_to_xy', 'torch LongTensor'), ('02_bilstm sent_to_xy', '02_bilstm to_idx'), ('02_bilstm BILSTMModel __init__', 'torch nn Embedding'), ('02_bilstm BILSTMModel __init__', 'torch nn LSTM'), ('02_bilstm BILSTMModel __init__', 'torch nn Linear'), ('02_bilstm BILSTMModel __init__', '02_bilstm BILSTMModel init_hidden'), ('02_bilstm BILSTMModel init_hidden', 'torch zeros'), ('02_bilstm BILSTMModel forward', 'torch nn functional log_softmax'), ('02_bilstm BILSTMModel forward', '02_bilstm BILSTMModel init_hidden'), ('02_bilstm train', 'torch nn Module parameters'), ('02_bilstm train', 'torch optim Adam'), ('02_bilstm train', 'tqdm tqdm'), ('02_bilstm train', '02_bilstm BILSTMModel init_hidden'), ('02_bilstm train', 'torch device'), ('02_bilstm train', 'torch nn Module zero_grad'), ('02_bilstm train', '02_bilstm BILSTMModel __init__'), ('02_bilstm train', 'numpy argmax'), ('02_bilstm train', 'numpy asarray'), ('02_bilstm train', '02_bilstm train get_batches'), ('02_bilstm train', 'torch nn CrossEntropyLoss'), ('02_bilstm train', 'torch cuda is_available'), ('02_bilstm train', 'time time'), ('02_bilstm train get_batches', '02_bilstm sent_to_xy')], [('ner_visualization', 'ner_visualization main'), ('ner_visualization', 'spacy load'), ('ner_visualization visualize', 'spacy displacy serve'), ('ner_visualization save_as_html', 'spacy displacy render'), ('ner_visualization main', 'ner_visualization save_as_html'), ('ner_visualization main', 'ner_visualization visualize')], [('torch_lm', 'torch_lm evaluate'), ('torch_lm', 'torch nn Module to'), ('torch_lm', 'math exp'), ('torch_lm', 'torchtext vocab build_vocab_from_iterator'), ('torch_lm', 'torch nn CrossEntropyLoss'), ('torch_lm', 'torchtext datasets WikiText103'), ('torch_lm', 'torch_lm gen_all_batches'), ('torch_lm', 'torch optim SGD'), ('torch_lm', 'torch_lm data_processing'), ('torch_lm', 'torchtext data utils get_tokenizer'), ('torch_lm', 'torch device'), ('torch_lm', 'torch_lm TransformerModel __init__'), ('torch_lm', 'copy deepcopy'), ('torch_lm', 'torch_lm train'), ('torch_lm', 'torch cuda is_available'), ('torch_lm TransformerModel __init__', 'torch nn Embedding'), ('torch_lm TransformerModel __init__', 'torch nn Linear'), ('torch_lm TransformerModel __init__', 'torch nn TransformerEncoderLayer'), ('torch_lm TransformerModel __init__', 'torch_lm TransformerModel init_weights'), ('torch_lm TransformerModel __init__', 'torch nn TransformerEncoder'), ('torch_lm TransformerModel __init__', 'torch_lm PositionalEncoding __init__'), ('torch_lm PositionalEncoding __init__', 'torch zeros'), ('torch_lm PositionalEncoding __init__', 'torch nn Module register_buffer'), ('torch_lm PositionalEncoding __init__', 'torch nn Dropout'), ('torch_lm PositionalEncoding __init__', 'torch exp'), ('torch_lm PositionalEncoding __init__', 'torch sin'), ('torch_lm PositionalEncoding __init__', 'math log'), ('torch_lm PositionalEncoding __init__', 'torch cos'), ('torch_lm PositionalEncoding __init__', 'torch arange'), ('torch_lm TransformerModel forward', 'math sqrt')], [('gender_classification_naive_bayes', 'nltk classify accuracy'), ('gender_classification_naive_bayes', 'gender_classification_naive_bayes more_features'), ('gender_classification_naive_bayes', 'gender_classification_naive_bayes single_features'), ('gender_classification_naive_bayes', 'random shuffle'), ('gender_classification_naive_bayes', 'nltk NaiveBayesClassifier train'), ('gender_classification_naive_bayes', 'nltk corpus names words')]]\n",
      "********************doctrings*************************\n",
      "['generate dataset cleanup and expand text str idx pad sentence batch', 'plot graphs', 'read file preprocess text split sentences nltk split sentences spacy split sentences main', 'parse process string to title parse   iter seq to train seq generate char seq', 'plot graphs', 'split input target build model loss', 'generate dataset cleanup and expand text str idx pad sentence batch', 'parse iter seq to train seq parse', '', 'parse process string to title parse   iter seq to train seq generate char seq train model', 'get dependency parse main', 'get length of file in lines lazy scan vocabulary space tag to idx to item sent to xy train [SEP] Responsible for loading the whole vocabulary of the given training set. :param sent: str   Input sentence :param nonspace: Object   Non-space tag. Default is 0, int typ :param item: Object   Object to be encoded :param mapper: dict   Dictiona', 'visualize save as html main', 'generate square subsequent mask data processing gen all batches get batch train evaluate', 'single features more features']\n",
      "embed index dataset: 22\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\dhk3136_summarization-bert-vs-baseline\\\\summarizer\\\\BertParent.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\dhk3136_summarization-bert-vs-baseline\\\\summarizer\\\\ClusterFeatures.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\dhk3136_summarization-bert-vs-baseline\\\\summarizer\\\\model_processors.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\dhk3136_summarization-bert-vs-baseline\\\\summarize.py']\n",
      "from pytorch_pretrained_bert import BertTokenizer, BertModel, GPT2Model, GPT2Tokenizer\n",
      "import logging\n",
      "import torch\n",
      "import numpy as np\n",
      "from tqdm import tqdm\n",
      "from numpy import ndarray\n",
      "from typing import List\n",
      "\n",
      "logging.basicConfig(level=logging.WARNING)\n",
      "\n",
      "\n",
      "class BertParent(object):\n",
      "\n",
      "    def __init__(self, model: str, vector_size: int=None):\n",
      "        self.model = BertModel.from_pretrained(model)\n",
      "        self.tokenizer = BertTokenizer.from_pretrained(model)\n",
      "\n",
      "        if model == 'bert-base-uncased':\n",
      "            self.vector_size = 768\n",
      "        elif model == 'bert-large-uncased':\n",
      "            self.vector_size = 1024\n",
      "        elif vector_size is None:\n",
      "            raise RuntimeError(\"Vector size must be supplied for custom models\")\n",
      "        else:\n",
      "            self.vector_size = vector_size\n",
      "\n",
      "        self.model.eval()\n",
      "\n",
      "    def tokenize_input(self, text: str) -> torch.tensor:\n",
      "        tokenized_text = self.tokenizer.tokenize(text)\n",
      "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
      "        return torch.tensor([indexed_tokens])\n",
      "\n",
      "    def extract_embeddings(self, text: str, hidden: int=-2, squeeze: bool=False, reduce_option: str ='mean') -> ndarray:\n",
      "        tokens_tensor = self.tokenize_input(text)\n",
      "        hidden_states, pooled = self.model(tokens_tensor)\n",
      "\n",
      "        if hidden < -1 and hidden > -12:\n",
      "            if reduce_option == 'max':\n",
      "                pooled = hidden_states[hidden].max(dim=1)\n",
      "            elif reduce_option == 'median':\n",
      "                pooled = hidden_states[hidden].median(dim=1)\n",
      "            else:\n",
      "                pooled = hidden_states[hidden].mean(dim=1)\n",
      "\n",
      "        if squeeze:\n",
      "            return pooled.detach().numpy().squeeze()\n",
      "\n",
      "        return pooled\n",
      "\n",
      "    def create_matrix(self, content: List[str], hidden: int=-2, reduce_option: str = 'mean') -> ndarray:\n",
      "        train_vec = np.zeros((len(content), self.vector_size))\n",
      "        for i, t in tqdm(enumerate(content)):\n",
      "            train_vec[i] = self.extract_embeddings(t, hidden=hidden, reduce_option=reduce_option).data.numpy()\n",
      "        return train_vec\n",
      "\n",
      "    def __call__(self, content: List[str], hidden: int=-2, reduce_option: str = 'mean') -> ndarray:\n",
      "        return self.create_matrix(content, hidden, reduce_option)\n",
      "\n",
      "Output: {'BertParent': ['logging.basicConfig'], 'logging.basicConfig': [], 'BertParent.BertParent.__init__': ['pytorch_pretrained_bert.BertModel.from_pretrained', 'pytorch_pretrained_bert.BertTokenizer.from_pretrained', '<builtin>.RuntimeError'], 'pytorch_pretrained_bert.BertModel.from_pretrained': [], 'pytorch_pretrained_bert.BertTokenizer.from_pretrained': [], '<builtin>.RuntimeError': [], 'BertParent.BertParent.tokenize_input': ['torch.tensor'], 'torch.tensor': [], 'BertParent.BertParent.extract_embeddings': ['BertParent.BertParent.tokenize_input'], 'BertParent.BertParent.create_matrix': ['<builtin>.enumerate', '<builtin>.len', 'numpy.zeros', 'tqdm.tqdm', 'BertParent.BertParent.extract_embeddings'], '<builtin>.len': [], 'numpy.zeros': [], '<builtin>.enumerate': [], 'tqdm.tqdm': [], 'BertParent.BertParent.__call__': ['BertParent.BertParent.create_matrix']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\dhk3136_summarization-bert-vs-baseline\\summarizer\\BertParent.py\n",
      "[('BertParent', 'logging basicConfig'), ('BertParent BertParent __init__', 'pytorch_pretrained_bert BertModel from_pretrained'), ('BertParent BertParent __init__', 'pytorch_pretrained_bert BertTokenizer from_pretrained'), ('BertParent BertParent tokenize_input', 'torch tensor'), ('BertParent BertParent extract_embeddings', 'BertParent BertParent tokenize_input'), ('BertParent BertParent create_matrix', 'numpy zeros'), ('BertParent BertParent create_matrix', 'tqdm tqdm'), ('BertParent BertParent create_matrix', 'BertParent BertParent extract_embeddings'), ('BertParent BertParent __call__', 'BertParent BertParent create_matrix')]\n",
      "0\n",
      "found files: []\n",
      "import numpy as np\n",
      "from numpy import ndarray\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.mixture import GaussianMixture\n",
      "from sklearn.decomposition import PCA\n",
      "from typing import List\n",
      "\n",
      "\n",
      "class ClusterFeatures(object):\n",
      "\n",
      "    def __init__(self, features: ndarray, algorithm: str='kmeans', pca_k: int=None):\n",
      "        if pca_k:\n",
      "            self.features = PCA(n_components=pca_k).fit_transform(features)\n",
      "        else:\n",
      "            self.features = features\n",
      "        self.algorithm = algorithm\n",
      "        self.pca_k = pca_k\n",
      "\n",
      "    def __get_model(self, k: int):\n",
      "        if self.algorithm == 'gmm':\n",
      "            return GaussianMixture(n_components=k)\n",
      "        return KMeans(n_clusters=k)\n",
      "\n",
      "    def __get_centroids(self, model):\n",
      "        if self.algorithm == 'gmm':\n",
      "            return model.means_\n",
      "        return model.cluster_centers_\n",
      "\n",
      "    def __find_closest_args(self, centroids):\n",
      "        centroid_min = 1e7\n",
      "        cur_arg = -1\n",
      "        args = {}\n",
      "        used_idx = []\n",
      "        for j, centroid in enumerate(centroids):\n",
      "            for i, feature in enumerate(self.features):\n",
      "                value = np.sum(np.abs(feature - centroid))\n",
      "                if value < centroid_min and i not in used_idx:\n",
      "                    cur_arg = i\n",
      "                    centroid_min = value\n",
      "            used_idx.append(cur_arg)\n",
      "            args[j] = cur_arg\n",
      "            centroid_min = 1e7\n",
      "            cur_arg = -1\n",
      "        return args\n",
      "\n",
      "    # change ratios for following two functions to control summary length; keep consistent at the same ratio; default = 0.2\n",
      "    def cluster(self, ratio: float=0.13) -> List[int]:\n",
      "        k = 1 if ratio * len(self.features) < 1 else int(len(self.features) * ratio)\n",
      "        model = self.__get_model(k).fit(self.features)\n",
      "        centroids = self.__get_centroids(model)\n",
      "        cluster_args = self.__find_closest_args(centroids)\n",
      "        sorted_values = sorted(cluster_args.values())\n",
      "        return sorted_values\n",
      "\n",
      "    def __call__(self, ratio: float=0.13) -> List[int]:\n",
      "        return self.cluster(ratio)\n",
      "\n",
      "Output: {'ClusterFeatures': [], 'ClusterFeatures.ClusterFeatures.__init__': ['sklearn.decomposition.PCA'], 'sklearn.decomposition.PCA': [], 'ClusterFeatures.ClusterFeatures.__get_model': ['sklearn.mixture.GaussianMixture', 'sklearn.cluster.KMeans'], 'sklearn.mixture.GaussianMixture': [], 'sklearn.cluster.KMeans': [], 'ClusterFeatures.ClusterFeatures.__get_centroids': [], 'ClusterFeatures.ClusterFeatures.__find_closest_args': ['numpy.abs', '<builtin>.enumerate', 'numpy.sum'], '<builtin>.enumerate': [], 'numpy.abs': [], 'numpy.sum': [], 'ClusterFeatures.ClusterFeatures.cluster': ['ClusterFeatures.ClusterFeatures.__get_model', '<builtin>.sorted', '<builtin>.int', 'ClusterFeatures.ClusterFeatures.__find_closest_args', 'ClusterFeatures.ClusterFeatures.__get_centroids', '<builtin>.len'], '<builtin>.len': [], '<builtin>.int': [], '<builtin>.sorted': [], 'ClusterFeatures.ClusterFeatures.__call__': ['ClusterFeatures.ClusterFeatures.cluster']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\dhk3136_summarization-bert-vs-baseline\\summarizer\\ClusterFeatures.py\n",
      "[('ClusterFeatures ClusterFeatures __init__', 'sklearn decomposition PCA'), ('ClusterFeatures ClusterFeatures __get_model', 'sklearn mixture GaussianMixture'), ('ClusterFeatures ClusterFeatures __get_model', 'sklearn cluster KMeans'), ('ClusterFeatures ClusterFeatures __find_closest_args', 'numpy abs'), ('ClusterFeatures ClusterFeatures __find_closest_args', 'numpy sum'), ('ClusterFeatures ClusterFeatures cluster', 'ClusterFeatures ClusterFeatures __get_model'), ('ClusterFeatures ClusterFeatures cluster', 'ClusterFeatures ClusterFeatures __find_closest_args'), ('ClusterFeatures ClusterFeatures cluster', 'ClusterFeatures ClusterFeatures __get_centroids'), ('ClusterFeatures ClusterFeatures __call__', 'ClusterFeatures ClusterFeatures cluster')]\n",
      "0\n",
      "found files: []\n",
      "from summarizer.BertParent import BertParent\n",
      "from typing import List\n",
      "from summarizer.ClusterFeatures import ClusterFeatures\n",
      "from abc import abstractmethod\n",
      "import neuralcoref\n",
      "from spacy.lang.en import English\n",
      "\n",
      "\n",
      "class ModelProcessor(object):\n",
      "\n",
      "    def __init__(self, model='bert-large-uncased',\n",
      "                 vector_size: int = None,\n",
      "                 hidden: int=-2,\n",
      "                 reduce_option: str = 'mean',\n",
      "                 greedyness: float=0.45):\n",
      "        self.model = BertParent(model, vector_size)\n",
      "        self.hidden = hidden\n",
      "        self.vector_size = vector_size\n",
      "        self.reduce_option = reduce_option\n",
      "        self.nlp = English()\n",
      "        self.nlp.add_pipe(self.nlp.create_pipe('sentencizer'))\n",
      "        neuralcoref.add_to_pipe(self.nlp, greedyness=greedyness)\n",
      "\n",
      "    def process_content_sentences(self, body: str, min_length=40, max_length=1000) -> List[str]:\n",
      "        doc = self.nlp(body)._.coref_resolved\n",
      "        doc = self.nlp(doc)\n",
      "        return [c.string.strip() for c in doc.sents\n",
      "                if len(c.string.strip()) > min_length and len(c.string.strip()) < max_length]\n",
      "\n",
      "    # change ratio for four functions below to specify size of summary (keep all ratios consistent); default = 0.2 for all\n",
      "    @abstractmethod\n",
      "    def run_clusters(self, content: List[str], ratio=0.13, algorithm='kmeans', use_first: bool=True) -> List[str]:\n",
      "        raise NotImplementedError(\"Must Implement run_clusters\")\n",
      "\n",
      "    def run(self, body: str, ratio: float=0.13, min_length: int=40, max_length: int=1000,\n",
      "            use_first: bool=True, algorithm='kmeans') -> str:\n",
      "        sentences = self.process_content_sentences(body, min_length, max_length)\n",
      "        res = self.run_clusters(sentences, ratio, algorithm, use_first)\n",
      "        return ' '.join(res)\n",
      "\n",
      "    def __call__(self, body: str, ratio: float=0.13, min_length: int=40, max_length: int=1000,\n",
      "                 use_first: bool=True, algorithm='kmeans') -> str:\n",
      "        return self.run(body, ratio, min_length, max_length)\n",
      "\n",
      "\n",
      "class SingleModel(ModelProcessor):\n",
      "\n",
      "    def __init__(self, model='bert-large-uncased',\n",
      "                 vector_size: int = None,\n",
      "                 hidden: int=-2,\n",
      "                 reduce_option: str = 'mean',\n",
      "                 greedyness: float=0.45):\n",
      "        super(SingleModel, self).__init__(model, vector_size, hidden, reduce_option, greedyness)\n",
      "\n",
      "    def run_clusters(self, content: List[str], ratio=0.13, algorithm='kmeans', use_first: bool= True) -> List[str]:\n",
      "        hidden = self.model(content, self.hidden, self.reduce_option)\n",
      "        hidden_args = ClusterFeatures(hidden, algorithm).cluster(ratio)\n",
      "        if use_first:\n",
      "            if hidden_args[0] != 0:\n",
      "                hidden_args.insert(0,0)\n",
      "        return [content[j] for j in hidden_args]\n",
      "        \n",
      "Output: {'model_processors': [], 'model_processors.ModelProcessor.__init__': ['spacy.lang.en.English', 'neuralcoref.add_to_pipe', 'summarizer.BertParent.BertParent'], 'summarizer.BertParent.BertParent': [], 'spacy.lang.en.English': [], 'neuralcoref.add_to_pipe': [], 'model_processors.ModelProcessor.process_content_sentences': ['<builtin>.len'], '<builtin>.len': [], 'model_processors.ModelProcessor': ['abc.abstractmethod'], 'abc.abstractmethod': [], 'model_processors.ModelProcessor.run_clusters': ['<builtin>.NotImplementedError'], '<builtin>.NotImplementedError': [], 'model_processors.ModelProcessor.run': ['model_processors.ModelProcessor.run_clusters', 'model_processors.ModelProcessor.process_content_sentences'], 'model_processors.ModelProcessor.__call__': ['model_processors.ModelProcessor.run'], 'model_processors.SingleModel.__init__': ['<builtin>.super'], '<builtin>.super': [], 'model_processors.SingleModel.run_clusters': ['summarizer.ClusterFeatures.ClusterFeatures'], 'summarizer.ClusterFeatures.ClusterFeatures': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\dhk3136_summarization-bert-vs-baseline\\summarizer\\model_processors.py\n",
      "[('model_processors ModelProcessor __init__', 'spacy lang en English'), ('model_processors ModelProcessor __init__', 'neuralcoref add_to_pipe'), ('model_processors ModelProcessor __init__', 'summarizer BertParent BertParent'), ('model_processors ModelProcessor', 'abc abstractmethod'), ('model_processors ModelProcessor run', 'model_processors ModelProcessor run_clusters'), ('model_processors ModelProcessor run', 'model_processors ModelProcessor process_content_sentences'), ('model_processors ModelProcessor __call__', 'model_processors ModelProcessor run'), ('model_processors SingleModel run_clusters', 'summarizer ClusterFeatures ClusterFeatures')]\n",
      "0\n",
      "found files: []\n",
      "import numpy as np\n",
      "from summarizer import SingleModel\n",
      "import bs4 as bs  \n",
      "import urllib.request  \n",
      "import re\n",
      "import argparse\n",
      "import nltk\n",
      "import logging\n",
      "import heapq\n",
      "\n",
      "\n",
      "# choose BERT or vanilla summarizer\n",
      "choose_bert_or_vanilla = input('Please enter 1 to use the BERT summarizer or 2 for the Vanilla summarizer:\\n')\n",
      "\n",
      "# BERT summarizer\n",
      "if choose_bert_or_vanilla == '1':\n",
      "    print('Welcome to the BERT Summarizer!\\n')\n",
      "    \n",
      "    # choose URL, text file, or copy/paste input\n",
      "    choose_summarizer = input('Enter A for URL input:\\nEnter B for text file input:\\nEnter C for copy/paste input:\\n(case-sensitive)\\n')\n",
      "\n",
      "    if choose_summarizer == 'A':\n",
      "        print('\\nOption A processes and summarizes web articles.\\nBest results are obtained by entering a URL of a text-centric website (e.g., Wikipedia, news sites, blogs.)\\n')\n",
      "        print(\"NB: A good rule of thumb... if your browser can display the webpage via its 'Reader View,' it's likely the summarizer is compatible with the site.\")\n",
      "        print(\"If not, feel free to start over and select one of the other two summary options; it's just as simple to use the Text Document Summarizer or the Copy/Paste Summarizer.\\n\")\n",
      "        print(\"Either enter the URL of the page you'd like to summarize or feel free to copy/paste one of the URLs below to take the summarizer out for a spin:\")\n",
      "        print('https://en.wikipedia.org/wiki/Chernobyl_(miniseries)\\nhttps://www.blog.google/products/assistant/more-information-about-our-processes-safeguard-speech-data\\n')\n",
      "        print(\"If you'd like a copy of your summary, you can find it in the `your_summaries` directory.\\n\")\n",
      "\n",
      "        # taking input from website article\n",
      "        url = input('URL to summarize:\\n')\n",
      "        print('Summarizing...')\n",
      "\n",
      "        # fetching and reading in data from URL\n",
      "        scraped_data = urllib.request.urlopen(url)  \n",
      "        article = scraped_data.read()\n",
      "\n",
      "        # using beautifulsoup to parse article\n",
      "        parsed_article = bs.BeautifulSoup(article,'lxml')\n",
      "        paragraphs = parsed_article.find_all('p')\n",
      "\n",
      "        # iterating and appending text to string\n",
      "        article_text = \"\"\n",
      "\n",
      "        for p in paragraphs:  \n",
      "            article_text += p.text\n",
      "\n",
      "        # model default params\n",
      "        # use bert-base-uncased for smaller, less resource-intensive model\n",
      "        model = SingleModel(\n",
      "            model='bert-large-uncased',\n",
      "            vector_size=None,\n",
      "            hidden=-2,\n",
      "            reduce_option='mean'\n",
      "    )\n",
      "\n",
      "        # passing in full text to model\n",
      "        m = model(article_text)\n",
      "\n",
      "        # creating final summary with a ratio of 0.13\n",
      "        summary_file = '\\n\\nSUMMARY:\\n' + m\n",
      "\n",
      "        # printing summary and full text for comparison\n",
      "        print(f'\\nSUMMARY:\\n{model(article_text)}\\n')\n",
      "        print(f'FULL TEXT:\\n', article_text)\n",
      "        \n",
      "        # appending summary output to text file\n",
      "        with open('your_summaries/summary.txt', 'a') as summary_output:\n",
      "            for line in summary_file:\n",
      "                summary_output.write(line)\n",
      "\n",
      "\n",
      "    # text file summary option\n",
      "    elif choose_summarizer == 'B':\n",
      "        print('\\nOption B summarizes text documents from Google Drive or your local machine.\\n')\n",
      "        print(\"\\nSimply provide the path to the text document you'd like to summarize.\\nOr feel free to copy/paste the filename of one of the sample documents below:\\n\")\n",
      "        print('full_text/google_pixel_photobooth_article.txt')\n",
      "        print('full_text/wash_post_youth_trending_away_from_news.txt\\n')\n",
      "        print(\"If you'd like a copy of your summary, you can find it in the `your_summaries` directory.\\n\")\n",
      "\n",
      "        document = input('Enter your <path/to/file.txt> here:\\n')\n",
      "\n",
      "        # reading in text file\n",
      "        with open(document, 'r') as d:\n",
      "            text_data = d.read()\n",
      "\n",
      "        # importing model and passing in full text\n",
      "        model = SingleModel()\n",
      "        m = model(text_data)\n",
      "\n",
      "        # creating final summary with a ratio of 0.13\n",
      "        summary_file = '\\n\\nSUMMARY:\\n' + m\n",
      "\n",
      "        # printing summary and full text output for comparison\n",
      "        print(f'\\nSUMMARY:\\n{model(text_data)}\\n')\n",
      "        print(f'FULL TEXT:\\n', text_data)\n",
      "\n",
      "        # appending summary output to text file\n",
      "        with open('your_summaries/summary.txt', 'a') as summary_output:\n",
      "            for line in summary_file:\n",
      "                summary_output.write(line)\n",
      "\n",
      "\n",
      "    # copy/paste string input option\n",
      "    elif choose_summarizer == 'C':\n",
      "        print(\"\\nFor Option C, simply copy/paste any text you'd like to summarize below.\\n\\n\")\n",
      "        print(\"If you'd like a copy of your summary, you can find it in the `your_summaries` directory.\\n\")\n",
      "\n",
      "        text_copy_paste = input('INPUT:\\n')\n",
      "        text_copy_paste = 'Please wait while your summary is processing...'\n",
      "\n",
      "        # importing model and passing in full-text string\n",
      "        model = SingleModel()\n",
      "        m = model(text_copy_paste)\n",
      "\n",
      "        # creating final summary with a ratio of 0.13\n",
      "        summary_file = '\\n\\nSUMMARY:\\n' + m\n",
      "\n",
      "        # printing summary and full text output for comparison\n",
      "        print(f'\\n\\nSUMMARY:\\n{model(text_copy_paste)}\\n')\n",
      "        print(f'FULL TEXT:\\n', text_copy_paste)\n",
      "\n",
      "        # appending summary output to text file\n",
      "        with open('your_summaries/summary.txt', 'a') as summary_output:\n",
      "            for line in summary_file:\n",
      "                summary_output.write(line)\n",
      "\n",
      "    else:\n",
      "        print('\\nMust choose from A, B, or C')\n",
      "\n",
      "\n",
      "# baseline summarizer\n",
      "if choose_bert_or_vanilla == '2':\n",
      "    print('Welcome to the Baseline Model Summarizer!\\n')\n",
      "\n",
      "    # choose URL, text file, or string input\n",
      "    choose_input = input('Enter A for URL input:\\nEnter B for text file input:\\nEnter C for copy/paste input:\\n(case-sensitive)\\n')\n",
      "\n",
      "    if choose_input == 'A':\n",
      "        print('\\nOption A processes and summarizes web articles.\\nBest results are obtained by entering a URL of a text-centric website (e.g., Wikipedia, news sites, blogs.)\\n')\n",
      "        print(\"NB: A good rule of thumb... if your browser can display the webpage via its 'Reader View,' it's likely the summarizer is compatible with the site.\")\n",
      "        print(\"If not, feel free to start over and select one of the other two summary options; it's just as simple to use the Text Document Summarizer or the Copy/Paste Summarizer.\\n\")\n",
      "        print(\"Either enter the URL of the page you'd like to summarize or feel free to copy/paste one of the URLs below to take the summarizer out for a spin:\")\n",
      "        print('https://en.wikipedia.org/wiki/Chernobyl_(miniseries)\\nhttps://www.blog.google/products/assistant/more-information-about-our-processes-safeguard-speech-data\\n')\n",
      "        print(\"If you'd like a copy of your summary, you can find it in the `your_summaries` directory.\\n\")\n",
      "\n",
      "        # enter URL\n",
      "        url = input('URL to summarize: \\n')\n",
      "        print('Summarizing...')\n",
      "\n",
      "        # fetching and reading in data from URL\n",
      "        scraped_data = urllib.request.urlopen(url)  \n",
      "        article = scraped_data.read()\n",
      "\n",
      "        # using beautifulsoup to parse article\n",
      "        parsed_article = bs.BeautifulSoup(article,'lxml')\n",
      "        paragraphs = parsed_article.find_all('p')\n",
      "\n",
      "        # iterating and appending to full-text string\n",
      "        article_text = \"\"\n",
      "\n",
      "        for p in paragraphs:  \n",
      "            article_text += p.text\n",
      "\n",
      "        # text clean up\n",
      "        article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)  \n",
      "        article_text = re.sub(r'\\s+', ' ', article_text)  \n",
      "\n",
      "        processed_article = re.sub('[^a-zA-Z]', ' ', article_text )  \n",
      "        processed_article = re.sub(r'\\s+', ' ', processed_article)\n",
      "\n",
      "        # sentence-level tokenization of full text\n",
      "        sentence_list = nltk.sent_tokenize(article_text)  \n",
      "\n",
      "        # NLTK stopwords\n",
      "        stopwords = nltk.corpus.stopwords.words('english')\n",
      "\n",
      "        # creating term frequency dict\n",
      "        word_frequencies = {}  \n",
      "        for word in nltk.word_tokenize(processed_article):  \n",
      "            if word not in stopwords:\n",
      "                if word not in word_frequencies.keys():\n",
      "                    word_frequencies[word] = 1\n",
      "                else:\n",
      "                    word_frequencies[word] += 1\n",
      "\n",
      "        maximum_frequency = max(word_frequencies.values())\n",
      "\n",
      "        # adding term frequency ratio as dict values\n",
      "        for word in word_frequencies.keys():  \n",
      "            word_frequencies[word] = (word_frequencies[word]/maximum_frequency)\n",
      "\n",
      "        # ranking sentences for summary inclusion\n",
      "        sentence_scores = {}  \n",
      "        for sent in sentence_list:  \n",
      "            for word in nltk.word_tokenize(sent.lower()):\n",
      "                if word in word_frequencies.keys():\n",
      "                    if len(sent.split(' ')) < 30:\n",
      "                        if sent not in sentence_scores.keys():\n",
      "                            sentence_scores[sent] = word_frequencies[word]\n",
      "                        else:\n",
      "                            sentence_scores[sent] += word_frequencies[word]\n",
      "\n",
      "        # creating final summary with default 4 highest-scoring sentences\n",
      "        summary_sentences = heapq.nlargest(4, sentence_scores, key=sentence_scores.get)\n",
      "        summary_sentences = ''.join(summary_sentences)\n",
      "        summary_file = '\\n\\nSUMMARY:\\n' + summary_sentences\n",
      "\n",
      "        # printing summary and full text for comparison\n",
      "        print(f'\\nSUMMARY:\\n{summary_sentences}\\n\\n')\n",
      "        print(f'FULL TEXT:')\n",
      "        print(article_text)\n",
      "\n",
      "        # appending summary output to text file\n",
      "        with open('your_summaries/summary.txt', 'a') as summary_output:\n",
      "            for line in summary_file:\n",
      "                summary_output.write(line)\n",
      "\n",
      "\n",
      "    # text file input option\n",
      "    elif choose_input == 'B':\n",
      "        print('\\nOption B summarizes text documents from Google Drive or your local machine.\\n')\n",
      "        print(\"\\nSimply provide the path to the text document you'd like to summarize.\\nOr feel free to copy/paste the filename of one of the sample documents below:\\n\")\n",
      "        print('full_text/google_pixel_photobooth_article.txt')\n",
      "        print('full_text/wash_post_youth_trending_away_from_news.txt\\n')\n",
      "        print(\"If you'd like a copy of your summary, you can find it in the `your_summaries` directory.\\n\")\n",
      "\n",
      "        document = input('Please enter your <path/to/file.txt> here:\\n')\n",
      "\n",
      "        # reading in text file\n",
      "        with open(document, 'r') as d:\n",
      "            text_data = d.read()\n",
      "\n",
      "        # text clean up\n",
      "        text_data = re.sub(r'\\[[0-9]*\\]', ' ', text_data)  \n",
      "        text_data = re.sub(r'\\s+', ' ', text_data)  \n",
      "\n",
      "        processed_article = re.sub('[^a-zA-Z]', ' ', text_data )  \n",
      "        processed_article = re.sub(r'\\s+', ' ', processed_article)\n",
      "\n",
      "        # sentence-level tokenization of full text\n",
      "        sentence_list = nltk.sent_tokenize(text_data)  \n",
      "\n",
      "        # NLTK stopword list\n",
      "        stopwords = nltk.corpus.stopwords.words('english')\n",
      "\n",
      "        # creating term frequency dict\n",
      "        word_frequencies = {}  \n",
      "        for word in nltk.word_tokenize(processed_article):  \n",
      "            if word not in stopwords:\n",
      "                if word not in word_frequencies.keys():\n",
      "                    word_frequencies[word] = 1\n",
      "                else:\n",
      "                    word_frequencies[word] += 1\n",
      "\n",
      "        maximum_frequency = max(word_frequencies.values())\n",
      "\n",
      "        # adding term frequency ratios as dict values\n",
      "        for word in word_frequencies.keys():  \n",
      "            word_frequencies[word] = (word_frequencies[word]/maximum_frequency)\n",
      "\n",
      "        # ranking sentences for summary inclusion\n",
      "        sentence_scores = {}  \n",
      "        for sent in sentence_list:  \n",
      "            for word in nltk.word_tokenize(sent.lower()):\n",
      "                if word in word_frequencies.keys():\n",
      "                    if len(sent.split(' ')) < 30:\n",
      "                        if sent not in sentence_scores.keys():\n",
      "                            sentence_scores[sent] = word_frequencies[word]\n",
      "                        else:\n",
      "                            sentence_scores[sent] += word_frequencies[word]\n",
      "\n",
      "        # creating final summary with default 4 highest-scoring sentences\n",
      "        summary_sentences = heapq.nlargest(4, sentence_scores, key=sentence_scores.get)\n",
      "        summary_sentences = ''.join(summary_sentences)\n",
      "        summary_file = '\\n\\nSUMMARY:\\n' + summary_sentences\n",
      "\n",
      "        # printing summary and full-text output for comparison\n",
      "        print(f'\\nSUMMARY:\\n{summary_sentences}\\n')\n",
      "        print(f'FULL TEXT:')\n",
      "        print(text_data)\n",
      "\n",
      "        # appending summary to text file\n",
      "        with open('your_summaries/summary.txt', 'a') as summary_output:\n",
      "            for line in summary_file:\n",
      "                summary_output.write(line)\n",
      "\n",
      "\n",
      "    # copy/paste string input option\n",
      "    elif choose_input == 'C':\n",
      "        print(\"\\nFor Option C, simply copy/paste any text you'd like to summarize below.\\n\\n\")\n",
      "        print(\"If you'd like a copy of your summary, you can find it in the `your_summaries` directory.\\n\")\n",
      "\n",
      "        # reading in text as string\n",
      "        text_copy_paste = input('INPUT:\\n')\n",
      "        text_copy_paste = str(text_copy_paste)\n",
      "\n",
      "        # text processing and clean up\n",
      "        text_copy_paste = re.sub(r'\\[[0-9]*\\]', ' ', text_copy_paste)  \n",
      "        text_copy_paste = re.sub(r'\\s+', ' ', text_copy_paste)  \n",
      "\n",
      "        processed_article = re.sub('[^a-zA-Z]', ' ', text_copy_paste )  \n",
      "        processed_article = re.sub(r'\\s+', ' ', processed_article)\n",
      "\n",
      "        # sentence-level tokenization of full text\n",
      "        sentence_list = nltk.sent_tokenize(text_copy_paste)  \n",
      "\n",
      "        # NLTK stopword list; optionally can use sklearn stopwords\n",
      "        stopwords = nltk.corpus.stopwords.words('english')\n",
      "\n",
      "        # creating term frequency dict\n",
      "        word_frequencies = {}  \n",
      "        for word in nltk.word_tokenize(processed_article):  \n",
      "            if word not in stopwords:\n",
      "                if word not in word_frequencies.keys():\n",
      "                    word_frequencies[word] = 1\n",
      "                else:\n",
      "                    word_frequencies[word] += 1\n",
      "\n",
      "        maximum_frequency = max(word_frequencies.values())\n",
      "        \n",
      "        # adding term frequency ratios as dict values\n",
      "        for word in word_frequencies.keys():  \n",
      "            word_frequencies[word] = (word_frequencies[word]/maximum_frequency)\n",
      "\n",
      "        # final ranking for summary sentence inclusion\n",
      "        sentence_scores = {}  \n",
      "        for sent in sentence_list:  \n",
      "            for word in nltk.word_tokenize(sent.lower()):\n",
      "                if word in word_frequencies.keys():\n",
      "                    if len(sent.split(' ')) < 30:\n",
      "                        if sent not in sentence_scores.keys():\n",
      "                            sentence_scores[sent] = word_frequencies[word]\n",
      "                        else:\n",
      "                            sentence_scores[sent] += word_frequencies[word]\n",
      "\n",
      "        # creating final summary with default 4 highest-scoring sentences\n",
      "        summary_sentences = heapq.nlargest(4, sentence_scores, key=sentence_scores.get)\n",
      "        summary_sentences = ''.join(summary_sentences)\n",
      "        summary_file = '\\n\\nSUMMARY:\\n' + summary_sentences\n",
      "\n",
      "        # printing summary and full-text output for comparison\n",
      "        print(f'\\nSUMMARY:\\n{summary_sentences}\\n')\n",
      "        print(f'FULL TEXT:')\n",
      "        print(text_copy_paste)\n",
      "\n",
      "        # appending summary to text file\n",
      "        with open('your_summaries/summary.txt', 'a') as summary_output:\n",
      "            for line in summary_file:\n",
      "                summary_output.write(line)\n",
      "\n",
      "    else:\n",
      "        print('\\nMust choose from A, B, or C')\n",
      "\n",
      "Output: {'summarize': ['re.sub', '<builtin>.input', 'nltk.sent_tokenize', 'nltk.word_tokenize', '<builtin>.str', 'bs4.BeautifulSoup', '<builtin>.len', 'heapq.nlargest', 'nltk.corpus.stopwords.words', '<builtin>.open', '<builtin>.print', 'summarizer.model_processors.SingleModel', '<builtin>.max'], '<builtin>.input': [], '<builtin>.print': [], 'bs4.BeautifulSoup': [], 'summarizer.model_processors.SingleModel': [], '<builtin>.open': [], 're.sub': [], 'nltk.sent_tokenize': [], 'nltk.corpus.stopwords.words': [], 'nltk.word_tokenize': [], '<builtin>.max': [], '<builtin>.len': [], 'heapq.nlargest': [], '<builtin>.str': [], 'summarizer': [], 'summarizer.model_processors': [], 'summarizer.model_processors.ModelProcessor.__init__': ['spacy.lang.en.English', 'summarizer.BertParent.BertParent', 'neuralcoref.add_to_pipe'], 'summarizer.BertParent.BertParent': [], 'spacy.lang.en.English': [], 'neuralcoref.add_to_pipe': [], 'summarizer.model_processors.ModelProcessor.process_content_sentences': ['<builtin>.len'], 'summarizer.model_processors.ModelProcessor': ['abc.abstractmethod'], 'abc.abstractmethod': [], 'summarizer.model_processors.ModelProcessor.run_clusters': ['<builtin>.NotImplementedError'], '<builtin>.NotImplementedError': [], 'summarizer.model_processors.ModelProcessor.run': ['summarizer.model_processors.ModelProcessor.process_content_sentences', 'summarizer.model_processors.ModelProcessor.run_clusters'], 'summarizer.model_processors.ModelProcessor.__call__': ['summarizer.model_processors.ModelProcessor.run'], 'summarizer.model_processors.SingleModel.__init__': ['<builtin>.super'], '<builtin>.super': [], 'summarizer.model_processors.SingleModel.run_clusters': ['summarizer.ClusterFeatures.ClusterFeatures'], 'summarizer.ClusterFeatures.ClusterFeatures': [], 'summarizer.ClusterFeatures': [], 'summarizer.ClusterFeatures.ClusterFeatures.__init__': ['sklearn.decomposition.PCA'], 'sklearn.decomposition.PCA': [], 'summarizer.ClusterFeatures.ClusterFeatures.__get_model': ['sklearn.cluster.KMeans', 'sklearn.mixture.GaussianMixture'], 'sklearn.mixture.GaussianMixture': [], 'sklearn.cluster.KMeans': [], 'summarizer.ClusterFeatures.ClusterFeatures.__get_centroids': [], 'summarizer.ClusterFeatures.ClusterFeatures.__find_closest_args': ['<builtin>.enumerate', 'numpy.sum', 'numpy.abs'], '<builtin>.enumerate': [], 'numpy.abs': [], 'numpy.sum': [], 'summarizer.ClusterFeatures.ClusterFeatures.cluster': ['<builtin>.len', '<builtin>.int', '<builtin>.sorted'], '<builtin>.int': [], '<builtin>.sorted': [], 'summarizer.ClusterFeatures.ClusterFeatures.__call__': [], 'summarizer.BertParent': ['logging.basicConfig'], 'logging.basicConfig': [], 'summarizer.BertParent.BertParent.__init__': ['<builtin>.RuntimeError', 'pytorch_pretrained_bert.BertTokenizer.from_pretrained', 'pytorch_pretrained_bert.BertModel.from_pretrained'], 'pytorch_pretrained_bert.BertModel.from_pretrained': [], 'pytorch_pretrained_bert.BertTokenizer.from_pretrained': [], '<builtin>.RuntimeError': [], 'summarizer.BertParent.BertParent.tokenize_input': ['torch.tensor'], 'torch.tensor': [], 'summarizer.BertParent.BertParent.extract_embeddings': [], 'summarizer.BertParent.BertParent.create_matrix': ['numpy.zeros', 'tqdm.tqdm', '<builtin>.len', '<builtin>.enumerate'], 'numpy.zeros': [], 'tqdm.tqdm': [], 'summarizer.BertParent.BertParent.__call__': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\dhk3136_summarization-bert-vs-baseline\\summarize.py\n",
      "[('summarize', 're sub'), ('summarize', 'nltk sent_tokenize'), ('summarize', 'nltk word_tokenize'), ('summarize', 'bs4 BeautifulSoup'), ('summarize', 'heapq nlargest'), ('summarize', 'nltk corpus stopwords words'), ('summarize', 'summarizer model_processors SingleModel'), ('summarizer model_processors ModelProcessor __init__', 'spacy lang en English'), ('summarizer model_processors ModelProcessor __init__', 'summarizer BertParent BertParent'), ('summarizer model_processors ModelProcessor __init__', 'neuralcoref add_to_pipe'), ('summarizer model_processors ModelProcessor', 'abc abstractmethod'), ('summarizer model_processors ModelProcessor run', 'summarizer model_processors ModelProcessor process_content_sentences'), ('summarizer model_processors ModelProcessor run', 'summarizer model_processors ModelProcessor run_clusters'), ('summarizer model_processors ModelProcessor __call__', 'summarizer model_processors ModelProcessor run'), ('summarizer model_processors SingleModel run_clusters', 'summarizer ClusterFeatures ClusterFeatures'), ('summarizer ClusterFeatures ClusterFeatures __init__', 'sklearn decomposition PCA'), ('summarizer ClusterFeatures ClusterFeatures __get_model', 'sklearn cluster KMeans'), ('summarizer ClusterFeatures ClusterFeatures __get_model', 'sklearn mixture GaussianMixture'), ('summarizer ClusterFeatures ClusterFeatures __find_closest_args', 'numpy sum'), ('summarizer ClusterFeatures ClusterFeatures __find_closest_args', 'numpy abs'), ('summarizer BertParent', 'logging basicConfig'), ('summarizer BertParent BertParent __init__', 'pytorch_pretrained_bert BertTokenizer from_pretrained'), ('summarizer BertParent BertParent __init__', 'pytorch_pretrained_bert BertModel from_pretrained'), ('summarizer BertParent BertParent tokenize_input', 'torch tensor'), ('summarizer BertParent BertParent create_matrix', 'numpy zeros'), ('summarizer BertParent BertParent create_matrix', 'tqdm tqdm')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('BertParent', 'logging basicConfig'), ('BertParent BertParent __init__', 'pytorch_pretrained_bert BertModel from_pretrained'), ('BertParent BertParent __init__', 'pytorch_pretrained_bert BertTokenizer from_pretrained'), ('BertParent BertParent tokenize_input', 'torch tensor'), ('BertParent BertParent extract_embeddings', 'BertParent BertParent tokenize_input'), ('BertParent BertParent create_matrix', 'numpy zeros'), ('BertParent BertParent create_matrix', 'tqdm tqdm'), ('BertParent BertParent create_matrix', 'BertParent BertParent extract_embeddings'), ('BertParent BertParent __call__', 'BertParent BertParent create_matrix')], [('ClusterFeatures ClusterFeatures __init__', 'sklearn decomposition PCA'), ('ClusterFeatures ClusterFeatures __get_model', 'sklearn mixture GaussianMixture'), ('ClusterFeatures ClusterFeatures __get_model', 'sklearn cluster KMeans'), ('ClusterFeatures ClusterFeatures __find_closest_args', 'numpy abs'), ('ClusterFeatures ClusterFeatures __find_closest_args', 'numpy sum'), ('ClusterFeatures ClusterFeatures cluster', 'ClusterFeatures ClusterFeatures __get_model'), ('ClusterFeatures ClusterFeatures cluster', 'ClusterFeatures ClusterFeatures __find_closest_args'), ('ClusterFeatures ClusterFeatures cluster', 'ClusterFeatures ClusterFeatures __get_centroids'), ('ClusterFeatures ClusterFeatures __call__', 'ClusterFeatures ClusterFeatures cluster')], [('model_processors ModelProcessor __init__', 'spacy lang en English'), ('model_processors ModelProcessor __init__', 'neuralcoref add_to_pipe'), ('model_processors ModelProcessor __init__', 'summarizer BertParent BertParent'), ('model_processors ModelProcessor', 'abc abstractmethod'), ('model_processors ModelProcessor run', 'model_processors ModelProcessor run_clusters'), ('model_processors ModelProcessor run', 'model_processors ModelProcessor process_content_sentences'), ('model_processors ModelProcessor __call__', 'model_processors ModelProcessor run'), ('model_processors SingleModel run_clusters', 'summarizer ClusterFeatures ClusterFeatures')], [('summarize', 're sub'), ('summarize', 'nltk sent_tokenize'), ('summarize', 'nltk word_tokenize'), ('summarize', 'bs4 BeautifulSoup'), ('summarize', 'heapq nlargest'), ('summarize', 'nltk corpus stopwords words'), ('summarize', 'summarizer model_processors SingleModel'), ('summarizer model_processors ModelProcessor __init__', 'spacy lang en English'), ('summarizer model_processors ModelProcessor __init__', 'summarizer BertParent BertParent'), ('summarizer model_processors ModelProcessor __init__', 'neuralcoref add_to_pipe'), ('summarizer model_processors ModelProcessor', 'abc abstractmethod'), ('summarizer model_processors ModelProcessor run', 'summarizer model_processors ModelProcessor process_content_sentences'), ('summarizer model_processors ModelProcessor run', 'summarizer model_processors ModelProcessor run_clusters'), ('summarizer model_processors ModelProcessor __call__', 'summarizer model_processors ModelProcessor run'), ('summarizer model_processors SingleModel run_clusters', 'summarizer ClusterFeatures ClusterFeatures'), ('summarizer ClusterFeatures ClusterFeatures __init__', 'sklearn decomposition PCA'), ('summarizer ClusterFeatures ClusterFeatures __get_model', 'sklearn cluster KMeans'), ('summarizer ClusterFeatures ClusterFeatures __get_model', 'sklearn mixture GaussianMixture'), ('summarizer ClusterFeatures ClusterFeatures __find_closest_args', 'numpy sum'), ('summarizer ClusterFeatures ClusterFeatures __find_closest_args', 'numpy abs'), ('summarizer BertParent', 'logging basicConfig'), ('summarizer BertParent BertParent __init__', 'pytorch_pretrained_bert BertTokenizer from_pretrained'), ('summarizer BertParent BertParent __init__', 'pytorch_pretrained_bert BertModel from_pretrained'), ('summarizer BertParent BertParent tokenize_input', 'torch tensor'), ('summarizer BertParent BertParent create_matrix', 'numpy zeros'), ('summarizer BertParent BertParent create_matrix', 'tqdm tqdm')]]\n",
      "********************doctrings*************************\n",
      "['', '', '', '']\n",
      "embed index dataset: 23\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\KBNLresearch_multiNER\\\\ner.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\KBNLresearch_multiNER\\\\setup.py']\n",
      "#!/usr/bin/env python3\n",
      "'''\n",
      "MultiNER\n",
      "\n",
      "MultiNER combines the output from five different\n",
      "named-entity recognition packages into one answer.\n",
      "\n",
      "https://github.com/KBNLresearch/MultiNER\n",
      "\n",
      "Copyright 2013, 2019 Willem Jan Faber,\n",
      "KB/National Library of the Netherlands.\n",
      "\n",
      "To install most external dependencies using the following command:\n",
      "\n",
      "    pip3 install -r requirements.txt\n",
      "    ./install_external_ners.sh\n",
      "\n",
      "For Stanford and Spotlight, see their own manuals on howto install those:\n",
      "\n",
      "https://nlp.stanford.edu/software/crf-faq.shtml#cc\n",
      "\n",
      "https://github.com/dbpedia-spotlight/dbpedia-spotlight/wiki/Run-from-a-JAR\n",
      "https://github.com/dbpedia-spotlight/dbpedia-spotlight/\n",
      "\n",
      "Spotlight needs older java version 8 to run.\n",
      "\n",
      "Once installed (With wanted language models),\n",
      "run the webservices so MultiNER can contact those:\n",
      "\n",
      "    $ cd /path/to/stanford-ner-2018-10-16\n",
      "    $ java -mx400m -cp stanford-ner.jar edu.stanford.nlp.ie.NERServer \\\n",
      "           -outputFormat inlineXML -encoding \"utf-8\" \\\n",
      "           -loadClassifier dutch.crf.gz -port 1234\n",
      "\n",
      "    $ cd /path/to/spotlight\n",
      "    $ java --add-modules java.xml.bind -jar dbpedia-spotlight-1.0.0.jar \\\n",
      "                         nl http://localhost:9090/rest\n",
      "\n",
      "There is a small shell-script (run_external_ners.sh) available for this,\n",
      "modify it to your needs, if you change ports or want to use an external server,\n",
      "please keep them in sync with this file:\n",
      "(STANFORD_HOST/PORT, SPOTLIGHT_HOST/PORT).\n",
      "\n",
      "Language models spacy, polyglot and flair:\n",
      "\n",
      "There is a big try catch block surrounding the invocation of polyglot,\n",
      "there is a good reason for that, I cannot seem to be able to force it to\n",
      "use a specific language, it will do a lang-detect and handle on that info.\n",
      "If the guessed language is not present, it will throw an exception.\n",
      "\n",
      "You can soft-link mutiple languages to other languages, to fool the software\n",
      "into using a wanted language, for example:\n",
      "\n",
      "    $ mkdir af; ln -s ./nl/nl_ner.pkl.tar.bz2 ./af/af_ner.pkl.tar.bz2\n",
      "\n",
      "    # apt-get install python-numpy libicu-dev\n",
      "    $ pip install polyglot\n",
      "    $ polyglot download embeddings2.nl\n",
      "\n",
      "    $ python -m spacy download nl\n",
      "    $ python -m spacy download de\n",
      "    $ python -m spacy download fr\n",
      "    $ python -m spacy download nl\n",
      "    $ python -m spacy download en\n",
      "\n",
      "Flair will automaticaly download the language model on firstrun.\n",
      "\n",
      "\n",
      "Running test, and stable web-service:\n",
      "\n",
      "    $ python3 ./ner.py\n",
      "\n",
      "This will run the doctest, if everything works, and external services are up,\n",
      "0 errors should be the result.\n",
      "\n",
      "    $ gunicorn -w 10 web:application -b :8099\n",
      "\n",
      "Afther this the service can be envoked like this:\n",
      "\n",
      "    $ curl -s localhost:8099/?text=\"This is a test by Willem Jan.\"\n",
      "\n",
      "If you expect to process a lot:\n",
      "\n",
      "    # echo 1 > /proc/sys/ipv4/tcp_tw_recycle\n",
      "\n",
      "Else there will be no socket's left to process.\n",
      "\n",
      "'''\n",
      "import ast\n",
      "import json\n",
      "import lxml.html\n",
      "import operator\n",
      "import requests\n",
      "import spacy\n",
      "import telnetlib\n",
      "import threading\n",
      "import time\n",
      "\n",
      "from flask import request, Response, Flask\n",
      "from lxml import etree\n",
      "from polyglot.text import Text\n",
      "\n",
      "from flair.models import SequenceTagger\n",
      "from flair.data import Sentence\n",
      "\n",
      "application = Flask(__name__)\n",
      "application.debug = True\n",
      "\n",
      "# Preload Dutch data.\n",
      "nlp_spacy = spacy.load('nl')\n",
      "nlp_flair = SequenceTagger.load('ner-multi')\n",
      "\n",
      "# Will be used in web-service and doctest.\n",
      "EXAMPLE_URL = \"http://resolver.kb.nl/resolve?\"\n",
      "EXAMPLE_URL += \"urn=ddd:010381561:mpeg21:a0049:ocr\"\n",
      "\n",
      "# Baseurl for Stanford standalone NER setup.\n",
      "# https://nlp.stanford.edu/software/crf-faq.shtml#cc\n",
      "# (Use inlineXML)\n",
      "STANFORD_HOST = \"localhost\"\n",
      "STANFORD_PORT = 9092\n",
      "\n",
      "# Baseurl for Spotlight rest-service.\n",
      "# https://github.com/dbpedia-spotlight/dbpedia-spotlight/\n",
      "SPOTLIGHT_HOST = \"localhost\"\n",
      "SPOTLIGHT_PORT = \"9091\"\n",
      "SPOTLIGHT_PATH = \"/rest/annotate/\"\n",
      "\n",
      "# Timeout for external NER's (stanford, spotlight)\n",
      "TIMEOUT = 1000\n",
      "\n",
      "\n",
      "def context(text_org, ne, pos, context=5):\n",
      "    '''\n",
      "        Return the context of an NE, based on abs-pos,\n",
      "        if there are 'context-tokens' in the way,\n",
      "        skip those.\n",
      "\n",
      "        Current defined context-tokens:\n",
      "        !,'\\\",`<>?-+\"\n",
      "    '''\n",
      "    CONTEXT_TOKENS = \"!,'\\\",`<>?-+\\\\\"\n",
      "\n",
      "    leftof = text_org[:pos].strip()\n",
      "    l_context = \" \".join(leftof.split()[-context:])\n",
      "\n",
      "    rightof = text_org[pos + len(ne):].strip()\n",
      "    r_context = \" \".join(rightof.split()[:context])\n",
      "\n",
      "    ne_context = ne\n",
      "\n",
      "    try:\n",
      "        if l_context[-1] in CONTEXT_TOKENS:\n",
      "            ne_context = l_context[-1] + ne_context\n",
      "    except Exception:\n",
      "        pass\n",
      "\n",
      "    try:\n",
      "        if r_context[0] in CONTEXT_TOKENS:\n",
      "            ne_context = ne_context + r_context[0]\n",
      "    except Exception:\n",
      "        pass\n",
      "\n",
      "    return l_context, r_context, ne_context\n",
      "\n",
      "\n",
      "def translate(input_str):\n",
      "    '''\n",
      "        Translate the labels to human-readable.\n",
      "    '''\n",
      "    input_str = input_str.lower()\n",
      "\n",
      "    if input_str == \"org\":\n",
      "        return 'organisation'\n",
      "    if input_str == \"per\":\n",
      "        return 'person'\n",
      "    if input_str == \"misc\":\n",
      "        return 'other'\n",
      "    if input_str == \"gpe\":\n",
      "        return 'location'\n",
      "    if input_str == \"loc\":\n",
      "        return 'location'\n",
      "    return input_str\n",
      "\n",
      "\n",
      "class Stanford(threading.Thread):\n",
      "    '''\n",
      "        Wrapper for Stanford.\n",
      "\n",
      "        https://nlp.stanford.edu/software/CRF-NER.shtml\n",
      "\n",
      "        >>> test = \"Deze iets langere test bevat de naam Albert Einstein.\"\n",
      "        >>> p = Stanford(parsed_text=test)\n",
      "        >>> p.start()\n",
      "        >>> import time\n",
      "        >>> time.sleep(0.1)\n",
      "        >>> from pprint import pprint\n",
      "        >>> pprint(p.join())\n",
      "        {'stanford': [{'ne': 'Albert Einstein', 'pos': 37, 'type': 'person'}]}\n",
      "    '''\n",
      "\n",
      "    result = {}\n",
      "\n",
      "    def __init__(self, group=None, target=None,\n",
      "                 name=None, parsed_text={}):\n",
      "\n",
      "        threading.Thread.__init__(self, group=group, target=target, name=name)\n",
      "        self.parsed_text = parsed_text\n",
      "\n",
      "    def run(self):\n",
      "        start_time = time.time()\n",
      "\n",
      "        text = self.parsed_text.replace('\\n', ' ')\n",
      "\n",
      "        done = False\n",
      "        retry = 0\n",
      "        max_retry = 10\n",
      "\n",
      "        while not done and retry < max_retry:\n",
      "            try:\n",
      "                conn = telnetlib.Telnet(host=STANFORD_HOST,\n",
      "                                        port=STANFORD_PORT,\n",
      "                                        timeout=TIMEOUT)\n",
      "                done = True\n",
      "            except Exception:\n",
      "                retry += 1\n",
      "\n",
      "        if not done:\n",
      "            self.result = {\"stanford\": []}\n",
      "            return\n",
      "\n",
      "        text = text.encode('utf-8') + b'\\n'\n",
      "        conn.write(text)\n",
      "        raw_data = conn.read_all().decode('utf-8')\n",
      "        conn.close()\n",
      "\n",
      "        data = etree.fromstring('<root>' + \\\n",
      "                                raw_data.replace('<', '|') + \\\n",
      "                                '</root>')\n",
      "\n",
      "        result = []\n",
      "\n",
      "        p_tag = ''\n",
      "        for item in data.iter():\n",
      "            if not item.tag == 'root':\n",
      "                tag = item.tag.split('-')[1]\n",
      "                if item.tag.split('-')[0] == 'I' and p_tag == tag:\n",
      "                    result[-1][\"ne\"] = result[-1][\"ne\"] + ' ' + item.text\n",
      "                else:\n",
      "                    result.append({\"ne\": item.text,\n",
      "                                   \"type\": translate(item.tag.split('-')[1])})\n",
      "                    p_tag = tag\n",
      "\n",
      "        offset = 0\n",
      "        for i, ne in enumerate(result):\n",
      "            ne = ne[\"ne\"]\n",
      "            pos = self.parsed_text[offset:].find(ne)\n",
      "            result[i][\"pos\"] = pos + offset\n",
      "            offset += pos + len(ne)\n",
      "\n",
      "        self.result = {\"stanford\": result,\n",
      "                       \"timing_stanford\": time.time() - start_time}\n",
      "\n",
      "    def join(self):\n",
      "        threading.Thread.join(self)\n",
      "        return self.result\n",
      "\n",
      "\n",
      "class Flair(threading.Thread):\n",
      "    '''\n",
      "        Wrapper for Flair.\n",
      "\n",
      "        https://github.com/zalandoresearch/flair\n",
      "\n",
      "        >>> test = \"Deze iets langere test bevat de naam Albert Einstein.\"\n",
      "        >>> f = Flair(parsed_text=test)\n",
      "        >>> f.start()\n",
      "        >>> import time\n",
      "        >>> time.sleep(0.1)\n",
      "        >>> from pprint import pprint\n",
      "        >>> pprint(f.join())\n",
      "        {'flair': [{'ne': 'Albert Einstein.', 'pos': 37, 'type': 'person'}]}\n",
      "    '''\n",
      "    result = {}\n",
      "\n",
      "    def __init__(self, group=None, target=None,\n",
      "                 name=None, parsed_text={}):\n",
      "\n",
      "        threading.Thread.__init__(self, group=group, target=target, name=name)\n",
      "        self.parsed_text = parsed_text\n",
      "\n",
      "    def run(self):\n",
      "        start_time = time.time()\n",
      "        sentence = [Sentence(self.parsed_text, use_tokenizer=False)]\n",
      "        tagged = nlp_flair.predict(sentence)\n",
      "\n",
      "        tagged_items = [\n",
      "                s.to_dict(tag_type='ner').get('entities') for s in tagged\n",
      "                ]\n",
      "\n",
      "        result = []\n",
      "\n",
      "        for item in tagged_items:\n",
      "            for i in item:\n",
      "                if not i:\n",
      "                    continue\n",
      "                result.append({\n",
      "                    \"ne\": i.get('text'),\n",
      "                    \"pos\": i.get('start_pos'),\n",
      "                    \"type\": translate(i.get('type'))\n",
      "                })\n",
      "\n",
      "        self.result = {\"flair\": self.result,\n",
      "                       \"timing_flair\": time.time() - start_time}\n",
      "\n",
      "    def join(self):\n",
      "        threading.Thread.join(self)\n",
      "        return self.result\n",
      "\n",
      "\n",
      "class Polyglot(threading.Thread):\n",
      "    '''\n",
      "        Wrapper for Polyglot.\n",
      "\n",
      "        http://polyglot.readthedocs.io/en/latest/index.html\n",
      "\n",
      "        >>> test = \"Deze iets langere test bevat de naam Albert Einstein.\"\n",
      "        >>> p = Polyglot(parsed_text=test)\n",
      "        >>> p.start()\n",
      "        >>> import time\n",
      "        >>> time.sleep(0.1)\n",
      "        >>> from pprint import pprint\n",
      "        >>> pprint(p.join())\n",
      "        {'polyglot': [{'ne': 'Albert Einstein', 'pos': 37, 'type': 'person'}]}\n",
      "    '''\n",
      "\n",
      "    def __init__(self, group=None, target=None,\n",
      "                 name=None, parsed_text={}):\n",
      "\n",
      "        threading.Thread.__init__(self, group=group, target=target, name=name)\n",
      "        self.parsed_text = parsed_text\n",
      "\n",
      "    def run(self):\n",
      "        start_time = time.time()\n",
      "        buffer_all = []\n",
      "\n",
      "        try:\n",
      "            text = Text(self.parsed_text, hint_language_code='nl')\n",
      "\n",
      "            for sent in text.sentences:\n",
      "                entity_buffer = []\n",
      "                prev_entity_start = -1\n",
      "                for entity in sent.entities:\n",
      "                    if entity not in entity_buffer:\n",
      "                        # For some reason polyglot double's it's output.\n",
      "                        if not prev_entity_start == entity.start:\n",
      "                            prev_entity_start = entity.start\n",
      "                            entity_buffer.append(entity)\n",
      "                        else:\n",
      "                            entity_buffer.pop()\n",
      "                            entity_buffer.append(entity)\n",
      "\n",
      "                for item in entity_buffer:\n",
      "                    buffer_all.append(item)\n",
      "\n",
      "            result = []\n",
      "            for entity in buffer_all:\n",
      "                # For there is no sane way to do this.\n",
      "                ne = \" \".join(ast.literal_eval(entity.__str__()))\n",
      "                tag = str(entity.tag.split('-')[1])\n",
      "                result.append({\"ne\": ne,\n",
      "                               \"type\": translate(tag)})\n",
      "\n",
      "            offset = 0\n",
      "            for i, ne in enumerate(result):\n",
      "                ne = ne[\"ne\"]\n",
      "                pos = self.parsed_text[offset:].find(ne)\n",
      "                result[i][\"pos\"] = pos + offset\n",
      "                offset += pos + len(ne)\n",
      "        except Exception:\n",
      "            result = []\n",
      "\n",
      "        self.result = {\"polyglot\": result,\n",
      "                       \"timing_polyglot\": time.time() - start_time}\n",
      "\n",
      "    def join(self):\n",
      "        threading.Thread.join(self)\n",
      "        return self.result\n",
      "\n",
      "\n",
      "class Spacy(threading.Thread):\n",
      "    '''\n",
      "        Wrapper for Spacy.\n",
      "\n",
      "        https://spacy.io/\n",
      "\n",
      "        >>> test = \"Deze iets langere test bevat de naam Einstein.\"\n",
      "        >>> p = Spacy(parsed_text=test)\n",
      "        >>> p.start()\n",
      "        >>> import time\n",
      "        >>> time.sleep(0.1)\n",
      "        >>> from pprint import pprint\n",
      "        >>> pprint(p.join())\n",
      "        {'spacy': [{'ne': 'Einstein', 'pos': 37, 'type': 'location'}]}\n",
      "    '''\n",
      "\n",
      "    def __init__(self, group=None, target=None,\n",
      "                 name=None, parsed_text={}):\n",
      "\n",
      "        threading.Thread.__init__(self, group=group, target=target, name=name)\n",
      "        self.parsed_text = parsed_text\n",
      "\n",
      "    def run(self):\n",
      "        start_time = time.time()\n",
      "        result = []\n",
      "        try:\n",
      "            doc = nlp_spacy(self.parsed_text)\n",
      "\n",
      "            for ent in doc.ents:\n",
      "                result.append({\"ne\": ent.text, \"type\": translate(ent.label_)})\n",
      "\n",
      "            offset = 0\n",
      "            for i, ne in enumerate(result):\n",
      "                ne = ne[\"ne\"]\n",
      "                pos = self.parsed_text[offset:].find(ne)\n",
      "                result[i][\"pos\"] = pos + offset\n",
      "                offset += pos + len(ne)\n",
      "        except Exception:\n",
      "            pass\n",
      "\n",
      "        self.result = {\"spacy\": result,\n",
      "                       \"timing_spacy\": time.time() - start_time}\n",
      "\n",
      "    def join(self):\n",
      "        threading.Thread.join(self)\n",
      "        return self.result\n",
      "\n",
      "\n",
      "class Spotlight(threading.Thread):\n",
      "    '''\n",
      "        Wrapper for DBpedia-Spotlight.\n",
      "\n",
      "        https://www.dbpedia-spotlight.org/\n",
      "        >>> t = \"Richard Nixon bakt een taart voor zichzelf.\"\n",
      "        >>> p = Spotlight(parsed_text=t)\n",
      "        >>> p.start()\n",
      "        >>> import time\n",
      "        >>> time.sleep(1)\n",
      "        >>> from pprint import pprint\n",
      "        >>> pprint(p.join())\n",
      "        {'spotlight': [{'ne': 'Richard Nixon', 'pos': 0, 'type': 'other'}]}\n",
      "    '''\n",
      "\n",
      "    def __init__(self, group=None, target=None,\n",
      "                 name=None, parsed_text={}, confidence='0.9'):\n",
      "\n",
      "        threading.Thread.__init__(self, group=group, target=target, name=name)\n",
      "        self.parsed_text = parsed_text\n",
      "        self.confidence = confidence\n",
      "\n",
      "    def run(self):\n",
      "        start_time = time.time()\n",
      "\n",
      "        data = {'text': self.parsed_text,\n",
      "                'confidence': str(self.confidence)}\n",
      "\n",
      "        url = 'http://'\n",
      "        url += SPOTLIGHT_HOST\n",
      "        url += ':' + SPOTLIGHT_PORT\n",
      "        url += SPOTLIGHT_PATH\n",
      "\n",
      "        header = {\"Accept\": \"application/json\"}\n",
      "\n",
      "        done = False\n",
      "        retry = 0\n",
      "        max_retry = 10\n",
      "\n",
      "        while not done and retry < max_retry:\n",
      "            try:\n",
      "                response = requests.get(url,\n",
      "                                        params=data,\n",
      "                                        headers=header,\n",
      "                                        timeout=TIMEOUT)\n",
      "\n",
      "                data = response.json()\n",
      "                result = []\n",
      "\n",
      "                if data and data.get('Resources'):\n",
      "                    for item in data.get('Resources'):\n",
      "                        ne = {}\n",
      "                        ne[\"ne\"] = item.get('@surfaceForm')\n",
      "                        ne[\"pos\"] = int(item.get('@offset'))\n",
      "                        ne[\"type\"] = \"other\"\n",
      "                        result.append(ne)\n",
      "\n",
      "                self.result = {\"spotlight\": result,\n",
      "                               \"timing_spotlight\": time.time() - start_time}\n",
      "                done = True\n",
      "            except Exception:\n",
      "                self.result = {\"spotlight\": []}\n",
      "                retry += 1\n",
      "\n",
      "    def join(self):\n",
      "        threading.Thread.join(self)\n",
      "        return self.result\n",
      "\n",
      "\n",
      "def intergrate_results(result, source, source_text, context_len):\n",
      "    new_result = {}\n",
      "    res = []\n",
      "\n",
      "    for ne in result.get(\"stanford\"):\n",
      "        res = {}\n",
      "        res[\"count\"] = 1\n",
      "        res[\"ne\"] = ne.get(\"ne\")\n",
      "        res[\"ner_src\"] = [\"stanford\"]\n",
      "        res[\"type\"] = {ne.get(\"type\"): 1}\n",
      "        res[\"pref_type\"] = ne.get(\"type\")\n",
      "        new_result[ne.get(\"pos\")] = res\n",
      "\n",
      "    for ne in result.get(\"spotlight\"):\n",
      "        if not ne.get(\"pos\") in res:\n",
      "            res = {}\n",
      "            res[\"count\"] = 1\n",
      "            res[\"ne\"] = ne.get(\"ne\")\n",
      "            res[\"ner_src\"] = [\"spotlight\"]\n",
      "            res[\"type\"] = {ne.get(\"type\"): 1}\n",
      "            res[\"pref_type\"] = ne.get(\"type\")\n",
      "            new_result[ne.get(\"pos\")] = res\n",
      "        else:\n",
      "            new_result[ne.get(\"pos\")][\"count\"] += 1\n",
      "            new_result[ne.get(\"pos\")][\"ner_src\"].append(\"spotlight\")\n",
      "\n",
      "            if not ne.get(\"type\") in new_result[ne.get(\"pos\")][\"type\"]:\n",
      "                new_result[ne.get(\"pos\")][\"type\"][ne.get(\"type\")] = 1\n",
      "            else:\n",
      "                new_result[ne.get(\"pos\")][\"type\"][ne.get(\"type\")] += 1\n",
      "\n",
      "    parsers = [\"spacy\", \"polyglot\", \"flair\"]\n",
      "\n",
      "    for parser in parsers:\n",
      "        if result.get(parser) is None:\n",
      "            continue\n",
      "        for ne in result.get(parser):\n",
      "            if ne.get(\"pos\") in new_result:\n",
      "\n",
      "                if parser in new_result[ne.get(\"pos\")][\"ner_src\"]:\n",
      "                    continue\n",
      "\n",
      "                new_result[ne.get(\"pos\")][\"count\"] += 1\n",
      "                new_result[ne.get(\"pos\")][\"ner_src\"].append(parser)\n",
      "\n",
      "                if ne.get(\"type\") in new_result[ne.get(\"pos\")][\"type\"]:\n",
      "                    new_result[ne.get(\"pos\")][\"type\"][ne.get(\"type\")] += 1\n",
      "                else:\n",
      "                    new_result[ne.get(\"pos\")][\"type\"][ne.get(\"type\")] = 1\n",
      "\n",
      "                if not ne.get(\"ne\") == new_result[ne.get(\"pos\")].get(\"ne\"):\n",
      "                    new_result[ne.get(\"pos\")][\"alt_ne\"] = ne.get(\"ne\")\n",
      "\n",
      "            else:\n",
      "                new_result[ne.get(\"pos\")] = {\n",
      "                    \"count\": 1,\n",
      "                    \"ne\": ne.get(\"ne\"),\n",
      "                    \"ner_src\": [parser],\n",
      "                    \"type\": {ne.get(\"type\"): 1}}\n",
      "\n",
      "    final_result = []\n",
      "    for ne in new_result:\n",
      "        if new_result[ne].get(\"pref_type\") or \\\n",
      "                len(new_result[ne].get(\"ner_src\")) == 2:\n",
      "            if \"pref_type\" in new_result[ne]:\n",
      "                ne_type = max_class(new_result[ne][\"type\"],\n",
      "                                    new_result[ne][\"pref_type\"])\n",
      "                new_result[ne].pop(\"pref_type\")\n",
      "            else:\n",
      "                ne_type = max_class(new_result[ne][\"type\"],\n",
      "                                    list(new_result[ne][\"type\"])[0])\n",
      "\n",
      "            new_result[ne][\"types\"] = list(new_result[ne][\"type\"])\n",
      "            new_result[ne][\"type\"] = ne_type[0]\n",
      "            new_result[ne][\"type_certainty\"] = ne_type[1]\n",
      "\n",
      "            new_result[ne][\"left_context\"], \\\n",
      "                new_result[ne][\"right_context\"], \\\n",
      "                new_result[ne][\"ne_context\"] = context(source_text,\n",
      "                                                       new_result[ne][\"ne\"],\n",
      "                                                       ne,\n",
      "                                                       context_len)\n",
      "            new_result[ne][\"pos\"] = ne\n",
      "            if source:\n",
      "                new_result[ne][\"source\"] = source\n",
      "\n",
      "            final_result.append(new_result[ne])\n",
      "\n",
      "    final_result = sorted(final_result, key=operator.itemgetter('pos'))\n",
      "\n",
      "    return final_result\n",
      "\n",
      "\n",
      "def manual_find(input_str, source_text, source, context_len):\n",
      "    '''\n",
      "        Find occurrence of an 'ne' and\n",
      "        get the left and right context.\n",
      "    '''\n",
      "\n",
      "    result = {}\n",
      "\n",
      "    pos = source_text.find(input_str)\n",
      "    result[\"pos\"] = pos\n",
      "    result[\"ne\"] = input_str\n",
      "    result[\"source\"] = source\n",
      "    result[\"type\"] = 'manual'\n",
      "\n",
      "    try:\n",
      "        if not pos == -1:\n",
      "            result[\"left_context\"],\n",
      "            result[\"right_context\"],\n",
      "            result[\"ne_context\"] = context(source_text,\n",
      "                                           input_str,\n",
      "                                           pos,\n",
      "                                           context_len)\n",
      "        else:\n",
      "            result[\"left_context\"] = result[\"right_context\"] = ''\n",
      "            result[\"ne_context\"] = input_str\n",
      "    except:\n",
      "        pass\n",
      "\n",
      "    return result\n",
      "\n",
      "\n",
      "def max_class(input_type={\"LOC\": 2, \"MISC\": 3}, pref_type=\"LOC\"):\n",
      "    mc = max(input_type, key=input_type.get)\n",
      "\n",
      "    if input_type.get(mc) == 1:\n",
      "        mc = pref_type\n",
      "        sure = 1\n",
      "    if input_type.get(mc) == 2:\n",
      "        sure = 2\n",
      "    if input_type.get(mc) == 3:\n",
      "        sure = 3\n",
      "    if input_type.get(mc) == 4:\n",
      "        sure = 4\n",
      "\n",
      "    return(mc, sure)\n",
      "\n",
      "\n",
      "@application.route('/')\n",
      "def index():\n",
      "    parsers = {\"flair\": Flair,\n",
      "               \"polyglot\": Polyglot,\n",
      "               \"spacy\": Spacy,\n",
      "               \"spotlight\": Spotlight,\n",
      "               \"stanford\": Stanford}\n",
      "\n",
      "    text = request.args.get('text')\n",
      "    url = request.args.get('url')\n",
      "    manual = request.args.get('ne')\n",
      "    context_len = request.args.get('context')\n",
      "\n",
      "    if not context_len:\n",
      "        context_len = 5\n",
      "    else:\n",
      "        context_len = int(context_len)\n",
      "\n",
      "    if not url and not text:\n",
      "        result = {\"error\": \"Missing argument ?text= or ?url=%s\" % EXAMPLE_URL}\n",
      "        resp = Response(response=json.dumps(result),\n",
      "                        mimetype='application/json; charset=utf-8')\n",
      "        return (resp)\n",
      "\n",
      "    parsed_text = False\n",
      "\n",
      "    if url:\n",
      "        try:\n",
      "            parsed_text = ocr_to_dict(url)\n",
      "        except Exception:\n",
      "            result = {\"error\": \"Failed to fetch %s\" % url}\n",
      "            resp = Response(response=json.dumps(result),\n",
      "                            mimetype='application/json; charset=utf-8')\n",
      "            return (resp)\n",
      "\n",
      "    if text:\n",
      "        parsed_text = {'p': text}\n",
      "\n",
      "    timing = {}\n",
      "\n",
      "    if parsed_text:\n",
      "        result_all = {}\n",
      "\n",
      "        fresult = []\n",
      "        for part in parsed_text:\n",
      "            result = {}\n",
      "            tasks = []\n",
      "\n",
      "            if manual:\n",
      "                fresult.append(manual_find(manual,\n",
      "                                           parsed_text[part],\n",
      "                                           part,\n",
      "                                           context_len))\n",
      "\n",
      "            for p in parsers:\n",
      "                tasks.append(parsers[p](parsed_text=parsed_text[part]))\n",
      "                tasks[-1].start()\n",
      "\n",
      "            for p in tasks:\n",
      "                ner_result = p.join()\n",
      "\n",
      "                # Add timing information per parser.\n",
      "                try:\n",
      "                    if not list(ner_result)[1] in timing:\n",
      "                        timing[list(ner_result)[1]] = \\\n",
      "                            ner_result[list(ner_result)[1]]\n",
      "                    else:\n",
      "                        timing[list(ner_result)[1]] += \\\n",
      "                            ner_result[list(ner_result)[1]]\n",
      "                except:\n",
      "                    pass\n",
      "\n",
      "                # Add entities per parser result.\n",
      "                result[list(ner_result)[0]] = ner_result[list(ner_result)[0]]\n",
      "\n",
      "            if text:\n",
      "                result_all[part] = intergrate_results(result,\n",
      "                                                      False,\n",
      "                                                      parsed_text[part],\n",
      "                                                      context_len)\n",
      "            else:\n",
      "                result_all[part] = intergrate_results(result,\n",
      "                                                      part,\n",
      "                                                      parsed_text[part],\n",
      "                                                      context_len)\n",
      "\n",
      "        for part in result_all:\n",
      "            if result_all[part]:\n",
      "                for item in result_all[part]:\n",
      "                    fresult.append(item)\n",
      "\n",
      "        if text:\n",
      "            result = json.dumps({\"entities\": fresult,\n",
      "                                 \"text\": text,\n",
      "                                 \"timing\": timing})\n",
      "        else:\n",
      "            result = json.dumps({\"entities\": fresult,\n",
      "                                 \"text\": parsed_text,\n",
      "                                 \"timing\": timing})\n",
      "\n",
      "        resp = Response(response=result,\n",
      "                        mimetype='application/json; charset=utf-8')\n",
      "\n",
      "        return (resp)\n",
      "\n",
      "\n",
      "def ocr_to_dict(url):\n",
      "    '''\n",
      "        Fetch some OCR from the KB / Depher newspaper collection,\n",
      "        remove the XML-tags, and put it into a dictionary:\n",
      "\n",
      "        >>> EXAMPLE_URL = \"http://resolver.kb.nl/resolve?\"\n",
      "        >>> EXAMPLE_URL += \"urn=ddd:010381561:mpeg21:a0049:ocr\"\n",
      "        >>> ocr_to_dict(EXAMPLE_URL).get(\"title\")\n",
      "        'EERSTE HOOFDSTUK'\n",
      "    '''\n",
      "\n",
      "    done = False\n",
      "    retry = 0\n",
      "\n",
      "    while not done:\n",
      "        try:\n",
      "            req = requests.get(url, timeout=TIMEOUT)\n",
      "            if req.status_code == 200:\n",
      "                done = True\n",
      "            retry += 1\n",
      "            if retry > 50:\n",
      "                done = True\n",
      "        except Exception:\n",
      "            done = False\n",
      "\n",
      "    text = req.content\n",
      "    text = text.decode('utf-8')\n",
      "\n",
      "    parser = lxml.etree.XMLParser(ns_clean=False,\n",
      "                                  recover=True,\n",
      "                                  encoding='utf-8',\n",
      "                                  resolve_entities=False)\n",
      "\n",
      "    xml = lxml.etree.fromstring(text.encode(), parser=parser)\n",
      "\n",
      "    parsed_text = {}\n",
      "\n",
      "    for item in xml.iter():\n",
      "        if not item.text:\n",
      "            continue\n",
      "\n",
      "        item.text = item.text.replace('&', '&amp;')\n",
      "        item.text = item.text.replace('>', '&gt;')\n",
      "        item.text = item.text.replace('<', '&lt;')\n",
      "\n",
      "        if item.tag == 'title':\n",
      "            if \"title\" not in parsed_text:\n",
      "                parsed_text[\"title\"] = []\n",
      "            parsed_text[\"title\"].append(item.text)\n",
      "        else:\n",
      "            if \"p\" not in parsed_text:\n",
      "                parsed_text[\"p\"] = []\n",
      "            parsed_text[\"p\"].append(item.text)\n",
      "\n",
      "    for part in parsed_text:\n",
      "        parsed_text[part] = \"\".join(parsed_text[part])\n",
      "\n",
      "    return parsed_text\n",
      "\n",
      "\n",
      "def test_all():\n",
      "    '''\n",
      "    Example usage:\n",
      "\n",
      "    >>> parsers = {\n",
      "    ...            \"polyglot\": Polyglot,\n",
      "    ...            \"stanford\": Stanford,\n",
      "    ...            \"flair\" : Flair,\n",
      "    ...            \"spacy\": Spacy,\n",
      "    ...            \"spotlight\": Spotlight,\n",
      "    ...           }\n",
      "\n",
      "    >>> url = [EXAMPLE_URL]\n",
      "    >>> parsed_text = ocr_to_dict(url[0])\n",
      "\n",
      "    >>> tasks = []\n",
      "    >>> result = {}\n",
      "\n",
      "    >>> for p in parsers:\n",
      "    ...     tasks.append(parsers[p](parsed_text=parsed_text[\"p\"]))\n",
      "    ...     tasks[-1].start()\n",
      "\n",
      "    >>> import time\n",
      "    >>> time.sleep(1)\n",
      "\n",
      "    >>> for p in tasks:\n",
      "    ...     ner_result = p.join()\n",
      "    ...     result[list(ner_result)[0]] = ner_result[list(ner_result)[0]]\n",
      "\n",
      "    >>> from pprint import pprint\n",
      "    >>> pprint(intergrate_results(result, \"p\", parsed_text[\"p\"], 5)[-1])\n",
      "    {'count': 4,\n",
      "     'left_context': 'als wie haar nadert streelt:',\n",
      "     'ne': 'Ren',\n",
      "     'ne_context': 'Ren',\n",
      "     'ner_src': ['stanford', 'spacy', 'polyglot', 'flair'],\n",
      "     'pos': 5597,\n",
      "     'right_context': 'genoot van zijn charme als',\n",
      "     'source': 'p',\n",
      "     'type': 'person',\n",
      "     'type_certainty': 4,\n",
      "     'types': ['person']}\n",
      "    '''\n",
      "    return\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    import doctest\n",
      "    doctest.testmod(verbose=True)\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\KBNLresearch_multiNER\\ner.py\n",
      "[]\n",
      "found files: []\n",
      "#!/usr/bin/env python3\n",
      "\n",
      "import os\n",
      "import sys\n",
      "\n",
      "try:\n",
      "    from setuptools import setup\n",
      "except ImportError:\n",
      "    from distutils.core import setup\n",
      "\n",
      "with open('requirements.txt') as fh:\n",
      "    required = fh.read().splitlines()\n",
      "\n",
      "setup(\n",
      "    name='multiNER',\n",
      "    version='0.1',\n",
      "    description='Multiple NE-engines combined',\n",
      "    author='Willem Jan Faber',\n",
      "    url='https://github.com/KBNLresearch/multiNER/',\n",
      "    package_dir={'multiNER': '.'},\n",
      "    packages=['multiNER', 'multiNER'],\n",
      "    install_requires=required,\n",
      "    license='GPL-3.0',\n",
      ")\n",
      "\n",
      "Output: {'setup': ['distutils.core.setup', '<builtin>.open', 'setuptools.setup'], '<builtin>.open': [], 'distutils.core.setup': [], 'setuptools.setup': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\KBNLresearch_multiNER\\setup.py\n",
      "[('setup', 'distutils core setup'), ('setup', 'setuptools setup')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('setup', 'distutils core setup'), ('setup', 'setuptools setup')]]\n",
      "********************doctrings*************************\n",
      "['']\n",
      "embed index dataset: 24\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\phamdinhha_end-to-end-qna\\\\api\\\\cdqadocumentretriever\\\\retriever_sklearn.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\phamdinhha_end-to-end-qna\\\\api\\\\utils\\\\converters.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\phamdinhha_end-to-end-qna\\\\api\\\\customdocumentretriever\\\\QuestionProcessor.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\phamdinhha_end-to-end-qna\\\\api\\\\cdqadocumentretriever\\\\vectorizers.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\phamdinhha_end-to-end-qna\\\\api\\\\api.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\phamdinhha_end-to-end-qna\\\\api\\\\customdocumentretriever\\\\customgooglesearchengine.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\phamdinhha_end-to-end-qna\\\\api\\\\customdocumentretriever\\\\ParagraphsGenerator.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\phamdinhha_end-to-end-qna\\\\api\\\\customdocumentretriever\\\\DocumentRetrievalModel.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\phamdinhha_end-to-end-qna\\\\api\\\\documentretriever.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\phamdinhha_end-to-end-qna\\\\api\\\\utils\\\\filters.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\phamdinhha_end-to-end-qna\\\\api\\\\qamodelloader.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\phamdinhha_end-to-end-qna\\\\api\\\\cdqadocumentretriever\\\\text_transformers.py']\n",
      "import pandas as pd\n",
      "import prettytable\n",
      "import time\n",
      "from abc import ABC, abstractmethod\n",
      "from collections import OrderedDict\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.base import BaseEstimator\n",
      "from .vectorizers import BM25Vectorizer\n",
      "\n",
      "\n",
      "class BaseRetriever(BaseEstimator, ABC):\n",
      "    \"\"\"\n",
      "    Abstract base class for all Retriever classes.\n",
      "    All retrievers should inherit from this class.\n",
      "    Each retriever class should implement a _fit_vectorizer method and a\n",
      "    _compute_scores method\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, vectorizer, top_n=10, verbose=False):\n",
      "        self.vectorizer = vectorizer\n",
      "        self.top_n = top_n\n",
      "        self.verbose = verbose\n",
      "\n",
      "    def fit(self, df: pd.DataFrame, y=None):\n",
      "        \"\"\"\n",
      "        Fit the retriever to a list of documents or paragraphs\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        df: pandas.DataFrame object with all documents\n",
      "        \"\"\"\n",
      "        self.metadata = df\n",
      "        return self._fit_vectorizer(df)\n",
      "\n",
      "    @abstractmethod\n",
      "    def _fit_vectorizer(self, df):\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def _compute_scores(self, query):\n",
      "        pass\n",
      "\n",
      "    def predict(self, query: str) -> OrderedDict:\n",
      "        \"\"\"\n",
      "        Compute the top_n closest documents given a query\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        query: str\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        best_idx_scores: OrderedDict\n",
      "            Dictionnaire with top_n best scores and idices of the documents as keys\n",
      "\n",
      "        \"\"\"\n",
      "        t0 = time.time()\n",
      "        scores = self._compute_scores(query)\n",
      "        idx_scores = [(idx, score) for idx, score in enumerate(scores)]\n",
      "        best_idx_scores = OrderedDict(\n",
      "            sorted(idx_scores, key=(lambda tup: tup[1]), reverse=True)[: self.top_n]\n",
      "        )\n",
      "\n",
      "        # # inspired from https://github.com/facebookresearch/DrQA/blob/50d0e49bb77fe0c6e881efb4b6fe2e61d3f92509/scripts/reader/interactive.py#L63\n",
      "        # if self.verbose:\n",
      "        #     rank = 1\n",
      "        #     table = prettytable.PrettyTable([\"rank\", \"index\", \"title\"])\n",
      "        #     for i in range(len(best_idx_scores)):\n",
      "        #         index = best_idx_scores[i]\n",
      "        #         if self.paragraphs:\n",
      "        #             article_index = self.paragraphs[int(index)][\"index\"]\n",
      "        #             title = self.metadata.iloc[int(article_index)][\"title\"]\n",
      "        #         else:\n",
      "        #             title = self.metadata.iloc[int(index)][\"title\"]\n",
      "        #         table.add_row([rank, index, title])\n",
      "        #         rank += 1\n",
      "        #     print(table)\n",
      "        print(\"Time: {} seconds\".format(round(time.time() - t0, 5)))\n",
      "\n",
      "        return best_idx_scores\n",
      "\n",
      "\n",
      "class TfidfRetriever(BaseRetriever):\n",
      "    \"\"\"\n",
      "    A scikit-learn estimator for TfidfRetriever. Trains a tf-idf matrix from a corpus\n",
      "    of documents then finds the most N similar documents of a given input document by\n",
      "    taking the dot product of the vectorized input document and the trained tf-idf matrix.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    lowercase : boolean\n",
      "        Convert all characters to lowercase before tokenizing. (default is True)\n",
      "    preprocessor : callable or None\n",
      "        Override the preprocessing (string transformation) stage while preserving\n",
      "        the tokenizing and n-grams generation steps. (default is None)\n",
      "    tokenizer : callable or None\n",
      "        Override the string tokenization step while preserving the preprocessing\n",
      "        and n-grams generation steps (default is None)\n",
      "    stop_words : string {english}, list, or None\n",
      "        If a string, it is passed to _check_stop_list and the appropriate stop\n",
      "        list is returned. english is currently the only supported string value.\n",
      "        If a list, that list is assumed to contain stop words, all of which will\n",
      "        be removed from the resulting tokens.\n",
      "        If None, no stop words will be used. max_df can be set to a value in the\n",
      "        range [0.7, 1.0) to automatically detect and filter stop words based on\n",
      "        intra corpus document frequency of terms.\n",
      "        (default is None)\n",
      "    token_pattern : string\n",
      "        Regular expression denoting what constitutes a token. The default regexp\n",
      "        selects tokens of 2 or more alphanumeric characters (punctuation is completely\n",
      "        ignored and always treated as a token separator).\n",
      "    ngram_range : tuple (min_n, max_n)\n",
      "        The lower and upper boundary of the range of n-values for different n-grams\n",
      "        to be extracted. All values of n such that min_n <= n <= max_n will be used.\n",
      "        (default is (1, 1))\n",
      "    max_df : float in range [0.0, 1.0] or int\n",
      "        When building the vocabulary ignore terms that have a document frequency strictly\n",
      "        higher than the given threshold (corpus-specific stop words). If float, the parameter\n",
      "        represents a proportion of documents, integer absolute counts. This parameter is\n",
      "        ignored if vocabulary is not None. (default is 1.0)\n",
      "    min_df : float in range [0.0, 1.0] or int\n",
      "        When building the vocabulary ignore terms that have a document frequency\n",
      "        strictly lower than the given threshold. This value is also called cut-off\n",
      "        in the literature. If float, the parameter represents a proportion of\n",
      "        documents, integer absolute counts. This parameter is ignored if vocabulary\n",
      "        is not None. (default is 1)\n",
      "    vocabulary : Mapping or iterable, optional\n",
      "        Either a Mapping (e.g., a dict) where keys are terms and values are indices\n",
      "        in the feature matrix, or an iterable over terms. If not given, a vocabulary\n",
      "        is determined from the input documents. (default is None)\n",
      "    paragraphs : iterable\n",
      "        an iterable which yields either str, unicode or file objects\n",
      "    top_n : int (default 20)\n",
      "        maximum number of top articles (or paragraphs) to retrieve\n",
      "    verbose : bool, optional\n",
      "        If true, all of the warnings related to data processing will be printed.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    vectorizer : TfidfVectorizer\n",
      "        See https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
      "    tfidf_matrix : sparse matrix, [n_samples, n_features]\n",
      "        Tf-idf-weighted document-term matrix.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from cdqa.retriever import TfidfRetriever\n",
      "\n",
      "    >>> retriever = TfidfRetriever(ngram_range=(1, 2), max_df=0.85, stop_words='english')\n",
      "    >>> retriever.fit(X=df)\n",
      "    >>> best_idx_scores = retriever.predict(X='Since when does the the Excellence Program of BNP Paribas exist?')\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        lowercase=True,\n",
      "        preprocessor=None,\n",
      "        tokenizer=None,\n",
      "        stop_words=\"english\",\n",
      "        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
      "        ngram_range=(1, 2),\n",
      "        max_df=0.85,\n",
      "        min_df=2,\n",
      "        vocabulary=None,\n",
      "        top_n=20,\n",
      "        verbose=False,\n",
      "    ):\n",
      "        self.lowercase = lowercase\n",
      "        self.preprocessor = preprocessor\n",
      "        self.tokenizer = tokenizer\n",
      "        self.stop_words = stop_words\n",
      "        self.token_pattern = token_pattern\n",
      "        self.ngram_range = ngram_range\n",
      "        self.max_df = max_df\n",
      "        self.min_df = min_df\n",
      "        self.vocabulary = vocabulary\n",
      "\n",
      "        vectorizer = TfidfVectorizer(\n",
      "            lowercase=self.lowercase,\n",
      "            preprocessor=self.preprocessor,\n",
      "            tokenizer=self.tokenizer,\n",
      "            stop_words=self.stop_words,\n",
      "            token_pattern=self.token_pattern,\n",
      "            ngram_range=self.ngram_range,\n",
      "            max_df=self.max_df,\n",
      "            min_df=self.min_df,\n",
      "            vocabulary=self.vocabulary,\n",
      "        )\n",
      "        super().__init__(vectorizer, top_n, verbose)\n",
      "\n",
      "    def _fit_vectorizer(self, df, y=None):\n",
      "        self.tfidf_matrix = self.vectorizer.fit_transform(df[\"content\"])\n",
      "        return self\n",
      "\n",
      "    def _compute_scores(self, query):\n",
      "        question_vector = self.vectorizer.transform([query])\n",
      "        scores = self.tfidf_matrix.dot(question_vector.T).toarray()\n",
      "        return scores\n",
      "\n",
      "\n",
      "class BM25Retriever(BaseRetriever):\n",
      "    \"\"\"\n",
      "    A scikit-learn estimator for BM25Retriever. Trains a matrix based on BM25 statistics\n",
      "    from a corpus of documents then finds the most N similar documents of a given input\n",
      "    query by computing the BM25 score for each document based on the query.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    lowercase : boolean\n",
      "        Convert all characters to lowercase before tokenizing. (default is True)\n",
      "    preprocessor : callable or None\n",
      "        Override the preprocessing (string transformation) stage while preserving\n",
      "        the tokenizing and n-grams generation steps. (default is None)\n",
      "    tokenizer : callable or None\n",
      "        Override the string tokenization step while preserving the preprocessing\n",
      "        and n-grams generation steps (default is None)\n",
      "    stop_words : string {english}, list, or None\n",
      "        If a string, it is passed to _check_stop_list and the appropriate stop\n",
      "        list is returned. english is currently the only supported string value.\n",
      "        If a list, that list is assumed to contain stop words, all of which will\n",
      "        be removed from the resulting tokens.\n",
      "        If None, no stop words will be used. max_df can be set to a value in the\n",
      "        range [0.7, 1.0) to automatically detect and filter stop words based on\n",
      "        intra corpus document frequency of terms.\n",
      "        (default is None)\n",
      "    token_pattern : string\n",
      "        Regular expression denoting what constitutes a token. The default regexp\n",
      "        selects tokens of 2 or more alphanumeric characters (punctuation is completely\n",
      "        ignored and always treated as a token separator).\n",
      "    ngram_range : tuple (min_n, max_n)\n",
      "        The lower and upper boundary of the range of n-values for different n-grams\n",
      "        to be extracted. All values of n such that min_n <= n <= max_n will be used.\n",
      "        (default is (1, 1))\n",
      "    max_df : float in range [0.0, 1.0] or int\n",
      "        When building the vocabulary ignore terms that have a document frequency strictly\n",
      "        higher than the given threshold (corpus-specific stop words). If float, the parameter\n",
      "        represents a proportion of documents, integer absolute counts. This parameter is\n",
      "        ignored if vocabulary is not None. (default is 1.0)\n",
      "    min_df : float in range [0.0, 1.0] or int\n",
      "        When building the vocabulary ignore terms that have a document frequency\n",
      "        strictly lower than the given threshold. This value is also called cut-off\n",
      "        in the literature. If float, the parameter represents a proportion of\n",
      "        documents, integer absolute counts. This parameter is ignored if vocabulary\n",
      "        is not None. (default is 1)\n",
      "    vocabulary : Mapping or iterable, optional\n",
      "        Either a Mapping (e.g., a dict) where keys are terms and values are indices\n",
      "        in the feature matrix, or an iterable over terms. If not given, a vocabulary\n",
      "        is determined from the input documents. (default is None)\n",
      "    paragraphs : iterable\n",
      "        an iterable which yields either str, unicode or file objects\n",
      "    top_n : int (default 20)\n",
      "        maximum number of top articles (or paragraphs) to retrieve\n",
      "    verbose : bool, optional\n",
      "        If true, all of the warnings related to data processing will be printed.\n",
      "    k1 : float, optional (default=2.0)\n",
      "        term k1 in the BM25 formula\n",
      "    b : float, optional (default=0.75)\n",
      "        term b in the BM25 formula\n",
      "    floor : float or None, optional (default=None)\n",
      "        floor value for idf terms\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    vectorizer : BM25Vectorizer\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from cdqa.retriever import BM25Retriever\n",
      "\n",
      "    >>> retriever = BM25Retriever(ngram_range=(1, 2), max_df=0.85, stop_words='english')\n",
      "    >>> retriever.fit(df=df)\n",
      "    >>> best_idx_scores = retriever.predict(query='Since when does the the Excellence Program of BNP Paribas exist?')\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        lowercase=True,\n",
      "        preprocessor=None,\n",
      "        tokenizer=None,\n",
      "        stop_words=\"english\",\n",
      "        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
      "        ngram_range=(1, 2),\n",
      "        max_df=0.85,\n",
      "        min_df=2,\n",
      "        vocabulary=None,\n",
      "        top_n=20,\n",
      "        verbose=False,\n",
      "        k1=2.0,\n",
      "        b=0.75,\n",
      "        floor=None,\n",
      "    ):\n",
      "\n",
      "        self.lowercase = lowercase\n",
      "        self.preprocessor = preprocessor\n",
      "        self.tokenizer = tokenizer\n",
      "        self.stop_words = stop_words\n",
      "        self.token_pattern = token_pattern\n",
      "        self.ngram_range = ngram_range\n",
      "        self.max_df = max_df\n",
      "        self.min_df = min_df\n",
      "        self.vocabulary = vocabulary\n",
      "        self.k1 = k1\n",
      "        self.b = b\n",
      "        self.floor = floor\n",
      "\n",
      "        vectorizer = BM25Vectorizer(\n",
      "            lowercase=self.lowercase,\n",
      "            preprocessor=self.preprocessor,\n",
      "            tokenizer=self.tokenizer,\n",
      "            stop_words=self.stop_words,\n",
      "            token_pattern=self.token_pattern,\n",
      "            ngram_range=self.ngram_range,\n",
      "            max_df=self.max_df,\n",
      "            min_df=self.min_df,\n",
      "            vocabulary=self.vocabulary,\n",
      "            k1=self.k1,\n",
      "            b=self.b,\n",
      "            floor=self.floor,\n",
      "        )\n",
      "        super().__init__(vectorizer, top_n, verbose)\n",
      "\n",
      "    def _fit_vectorizer(self, df, y=None):\n",
      "        self.bm25_matrix = self.vectorizer.fit_transform(df[\"content\"])\n",
      "        return self\n",
      "\n",
      "    def _compute_scores(self, query):\n",
      "        question_vector = self.vectorizer.transform([query], is_query=True)\n",
      "        scores = self.bm25_matrix.dot(question_vector.T).toarray()\n",
      "        return scores\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\phamdinhha_end-to-end-qna\\api\\cdqadocumentretriever\\retriever_sklearn.py\n",
      "[]\n",
      "found files: []\n",
      "import json\n",
      "import os\n",
      "import re\n",
      "import sys\n",
      "from tqdm import tqdm\n",
      "from tika import parser\n",
      "import pandas as pd\n",
      "import uuid\n",
      "import markdown\n",
      "from pathlib import Path\n",
      "from html.parser import HTMLParser\n",
      "\n",
      "\n",
      "def df2squad(df, squad_version=\"v1.1\", output_dir=None, filename=None):\n",
      "    \"\"\"\n",
      "     Converts a pandas dataframe with columns ['title', 'paragraphs'] to a json file with SQuAD format.\n",
      "\n",
      "     Parameters\n",
      "    ----------\n",
      "     df : pandas.DataFrame\n",
      "         a pandas dataframe with columns ['title', 'paragraphs']\n",
      "     squad_version : str, optional\n",
      "         the SQuAD dataset version format (the default is 'v2.0')\n",
      "     output_dir : str, optional\n",
      "         Enable export of output (the default is None)\n",
      "     filename : str, optional\n",
      "         [description]\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    json_data: dict\n",
      "        A json object with SQuAD format\n",
      "\n",
      "     Examples\n",
      "     --------\n",
      "     >>> from ast import literal_eval\n",
      "     >>> import pandas as pd\n",
      "     >>> from cdqa.utils.converters import df2squad\n",
      "     >>> from cdqa.utils.filters import filter_paragraphs\n",
      "\n",
      "     >>> df = pd.read_csv('../data/bnpp_newsroom_v1.1/bnpp_newsroom-v1.1.csv', converters={'paragraphs': literal_eval})\n",
      "     >>> df['paragraphs'] = df['paragraphs'].apply(filter_paragraphs)\n",
      "\n",
      "     >>> json_data = df2squad(df=df, squad_version='v1.1', output_dir='../data', filename='bnpp_newsroom-v1.1')\n",
      "    \"\"\"\n",
      "\n",
      "    json_data = {}\n",
      "    json_data[\"version\"] = squad_version\n",
      "    json_data[\"data\"] = []\n",
      "\n",
      "    for idx, row in tqdm(df.iterrows()):\n",
      "        temp = {\"title\": row[\"title\"], \"paragraphs\": []}\n",
      "        for paragraph in row[\"paragraphs\"]:\n",
      "            temp[\"paragraphs\"].append({\"context\": paragraph, \"qas\": []})\n",
      "        json_data[\"data\"].append(temp)\n",
      "\n",
      "    if output_dir:\n",
      "        with open(os.path.join(output_dir, \"{}.json\".format(filename)), \"w\") as outfile:\n",
      "            json.dump(json_data, outfile)\n",
      "\n",
      "    return json_data\n",
      "\n",
      "\n",
      "def generate_squad_examples(question, best_idx_scores, metadata, retrieve_by_doc):\n",
      "    \"\"\"\n",
      "    Creates a SQuAD examples json object for a given for a given question using outputs of retriever and document database.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    question : [type]\n",
      "        [description]\n",
      "    best_idx_scores : [type]\n",
      "        [description]\n",
      "    metadata : [type]\n",
      "        [description]\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    squad_examples: list\n",
      "        [description]\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from cdqa.utils.converters import generate_squad_examples\n",
      "    >>> squad_examples = generate_squad_examples(question='Since when does the the Excellence Program of BNP Paribas exist?',\n",
      "                                         best_idx_scores=[(788, 1.2), (408, 0.4), (2419, 0.2)],\n",
      "                                         metadata=df)\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    squad_examples = []\n",
      "\n",
      "    metadata_sliced = metadata.loc[best_idx_scores.keys()]\n",
      "\n",
      "    for idx, row in metadata_sliced.iterrows():\n",
      "        temp = {\"title\": row[\"title\"], \"paragraphs\": []}\n",
      "\n",
      "        if retrieve_by_doc:\n",
      "            for paragraph in row[\"paragraphs\"]:\n",
      "                temp[\"paragraphs\"].append(\n",
      "                    {\n",
      "                        \"context\": paragraph,\n",
      "                        \"qas\": [\n",
      "                            {\n",
      "                                \"answers\": [],\n",
      "                                \"question\": question,\n",
      "                                \"id\": str(uuid.uuid4()),\n",
      "                                \"retriever_score\": best_idx_scores[idx],\n",
      "                            }\n",
      "                        ],\n",
      "                    }\n",
      "                )\n",
      "        else:\n",
      "            temp[\"paragraphs\"] = [\n",
      "                {\n",
      "                    \"context\": row[\"content\"],\n",
      "                    \"qas\": [\n",
      "                        {\n",
      "                            \"answers\": [],\n",
      "                            \"question\": question,\n",
      "                            \"id\": str(uuid.uuid4()),\n",
      "                            \"retriever_score\": best_idx_scores[idx],\n",
      "                        }\n",
      "                    ],\n",
      "                }\n",
      "            ]\n",
      "\n",
      "        squad_examples.append(temp)\n",
      "\n",
      "    return squad_examples\n",
      "\n",
      "\n",
      "def pdf_converter(directory_path, min_length=200, include_line_breaks=False):\n",
      "    \"\"\"\n",
      "    Function to convert PDFs to Dataframe with columns as title & paragraphs.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "\n",
      "    min_length : integer\n",
      "        Minimum character length to be considered as a single paragraph\n",
      "\n",
      "    include_line_breaks: bool\n",
      "        To concatenate paragraphs less than min_length to a single paragraph\n",
      "\n",
      "\n",
      "\n",
      "    Returns\n",
      "    -------------\n",
      "    df : Dataframe\n",
      "\n",
      "\n",
      "    Description\n",
      "    -----------------\n",
      "    If include_line_breaks is set to True, paragraphs with character length\n",
      "    less than min_length (minimum character length of a paragraph) will be\n",
      "    considered as a line. Lines before or after each paragraph(length greater\n",
      "    than or equal to min_length) will be concatenated to a single paragraph to\n",
      "    form the list of paragraphs in Dataframe.\n",
      "\n",
      "    Else paragraphs are appended directly to form the list.\n",
      "\n",
      "    \"\"\"\n",
      "    list_file = os.listdir(directory_path)\n",
      "    list_pdf = []\n",
      "    for file in list_file:\n",
      "        if file.endswith(\"pdf\"):\n",
      "            list_pdf.append(file)\n",
      "    df = pd.DataFrame(columns=[\"title\", \"paragraphs\"])\n",
      "    for i, pdf in enumerate(list_pdf):\n",
      "        try:\n",
      "            df.loc[i] = [pdf.replace(\".pdf\",''), None]\n",
      "            raw = parser.from_file(os.path.join(directory_path, pdf))\n",
      "            s = raw[\"content\"].strip()\n",
      "            paragraphs = re.split(\"\\n\\n(?=\\u2028|[A-Z-0-9])\", s)\n",
      "            list_par = []\n",
      "            temp_para = \"\"  # variable that stores paragraphs with length<min_length\n",
      "            # (considered as a line)\n",
      "            for p in paragraphs:\n",
      "                if not p.isspace():  # checking if paragraph is not only spaces\n",
      "                    if include_line_breaks:  # if True, check length of paragraph\n",
      "                        if len(p) >= min_length:\n",
      "                            if temp_para:\n",
      "                                # if True, append temp_para which holds concatenated\n",
      "                                # lines to form a paragraph before current paragraph p\n",
      "                                list_par.append(temp_para.strip())\n",
      "                                temp_para = (\n",
      "                                    \"\"\n",
      "                                )  # reset temp_para for new lines to be concatenated\n",
      "                                list_par.append(\n",
      "                                    p.replace(\"\\n\", \"\")\n",
      "                                )  # append current paragraph with length>min_length\n",
      "                            else:\n",
      "                                list_par.append(p.replace(\"\\n\", \"\"))\n",
      "                        else:\n",
      "                            # paragraph p (line) is concatenated to temp_para\n",
      "                            line = p.replace(\"\\n\", \" \").strip()\n",
      "                            temp_para = temp_para + f\" {line}\"\n",
      "                    else:\n",
      "                        # appending paragraph p as is to list_par\n",
      "                        list_par.append(p.replace(\"\\n\", \"\"))\n",
      "                else:\n",
      "                    if temp_para:\n",
      "                        list_par.append(temp_para.strip())\n",
      "\n",
      "            df.loc[i, \"paragraphs\"] = list_par\n",
      "        except:\n",
      "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
      "            print(\"Unable to process file {}\".format(pdf))\n",
      "    return df\n",
      "\n",
      "\n",
      "class MLStripper(HTMLParser):\n",
      "    def __init__(self):\n",
      "        self.reset()\n",
      "        self.strict = False\n",
      "        self.convert_charrefs = True\n",
      "        self.fed = []\n",
      "\n",
      "    def handle_data(self, d):\n",
      "        self.fed.append(d)\n",
      "\n",
      "    def get_data(self):\n",
      "        return \"\".join(self.fed)\n",
      "\n",
      "\n",
      "def strip_tags(html):\n",
      "    s = MLStripper()\n",
      "    s.feed(html)\n",
      "    return s.get_data()\n",
      "\n",
      "\n",
      "def md_converter(directory_path):\n",
      "    \"\"\"Get all md, convert them to html and create the pandas dataframe with columns ['title', 'paragraphs']\"\"\"\n",
      "    dict_doc = {\"title\": [], \"paragraphs\": []}\n",
      "    for md_file in Path(directory_path).glob(\"**/*.md\"):\n",
      "        md_file = str(md_file)\n",
      "        filename = md_file.split(\"/\")[-1]\n",
      "        try:\n",
      "            with open(md_file, \"r\") as f:\n",
      "                dict_doc[\"title\"].append(filename)\n",
      "                md_text = f.read()\n",
      "                html_text = markdown.markdown(md_text)\n",
      "                html_text_list = list(html_text.split(\"<p>\"))\n",
      "                for i in range(len(html_text_list)):\n",
      "                    html_text_list[i] = (\n",
      "                        strip_tags(html_text_list[i])\n",
      "                        .replace(\"\\n\", \" \")\n",
      "                        .lstrip()\n",
      "                        .rstrip()\n",
      "                    )\n",
      "                clean_text_list = list(filter(None, html_text_list))\n",
      "                dict_doc[\"paragraphs\"].append(clean_text_list)\n",
      "        except:\n",
      "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
      "            print(\"Unable to process file {}\".format(filename))\n",
      "    df = pd.DataFrame.from_dict(dict_doc)\n",
      "    return df\n",
      "\n",
      "Output: {'converters': [], 'converters.df2squad': ['os.path.join', 'tqdm.tqdm', '<builtin>.open', 'json.dump'], 'tqdm.tqdm': [], 'os.path.join': [], '<builtin>.open': [], 'json.dump': [], 'converters.generate_squad_examples': ['<builtin>.str', 'uuid.uuid4'], 'uuid.uuid4': [], '<builtin>.str': [], 'converters.pdf_converter': ['re.split', 'os.listdir', 'sys.exc_info', 'os.path.join', 'tika.parser.from_file', '<builtin>.print', '<builtin>.len', '<builtin>.enumerate', 'pandas.DataFrame'], 'os.listdir': [], 'pandas.DataFrame': [], '<builtin>.enumerate': [], 'tika.parser.from_file': [], 're.split': [], '<builtin>.len': [], 'sys.exc_info': [], '<builtin>.print': [], 'converters.MLStripper.__init__': ['html.parser.HTMLParser.reset'], 'html.parser.HTMLParser.reset': [], 'converters.MLStripper.handle_data': [], 'converters.MLStripper.get_data': [], 'converters.strip_tags': ['converters.MLStripper.__init__', 'converters.MLStripper.get_data', 'html.parser.HTMLParser.feed'], 'html.parser.HTMLParser.feed': [], 'converters.md_converter': ['<builtin>.open', 'markdown.markdown', 'converters.strip_tags', '<builtin>.range', 'pathlib.Path', 'sys.exc_info', '<builtin>.list', '<builtin>.filter', 'pandas.DataFrame.from_dict', '<builtin>.print', '<builtin>.str', '<builtin>.len'], 'pathlib.Path': [], 'markdown.markdown': [], '<builtin>.list': [], '<builtin>.range': [], '<builtin>.filter': [], 'pandas.DataFrame.from_dict': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\phamdinhha_end-to-end-qna\\api\\utils\\converters.py\n",
      "[('converters df2squad', 'os path join'), ('converters df2squad', 'tqdm tqdm'), ('converters df2squad', 'json dump'), ('converters generate_squad_examples', 'uuid uuid4'), ('converters pdf_converter', 're split'), ('converters pdf_converter', 'os listdir'), ('converters pdf_converter', 'sys exc_info'), ('converters pdf_converter', 'os path join'), ('converters pdf_converter', 'tika parser from_file'), ('converters pdf_converter', 'pandas DataFrame'), ('converters MLStripper __init__', 'html parser HTMLParser reset'), ('converters strip_tags', 'converters MLStripper __init__'), ('converters strip_tags', 'converters MLStripper get_data'), ('converters strip_tags', 'html parser HTMLParser feed'), ('converters md_converter', 'markdown markdown'), ('converters md_converter', 'converters strip_tags'), ('converters md_converter', 'pathlib Path'), ('converters md_converter', 'sys exc_info'), ('converters md_converter', 'pandas DataFrame from_dict')]\n",
      "403\n",
      "found files: []\n",
      "# ScriptName : QuestionProcessor.py\n",
      "# Description : Takes question as an input and process it to find out question\n",
      "#   and answer type, also prepare question vector and prepare search query for\n",
      "#   Information Retrieval process\n",
      "# Arguments : \n",
      "#       Input :\n",
      "#           question(str) : String of question\n",
      "#           useStemmer(boolean) : Indicate to use stemmer for question tokens\n",
      "#           useSynonyms(boolean) : Indicate to use thesaraus for query expansion\n",
      "#           removeStopwords(boolean) : Indicate to remove stop words from search\n",
      "#                                      query\n",
      "#       Output :\n",
      "#           Instance of QuestionProcessor with useful following structure\n",
      "#               qVector(dict) : Key Value pair of word and its frequency\n",
      "#                               to be used for Information Retrieval and \n",
      "#                               similarity calculation\n",
      "#               question(str) : Raw question\n",
      "#               qType(str) : Type of question\n",
      "#               aType(str) : Expected answer type\n",
      "#                       [\"PERSON\",\"LOCATION\",\"DATE\",\"DEFINITION\",\"YESNO\"]\n",
      "#               \n",
      "\n",
      "from nltk import pos_tag,word_tokenize,ne_chunk\n",
      "from nltk.stem.porter import PorterStemmer\n",
      "import nltk\n",
      "nltk.download('stopwords')\n",
      "nltk.download('averaged_perceptron_tagger')\n",
      "from nltk.corpus import wordnet,stopwords\n",
      "\n",
      "class QuestionProcessor:\n",
      "    def __init__(self, question, useStemmer = False, useSynonyms = False, removeStopwords = False):\n",
      "        self.question = question\n",
      "        self.useStemmer = useStemmer\n",
      "        self.useSynonyms = useSynonyms\n",
      "        self.removeStopwords = removeStopwords\n",
      "        self.stopWords = stopwords.words(\"english\")\n",
      "        self.stem = lambda k : k.lower()\n",
      "        if self.useStemmer:\n",
      "            ps = PorterStemmer()\n",
      "            self.stem = ps.stem\n",
      "        self.qType = self.determineQuestionType(question)\n",
      "        self.searchQuery = self.buildSearchQuery(question)\n",
      "        self.qVector = self.getQueryVector(self.searchQuery)\n",
      "        self.aType = self.determineAnswerType(question)\n",
      "    \n",
      "    # To determine type of question by analyzing POS tag of question from Penn \n",
      "    # Treebank tagset\n",
      "    #\n",
      "    # Input:\n",
      "    #           question(str) : Question string\n",
      "    # Output:\n",
      "    #           qType(str) : Type of question among following\n",
      "    #                   [ WP ->  who\n",
      "    #                     WDT -> what, why, how\n",
      "    #                     WP$ -> whose\n",
      "    #                     WRB -> where ]\n",
      "    def determineQuestionType(self, question):\n",
      "        questionTaggers = ['WP','WDT','WP$','WRB']\n",
      "        qPOS = pos_tag(word_tokenize(question))\n",
      "        qTags = []\n",
      "        for token in qPOS:\n",
      "            if token[1] in questionTaggers:\n",
      "                qTags.append(token[1])\n",
      "        qType = ''\n",
      "        if(len(qTags)>1):\n",
      "            qType = 'complex'\n",
      "        elif(len(qTags) == 1):\n",
      "            qType = qTags[0]\n",
      "        else:\n",
      "            qType = \"None\"\n",
      "        return qType\n",
      "    \n",
      "    # To determine type of expected answer depending of question type\n",
      "    #\n",
      "    # Input:\n",
      "    #           question(str) : Question string\n",
      "    # Output:\n",
      "    #           aType(str) : Type of answer among following\n",
      "    #               [PERSON, LOCATION, DATE, ORGANIZATION, QUANTITY, DEFINITION\n",
      "    #                   FULL]\n",
      "    def determineAnswerType(self, question):\n",
      "        questionTaggers = ['WP','WDT','WP$','WRB']\n",
      "        qPOS = pos_tag(word_tokenize(question))\n",
      "        qTag = None\n",
      "\n",
      "        for token in qPOS:\n",
      "            if token[1] in questionTaggers:\n",
      "                qTag = token[0].lower()\n",
      "                break\n",
      "        \n",
      "        if(qTag == None):\n",
      "            if len(qPOS) > 1:\n",
      "                if qPOS[1][1].lower() in ['is','are','can','should']:\n",
      "                    qTag = \"YESNO\"\n",
      "        #who/where/what/why/when/is/are/can/should\n",
      "        if qTag == \"who\":\n",
      "            return \"PERSON\"\n",
      "        elif qTag == \"where\":\n",
      "            return \"LOCATION\"\n",
      "        elif qTag == \"when\":\n",
      "            return \"DATE\"\n",
      "        elif qTag == \"what\":\n",
      "            # Defination type question\n",
      "            # If question of type whd modal noun? its a defination question\n",
      "            qTok = self.getContinuousChunk(question)\n",
      "            #print(qTok)\n",
      "            if(len(qTok) == 4):\n",
      "                if qTok[1][1] in ['is','are','was','were'] and qTok[2][0] in [\"NN\",\"NNS\",\"NNP\",\"NNPS\"]:\n",
      "                    self.question = \" \".join([qTok[0][1],qTok[2][1],qTok[1][1]])\n",
      "                    #print(\"Type of question\",\"Definition\",self.question)\n",
      "                    return \"DEFINITION\"\n",
      "\n",
      "            # ELSE USE FIRST HEAD WORD\n",
      "            for token in qPOS:\n",
      "                if token[0].lower() in [\"city\",\"place\",\"country\"]:\n",
      "                    return \"LOCATION\"\n",
      "                elif token[0].lower() in [\"company\",\"industry\",\"organization\"]:\n",
      "                    return \"ORGANIZATION\"\n",
      "                elif token[1] in [\"NN\",\"NNS\"]:\n",
      "                    return \"FULL\"\n",
      "                elif token[1] in [\"NNP\",\"NNPS\"]:\n",
      "                    return \"FULL\"\n",
      "            return \"FULL\"\n",
      "        elif qTag == \"how\":\n",
      "            if len(qPOS)>1:\n",
      "                t2 = qPOS[2]\n",
      "                if t2[0].lower() in [\"few\",\"great\",\"little\",\"many\",\"much\"]:\n",
      "                    return \"QUANTITY\"\n",
      "                elif t2[0].lower() in [\"tall\",\"wide\",\"big\",\"far\"]:\n",
      "                    return \"LINEAR_MEASURE\"\n",
      "            return \"FULL\"\n",
      "        else:\n",
      "            return \"FULL\"\n",
      "    \n",
      "    # To build search query by dropping question word\n",
      "    #\n",
      "    # Input:\n",
      "    #           question(str) : Question string\n",
      "    # Output:\n",
      "    #           searchQuery(list) : List of tokens\n",
      "    def buildSearchQuery(self, question):\n",
      "        qPOS = pos_tag(word_tokenize(question))\n",
      "        searchQuery = []\n",
      "        questionTaggers = ['WP','WDT','WP$','WRB']\n",
      "        for tag in qPOS:\n",
      "            if tag[1] in questionTaggers:\n",
      "                continue\n",
      "            else:\n",
      "                searchQuery.append(tag[0])\n",
      "                if(self.useSynonyms):\n",
      "                    syn = self.getSynonyms(tag[0])\n",
      "                    if(len(syn) > 0):\n",
      "                        searchQuery.extend(syn)\n",
      "        return searchQuery\n",
      "    \n",
      "    # To build query vector\n",
      "    #\n",
      "    # Input:\n",
      "    #       searchQuery(list) : List of tokens from buildSearchQuery method\n",
      "    # Output:\n",
      "    #       qVector(dict) : Dictionary of words and their frequency\n",
      "    def getQueryVector(self, searchQuery):\n",
      "        vector = {}\n",
      "        for token in searchQuery:\n",
      "            if self.removeStopwords:\n",
      "                if token in self.stopWords:\n",
      "                    continue\n",
      "            token = self.stem(token)\n",
      "            if token in vector.keys():\n",
      "                vector[token] += 1\n",
      "            else:\n",
      "                vector[token] = 1\n",
      "        return vector\n",
      "    \n",
      "    # To get continuous chunk of similar POS tags.\n",
      "    # E.g.  If two NN tags are consequetive, this method will merge and return\n",
      "    #       single NN with combined value.\n",
      "    #       It is helpful in detecting name of single person like John Cena, \n",
      "    #       Steve Jobs\n",
      "    # Input:\n",
      "    #       question(str) : question string\n",
      "    # Output:\n",
      "    #       \n",
      "    def getContinuousChunk(self,question):\n",
      "        chunks = []\n",
      "        answerToken = word_tokenize(question)\n",
      "        nc = pos_tag(answerToken)\n",
      "\n",
      "        prevPos = nc[0][1]\n",
      "        entity = {\"pos\":prevPos,\"chunk\":[]}\n",
      "        for c_node in nc:\n",
      "            (token,pos) = c_node\n",
      "            if pos == prevPos:\n",
      "                prevPos = pos       \n",
      "                entity[\"chunk\"].append(token)\n",
      "            elif prevPos in [\"DT\",\"JJ\"]:\n",
      "                prevPos = pos\n",
      "                entity[\"pos\"] = pos\n",
      "                entity[\"chunk\"].append(token)\n",
      "            else:\n",
      "                if not len(entity[\"chunk\"]) == 0:\n",
      "                    chunks.append((entity[\"pos\"],\" \".join(entity[\"chunk\"])))\n",
      "                    entity = {\"pos\":pos,\"chunk\":[token]}\n",
      "                    prevPos = pos\n",
      "        if not len(entity[\"chunk\"]) == 0:\n",
      "            chunks.append((entity[\"pos\"],\" \".join(entity[\"chunk\"])))\n",
      "        return chunks\n",
      "    \n",
      "    # To get synonyms of word in order to improve query by using query\n",
      "    # expanision technique\n",
      "    # Input:\n",
      "    #       word(str) : Word token\n",
      "    # Output:\n",
      "    #       synonyms(list) : List of synonyms of given word\n",
      "    def getSynonyms(self, word):\n",
      "        synonyms = []\n",
      "        for syn in wordnet.synsets(word):\n",
      "            for l in syn.lemmas():\n",
      "                w = l.name().lower()\n",
      "                synonyms.extend(w.split(\"_\"))\n",
      "        return list(set(synonyms))\n",
      "    \n",
      "    # String representation of this class\n",
      "    def __repr__(self):\n",
      "        msg = \"Q: \" + self.question + \"\\n\"\n",
      "        msg += \"QType: \" + self.qType + \"\\n\"\n",
      "        msg += \"QVector: \" + str(self.qVector) + \"\\n\"\n",
      "        return msg\n",
      "Output: {'QuestionProcessor': ['nltk.download'], 'nltk.download': [], 'QuestionProcessor.QuestionProcessor.__init__': ['QuestionProcessor.QuestionProcessor.determineAnswerType', 'QuestionProcessor.QuestionProcessor.buildSearchQuery', 'QuestionProcessor.QuestionProcessor.getQueryVector', 'nltk.corpus.stopwords.words', 'nltk.stem.porter.PorterStemmer', 'QuestionProcessor.QuestionProcessor.determineQuestionType'], 'nltk.corpus.stopwords.words': [], 'QuestionProcessor.QuestionProcessor.__init__.<lambda1>': [], 'nltk.stem.porter.PorterStemmer': [], 'QuestionProcessor.QuestionProcessor.determineQuestionType': ['nltk.word_tokenize', '<builtin>.len', 'nltk.pos_tag'], 'QuestionProcessor.QuestionProcessor.buildSearchQuery': ['nltk.word_tokenize', 'QuestionProcessor.QuestionProcessor.getSynonyms', 'nltk.pos_tag', '<builtin>.len'], 'QuestionProcessor.QuestionProcessor.getQueryVector': ['QuestionProcessor.QuestionProcessor.__init__.<lambda1>'], 'QuestionProcessor.QuestionProcessor.determineAnswerType': ['nltk.word_tokenize', '<builtin>.len', 'nltk.pos_tag', 'QuestionProcessor.QuestionProcessor.getContinuousChunk'], 'nltk.word_tokenize': [], 'nltk.pos_tag': [], '<builtin>.len': [], 'QuestionProcessor.QuestionProcessor.getContinuousChunk': ['nltk.word_tokenize', '<builtin>.len', 'nltk.pos_tag'], 'QuestionProcessor.QuestionProcessor.getSynonyms': ['<builtin>.list', '<builtin>.set', 'nltk.corpus.wordnet.synsets'], 'nltk.corpus.wordnet.synsets': [], '<builtin>.set': [], '<builtin>.list': [], 'QuestionProcessor.QuestionProcessor.__repr__': ['<builtin>.str'], '<builtin>.str': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\phamdinhha_end-to-end-qna\\api\\customdocumentretriever\\QuestionProcessor.py\n",
      "[('QuestionProcessor', 'nltk download'), ('QuestionProcessor QuestionProcessor __init__', 'QuestionProcessor QuestionProcessor determineAnswerType'), ('QuestionProcessor QuestionProcessor __init__', 'QuestionProcessor QuestionProcessor buildSearchQuery'), ('QuestionProcessor QuestionProcessor __init__', 'QuestionProcessor QuestionProcessor getQueryVector'), ('QuestionProcessor QuestionProcessor __init__', 'nltk corpus stopwords words'), ('QuestionProcessor QuestionProcessor __init__', 'nltk stem porter PorterStemmer'), ('QuestionProcessor QuestionProcessor __init__', 'QuestionProcessor QuestionProcessor determineQuestionType'), ('QuestionProcessor QuestionProcessor determineQuestionType', 'nltk word_tokenize'), ('QuestionProcessor QuestionProcessor determineQuestionType', 'nltk pos_tag'), ('QuestionProcessor QuestionProcessor buildSearchQuery', 'nltk word_tokenize'), ('QuestionProcessor QuestionProcessor buildSearchQuery', 'QuestionProcessor QuestionProcessor getSynonyms'), ('QuestionProcessor QuestionProcessor buildSearchQuery', 'nltk pos_tag'), ('QuestionProcessor QuestionProcessor getQueryVector', 'QuestionProcessor QuestionProcessor __init__ <lambda1>'), ('QuestionProcessor QuestionProcessor determineAnswerType', 'nltk word_tokenize'), ('QuestionProcessor QuestionProcessor determineAnswerType', 'nltk pos_tag'), ('QuestionProcessor QuestionProcessor determineAnswerType', 'QuestionProcessor QuestionProcessor getContinuousChunk'), ('QuestionProcessor QuestionProcessor getContinuousChunk', 'nltk word_tokenize'), ('QuestionProcessor QuestionProcessor getContinuousChunk', 'nltk pos_tag'), ('QuestionProcessor QuestionProcessor getSynonyms', 'nltk corpus wordnet synsets')]\n",
      "0\n",
      "found files: []\n",
      "import numpy as np\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from cdqadocumentretriever.text_transformers import BM25Transformer\n",
      "\n",
      "\n",
      "class BM25Vectorizer(CountVectorizer):\n",
      "    \"\"\"Convert a collection of raw documents to a matrix of BM25 features and computes\n",
      "    scores of the documents based on a query\n",
      "\n",
      "    Vectorizer inspired on the sklearn.feature_extraction.text.TfidfVectorizer\n",
      "    class\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    input : string {'filename', 'file', 'content'}\n",
      "        If 'filename', the sequence passed as an argument to fit is\n",
      "        expected to be a list of filenames that need reading to fetch\n",
      "        the raw content to analyze.\n",
      "\n",
      "        If 'file', the sequence items must have a 'read' method (file-like\n",
      "        object) that is called to fetch the bytes in memory.\n",
      "\n",
      "        Otherwise the input is expected to be the sequence strings or\n",
      "        bytes items are expected to be analyzed directly.\n",
      "\n",
      "    encoding : string, 'utf-8' by default.\n",
      "        If bytes or files are given to analyze, this encoding is used to\n",
      "        decode.\n",
      "\n",
      "    decode_error : {'strict', 'ignore', 'replace'} (default='strict')\n",
      "        Instruction on what to do if a byte sequence is given to analyze that\n",
      "        contains characters not of the given `encoding`. By default, it is\n",
      "        'strict', meaning that a UnicodeDecodeError will be raised. Other\n",
      "        values are 'ignore' and 'replace'.\n",
      "\n",
      "    strip_accents : {'ascii', 'unicode', None} (default=None)\n",
      "        Remove accents and perform other character normalization\n",
      "        during the preprocessing step.\n",
      "        'ascii' is a fast method that only works on characters that have\n",
      "        an direct ASCII mapping.\n",
      "        'unicode' is a slightly slower method that works on any characters.\n",
      "        None (default) does nothing.\n",
      "\n",
      "        Both 'ascii' and 'unicode' use NFKD normalization from\n",
      "        :func:`unicodedata.normalize`.\n",
      "\n",
      "    lowercase : boolean (default=True)\n",
      "        Convert all characters to lowercase before tokenizing.\n",
      "\n",
      "    preprocessor : callable or None (default=None)\n",
      "        Override the preprocessing (string transformation) stage while\n",
      "        preserving the tokenizing and n-grams generation steps.\n",
      "\n",
      "    tokenizer : callable or None (default=None)\n",
      "        Override the string tokenization step while preserving the\n",
      "        preprocessing and n-grams generation steps.\n",
      "        Only applies if ``analyzer == 'word'``.\n",
      "\n",
      "    analyzer : string, {'word', 'char', 'char_wb'} or callable\n",
      "        Whether the feature should be made of word or character n-grams.\n",
      "        Option 'char_wb' creates character n-grams only from text inside\n",
      "        word boundaries; n-grams at the edges of words are padded with space.\n",
      "\n",
      "        If a callable is passed it is used to extract the sequence of features\n",
      "        out of the raw, unprocessed input.\n",
      "\n",
      "        .. versionchanged:: 0.21\n",
      "        Since v0.21, if ``input`` is ``filename`` or ``file``, the data is\n",
      "        first read from the file and then passed to the given callable\n",
      "        analyzer.\n",
      "\n",
      "    stop_words : string {'english'}, list, or None (default=None)\n",
      "        If a string, it is passed to _check_stop_list and the appropriate stop\n",
      "        list is returned. 'english' is currently the only supported string\n",
      "        value.\n",
      "        There are several known issues with 'english' and you should\n",
      "        consider an alternative (see :ref:`stop_words`).\n",
      "\n",
      "        If a list, that list is assumed to contain stop words, all of which\n",
      "        will be removed from the resulting tokens.\n",
      "        Only applies if ``analyzer == 'word'``.\n",
      "\n",
      "        If None, no stop words will be used. max_df can be set to a value\n",
      "        in the range [0.7, 1.0) to automatically detect and filter stop\n",
      "        words based on intra corpus document frequency of terms.\n",
      "\n",
      "    token_pattern : string\n",
      "        Regular expression denoting what constitutes a \"token\", only used\n",
      "        if ``analyzer == 'word'``. The default regexp selects tokens of 2\n",
      "        or more alphanumeric characters (punctuation is completely ignored\n",
      "        and always treated as a token separator).\n",
      "\n",
      "    ngram_range : tuple (min_n, max_n) (default=(1, 1))\n",
      "        The lower and upper boundary of the range of n-values for different\n",
      "        n-grams to be extracted. All values of n such that min_n <= n <= max_n\n",
      "        will be used.\n",
      "\n",
      "    max_df : float in range [0.0, 1.0] or int (default=1.0)\n",
      "        When building the vocabulary ignore terms that have a document\n",
      "        frequency strictly higher than the given threshold (corpus-specific\n",
      "        stop words).\n",
      "        If float, the parameter represents a proportion of documents, integer\n",
      "        absolute counts.\n",
      "        This parameter is ignored if vocabulary is not None.\n",
      "\n",
      "    min_df : float in range [0.0, 1.0] or int (default=1)\n",
      "        When building the vocabulary ignore terms that have a document\n",
      "        frequency strictly lower than the given threshold. This value is also\n",
      "        called cut-off in the literature.\n",
      "        If float, the parameter represents a proportion of documents, integer\n",
      "        absolute counts.\n",
      "        This parameter is ignored if vocabulary is not None.\n",
      "\n",
      "    max_features : int or None (default=None)\n",
      "        If not None, build a vocabulary that only consider the top\n",
      "        max_features ordered by term frequency across the corpus.\n",
      "\n",
      "        This parameter is ignored if vocabulary is not None.\n",
      "\n",
      "    vocabulary : Mapping or iterable, optional (default=None)\n",
      "        Either a Mapping (e.g., a dict) where keys are terms and values are\n",
      "        indices in the feature matrix, or an iterable over terms. If not\n",
      "        given, a vocabulary is determined from the input documents.\n",
      "\n",
      "    binary : boolean (default=False)\n",
      "        If True, all non-zero term counts are set to 1. This does not mean\n",
      "        outputs will have only 0/1 values, only that the tf term in tf-idf\n",
      "        is binary. (Set idf and normalization to False to get 0/1 outputs.)\n",
      "\n",
      "    dtype : type, optional (default=float64)\n",
      "        Type of the matrix returned by fit_transform() or transform().\n",
      "\n",
      "    norm : 'l1', 'l2' or None, optional (default='l2')\n",
      "        Each output row will have unit norm, either:\n",
      "        * 'l2': Sum of squares of vector elements is 1. The cosine\n",
      "        similarity between two vectors is their dot product when l2 norm has\n",
      "        been applied.\n",
      "        * 'l1': Sum of absolute values of vector elements is 1.\n",
      "        See :func:`preprocessing.normalize`\n",
      "\n",
      "    use_idf : boolean (default=True)\n",
      "        Enable inverse-document-frequency reweighting.\n",
      "\n",
      "    k1 : float, optional (default=2.0)\n",
      "        term k1 in the BM25 formula\n",
      "\n",
      "    b : float, optional (default=0.75)\n",
      "        term b in the BM25 formula\n",
      "\n",
      "    floor : float or None, optional (default=None)\n",
      "        floor value for idf terms\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    vocabulary_ : dict\n",
      "        A mapping of terms to feature indices.\n",
      "\n",
      "    idf_ : array, shape (n_features)\n",
      "        The inverse document frequency (IDF) vector; only defined\n",
      "        if ``use_idf`` is True.\n",
      "\n",
      "    stop_words_ : set\n",
      "        Terms that were ignored because they either:\n",
      "\n",
      "          - occurred in too many documents (`max_df`)\n",
      "          - occurred in too few documents (`min_df`)\n",
      "          - were cut off by feature selection (`max_features`).\n",
      "\n",
      "        This is only available if no vocabulary was given.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        input=\"content\",\n",
      "        encoding=\"utf-8\",\n",
      "        decode_error=\"strict\",\n",
      "        strip_accents=None,\n",
      "        lowercase=True,\n",
      "        preprocessor=None,\n",
      "        tokenizer=None,\n",
      "        analyzer=\"word\",\n",
      "        stop_words=None,\n",
      "        token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
      "        ngram_range=(1, 2),\n",
      "        max_df=1.0,\n",
      "        min_df=1,\n",
      "        max_features=None,\n",
      "        vocabulary=None,\n",
      "        binary=False,\n",
      "        dtype=np.float64,\n",
      "        norm=None,\n",
      "        use_idf=True,\n",
      "        k1=2.0,\n",
      "        b=0.75,\n",
      "        floor=None,\n",
      "    ):\n",
      "\n",
      "        super().__init__(\n",
      "            input=input,\n",
      "            encoding=encoding,\n",
      "            decode_error=decode_error,\n",
      "            strip_accents=strip_accents,\n",
      "            lowercase=lowercase,\n",
      "            preprocessor=preprocessor,\n",
      "            tokenizer=tokenizer,\n",
      "            analyzer=analyzer,\n",
      "            stop_words=stop_words,\n",
      "            token_pattern=token_pattern,\n",
      "            ngram_range=ngram_range,\n",
      "            max_df=max_df,\n",
      "            min_df=min_df,\n",
      "            max_features=max_features,\n",
      "            vocabulary=vocabulary,\n",
      "            binary=binary,\n",
      "            dtype=dtype,\n",
      "        )\n",
      "\n",
      "        self._bm25 = BM25Transformer(norm, use_idf, k1, b)\n",
      "\n",
      "    # Broadcast the BM25 parameters to the underlying transformer instance\n",
      "    # for easy grid search and repr\n",
      "    @property\n",
      "    def norm(self):\n",
      "        return self._bm25.norm\n",
      "\n",
      "    @norm.setter\n",
      "    def norm(self, value):\n",
      "        self._bm25.norm = value\n",
      "\n",
      "    @property\n",
      "    def use_idf(self):\n",
      "        return self._bm25.use_idf\n",
      "\n",
      "    @use_idf.setter\n",
      "    def use_idf(self, value):\n",
      "        self._bm25.use_idf = value\n",
      "\n",
      "    @property\n",
      "    def k1(self):\n",
      "        return self._bm25.k1\n",
      "\n",
      "    @k1.setter\n",
      "    def k1(self, value):\n",
      "        self._bm25.k1 = value\n",
      "\n",
      "    @property\n",
      "    def b(self):\n",
      "        return self._bm25.b\n",
      "\n",
      "    @b.setter\n",
      "    def b(self, value):\n",
      "        self._bm25.b = value\n",
      "\n",
      "    @property\n",
      "    def idf_(self):\n",
      "        return self._bm25.idf_\n",
      "\n",
      "    @idf_.setter\n",
      "    def idf_(self, value):\n",
      "        self._validate_vocabulary()\n",
      "        if hasattr(self, \"vocabulary_\"):\n",
      "            if len(self.vocabulary_) != len(value):\n",
      "                raise ValueError(\n",
      "                    \"idf length = %d must be equal \"\n",
      "                    \"to vocabulary size = %d\" % (len(value), len(self.vocabulary))\n",
      "                )\n",
      "        self._bm25.idf_ = value\n",
      "\n",
      "    def fit(self, raw_documents, y=None):\n",
      "        \"\"\"\n",
      "        Learn vocabulary and BM25 stats from training set.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        raw_documents : iterable\n",
      "            an iterable which yields either str, unicode or file objects\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self : BM25Vectorizer\n",
      "        \"\"\"\n",
      "        X = super().fit_transform(raw_documents)\n",
      "        self._bm25.fit(X)\n",
      "        return self\n",
      "\n",
      "    def transform(self, raw_corpus, is_query=False):\n",
      "        \"\"\"\n",
      "        Vectorizes the input, whether it is a query or the list of documents\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        raw_corpus : iterable\n",
      "            an iterable which yields either str, unicode or file objects\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        vectors : sparse matrix, [n_queries, n_documents]\n",
      "            scores from BM25 statics for each document with respect to each query\n",
      "        \"\"\"\n",
      "        X = super().transform(raw_corpus) if is_query else None\n",
      "\n",
      "        return self._bm25.transform(X, copy=False, is_query=is_query)\n",
      "\n",
      "    def fit_transform(self, raw_documents, y=None):\n",
      "        \"\"\"\n",
      "        Learn vocabulary, idf and BM25 features. Return term-document matrix.\n",
      "        This is equivalent to fit followed by transform, but more efficiently\n",
      "        implemented.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        raw_documents : iterable\n",
      "            an iterable which yields either str, unicode or file objects\n",
      "            \n",
      "        Returns\n",
      "        -------\n",
      "        X : sparse matrix, [n_samples, n_features]\n",
      "            BM25 document-term matrix.\n",
      "        \"\"\"\n",
      "        X = super().fit_transform(raw_documents)\n",
      "        self._bm25.fit(X)\n",
      "        return self._bm25.transform(X, copy=False)\n",
      "\n",
      "Output: {'vectorizers': [], 'vectorizers.BM25Vectorizer.__init__': ['cdqadocumentretriever.text_transformers.BM25Transformer', '<builtin>.super'], '<builtin>.super': [], 'cdqadocumentretriever.text_transformers.BM25Transformer': [], 'vectorizers.BM25Vectorizer.norm': [], 'vectorizers.BM25Vectorizer.use_idf': [], 'vectorizers.BM25Vectorizer.k1': [], 'vectorizers.BM25Vectorizer.b': [], 'vectorizers.BM25Vectorizer.idf_': ['<builtin>.ValueError', 'sklearn.feature_extraction.text.CountVectorizer._validate_vocabulary', '<builtin>.len', '<builtin>.hasattr'], 'sklearn.feature_extraction.text.CountVectorizer._validate_vocabulary': [], '<builtin>.hasattr': [], '<builtin>.len': [], '<builtin>.ValueError': [], 'vectorizers.BM25Vectorizer.fit': ['<builtin>.super'], 'vectorizers.BM25Vectorizer.transform': ['<builtin>.super'], 'vectorizers.BM25Vectorizer.fit_transform': ['<builtin>.super']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\phamdinhha_end-to-end-qna\\api\\cdqadocumentretriever\\vectorizers.py\n",
      "[('vectorizers BM25Vectorizer __init__', 'cdqadocumentretriever text_transformers BM25Transformer'), ('vectorizers BM25Vectorizer idf_', 'sklearn feature_extraction text CountVectorizer _validate_vocabulary')]\n",
      "0\n",
      "found files: []\n",
      "from flask import Flask, request, jsonify\n",
      "from flask_cors import CORS\n",
      "import os\n",
      "from simpletransformers.question_answering import QuestionAnsweringModel\n",
      "from googlesearch import search\n",
      "from documentretriever import DocumentRetriever\n",
      "import pandas as pd\n",
      "from qamodelloader import QAModelLoader\n",
      "from customdocumentretriever.customgooglesearchengine import CustomGoogleSearchEngine\n",
      "\n",
      "# configuration\n",
      "DEBUG = True\n",
      "\n",
      "# instantiate the app\n",
      "app = Flask(__name__)\n",
      "app.config.from_object(__name__)\n",
      "\n",
      "# enable CORS\n",
      "CORS(app, resources={r'/*': {'origins': '*'}})\n",
      "\n",
      "\n",
      "model = QAModelLoader()\n",
      "data_path = \"./data/customdata.csv\"\n",
      "\n",
      "@app.route('/fromgoolesearch', methods=['GET'])\n",
      "def fromgooglesearch():\n",
      "\n",
      "    query = request.args.get(\"query\")\n",
      "    search_engine = CustomGoogleSearchEngine(query)\n",
      "    doc_trunk = search_engine.buildDocumentTrunk()\n",
      "    documentRetriever = DocumentRetriever(data_path = doc_trunk)\n",
      "    squad_examples = documentRetriever.get_most_relevant_paragraph(query)\n",
      "    context = squad_examples['paragraphs'][0]['context']\n",
      "    print(context)\n",
      "    answer = model.answer(query, context)\n",
      "    #print(paragraphs[0])\n",
      "    print(answer)\n",
      "    return jsonify({\n",
      "        'query': query, \n",
      "        'answer': answer,\n",
      "        'paragraph': context\n",
      "    })\n",
      "\n",
      "\n",
      "@app.route('/fromcustomdata', methods=['GET'])\n",
      "def fromcollecteddata():\n",
      "\n",
      "    query = request.args.get(\"query\")\n",
      "    documentRetriever = DocumentRetriever(data_path = data_path)\n",
      "    squad_examples = documentRetriever.get_most_relevant_paragraph(query)\n",
      "    context = squad_examples['paragraphs'][0]['context']\n",
      "    answer = model.answer(query, context)\n",
      "    print(answer)\n",
      "\n",
      "    return jsonify({\n",
      "        'query': query, \n",
      "        'answer': answer,\n",
      "        'paragraph': context\n",
      "    })\n",
      "\n",
      "\n",
      "@app.route('/bertonly', methods=['GET'])\n",
      "def bertonly():\n",
      "\n",
      "    query = request.args.get(\"query\")\n",
      "    paragraph = request.args.get(\"paragraph\")\n",
      "    answer = model.answer(query, paragraph)\n",
      "    print(answer)\n",
      "\n",
      "    return jsonify({\n",
      "        'query': query, \n",
      "        'answer': answer,\n",
      "        'paragraph': paragraph\n",
      "    })\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    app.run()\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\phamdinhha_end-to-end-qna\\api\\api.py\n",
      "[]\n",
      "found files: []\n",
      "import nltk\n",
      "nltk.download('punkt')\n",
      "from nltk import sent_tokenize\n",
      "import re\n",
      "from bs4 import BeautifulSoup\n",
      "from bs4 import Comment\n",
      "from urllib.request import urlopen, Request\n",
      "import requests\n",
      "from googlesearch import search\n",
      "import csv\n",
      "import datetime\n",
      "\n",
      "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36',\n",
      "           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
      "           'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
      "           'Accept-Encoding': 'none',\n",
      "           'Accept-Language': 'en-US,en;q=0.8',\n",
      "           'Connection': 'keep-alive'}\n",
      "\n",
      "\n",
      "class CustomGoogleSearchEngine():\n",
      "    def __init__(self, question, path_to_document_trunk = \"./data/collecteddatafromgoogle.csv\"):\n",
      "        self.document_trunk = path_to_document_trunk\n",
      "        self.question = question\n",
      "\n",
      "    def buildDocumentTrunk(self):\n",
      "        paragraphs = []\n",
      "        links = self.customsearch(numberOfAnswer = 10)\n",
      "        with open(self.document_trunk, 'w', encoding=\"utf8\", newline='') as data_source:\n",
      "            writer = csv.writer(data_source)\n",
      "            writer.writerow([\"date\", \"title\", \"link\", \"paragraphs\"])\n",
      "            for link in links:\n",
      "                title, paragraphs = self.paragraphGenerator(link)\n",
      "                writer.writerow([datetime.datetime.now(), title, link, paragraphs])\n",
      "        print(\"Document trunk was built\")\n",
      "        return self.document_trunk\n",
      "\n",
      "\n",
      "    def customsearch(self, numberOfAnswer = 10):\n",
      "        links = []\n",
      "        for i in search(self.question, num=numberOfAnswer, stop=numberOfAnswer, pause=1):\n",
      "            links.append(i)\n",
      "        return links\n",
      "\n",
      "\n",
      "    def chunks(self, l, n):\n",
      "        for i in range(0, len(l), n):\n",
      "            yield l[i:i + n]\n",
      "\n",
      "    def paragraphGenerator(self, url):\n",
      "        req = Request(url, headers=headers) \n",
      "        html = urlopen(req).read()\n",
      "        soup = BeautifulSoup(html, 'html.parser')\n",
      "        title = soup.find('title')\n",
      "        for invisible_elem in soup.find_all(['script', 'style', 'head', 'title', 'meta', '[document]']):\n",
      "            invisible_elem.extract()\n",
      "\n",
      "        paragraphs = [p.get_text() for p in soup.find_all(\"p\")]\n",
      "        for para in soup.find_all('p'):\n",
      "            para.extract()\n",
      "\n",
      "        for href in soup.find_all(['a','strong']): \n",
      "            href.unwrap()\n",
      "\n",
      "        text = soup.get_text(separator='\\n\\n')\n",
      "        text = re.sub('\\n +\\n','\\n\\n',text)\n",
      "\n",
      "        paragraphs += text.split('\\n\\n')\n",
      "        paragraphs = [re.sub(' +',' ',p.strip()) for p in paragraphs]\n",
      "        paragraphs = [p for p in paragraphs if len(p.split()) > 10]\n",
      "        for i in range(0,len(paragraphs)):\n",
      "            sents = []\n",
      "            text_chunks = list(self.chunks(paragraphs[i],1000))\n",
      "            for chunk in text_chunks:\n",
      "                sents += sent_tokenize(chunk)\n",
      "            sents = [s for s in sents if len(s) > 2]\n",
      "            sents = ' '.join(sents)\n",
      "            regex_list = re.findall(r\"\\[(.*?)\\]\", sents)\n",
      "            for regex in regex_list:\n",
      "                sents = sents.replace(\"[\"+regex+\"]\", \" \")\n",
      "            sents = sents.replace(\"  \", \"\")\n",
      "            paragraphs[i] = sents\n",
      "\n",
      "        if(len(paragraphs) > 10):\n",
      "            return title, paragraphs[:10]\n",
      "        return title, paragraphs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Output: {'customgooglesearchengine': ['nltk.download'], 'nltk.download': [], 'customgooglesearchengine.CustomGoogleSearchEngine.__init__': [], 'customgooglesearchengine.CustomGoogleSearchEngine.buildDocumentTrunk': ['csv.writer', 'customgooglesearchengine.CustomGoogleSearchEngine.customsearch', '<builtin>.print', '<builtin>.open', 'customgooglesearchengine.CustomGoogleSearchEngine.paragraphGenerator'], 'customgooglesearchengine.CustomGoogleSearchEngine.customsearch': ['googlesearch.search'], '<builtin>.open': [], 'csv.writer': [], 'customgooglesearchengine.CustomGoogleSearchEngine.paragraphGenerator': ['nltk.sent_tokenize', 'urllib.request.Request', '<builtin>.list', '<builtin>.range', 'customgooglesearchengine.CustomGoogleSearchEngine.chunks', 'urllib.request.urlopen', 're.findall', 'bs4.BeautifulSoup', 're.sub', '<builtin>.len'], '<builtin>.print': [], 'googlesearch.search': [], 'customgooglesearchengine.CustomGoogleSearchEngine.chunks': ['<builtin>.range', '<builtin>.len'], '<builtin>.len': [], '<builtin>.range': [], 'urllib.request.Request': [], 'urllib.request.urlopen': [], 'bs4.BeautifulSoup': [], 're.sub': [], '<builtin>.list': [], 'nltk.sent_tokenize': [], 're.findall': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\phamdinhha_end-to-end-qna\\api\\customdocumentretriever\\customgooglesearchengine.py\n",
      "[('customgooglesearchengine', 'nltk download'), ('customgooglesearchengine CustomGoogleSearchEngine buildDocumentTrunk', 'csv writer'), ('customgooglesearchengine CustomGoogleSearchEngine buildDocumentTrunk', 'customgooglesearchengine CustomGoogleSearchEngine customsearch'), ('customgooglesearchengine CustomGoogleSearchEngine buildDocumentTrunk', 'customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator'), ('customgooglesearchengine CustomGoogleSearchEngine customsearch', 'googlesearch search'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 'nltk sent_tokenize'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 'urllib request Request'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 'customgooglesearchengine CustomGoogleSearchEngine chunks'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 'urllib request urlopen'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 're findall'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 'bs4 BeautifulSoup'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 're sub')]\n",
      "0\n",
      "found files: []\n",
      "import nltk\n",
      "nltk.download('punkt')\n",
      "from nltk import sent_tokenize\n",
      "import re\n",
      "from bs4 import BeautifulSoup\n",
      "from urllib.request import urlopen, Request\n",
      "import requests\n",
      "from googlesearch import search\n",
      "\n",
      "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36',\n",
      "           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
      "           'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
      "           'Accept-Encoding': 'none',\n",
      "           'Accept-Language': 'en-US,en;q=0.8',\n",
      "           'Connection': 'keep-alive'}\n",
      "\n",
      "class ParagraphGenerator:\n",
      "    def __init__(self, question):\n",
      "        self.paragraphs = self.paragraphsGenerator(question)\n",
      "\n",
      "    def ggSearch(self, question):\n",
      "        links = []\n",
      "        prevLink = \"\"\n",
      "        for j in search(question, lang='en', country='en', num=1, stop=8, pause=2):\n",
      "            curLink = re.findall(r\"\\//(.*?)\\/\", j)[0]\n",
      "            if (curLink != prevLink):\n",
      "                links.append(j)\n",
      "                prevLink = curLink\n",
      "        return links\n",
      "\n",
      "    def chunks(self, l, n):\n",
      "        for i in range(0, len(l), n):\n",
      "            yield l[i:i + n]\n",
      "\n",
      "    def paragraphSearch(self, url):\n",
      "        req = Request(url, headers=headers) \n",
      "        html = urlopen(req).read()\n",
      "        soup = BeautifulSoup(html, 'lxml')\n",
      "        for invisible_elem in soup.find_all(['script', 'style']):\n",
      "            invisible_elem.extract()\n",
      "\n",
      "        paragraphs = [p.get_text() for p in soup.find_all(\"p\")]\n",
      "        for para in soup.find_all('p'):\n",
      "            para.extract()\n",
      "\n",
      "        for href in soup.find_all(['a','strong']): \n",
      "            href.unwrap()\n",
      "        text = soup.get_text(separator='\\n\\n')\n",
      "        text = re.sub('\\n +\\n','\\n\\n',text)\n",
      "\n",
      "        paragraphs += text.split('\\n\\n')\n",
      "        paragraphs = [re.sub(' +',' ',p.strip()) for p in paragraphs[:5]]\n",
      "        paragraphs = [p for p in paragraphs if len(p.split()) > 50]\n",
      "\n",
      "        # for i in range(0,len(paragraphs)):\n",
      "        #     sents = []\n",
      "        #     text_chunks = list(self.chunks(paragraphs[i],10000))\n",
      "        #     for chunk in text_chunks:\n",
      "        #         sents += sent_tokenize(chunk)\n",
      "        #     sents = [s for s in sents if len(s) > 2]\n",
      "        #     sents = ' '.join(sents)\n",
      "        #     paragraphs[i] = sents\n",
      "\n",
      "        paragraph = '\\n\\n'.join(paragraphs)\n",
      "        regex_list = re.findall(r\"\\[(.*?)\\]\", paragraph)\n",
      "        for regex in regex_list:\n",
      "            paragraph = paragraph.replace(\"[\"+regex+\"]\", \" \")\n",
      "        regex_list = re.findall(r\"\\((.*?)\\)\", paragraph)\n",
      "        for regex in regex_list:\n",
      "            paragraph = paragraph.replace(\"(\"+regex+\")\", \" \")\n",
      "        paragraph = paragraph.replace(\"  \", \"\")\n",
      "\n",
      "        return paragraph\n",
      "\n",
      "    def paragraphsGenerator(self, question):\n",
      "        paras = []\n",
      "        links = self.ggSearch(question)\n",
      "        for link in links:\n",
      "            para = self.paragraphSearch(link)\n",
      "            if(para != \"\"):\n",
      "                paras.append(para)\n",
      "        return paras[0]\n",
      "Output: {'ParagraphsGenerator': ['nltk.download'], 'nltk.download': [], 'ParagraphsGenerator.ParagraphGenerator.__init__': ['ParagraphsGenerator.ParagraphGenerator.paragraphsGenerator'], 'ParagraphsGenerator.ParagraphGenerator.paragraphsGenerator': ['ParagraphsGenerator.ParagraphGenerator.paragraphSearch', 'ParagraphsGenerator.ParagraphGenerator.ggSearch'], 'ParagraphsGenerator.ParagraphGenerator.ggSearch': ['re.findall', 'googlesearch.search'], 'googlesearch.search': [], 're.findall': [], 'ParagraphsGenerator.ParagraphGenerator.chunks': ['<builtin>.len', '<builtin>.range'], '<builtin>.len': [], '<builtin>.range': [], 'ParagraphsGenerator.ParagraphGenerator.paragraphSearch': ['re.sub', '<builtin>.len', 're.findall', 'urllib.request.Request', 'urllib.request.urlopen', 'bs4.BeautifulSoup'], 'urllib.request.Request': [], 'urllib.request.urlopen': [], 'bs4.BeautifulSoup': [], 're.sub': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\phamdinhha_end-to-end-qna\\api\\customdocumentretriever\\ParagraphsGenerator.py\n",
      "[('ParagraphsGenerator', 'nltk download'), ('ParagraphsGenerator ParagraphGenerator __init__', 'ParagraphsGenerator ParagraphGenerator paragraphsGenerator'), ('ParagraphsGenerator ParagraphGenerator paragraphsGenerator', 'ParagraphsGenerator ParagraphGenerator paragraphSearch'), ('ParagraphsGenerator ParagraphGenerator paragraphsGenerator', 'ParagraphsGenerator ParagraphGenerator ggSearch'), ('ParagraphsGenerator ParagraphGenerator ggSearch', 're findall'), ('ParagraphsGenerator ParagraphGenerator ggSearch', 'googlesearch search'), ('ParagraphsGenerator ParagraphGenerator paragraphSearch', 're sub'), ('ParagraphsGenerator ParagraphGenerator paragraphSearch', 're findall'), ('ParagraphsGenerator ParagraphGenerator paragraphSearch', 'urllib request Request'), ('ParagraphsGenerator ParagraphGenerator paragraphSearch', 'urllib request urlopen'), ('ParagraphsGenerator ParagraphGenerator paragraphSearch', 'bs4 BeautifulSoup')]\n",
      "0\n",
      "found files: []\n",
      "# ScriptName : DocumentRetrievalModel.py\n",
      "# Description : Script preprocesses article and paragraph to computer TFIDF.\n",
      "#               Additionally, helps in answer processing \n",
      "# Arguments : \n",
      "#       Input :\n",
      "#           paragraphs(list)        : List of paragraphs\n",
      "#           useStemmer(boolean)     : Indicate to use stemmer for word tokens\n",
      "#           removeStopWord(boolean) : Indicate to remove stop words from \n",
      "#                                     paragraph in order to keep relevant words\n",
      "#       Output :\n",
      "#           Instance of DocumentRetrievalModel with following structure\n",
      "#               query(function) : Take instance of processedQuestion and return\n",
      "#                                 answer based on IR and Answer Processing\n",
      "#                                 techniques\n",
      "\n",
      "# Importing Library\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.tokenize import sent_tokenize, word_tokenize\n",
      "from nltk.stem.porter import PorterStemmer\n",
      "from nltk.tree import Tree\n",
      "from nltk import pos_tag,ne_chunk\n",
      "import json\n",
      "import math\n",
      "import re\n",
      "\n",
      "class DocumentRetrievalModel:\n",
      "    def __init__(self,paragraphs,removeStopWord = False,useStemmer = False):\n",
      "        self.idf = {}               # dict to store IDF for words in paragraph\n",
      "        self.paragraphInfo = {}     # structure to store paragraphVector\n",
      "        self.paragraphs = paragraphs\n",
      "        self.totalParas = len(paragraphs)\n",
      "        self.stopwords = stopwords.words('english')\n",
      "        self.removeStopWord = removeStopWord\n",
      "        self.useStemmer = useStemmer\n",
      "        self.vData = None\n",
      "        self.stem = lambda k:k.lower()\n",
      "        if(useStemmer):\n",
      "            ps = PorterStemmer()\n",
      "            self.stem = ps.stem\n",
      "            \n",
      "        # Initialize\n",
      "        self.computeTFIDF()\n",
      "        \n",
      "    # Return term frequency for Paragraph\n",
      "    # Input:\n",
      "    #       paragraph(str): Paragraph as a whole in string format\n",
      "    # Output:\n",
      "    #       wordFrequence(dict) : Dictionary of word and term frequency\n",
      "    def getTermFrequencyCount(self,paragraph):\n",
      "        sentences = sent_tokenize(paragraph)\n",
      "        wordFrequency = {}\n",
      "        for sent in sentences:\n",
      "            for word in word_tokenize(sent):\n",
      "                if self.removeStopWord == True:\n",
      "                    if word.lower() in self.stopwords:\n",
      "                        #Ignore stopwords\n",
      "                        continue\n",
      "                    if not re.match(r\"[a-zA-Z0-9\\-\\_\\\\/\\.\\']+\",word):\n",
      "                        continue\n",
      "                #Use of Stemmer\n",
      "                if self.useStemmer:\n",
      "                    word = self.stem(word)\n",
      "                    \n",
      "                if word in wordFrequency.keys():\n",
      "                    wordFrequency[word] += 1\n",
      "                else:\n",
      "                    wordFrequency[word] = 1\n",
      "        return wordFrequency\n",
      "    \n",
      "    # Computes term-frequency inverse document frequency for every token of each\n",
      "    # paragraph\n",
      "    # Output:\n",
      "    #       paragraphInfo(dict): Dictionary for every paragraph with following \n",
      "    #                            keys\n",
      "    #                               vector : dictionary of TFIDF for every word\n",
      "    def computeTFIDF(self):\n",
      "        # Compute Term Frequency\n",
      "        self.paragraphInfo = {}\n",
      "        for index in range(0,len(self.paragraphs)):\n",
      "            wordFrequency = self.getTermFrequencyCount(self.paragraphs[index])\n",
      "            self.paragraphInfo[index] = {}\n",
      "            self.paragraphInfo[index]['wF'] = wordFrequency\n",
      "        \n",
      "        wordParagraphFrequency = {}\n",
      "        for index in range(0,len(self.paragraphInfo)):\n",
      "            for word in self.paragraphInfo[index]['wF'].keys():\n",
      "                if word in wordParagraphFrequency.keys():\n",
      "                    wordParagraphFrequency[word] += 1\n",
      "                else:\n",
      "                    wordParagraphFrequency[word] = 1\n",
      "        \n",
      "        self.idf = {}\n",
      "        for word in wordParagraphFrequency:\n",
      "            # Adding Laplace smoothing by adding 1 to total number of documents\n",
      "            self.idf[word] = math.log((self.totalParas+1)/wordParagraphFrequency[word])\n",
      "        \n",
      "        #Compute Paragraph Vector\n",
      "        for index in range(0,len(self.paragraphInfo)):\n",
      "            self.paragraphInfo[index]['vector'] = {}\n",
      "            for word in self.paragraphInfo[index]['wF'].keys():\n",
      "                self.paragraphInfo[index]['vector'][word] = self.paragraphInfo[index]['wF'][word] * self.idf[word]\n",
      "    \n",
      "\n",
      "    # To find answer to the question by first finding relevant paragraph, then\n",
      "    # by finding relevant sentence and then by procssing sentence to get answer\n",
      "    # based on expected answer type\n",
      "    # Input:\n",
      "    #           pQ(ProcessedQuestion) : Instance of ProcessedQuestion\n",
      "    # Output:\n",
      "    #           answer(str) : Response of QA System\n",
      "    def query(self,pQ):\n",
      "        \n",
      "        # Get relevant Paragraph\n",
      "        relevantParagraph = self.getSimilarParagraph(pQ.qVector)\n",
      "\n",
      "        # Get All sentences\n",
      "        targetParagraph = \"\"\n",
      "        sentences = []\n",
      "        for tup in relevantParagraph:\n",
      "            if tup != None:\n",
      "                targetParagraph = self.paragraphs[tup[0]]\n",
      "                sentences.extend(sent_tokenize(targetParagraph))\n",
      "        # # Get Relevant Sentences\n",
      "        # if len(sentences) == 0:\n",
      "        #     return \"Oops! Unable to find answer\"\n",
      "\n",
      "        # # Get most relevant sentence using unigram similarity\n",
      "        # relevantSentences = self.getMostRelevantSentences(sentences,pQ,1)\n",
      "\n",
      "        return targetParagraph\n",
      "        \n",
      "    # Get top 3 relevant paragraph based on cosine similarity between question \n",
      "    # vector and paragraph vector\n",
      "    # Input :\n",
      "    #       queryVector(dict) : Dictionary of words in question with their \n",
      "    #                           frequency\n",
      "    # Output:\n",
      "    #       pRanking(list) : List of tuple with top 3 paragraph with its\n",
      "    #                        similarity coefficient\n",
      "    def getSimilarParagraph(self,queryVector):    \n",
      "        queryVectorDistance = 0\n",
      "        for word in queryVector.keys():\n",
      "            if word in self.idf.keys():\n",
      "                queryVectorDistance += math.pow(queryVector[word]*self.idf[word],2)\n",
      "        queryVectorDistance = math.pow(queryVectorDistance,0.5)\n",
      "        if queryVectorDistance == 0:\n",
      "            return [None]\n",
      "        pRanking = []\n",
      "        for index in range(0,len(self.paragraphInfo)):\n",
      "            sim = self.computeSimilarity(self.paragraphInfo[index], queryVector, queryVectorDistance)\n",
      "            pRanking.append((index,sim))\n",
      "        \n",
      "        return sorted(pRanking,key=lambda tup: (tup[1],tup[0]), reverse=True)[:3]\n",
      "    \n",
      "    # Compute cosine similarity betweent queryVector and paragraphVector\n",
      "    # Input:\n",
      "    #       pInfo(dict)         : Dictionary containing wordFrequency and \n",
      "    #                             paragraph Vector\n",
      "    #       queryVector(dict)   : Query vector for question\n",
      "    #       queryDistance(float): Distance of queryVector from origin\n",
      "    # Output:\n",
      "    #       sim(float)          : Cosine similarity coefficient\n",
      "    def computeSimilarity(self, pInfo, queryVector, queryDistance):\n",
      "        # Computing pVectorDistance\n",
      "        pVectorDistance = 0\n",
      "        for word in pInfo['wF'].keys():\n",
      "            pVectorDistance += math.pow(pInfo['wF'][word]*self.idf[word],2)\n",
      "        pVectorDistance = math.pow(pVectorDistance,0.5)\n",
      "        if(pVectorDistance == 0):\n",
      "            return 0\n",
      "\n",
      "        # Computing dot product\n",
      "        dotProduct = 0\n",
      "        for word in queryVector.keys():\n",
      "            if word in pInfo['wF']:\n",
      "                q = queryVector[word]\n",
      "                w = pInfo['wF'][word]\n",
      "                idf = self.idf[word]\n",
      "                dotProduct += q*w*idf*idf\n",
      "        \n",
      "        sim = dotProduct / (pVectorDistance * queryDistance)\n",
      "        return sim\n",
      "    \n",
      "    # Get most relevant sentences using unigram similarity between question\n",
      "    # sentence and sentence in paragraph containing potential answer\n",
      "    # Input:\n",
      "    #       sentences(list)      : List of sentences in order of occurance as in\n",
      "    #                              paragraph\n",
      "    #       pQ(ProcessedQuestion): Instance of processedQuestion\n",
      "    #       nGram(int)           : Value of nGram (default 3)\n",
      "    # Output:\n",
      "    #       relevantSentences(list) : List of tuple with sentence and their\n",
      "    #                                 similarity coefficient\n",
      "    def getMostRelevantSentences(self, sentences, pQ, nGram=3):\n",
      "        relevantSentences = []\n",
      "        for sent in sentences:\n",
      "            sim = 0\n",
      "            if(len(word_tokenize(pQ.question))>nGram+1):\n",
      "                sim = self.sim_ngram_sentence(pQ.question,sent,nGram)\n",
      "            else:\n",
      "                sim = self.sim_sentence(pQ.qVector, sent)\n",
      "            relevantSentences.append((sent,sim))\n",
      "        \n",
      "        return sorted(relevantSentences,key=lambda tup:(tup[1],tup[0]),reverse=True)\n",
      "    \n",
      "    # Compute ngram similarity between a sentence and question\n",
      "    # Input:\n",
      "    #       question(str)   : Question string\n",
      "    #       sentence(str)   : Sentence string\n",
      "    #       nGram(int)      : Value of n in nGram\n",
      "    # Output:\n",
      "    #       sim(float)      : Ngram Similarity Coefficient\n",
      "    def sim_ngram_sentence(self, question, sentence,nGram):\n",
      "        #considering stop words as well\n",
      "        ps = PorterStemmer()\n",
      "        getToken = lambda question:[ ps.stem(w.lower()) for w in word_tokenize(question) ]\n",
      "        getNGram = lambda tokens,n:[ \" \".join([tokens[index+i] for i in range(0,n)]) for index in range(0,len(tokens)-n+1)]\n",
      "        qToken = getToken(question)\n",
      "        sToken = getToken(sentence)\n",
      "\n",
      "        if(len(qToken) > nGram):\n",
      "            q3gram = set(getNGram(qToken,nGram))\n",
      "            s3gram = set(getNGram(sToken,nGram))\n",
      "            if(len(s3gram) < nGram):\n",
      "                return 0\n",
      "            sim = len(q3gram.intersection(s3gram)) / len(q3gram.union(s3gram))\n",
      "            return sim\n",
      "        else:\n",
      "            return 0\n",
      "    \n",
      "    # Compute similarity between sentence and queryVector based on number of \n",
      "    # common words in both sentence. It doesn't consider occurance of words\n",
      "    # Input:\n",
      "    #       queryVector(dict)   : Dictionary of words in question\n",
      "    #       sentence(str)       : Sentence string\n",
      "    # Ouput:\n",
      "    #       sim(float)          : Similarity Coefficient    \n",
      "    def sim_sentence(self, queryVector, sentence):\n",
      "        sentToken = word_tokenize(sentence)\n",
      "        ps = PorterStemmer()\n",
      "        for index in range(0,len(sentToken)):\n",
      "            sentToken[index] = ps.stem(sentToken[index])\n",
      "        sim = 0\n",
      "        for word in queryVector.keys():\n",
      "            w = ps.stem(word)\n",
      "            if w in sentToken:\n",
      "                sim += 1\n",
      "        return sim/(len(sentToken)*len(queryVector.keys()))\n",
      "    \n",
      "    # Get Named Entity from the sentence in form of PERSON, GPE, & ORGANIZATION\n",
      "    # Input:\n",
      "    #       answers(list)       : List of potential sentence containing answer\n",
      "    # Output:\n",
      "    #       chunks(list)        : List of tuple with entity and name in ranked \n",
      "    #                             order\n",
      "    def getNamedEntity(self,answers):\n",
      "        chunks = []\n",
      "        for answer in answers:\n",
      "            answerToken = word_tokenize(answer)\n",
      "            nc = ne_chunk(pos_tag(answerToken))\n",
      "            entity = {\"label\":None,\"chunk\":[]}\n",
      "            for c_node in nc:\n",
      "                if(type(c_node) == Tree):\n",
      "                    if(entity[\"label\"] == None):\n",
      "                        entity[\"label\"] = c_node.label()\n",
      "                    entity[\"chunk\"].extend([ token for (token,pos) in c_node.leaves()])\n",
      "                else:\n",
      "                    (token,pos) = c_node\n",
      "                    if pos == \"NNP\":\n",
      "                        entity[\"chunk\"].append(token)\n",
      "                    else:\n",
      "                        if not len(entity[\"chunk\"]) == 0:\n",
      "                            chunks.append((entity[\"label\"],\" \".join(entity[\"chunk\"])))\n",
      "                            entity = {\"label\":None,\"chunk\":[]}\n",
      "            if not len(entity[\"chunk\"]) == 0:\n",
      "                chunks.append((entity[\"label\"],\" \".join(entity[\"chunk\"])))\n",
      "        return chunks\n",
      "    \n",
      "    # To get continuous chunk of similar POS tags.\n",
      "    # E.g.  If two NN tags are consequetive, this method will merge and return\n",
      "    #       single NN with combined value.\n",
      "    #       It is helpful in detecting name of single person like John Cena, \n",
      "    #       Steve Jobs\n",
      "    # Input:\n",
      "    #       answers(list) : list of potential sentence string\n",
      "    # Output:\n",
      "    #       chunks(list)  : list of tuple with entity and name in ranked order\n",
      "    def getContinuousChunk(self,answers):\n",
      "        chunks = []\n",
      "        for answer in answers:\n",
      "            answerToken = word_tokenize(answer)\n",
      "            if(len(answerToken)==0):\n",
      "                continue\n",
      "            nc = pos_tag(answerToken)\n",
      "            \n",
      "            prevPos = nc[0][1]\n",
      "            entity = {\"pos\":prevPos,\"chunk\":[]}\n",
      "            for c_node in nc:\n",
      "                (token,pos) = c_node\n",
      "                if pos == prevPos:\n",
      "                    prevPos = pos       \n",
      "                    entity[\"chunk\"].append(token)\n",
      "                elif prevPos in [\"DT\",\"JJ\"]:\n",
      "                    prevPos = pos\n",
      "                    entity[\"pos\"] = pos\n",
      "                    entity[\"chunk\"].append(token)\n",
      "                else:\n",
      "                    if not len(entity[\"chunk\"]) == 0:\n",
      "                        chunks.append((entity[\"pos\"],\" \".join(entity[\"chunk\"])))\n",
      "                        entity = {\"pos\":pos,\"chunk\":[token]}\n",
      "                        prevPos = pos\n",
      "            if not len(entity[\"chunk\"]) == 0:\n",
      "                chunks.append((entity[\"pos\"],\" \".join(entity[\"chunk\"])))\n",
      "        return chunks\n",
      "    \n",
      "    def getqRev(self, pq):\n",
      "        if self.vData == None:\n",
      "            # For testing purpose\n",
      "            self.vData = json.loads(open(\"validatedata.py\",\"r\").readline())\n",
      "        revMatrix = []\n",
      "        for t in self.vData:\n",
      "            sent = t[\"q\"]\n",
      "            revMatrix.append((t[\"a\"],self.sim_sentence(pq.qVector,sent)))\n",
      "        return sorted(revMatrix,key=lambda tup:(tup[1],tup[0]),reverse=True)[0][0]\n",
      "        \n",
      "Output: {'DocumentRetrievalModel': [], 'DocumentRetrievalModel.DocumentRetrievalModel.__init__': ['nltk.stem.porter.PorterStemmer', 'DocumentRetrievalModel.DocumentRetrievalModel.computeTFIDF', '<builtin>.len'], '<builtin>.len': [], 'DocumentRetrievalModel.DocumentRetrievalModel.__init__.<lambda1>': [], 'nltk.stem.porter.PorterStemmer': [], 'DocumentRetrievalModel.DocumentRetrievalModel.computeTFIDF': ['DocumentRetrievalModel.DocumentRetrievalModel.getTermFrequencyCount', 'math.log', '<builtin>.range', '<builtin>.len'], 'DocumentRetrievalModel.DocumentRetrievalModel.getTermFrequencyCount': ['nltk.tokenize.sent_tokenize', 'nltk.tokenize.word_tokenize', 're.match', 'DocumentRetrievalModel.DocumentRetrievalModel.__init__.<lambda1>'], 'nltk.tokenize.sent_tokenize': [], 'nltk.tokenize.word_tokenize': [], 're.match': [], '<builtin>.range': [], 'math.log': [], 'DocumentRetrievalModel.DocumentRetrievalModel.query': ['nltk.tokenize.sent_tokenize', 'DocumentRetrievalModel.DocumentRetrievalModel.getSimilarParagraph'], 'DocumentRetrievalModel.DocumentRetrievalModel.getSimilarParagraph': ['<builtin>.sorted', '<builtin>.range', 'math.pow', 'DocumentRetrievalModel.DocumentRetrievalModel.computeSimilarity', '<builtin>.len'], 'math.pow': [], 'DocumentRetrievalModel.DocumentRetrievalModel.computeSimilarity': ['math.pow'], 'DocumentRetrievalModel.DocumentRetrievalModel.getSimilarParagraph.<lambda1>': [], '<builtin>.sorted': [], 'DocumentRetrievalModel.DocumentRetrievalModel.getMostRelevantSentences': ['<builtin>.sorted', 'nltk.tokenize.word_tokenize', 'DocumentRetrievalModel.DocumentRetrievalModel.sim_ngram_sentence', 'DocumentRetrievalModel.DocumentRetrievalModel.sim_sentence', '<builtin>.len'], 'DocumentRetrievalModel.DocumentRetrievalModel.sim_ngram_sentence': ['DocumentRetrievalModel.DocumentRetrievalModel.sim_ngram_sentence.<lambda2>', 'nltk.stem.porter.PorterStemmer', 'DocumentRetrievalModel.DocumentRetrievalModel.sim_ngram_sentence.<lambda1>', '<builtin>.set', '<builtin>.len'], 'DocumentRetrievalModel.DocumentRetrievalModel.sim_sentence': ['nltk.tokenize.word_tokenize', 'nltk.stem.porter.PorterStemmer', '<builtin>.range', '<builtin>.len'], 'DocumentRetrievalModel.DocumentRetrievalModel.getMostRelevantSentences.<lambda1>': [], 'DocumentRetrievalModel.DocumentRetrievalModel.sim_ngram_sentence.<lambda1>': ['nltk.tokenize.word_tokenize'], 'DocumentRetrievalModel.DocumentRetrievalModel.sim_ngram_sentence.<lambda2>': ['<builtin>.range', '<builtin>.len'], '<builtin>.set': [], 'DocumentRetrievalModel.DocumentRetrievalModel.getNamedEntity': ['<builtin>.type', 'nltk.pos_tag', 'nltk.tokenize.word_tokenize', 'nltk.ne_chunk', '<builtin>.len'], 'nltk.pos_tag': [], 'nltk.ne_chunk': [], '<builtin>.type': [], 'DocumentRetrievalModel.DocumentRetrievalModel.getContinuousChunk': ['nltk.tokenize.word_tokenize', '<builtin>.len', 'nltk.pos_tag'], 'DocumentRetrievalModel.DocumentRetrievalModel.getqRev': ['<builtin>.sorted', '<builtin>.open', 'DocumentRetrievalModel.DocumentRetrievalModel.sim_sentence', 'json.loads'], '<builtin>.open': [], 'json.loads': [], 'DocumentRetrievalModel.DocumentRetrievalModel.getqRev.<lambda1>': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\phamdinhha_end-to-end-qna\\api\\customdocumentretriever\\DocumentRetrievalModel.py\n",
      "[('DocumentRetrievalModel DocumentRetrievalModel __init__', 'nltk stem porter PorterStemmer'), ('DocumentRetrievalModel DocumentRetrievalModel __init__', 'DocumentRetrievalModel DocumentRetrievalModel computeTFIDF'), ('DocumentRetrievalModel DocumentRetrievalModel computeTFIDF', 'DocumentRetrievalModel DocumentRetrievalModel getTermFrequencyCount'), ('DocumentRetrievalModel DocumentRetrievalModel computeTFIDF', 'math log'), ('DocumentRetrievalModel DocumentRetrievalModel getTermFrequencyCount', 'nltk tokenize sent_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel getTermFrequencyCount', 'nltk tokenize word_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel getTermFrequencyCount', 're match'), ('DocumentRetrievalModel DocumentRetrievalModel getTermFrequencyCount', 'DocumentRetrievalModel DocumentRetrievalModel __init__ <lambda1>'), ('DocumentRetrievalModel DocumentRetrievalModel query', 'nltk tokenize sent_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel query', 'DocumentRetrievalModel DocumentRetrievalModel getSimilarParagraph'), ('DocumentRetrievalModel DocumentRetrievalModel getSimilarParagraph', 'math pow'), ('DocumentRetrievalModel DocumentRetrievalModel getSimilarParagraph', 'DocumentRetrievalModel DocumentRetrievalModel computeSimilarity'), ('DocumentRetrievalModel DocumentRetrievalModel computeSimilarity', 'math pow'), ('DocumentRetrievalModel DocumentRetrievalModel getMostRelevantSentences', 'nltk tokenize word_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel getMostRelevantSentences', 'DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence'), ('DocumentRetrievalModel DocumentRetrievalModel getMostRelevantSentences', 'DocumentRetrievalModel DocumentRetrievalModel sim_sentence'), ('DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence', 'DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence <lambda2>'), ('DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence', 'nltk stem porter PorterStemmer'), ('DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence', 'DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence <lambda1>'), ('DocumentRetrievalModel DocumentRetrievalModel sim_sentence', 'nltk tokenize word_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel sim_sentence', 'nltk stem porter PorterStemmer'), ('DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence <lambda1>', 'nltk tokenize word_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel getNamedEntity', 'nltk pos_tag'), ('DocumentRetrievalModel DocumentRetrievalModel getNamedEntity', 'nltk tokenize word_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel getNamedEntity', 'nltk ne_chunk'), ('DocumentRetrievalModel DocumentRetrievalModel getContinuousChunk', 'nltk tokenize word_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel getContinuousChunk', 'nltk pos_tag'), ('DocumentRetrievalModel DocumentRetrievalModel getqRev', 'DocumentRetrievalModel DocumentRetrievalModel sim_sentence'), ('DocumentRetrievalModel DocumentRetrievalModel getqRev', 'json loads')]\n",
      "0\n",
      "found files: []\n",
      "import joblib\n",
      "import warnings\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.base import BaseEstimator\n",
      "\n",
      "from cdqadocumentretriever import TfidfRetriever, BM25Retriever\n",
      "from utils.filters import filter_paragraphs \n",
      "from utils.converters import generate_squad_examples\n",
      "from ast import literal_eval\n",
      "\n",
      "\n",
      "\n",
      "RETRIEVERS = {\"bm25\": BM25Retriever, \"tfidf\": TfidfRetriever}\n",
      "\n",
      "\n",
      "class DocumentRetriever(BaseEstimator):\n",
      "    \"\"\"\n",
      "    A scikit-learn implementation of the whole cdQA pipeline\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "\n",
      "    retriever: \"bm25\" or \"tfidf\"\n",
      "        The type of retriever\n",
      "\n",
      "    retrieve_by_doc: bool (default: True). If Retriever will rank by documents\n",
      "        or by paragraphs.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from documentretriever import DocumentRetriever\n",
      "    >>> qa_pipeline = QAPipeline(reader='bert_qa_squad_vCPU-sklearn.joblib')\n",
      "    >>> qa_pipeline.fit_retriever(X=df)\n",
      "    >>> prediction = qa_pipeline.predict(X='When BNP Paribas was created?')\n",
      "\n",
      "    >>> from cdqa.pipeline import QAPipeline\n",
      "    >>> qa_pipeline = QAPipeline()\n",
      "    >>> qa_pipeline.fit_reader('train-v1.1.json')\n",
      "    >>> qa_pipeline.fit_retriever(X=df)\n",
      "    >>> prediction = qa_pipeline.predict(X='When BNP Paribas was created?')\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, data_path = \"./data/bnpp_newsroom-v1.1.csv\", retriever=\"bm25\", retrieve_by_doc=False, **kwargs):\n",
      "\n",
      "        if retriever not in RETRIEVERS:\n",
      "            raise ValueError(\n",
      "                \"You provided a type of retriever that is not supported. \"\n",
      "                + \"Please provide a retriver in the following list: \"\n",
      "                + str(list(RETRIEVERS.keys()))\n",
      "            )\n",
      "\n",
      "        retriever_class = RETRIEVERS[retriever]\n",
      "\n",
      "        kwargs_retriever = {\n",
      "            key: value\n",
      "            for key, value in kwargs.items()\n",
      "            if key in retriever_class.__init__.__code__.co_varnames\n",
      "        }\n",
      "\n",
      "        self.retriever = retriever_class(**kwargs_retriever)\n",
      "\n",
      "        self.data_path = data_path\n",
      "\n",
      "        self.retrieve_by_doc = retrieve_by_doc\n",
      "\n",
      "    def fit_retriever(self):\n",
      "        \"\"\" Fit the QAPipeline retriever to a list of documents in a dataframe.\n",
      "        Parameters\n",
      "        ----------\n",
      "        df: pandas.Dataframe\n",
      "            Dataframe with the following columns: \"title\", \"paragraphs\"\n",
      "        \"\"\"\n",
      "\n",
      "        df = pd.read_csv( self.data_path,\n",
      "                          converters={\"paragraphs\": literal_eval},\n",
      "                        )\n",
      "\n",
      "        df = filter_paragraphs(df)\n",
      "\n",
      "        if self.retrieve_by_doc:\n",
      "            self.metadata = df\n",
      "            self.metadata[\"content\"] = self.metadata[\"paragraphs\"].apply(\n",
      "                lambda x: \" \".join(x)\n",
      "            )\n",
      "        else:\n",
      "            self.metadata = self._expand_paragraphs(df)\n",
      "\n",
      "        self.retriever.fit(self.metadata)\n",
      "\n",
      "        return self\n",
      "\n",
      "    def get_best_indexes(\n",
      "        self,\n",
      "        query: str = None\n",
      "    ):\n",
      "        best_idx_scores = self.retriever.predict(query)\n",
      "        return best_idx_scores\n",
      "\n",
      "    @staticmethod\n",
      "    def _expand_paragraphs(df):\n",
      "        # Snippet taken from: https://stackoverflow.com/a/48532692/11514226\n",
      "        lst_col = \"paragraphs\"\n",
      "        df = pd.DataFrame(\n",
      "            {\n",
      "                col: np.repeat(df[col].values, df[lst_col].str.len())\n",
      "                for col in df.columns.drop(lst_col)\n",
      "            }\n",
      "        ).assign(**{lst_col: np.concatenate(df[lst_col].values)})[df.columns]\n",
      "        df[\"content\"] = df[\"paragraphs\"]\n",
      "        return df.drop(\"paragraphs\", axis=1)\n",
      "\n",
      "    def get_most_relevant_paragraph(self, query):\n",
      "        self.fit_retriever()\n",
      "        bestIndexes = self.get_best_indexes(query)\n",
      "        squad_examples = generate_squad_examples(\n",
      "            question=query,\n",
      "            best_idx_scores=bestIndexes,\n",
      "            metadata=self.metadata,\n",
      "            retrieve_by_doc=self.retrieve_by_doc,\n",
      "        )\n",
      "        return squad_examples[0]\n",
      "\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\phamdinhha_end-to-end-qna\\api\\documentretriever.py\n",
      "[]\n",
      "found files: []\n",
      "import os\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "def filter_paragraphs(\n",
      "    articles,\n",
      "    drop_empty=True,\n",
      "    read_threshold=1000,\n",
      "    public_data=True,\n",
      "    min_length=50,\n",
      "    max_length=300,\n",
      "):\n",
      "    \"\"\"\n",
      "    Cleans the paragraphs and filters them regarding their length\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    articles : DataFrame of all the articles \n",
      "\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    Cleaned and filtered dataframe\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> import pandas as pd\n",
      "    >>> from cdqa.utils.filters import filter_paragraphs\n",
      "\n",
      "    >>> df = pd.read_csv('data.csv')\n",
      "    >>> df_cleaned = filter_paragraphs(df)\n",
      "    \"\"\"\n",
      "\n",
      "    # Replace and split\n",
      "    def replace_and_split(paragraphs):\n",
      "        for paragraph in paragraphs:\n",
      "            paragraph.replace(\"'s\", \" \" \"s\").replace(\"\\\\n\", \"\").split(\"'\")\n",
      "        return paragraphs\n",
      "\n",
      "    # Select paragraphs with the required size\n",
      "    def filter_on_size(paragraphs, min_length=min_length, max_length=max_length):\n",
      "        paragraph_filtered = [\n",
      "            paragraph.strip()\n",
      "            for paragraph in paragraphs\n",
      "            if len(paragraph.split()) >= min_length\n",
      "            and len(paragraph.split()) <= max_length\n",
      "        ]\n",
      "        return paragraph_filtered\n",
      "\n",
      "    # Cleaning and filtering\n",
      "    articles[\"paragraphs\"] = articles[\"paragraphs\"].apply(replace_and_split)\n",
      "    articles[\"paragraphs\"] = articles[\"paragraphs\"].apply(filter_on_size)\n",
      "    articles[\"paragraphs\"] = articles[\"paragraphs\"].apply(\n",
      "        lambda x: x if len(x) > 0 else np.nan\n",
      "    )\n",
      "\n",
      "    # Read threshold for private dataset\n",
      "    if not public_data:\n",
      "        articles = articles.loc[articles[\"number_of_read\"] >= read_threshold]\n",
      "\n",
      "    # Drop empty articles\n",
      "    if drop_empty:\n",
      "        articles = articles.dropna(subset=[\"paragraphs\"]).reset_index(drop=True)\n",
      "\n",
      "    return articles\n",
      "\n",
      "Output: {'filters': [], 'filters.filter_paragraphs': [], 'filters.filter_paragraphs.replace_and_split': [], 'filters.filter_paragraphs.filter_on_size': ['<builtin>.len'], '<builtin>.len': [], 'filters.filter_paragraphs.<lambda1>': ['<builtin>.len']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\phamdinhha_end-to-end-qna\\api\\utils\\filters.py\n",
      "[]\n",
      "found files: []\n",
      "import torch\n",
      "from transformers import AlbertTokenizer, AlbertForQuestionAnswering\n",
      "from transformers import BertTokenizer, BertForQuestionAnswering\n",
      "\n",
      "\n",
      "model_path = \"path_to_your_model\"\n",
      "\n",
      "\n",
      "class QAModelLoader:\n",
      "\n",
      "    def __init__(self, model_path = model_path):\n",
      "        self.tokenizer = BertTokenizer.from_pretrained(model_path)\n",
      "        self.model = BertForQuestionAnswering.from_pretrained(model_path)\n",
      "\n",
      "    def answer(self, question, text):\n",
      "        input_dict = self.tokenizer.encode_plus(question, text, return_tensors='pt', max_length=512)\n",
      "        input_ids = input_dict[\"input_ids\"].tolist()\n",
      "        start_scores, end_scores = self.model(**input_dict)\n",
      "\n",
      "        start = torch.argmax(start_scores, dim=1)\n",
      "        end = torch.argmax(end_scores, dim=1)\n",
      "\n",
      "        all_tokens = self.tokenizer.convert_ids_to_tokens(input_ids[0])\n",
      "        answer = ''.join(all_tokens[start: end + 1]).replace('', ' ').strip()\n",
      "        answer = answer.replace('[SEP]', '')\n",
      "        return answer if answer != '[CLS]' and len(answer) != 0 else 'could not find an answer'\n",
      "\n",
      "\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\phamdinhha_end-to-end-qna\\api\\qamodelloader.py\n",
      "[]\n",
      "found files: []\n",
      "# BSD 3-Clause License\n",
      "#\n",
      "# Copyright (c) 2018, Sho IIZUKA\n",
      "# All rights reserved.\n",
      "#\n",
      "# Redistribution and use in source and binary forms, with or without\n",
      "# modification, are permitted provided that the following conditions are met:\n",
      "#\n",
      "# * Redistributions of source code must retain the above copyright notice, this\n",
      "#   list of conditions and the following disclaimer.\n",
      "#\n",
      "# * Redistributions in binary form must reproduce the above copyright notice,\n",
      "#   this list of conditions and the following disclaimer in the documentation\n",
      "#   and/or other materials provided with the distribution.\n",
      "#\n",
      "# * Neither the name of the copyright holder nor the names of its\n",
      "#   contributors may be used to endorse or promote products derived from\n",
      "#   this software without specific prior written permission.\n",
      "#\n",
      "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
      "# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
      "# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
      "# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
      "# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
      "# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
      "# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "import scipy.sparse as sp\n",
      "from sklearn.base import BaseEstimator, TransformerMixin\n",
      "from sklearn.utils.validation import check_is_fitted, check_array, FLOAT_DTYPES\n",
      "from sklearn.feature_extraction.text import _document_frequency\n",
      "from sklearn.preprocessing import normalize\n",
      "\n",
      "\n",
      "class BM25Transformer(BaseEstimator, TransformerMixin):\n",
      "    \"\"\"\n",
      "    Parameters\n",
      "    ----------\n",
      "     norm : 'l1', 'l2' or None, optional (default=None)\n",
      "        Each output row will have unit norm, either:\n",
      "        * 'l2': Sum of squares of vector elements is 1. The cosine\n",
      "        similarity between two vectors is their dot product when l2 norm has\n",
      "        been applied.\n",
      "        * 'l1': Sum of absolute values of vector elements is 1.\n",
      "    use_idf : boolean, optional (default=True)\n",
      "        Enable inverse-document-frequency reweighting\n",
      "    k1 : float, optional (default=2.0)\n",
      "        term k1 in the BM25 formula\n",
      "    b : float, optional (default=0.75)\n",
      "        term b in the BM25 formula\n",
      "    floor : float or None, optional (default=None)\n",
      "        floor value for idf terms\n",
      "    References\n",
      "    ----------\n",
      "    Okapi BM25: a non-binary model - Introduction to Information Retrieval\n",
      "    http://nlp.stanford.edu/IR-book/html/htmledition/okapi-bm25-a-non-binary-model-1.html\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, norm=None, use_idf=True, k1=2.0, b=0.75, floor=None):\n",
      "        self.norm = norm\n",
      "        self.use_idf = use_idf\n",
      "        self.k1 = k1\n",
      "        self.b = b\n",
      "        self.floor = floor\n",
      "\n",
      "    def fit(self, X):\n",
      "        \"\"\"\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : sparse matrix, [n_samples, n_features]\n",
      "            document-term matrix\n",
      "        \"\"\"\n",
      "        X = check_array(X, accept_sparse=(\"csr\", \"csc\"))\n",
      "        if not sp.issparse(X):\n",
      "            X = sp.csc_matrix(X)\n",
      "        if self.use_idf:\n",
      "            n_samples, n_features = X.shape\n",
      "            df = _document_frequency(X)\n",
      "            idf = np.log((n_samples - df + 0.5) / (df + 0.5))\n",
      "            if self.floor is not None:\n",
      "                idf = idf * (idf > self.floor) + self.floor * (idf < self.floor)\n",
      "            self._idf_diag = sp.spdiags(idf, diags=0, m=n_features, n=n_features)\n",
      "\n",
      "        # Create BM25 features\n",
      "\n",
      "        # Document length (number of terms) in each row\n",
      "        # Shape is (n_samples, 1)\n",
      "        dl = X.sum(axis=1)\n",
      "        # Number of non-zero elements in each row\n",
      "        # Shape is (n_samples, )\n",
      "        sz = X.indptr[1:] - X.indptr[0:-1]\n",
      "        # In each row, repeat `dl` for `sz` times\n",
      "        # Shape is (sum(sz), )\n",
      "        # Example\n",
      "        # -------\n",
      "        # dl = [4, 5, 6]\n",
      "        # sz = [1, 2, 3]\n",
      "        # rep = [4, 5, 5, 6, 6, 6]\n",
      "        rep = np.repeat(np.asarray(dl), sz)\n",
      "        # Average document length\n",
      "        # Scalar value\n",
      "        avgdl = np.average(dl)\n",
      "        # Compute BM25 score only for non-zero elements\n",
      "        data = (\n",
      "            X.data\n",
      "            * (self.k1 + 1)\n",
      "            / (X.data + self.k1 * (1 - self.b + self.b * rep / avgdl))\n",
      "        )\n",
      "        X = sp.csr_matrix((data, X.indices, X.indptr), shape=X.shape)\n",
      "\n",
      "        if self.norm:\n",
      "            X = normalize(X, norm=self.norm, copy=False)\n",
      "\n",
      "        self._doc_matrix = X\n",
      "        return self\n",
      "\n",
      "    def transform(self, X=None, copy=True, is_query=False):\n",
      "        \"\"\"\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : sparse matrix, [n_samples, n_features]\n",
      "            document-term query matrix\n",
      "        copy : boolean, optional (default=True)\n",
      "        query: boolean (default=False)\n",
      "            whether to transform a query or the documents database\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        vectors : sparse matrix, [n_samples, n_features]\n",
      "\n",
      "        \"\"\"\n",
      "        if is_query:\n",
      "            X = check_array(X, accept_sparse=\"csr\", dtype=FLOAT_DTYPES, copy=copy)\n",
      "            if not sp.issparse(X):\n",
      "                X = sp.csr_matrix(X, dtype=np.float64)\n",
      "\n",
      "            n_samples, n_features = X.shape\n",
      "\n",
      "            expected_n_features = self._doc_matrix.shape[1]\n",
      "            if n_features != expected_n_features:\n",
      "                raise ValueError(\n",
      "                    \"Input has n_features=%d while the model\"\n",
      "                    \" has been trained with n_features=%d\"\n",
      "                    % (n_features, expected_n_features)\n",
      "                )\n",
      "\n",
      "            if self.use_idf:\n",
      "                check_is_fitted(self, \"_idf_diag\", \"idf vector is not fitted\")\n",
      "                X = sp.csr_matrix(X.toarray() * self._idf_diag.diagonal())\n",
      "\n",
      "            return X\n",
      "\n",
      "        else:\n",
      "            return self._doc_matrix\n",
      "\n",
      "    @property\n",
      "    def idf_(self):\n",
      "        # if _idf_diag is not set, this will raise an attribute error,\n",
      "        # which means hasattr(self, \"idf_\") is False\n",
      "        return np.ravel(self._idf_diag.sum(axis=0))\n",
      "\n",
      "    @idf_.setter\n",
      "    def idf_(self, value):\n",
      "        value = np.asarray(value, dtype=np.float64)\n",
      "        n_features = value.shape[0]\n",
      "        self._idf_diag = sp.spdiags(\n",
      "            value, diags=0, m=n_features, n=n_features, format=\"csr\"\n",
      "        )\n",
      "\n",
      "Output: {'text_transformers': [], 'text_transformers.BM25Transformer.__init__': [], 'text_transformers.BM25Transformer.fit': ['scipy.sparse.csc_matrix', 'scipy.sparse.issparse', 'scipy.sparse.csr_matrix', 'sklearn.preprocessing.normalize', 'numpy.asarray', 'numpy.repeat', 'numpy.average', 'numpy.log', 'sklearn.utils.validation.check_array', 'sklearn.feature_extraction.text._document_frequency', 'scipy.sparse.spdiags'], 'sklearn.utils.validation.check_array': [], 'scipy.sparse.issparse': [], 'scipy.sparse.csc_matrix': [], 'sklearn.feature_extraction.text._document_frequency': [], 'numpy.log': [], 'scipy.sparse.spdiags': [], 'numpy.asarray': [], 'numpy.repeat': [], 'numpy.average': [], 'scipy.sparse.csr_matrix': [], 'sklearn.preprocessing.normalize': [], 'text_transformers.BM25Transformer.transform': ['scipy.sparse.issparse', 'scipy.sparse.csr_matrix', '<builtin>.ValueError', 'sklearn.utils.validation.check_is_fitted', 'sklearn.utils.validation.check_array'], '<builtin>.ValueError': [], 'sklearn.utils.validation.check_is_fitted': [], 'text_transformers.BM25Transformer.idf_': ['numpy.ravel', 'scipy.sparse.spdiags', 'numpy.asarray'], 'numpy.ravel': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\phamdinhha_end-to-end-qna\\api\\cdqadocumentretriever\\text_transformers.py\n",
      "[('text_transformers BM25Transformer fit', 'scipy sparse csc_matrix'), ('text_transformers BM25Transformer fit', 'scipy sparse issparse'), ('text_transformers BM25Transformer fit', 'scipy sparse csr_matrix'), ('text_transformers BM25Transformer fit', 'sklearn preprocessing normalize'), ('text_transformers BM25Transformer fit', 'numpy asarray'), ('text_transformers BM25Transformer fit', 'numpy repeat'), ('text_transformers BM25Transformer fit', 'numpy average'), ('text_transformers BM25Transformer fit', 'numpy log'), ('text_transformers BM25Transformer fit', 'sklearn utils validation check_array'), ('text_transformers BM25Transformer fit', 'sklearn feature_extraction text _document_frequency'), ('text_transformers BM25Transformer fit', 'scipy sparse spdiags'), ('text_transformers BM25Transformer transform', 'scipy sparse issparse'), ('text_transformers BM25Transformer transform', 'scipy sparse csr_matrix'), ('text_transformers BM25Transformer transform', 'sklearn utils validation check_is_fitted'), ('text_transformers BM25Transformer transform', 'sklearn utils validation check_array'), ('text_transformers BM25Transformer idf_', 'numpy ravel'), ('text_transformers BM25Transformer idf_', 'scipy sparse spdiags'), ('text_transformers BM25Transformer idf_', 'numpy asarray')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('converters df2squad', 'os path join'), ('converters df2squad', 'tqdm tqdm'), ('converters df2squad', 'json dump'), ('converters generate_squad_examples', 'uuid uuid4'), ('converters pdf_converter', 're split'), ('converters pdf_converter', 'os listdir'), ('converters pdf_converter', 'sys exc_info'), ('converters pdf_converter', 'os path join'), ('converters pdf_converter', 'tika parser from_file'), ('converters pdf_converter', 'pandas DataFrame'), ('converters MLStripper __init__', 'html parser HTMLParser reset'), ('converters strip_tags', 'converters MLStripper __init__'), ('converters strip_tags', 'converters MLStripper get_data'), ('converters strip_tags', 'html parser HTMLParser feed'), ('converters md_converter', 'markdown markdown'), ('converters md_converter', 'converters strip_tags'), ('converters md_converter', 'pathlib Path'), ('converters md_converter', 'sys exc_info'), ('converters md_converter', 'pandas DataFrame from_dict')], [('QuestionProcessor', 'nltk download'), ('QuestionProcessor QuestionProcessor __init__', 'QuestionProcessor QuestionProcessor determineAnswerType'), ('QuestionProcessor QuestionProcessor __init__', 'QuestionProcessor QuestionProcessor buildSearchQuery'), ('QuestionProcessor QuestionProcessor __init__', 'QuestionProcessor QuestionProcessor getQueryVector'), ('QuestionProcessor QuestionProcessor __init__', 'nltk corpus stopwords words'), ('QuestionProcessor QuestionProcessor __init__', 'nltk stem porter PorterStemmer'), ('QuestionProcessor QuestionProcessor __init__', 'QuestionProcessor QuestionProcessor determineQuestionType'), ('QuestionProcessor QuestionProcessor determineQuestionType', 'nltk word_tokenize'), ('QuestionProcessor QuestionProcessor determineQuestionType', 'nltk pos_tag'), ('QuestionProcessor QuestionProcessor buildSearchQuery', 'nltk word_tokenize'), ('QuestionProcessor QuestionProcessor buildSearchQuery', 'QuestionProcessor QuestionProcessor getSynonyms'), ('QuestionProcessor QuestionProcessor buildSearchQuery', 'nltk pos_tag'), ('QuestionProcessor QuestionProcessor getQueryVector', 'QuestionProcessor QuestionProcessor __init__ <lambda1>'), ('QuestionProcessor QuestionProcessor determineAnswerType', 'nltk word_tokenize'), ('QuestionProcessor QuestionProcessor determineAnswerType', 'nltk pos_tag'), ('QuestionProcessor QuestionProcessor determineAnswerType', 'QuestionProcessor QuestionProcessor getContinuousChunk'), ('QuestionProcessor QuestionProcessor getContinuousChunk', 'nltk word_tokenize'), ('QuestionProcessor QuestionProcessor getContinuousChunk', 'nltk pos_tag'), ('QuestionProcessor QuestionProcessor getSynonyms', 'nltk corpus wordnet synsets')], [('vectorizers BM25Vectorizer __init__', 'cdqadocumentretriever text_transformers BM25Transformer'), ('vectorizers BM25Vectorizer idf_', 'sklearn feature_extraction text CountVectorizer _validate_vocabulary')], [('customgooglesearchengine', 'nltk download'), ('customgooglesearchengine CustomGoogleSearchEngine buildDocumentTrunk', 'csv writer'), ('customgooglesearchengine CustomGoogleSearchEngine buildDocumentTrunk', 'customgooglesearchengine CustomGoogleSearchEngine customsearch'), ('customgooglesearchengine CustomGoogleSearchEngine buildDocumentTrunk', 'customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator'), ('customgooglesearchengine CustomGoogleSearchEngine customsearch', 'googlesearch search'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 'nltk sent_tokenize'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 'urllib request Request'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 'customgooglesearchengine CustomGoogleSearchEngine chunks'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 'urllib request urlopen'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 're findall'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 'bs4 BeautifulSoup'), ('customgooglesearchengine CustomGoogleSearchEngine paragraphGenerator', 're sub')], [('ParagraphsGenerator', 'nltk download'), ('ParagraphsGenerator ParagraphGenerator __init__', 'ParagraphsGenerator ParagraphGenerator paragraphsGenerator'), ('ParagraphsGenerator ParagraphGenerator paragraphsGenerator', 'ParagraphsGenerator ParagraphGenerator paragraphSearch'), ('ParagraphsGenerator ParagraphGenerator paragraphsGenerator', 'ParagraphsGenerator ParagraphGenerator ggSearch'), ('ParagraphsGenerator ParagraphGenerator ggSearch', 're findall'), ('ParagraphsGenerator ParagraphGenerator ggSearch', 'googlesearch search'), ('ParagraphsGenerator ParagraphGenerator paragraphSearch', 're sub'), ('ParagraphsGenerator ParagraphGenerator paragraphSearch', 're findall'), ('ParagraphsGenerator ParagraphGenerator paragraphSearch', 'urllib request Request'), ('ParagraphsGenerator ParagraphGenerator paragraphSearch', 'urllib request urlopen'), ('ParagraphsGenerator ParagraphGenerator paragraphSearch', 'bs4 BeautifulSoup')], [('DocumentRetrievalModel DocumentRetrievalModel __init__', 'nltk stem porter PorterStemmer'), ('DocumentRetrievalModel DocumentRetrievalModel __init__', 'DocumentRetrievalModel DocumentRetrievalModel computeTFIDF'), ('DocumentRetrievalModel DocumentRetrievalModel computeTFIDF', 'DocumentRetrievalModel DocumentRetrievalModel getTermFrequencyCount'), ('DocumentRetrievalModel DocumentRetrievalModel computeTFIDF', 'math log'), ('DocumentRetrievalModel DocumentRetrievalModel getTermFrequencyCount', 'nltk tokenize sent_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel getTermFrequencyCount', 'nltk tokenize word_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel getTermFrequencyCount', 're match'), ('DocumentRetrievalModel DocumentRetrievalModel getTermFrequencyCount', 'DocumentRetrievalModel DocumentRetrievalModel __init__ <lambda1>'), ('DocumentRetrievalModel DocumentRetrievalModel query', 'nltk tokenize sent_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel query', 'DocumentRetrievalModel DocumentRetrievalModel getSimilarParagraph'), ('DocumentRetrievalModel DocumentRetrievalModel getSimilarParagraph', 'math pow'), ('DocumentRetrievalModel DocumentRetrievalModel getSimilarParagraph', 'DocumentRetrievalModel DocumentRetrievalModel computeSimilarity'), ('DocumentRetrievalModel DocumentRetrievalModel computeSimilarity', 'math pow'), ('DocumentRetrievalModel DocumentRetrievalModel getMostRelevantSentences', 'nltk tokenize word_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel getMostRelevantSentences', 'DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence'), ('DocumentRetrievalModel DocumentRetrievalModel getMostRelevantSentences', 'DocumentRetrievalModel DocumentRetrievalModel sim_sentence'), ('DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence', 'DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence <lambda2>'), ('DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence', 'nltk stem porter PorterStemmer'), ('DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence', 'DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence <lambda1>'), ('DocumentRetrievalModel DocumentRetrievalModel sim_sentence', 'nltk tokenize word_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel sim_sentence', 'nltk stem porter PorterStemmer'), ('DocumentRetrievalModel DocumentRetrievalModel sim_ngram_sentence <lambda1>', 'nltk tokenize word_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel getNamedEntity', 'nltk pos_tag'), ('DocumentRetrievalModel DocumentRetrievalModel getNamedEntity', 'nltk tokenize word_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel getNamedEntity', 'nltk ne_chunk'), ('DocumentRetrievalModel DocumentRetrievalModel getContinuousChunk', 'nltk tokenize word_tokenize'), ('DocumentRetrievalModel DocumentRetrievalModel getContinuousChunk', 'nltk pos_tag'), ('DocumentRetrievalModel DocumentRetrievalModel getqRev', 'DocumentRetrievalModel DocumentRetrievalModel sim_sentence'), ('DocumentRetrievalModel DocumentRetrievalModel getqRev', 'json loads')], [('text_transformers BM25Transformer fit', 'scipy sparse csc_matrix'), ('text_transformers BM25Transformer fit', 'scipy sparse issparse'), ('text_transformers BM25Transformer fit', 'scipy sparse csr_matrix'), ('text_transformers BM25Transformer fit', 'sklearn preprocessing normalize'), ('text_transformers BM25Transformer fit', 'numpy asarray'), ('text_transformers BM25Transformer fit', 'numpy repeat'), ('text_transformers BM25Transformer fit', 'numpy average'), ('text_transformers BM25Transformer fit', 'numpy log'), ('text_transformers BM25Transformer fit', 'sklearn utils validation check_array'), ('text_transformers BM25Transformer fit', 'sklearn feature_extraction text _document_frequency'), ('text_transformers BM25Transformer fit', 'scipy sparse spdiags'), ('text_transformers BM25Transformer transform', 'scipy sparse issparse'), ('text_transformers BM25Transformer transform', 'scipy sparse csr_matrix'), ('text_transformers BM25Transformer transform', 'sklearn utils validation check_is_fitted'), ('text_transformers BM25Transformer transform', 'sklearn utils validation check_array'), ('text_transformers BM25Transformer idf_', 'numpy ravel'), ('text_transformers BM25Transformer idf_', 'scipy sparse spdiags'), ('text_transformers BM25Transformer idf_', 'numpy asarray')]]\n",
      "********************doctrings*************************\n",
      "[\"df2squad generate squad examples pdf converter strip tags md converter [SEP] Converts a pandas dataframe with columns ['title', 'paragraphs'] to a json file with SQuAD format. Creates a SQuAD examples json object for a given for a given question using outputs of retriever and Function to convert PDFs to Dataframe with colum\", '', '', '', '', '', '']\n",
      "embed index dataset: 25\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\montague\\\\ast.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\test\\\\test_integration.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\test\\\\test_ast.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\test\\\\conftest.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\montague\\\\main.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\test\\\\test_translator.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\montague\\\\parser.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\montague\\\\interpreter.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\precommit.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\montague\\\\translator.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\test\\\\test_interpreter.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\test\\\\test_parser.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\montague\\\\exceptions.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\setup.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\iafisher_montague\\\\test\\\\test_main.py']\n",
      "\"\"\"The representation of logical formulas, semantic types and sentences as trees.\n",
      "\n",
      "Logical formulas: Formula subclasses\n",
      "Semantic types: ComplexType and AtomicType\n",
      "Sentences: SentenceNode\n",
      "\n",
      "Author:  Ian Fisher (iafisher@protonmail.com)\n",
      "Version: September 2018\n",
      "\"\"\"\n",
      "from collections import namedtuple\n",
      "\n",
      "\n",
      "# Below are defined the classes to represent logical formulas as trees.\n",
      "\n",
      "\n",
      "class Formula:\n",
      "    def replace_variable(self, variable, replacement):\n",
      "        \"\"\"Replace all unbound instances of `variable`, a string, with `replacement`.\n",
      "\n",
      "        The default implementation recursively replaces the variable in all children.\n",
      "        Subclasses may need to override this implementation.\n",
      "        \"\"\"\n",
      "        children = [\n",
      "            c.replace_variable(variable, replacement) if isinstance(c, Formula) else c\n",
      "            for c in self\n",
      "        ]\n",
      "        return self.__class__(*children)\n",
      "\n",
      "    def simplify(self):\n",
      "        \"\"\"Simplify the tree by lambda conversion.\n",
      "\n",
      "        The default implementation recursively simplifies each child. Subclasses may\n",
      "        need to override this implementation.\n",
      "        \"\"\"\n",
      "        children = [c.simplify() if isinstance(c, Formula) else c for c in self]\n",
      "        return self.__class__(*children)\n",
      "\n",
      "    def ascii_str(self):\n",
      "        \"\"\"Render the formula as a string containing only ASCII characters.\n",
      "\n",
      "        The default implementation falls back to __str__. Subclasses whose __str__\n",
      "        contains non-ASCII characters should override this method.\n",
      "        \"\"\"\n",
      "        return str(self)\n",
      "\n",
      "\n",
      "class Var(Formula, namedtuple(\"Var\", [\"value\"])):\n",
      "    prec = 1\n",
      "\n",
      "    def __str__(self):\n",
      "        return self.value\n",
      "\n",
      "    def replace_variable(self, variable, replacement):\n",
      "        return self if variable != self.value else replacement\n",
      "\n",
      "\n",
      "class And(Formula, namedtuple(\"And\", [\"left\", \"right\"])):\n",
      "    prec = 2\n",
      "\n",
      "    def __str__(self):\n",
      "        # wrapb applies brackets if needed for the proper precedence.\n",
      "        left = wrapb(self, self.left)\n",
      "        right = wrapb(self, self.right)\n",
      "        return left + \" & \" + right\n",
      "\n",
      "\n",
      "class Or(Formula, namedtuple(\"Or\", [\"left\", \"right\"])):\n",
      "    prec = 3\n",
      "\n",
      "    def __str__(self):\n",
      "        left = wrapb(self, self.left)\n",
      "        right = wrapb(self, self.right)\n",
      "        return left + \" | \" + right\n",
      "\n",
      "\n",
      "class IfThen(Formula, namedtuple(\"IfThen\", [\"left\", \"right\"])):\n",
      "    prec = 4\n",
      "\n",
      "    def __str__(self):\n",
      "        left = wrapb(self, self.left)\n",
      "        right = wrapb(self, self.right)\n",
      "        return left + \" -> \" + right\n",
      "\n",
      "\n",
      "class IfAndOnlyIf(Formula, namedtuple(\"IfAndOnlyIf\", [\"left\", \"right\"])):\n",
      "    prec = 4\n",
      "\n",
      "    def __str__(self):\n",
      "        left = wrapb(self, self.left)\n",
      "        right = wrapb(self, self.right)\n",
      "        return left + \" <-> \" + right\n",
      "\n",
      "\n",
      "class Not(Formula, namedtuple(\"Not\", [\"operand\"])):\n",
      "    prec = 1\n",
      "\n",
      "    def __str__(self):\n",
      "        operand = wrapb(self, self.operand)\n",
      "        return \"~\" + operand\n",
      "\n",
      "\n",
      "class Lambda(Formula, namedtuple(\"Lambda\", [\"parameter\", \"body\"])):\n",
      "    prec = 5\n",
      "\n",
      "    def __str__(self):\n",
      "        return \"{0.parameter}.{0.body}\".format(self)\n",
      "\n",
      "    def ascii_str(self):\n",
      "        return \"L{0.parameter}.{0.body}\".format(self)\n",
      "\n",
      "    def replace_variable(self, variable, replacement):\n",
      "        if variable != self.parameter:\n",
      "            return Lambda(\n",
      "                self.parameter, self.body.replace_variable(variable, replacement)\n",
      "            )\n",
      "        else:\n",
      "            return self\n",
      "\n",
      "\n",
      "class Call(Formula, namedtuple(\"Call\", [\"caller\", \"arg\"])):\n",
      "    prec = 1\n",
      "\n",
      "    def __str__(self):\n",
      "        # To make string representations more natural, F(x)(y) is printed as F(x, y),\n",
      "        # which is why this method is more complicated than you would expect.\n",
      "        args = [str(self.arg)]\n",
      "        func = self.caller\n",
      "        while isinstance(func, Call):\n",
      "            args.append(str(func.arg))\n",
      "            func = func.caller\n",
      "        args = \", \".join(reversed(args))\n",
      "        if isinstance(func, Var):\n",
      "            return \"{}({})\".format(func, args)\n",
      "        else:\n",
      "            # Syntactically, a non-constant function must be in parentheses in a call\n",
      "            # expression.\n",
      "            return \"({})({})\".format(func, args)\n",
      "\n",
      "    def simplify(self):\n",
      "        caller = self.caller.simplify()\n",
      "        arg = self.arg.simplify()\n",
      "        if isinstance(caller, Lambda):\n",
      "            return caller.body.replace_variable(caller.parameter, arg).simplify()\n",
      "        else:\n",
      "            return Call(self.caller, arg)\n",
      "\n",
      "\n",
      "class ForAll(Formula, namedtuple(\"ForAll\", [\"symbol\", \"body\"])):\n",
      "    prec = 5\n",
      "\n",
      "    def __str__(self):\n",
      "        return \" {0.symbol}.{0.body}\".format(self)\n",
      "\n",
      "    def ascii_str(self):\n",
      "        return \"A{0.symbol}.{0.body}\".format(self)\n",
      "\n",
      "    def replace_variable(self, variable, replacement):\n",
      "        if variable != self.symbol:\n",
      "            return ForAll(\n",
      "                self.symbol, self.body.replace_variable(variable, replacement)\n",
      "            )\n",
      "        else:\n",
      "            return self\n",
      "\n",
      "\n",
      "class Exists(Formula, namedtuple(\"Exists\", [\"symbol\", \"body\"])):\n",
      "    prec = 5\n",
      "\n",
      "    def __str__(self):\n",
      "        return \" {0.symbol}.{0.body}\".format(self)\n",
      "\n",
      "    def ascii_str(self):\n",
      "        return \"E{0.symbol}.{0.body}\".format(self)\n",
      "\n",
      "    def replace_variable(self, variable, replacement):\n",
      "        if variable != self.symbol:\n",
      "            return Exists(\n",
      "                self.symbol, self.body.replace_variable(variable, replacement)\n",
      "            )\n",
      "        else:\n",
      "            return self\n",
      "\n",
      "\n",
      "class Iota(Formula, namedtuple(\"Iota\", [\"symbol\", \"body\"])):\n",
      "    prec = 5\n",
      "\n",
      "    def __str__(self):\n",
      "        return \"{0.symbol}.{0.body}\".format(self)\n",
      "\n",
      "    def ascii_str(self):\n",
      "        # 'i' instead of ''\n",
      "        return \"i{0.symbol}.{0.body}\".format(self)\n",
      "\n",
      "    def replace_variable(self, variable, replacement):\n",
      "        if variable != self.symbol:\n",
      "            return Iota(self.symbol, self.body.replace_variable(variable, replacement))\n",
      "        else:\n",
      "            return self\n",
      "\n",
      "\n",
      "# Below are defined the classes to represent semantic types as trees.\n",
      "\n",
      "\n",
      "class ComplexType(namedtuple(\"ComplexType\", [\"left\", \"right\"])):\n",
      "    def __str__(self):\n",
      "        return \"<{0.left}, {0.right}>\".format(self)\n",
      "\n",
      "    def concise_str(self):\n",
      "        \"\"\"Convert the type to a string, recursively abbreviating '<x, y>' as 'xy' as\n",
      "        long as 'x' and 'y' are atomic types.\n",
      "\n",
      "           >>> typ = ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE)\n",
      "           >>> str(typ)\n",
      "           '<e, t>'\n",
      "           >>> typ.concise_str()\n",
      "           'et'\n",
      "        \"\"\"\n",
      "        if isinstance(self.left, AtomicType) and isinstance(self.right, AtomicType):\n",
      "            return \"{0.left}{0.right}\".format(self)\n",
      "        else:\n",
      "            return \"<{}, {}>\".format(self.left.concise_str(), self.right.concise_str())\n",
      "\n",
      "\n",
      "class AtomicType(str):\n",
      "    def concise_str(self):\n",
      "        return self\n",
      "\n",
      "\n",
      "# Constants for the recognized atomic types.\n",
      "TYPE_ENTITY = AtomicType(\"e\")\n",
      "TYPE_TRUTH_VALUE = AtomicType(\"t\")\n",
      "TYPE_EVENT = AtomicType(\"v\")\n",
      "TYPE_WORLD = AtomicType(\"s\")\n",
      "\n",
      "\n",
      "# The class to represent English sentences as logical formulas. `text` is the\n",
      "# English text corresponding to the node.\n",
      "class SentenceNode(namedtuple(\"SentenceNode\", [\"text\", \"formula\", \"type\"])):\n",
      "    def __repr__(self):\n",
      "        return f\"SentenceNode({repr(self.text)}, {repr(str(self.formula))}, {repr(self.type.concise_str())})\"\n",
      "\n",
      "\n",
      "def wrapb(parent, child):\n",
      "    \"\"\"Return the child node as a string, wrapped in brackets if its precedence is\n",
      "    higher than the parent node.\n",
      "    \"\"\"\n",
      "    if child.prec > parent.prec:\n",
      "        return \"[{}]\".format(child)\n",
      "    else:\n",
      "        return str(child)\n",
      "\n",
      "Output: {'ast': [], 'ast.Formula.replace_variable': ['<builtin>.isinstance'], '<builtin>.isinstance': [], 'ast.Formula.simplify': ['<builtin>.isinstance'], 'ast.Formula.ascii_str': ['<builtin>.str'], '<builtin>.str': [], 'ast.Var.__str__': [], 'ast.Var.replace_variable': [], 'ast.And.__str__': ['ast.wrapb'], 'ast.wrapb': ['<builtin>.str'], 'ast.Or.__str__': ['ast.wrapb'], 'ast.IfThen.__str__': ['ast.wrapb'], 'ast.IfAndOnlyIf.__str__': ['ast.wrapb'], 'ast.Not.__str__': ['ast.wrapb'], 'ast.Lambda.__str__': [], 'ast.Lambda.ascii_str': [], 'ast.Lambda.replace_variable': [], 'ast.Call.__str__': ['<builtin>.isinstance', '<builtin>.str', '<builtin>.reversed'], '<builtin>.reversed': [], 'ast.Call.simplify': ['<builtin>.isinstance'], 'ast.ForAll.__str__': [], 'ast.ForAll.ascii_str': [], 'ast.ForAll.replace_variable': [], 'ast.Exists.__str__': [], 'ast.Exists.ascii_str': [], 'ast.Exists.replace_variable': [], 'ast.Iota.__str__': [], 'ast.Iota.ascii_str': [], 'ast.Iota.replace_variable': [], 'ast.ComplexType.__str__': [], 'ast.ComplexType.concise_str': ['<builtin>.isinstance'], 'ast.AtomicType.concise_str': [], 'ast.SentenceNode.__repr__': ['<builtin>.repr', '<builtin>.str'], '<builtin>.repr': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\montague\\ast.py\n",
      "[('ast And __str__', 'ast wrapb'), ('ast Or __str__', 'ast wrapb'), ('ast IfThen __str__', 'ast wrapb'), ('ast IfAndOnlyIf __str__', 'ast wrapb'), ('ast Not __str__', 'ast wrapb')]\n",
      "100\n",
      "found files: []\n",
      "from montague.interpreter import WorldModel, interpret_formula\n",
      "from montague.translator import translate_sentence\n",
      "\n",
      "\n",
      "John = object()\n",
      "Mary = object()\n",
      "\n",
      "\n",
      "test_model = WorldModel(\n",
      "    set([John, Mary]),\n",
      "    {\n",
      "        \"john\": John,\n",
      "        \"mary\": Mary,\n",
      "        \"Good\": {John},\n",
      "        \"Bad\": {Mary},\n",
      "        \"Man\": {John},\n",
      "        \"Human\": {Mary, John},\n",
      "        \"Alien\": set(),\n",
      "    },\n",
      ")\n",
      "\n",
      "\n",
      "def test_john_is_good_is_true(lexicon):\n",
      "    nodes = translate_sentence(\"John is good\", lexicon)\n",
      "\n",
      "    assert len(nodes) == 1\n",
      "    assert interpret_formula(nodes[0].formula, test_model)\n",
      "\n",
      "\n",
      "def test_john_is_bad_is_false(lexicon):\n",
      "    nodes = translate_sentence(\"John is bad\", lexicon)\n",
      "\n",
      "    assert len(nodes) == 1\n",
      "    assert not interpret_formula(nodes[0].formula, test_model)\n",
      "\n",
      "Output: {'test_integration': ['<builtin>.object', '<builtin>.set', 'montague.interpreter.WorldModel'], '<builtin>.object': [], '<builtin>.set': [], 'montague.interpreter.WorldModel': [], 'test_integration.test_john_is_good_is_true': ['montague.translator.translate_sentence', '<builtin>.len', 'montague.interpreter.interpret_formula'], 'montague.translator.translate_sentence': [], '<builtin>.len': [], 'montague.interpreter.interpret_formula': [], 'test_integration.test_john_is_bad_is_false': ['montague.translator.translate_sentence', '<builtin>.len', 'montague.interpreter.interpret_formula']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\test\\test_integration.py\n",
      "[('test_integration', 'montague interpreter WorldModel'), ('test_integration test_john_is_good_is_true', 'montague translator translate_sentence'), ('test_integration test_john_is_good_is_true', 'montague interpreter interpret_formula'), ('test_integration test_john_is_bad_is_false', 'montague translator translate_sentence'), ('test_integration test_john_is_bad_is_false', 'montague interpreter interpret_formula')]\n",
      "0\n",
      "found files: []\n",
      "from montague.ast import (\n",
      "    And,\n",
      "    Call,\n",
      "    ComplexType,\n",
      "    Exists,\n",
      "    ForAll,\n",
      "    IfAndOnlyIf,\n",
      "    IfThen,\n",
      "    Iota,\n",
      "    Lambda,\n",
      "    Not,\n",
      "    Or,\n",
      "    TYPE_ENTITY,\n",
      "    TYPE_EVENT,\n",
      "    TYPE_TRUTH_VALUE,\n",
      "    TYPE_WORLD,\n",
      "    Var,\n",
      ")\n",
      "\n",
      "\n",
      "def test_variable_to_str():\n",
      "    assert str(Var(\"a\")) == \"a\"\n",
      "\n",
      "\n",
      "def test_and_to_str():\n",
      "    assert str(And(Var(\"a\"), Var(\"b\"))) == \"a & b\"\n",
      "\n",
      "\n",
      "def test_or_to_str():\n",
      "    assert str(Or(Var(\"a\"), Var(\"b\"))) == \"a | b\"\n",
      "\n",
      "\n",
      "def test_if_then_to_str():\n",
      "    assert str(IfThen(Var(\"a\"), Var(\"b\"))) == \"a -> b\"\n",
      "\n",
      "\n",
      "def test_if_and_only_if_to_str():\n",
      "    assert str(IfAndOnlyIf(Var(\"a\"), Var(\"b\"))) == \"a <-> b\"\n",
      "\n",
      "\n",
      "def test_lambda_to_str():\n",
      "    tree = Lambda(\"x\", And(Var(\"a\"), Var(\"x\")))\n",
      "    assert str(tree) == \"x.a & x\"\n",
      "    assert tree.ascii_str() == \"Lx.a & x\"\n",
      "    # This formula is semantically invalid but that doesn't matter.\n",
      "    assert str(And(Lambda(\"x\", Var(\"x\")), Lambda(\"y\", Var(\"y\")))) == \"[x.x] & [y.y]\"\n",
      "\n",
      "\n",
      "def test_call_to_str():\n",
      "    assert (\n",
      "        str(Call(Call(Var(\"P\"), And(Var(\"a\"), Var(\"b\"))), Lambda(\"x\", Var(\"x\"))))\n",
      "        == \"P(a & b, x.x)\"\n",
      "    )\n",
      "    assert str(Call(Var(\"P\"), Var(\"x\"))) == \"P(x)\"\n",
      "\n",
      "\n",
      "def test_for_all_to_str():\n",
      "    tree = ForAll(\"x\", Call(Var(\"P\"), Var(\"x\")))\n",
      "    assert str(tree) == \" x.P(x)\"\n",
      "    assert tree.ascii_str() == \"Ax.P(x)\"\n",
      "\n",
      "\n",
      "def test_exists_to_str():\n",
      "    tree = Exists(\"x\", Call(Var(\"P\"), Var(\"x\")))\n",
      "    assert str(tree) == \" x.P(x)\"\n",
      "    assert tree.ascii_str() == \"Ex.P(x)\"\n",
      "\n",
      "\n",
      "def test_not_to_str():\n",
      "    assert str(Not(Var(\"x\"))) == \"~x\"\n",
      "    assert str(Not(Or(Var(\"x\"), Var(\"y\")))) == \"~[x | y]\"\n",
      "\n",
      "\n",
      "def test_binary_operators_to_str():\n",
      "    assert str(And(Or(Var(\"a\"), Var(\"b\")), Var(\"c\"))) == \"[a | b] & c\"\n",
      "    assert str(Or(And(Var(\"a\"), Var(\"b\")), Var(\"c\"))) == \"a & b | c\"\n",
      "    assert str(Or(Var(\"a\"), Or(Var(\"b\"), Var(\"c\")))) == \"a | b | c\"\n",
      "    assert str(And(Var(\"a\"), And(Var(\"b\"), Var(\"c\")))) == \"a & b & c\"\n",
      "\n",
      "\n",
      "def test_nested_exists_and_for_all_to_str():\n",
      "    assert str(And(ForAll(\"x\", Var(\"x\")), Exists(\"x\", Var(\"x\")))) == \"[ x.x] & [ x.x]\"\n",
      "\n",
      "\n",
      "def test_iota_to_str():\n",
      "    tree = Iota(\"x\", Var(\"x\"))\n",
      "    assert str(tree) == \"x.x\"\n",
      "    assert tree.ascii_str() == \"ix.x\"\n",
      "\n",
      "\n",
      "def test_entity_to_str():\n",
      "    assert str(TYPE_ENTITY) == \"e\"\n",
      "\n",
      "\n",
      "def test_event_to_str():\n",
      "    assert str(TYPE_EVENT) == \"v\"\n",
      "\n",
      "\n",
      "def test_truth_value_to_str():\n",
      "    assert str(TYPE_TRUTH_VALUE) == \"t\"\n",
      "\n",
      "\n",
      "def test_world_to_str():\n",
      "    assert str(TYPE_WORLD) == \"s\"\n",
      "\n",
      "\n",
      "def test_recursive_type_to_str():\n",
      "    assert str(ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE)) == \"<e, t>\"\n",
      "\n",
      "\n",
      "def test_deeply_recursive_type_to_str():\n",
      "    assert (\n",
      "        str(\n",
      "            ComplexType(\n",
      "                TYPE_EVENT,\n",
      "                ComplexType(\n",
      "                    ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE),\n",
      "                    ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE),\n",
      "                ),\n",
      "            )\n",
      "        )\n",
      "        == \"<v, <<e, t>, <e, t>>>\"\n",
      "    )\n",
      "\n",
      "\n",
      "def test_recursive_type_to_concise_str():\n",
      "    typ = ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE)\n",
      "    assert typ.concise_str() == \"et\"\n",
      "\n",
      "\n",
      "def test_deeply_recursive_type_to_concise_str():\n",
      "    typ = ComplexType(\n",
      "        TYPE_EVENT,\n",
      "        ComplexType(\n",
      "            ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE),\n",
      "            ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE),\n",
      "        ),\n",
      "    )\n",
      "    assert typ.concise_str() == \"<v, <et, et>>\"\n",
      "\n",
      "\n",
      "def test_simple_replace_variable():\n",
      "    assert Var(\"x\").replace_variable(\"x\", Var(\"y\")) == Var(\"y\")\n",
      "\n",
      "\n",
      "def test_replace_variable_in_and_or():\n",
      "    tree = And(Or(Var(\"x\"), Var(\"y\")), Var(\"z\"))\n",
      "    assert tree.replace_variable(\"x\", Var(\"x'\")) == And(\n",
      "        Or(Var(\"x'\"), Var(\"y\")), Var(\"z\")\n",
      "    )\n",
      "\n",
      "\n",
      "def test_replace_predicate():\n",
      "    tree = Call(Var(\"P\"), Var(\"x\"))\n",
      "    assert tree.replace_variable(\"P\", Var(\"Good\")) == Call(Var(\"Good\"), Var(\"x\"))\n",
      "\n",
      "\n",
      "def test_replace_variable_in_quantifiers():\n",
      "    tree = ForAll(\n",
      "        \"x\",\n",
      "        Or(And(ForAll(\"b\", Var(\"b\")), Exists(\"b\", Var(\"b\"))), Exists(\"y\", Var(\"b\"))),\n",
      "    )\n",
      "    assert tree.replace_variable(\"b\", Var(\"bbb\")) == ForAll(\n",
      "        \"x\",\n",
      "        Or(And(ForAll(\"b\", Var(\"b\")), Exists(\"b\", Var(\"b\"))), Exists(\"y\", Var(\"bbb\"))),\n",
      "    )\n",
      "\n",
      "\n",
      "def test_recursive_replace_variable():\n",
      "    # BFP(x, Lx.x, x & y)\n",
      "    tree = Call(\n",
      "        Call(\n",
      "            Call(Var(\"BFP\"), Var(\"x\")),\n",
      "            Lambda(\"x\", Var(\"x\")),  # This should not be replaced.\n",
      "        ),\n",
      "        And(Var(\"x\"), Var(\"y\")),\n",
      "    )\n",
      "    assert tree.replace_variable(\"x\", Var(\"j\")) == Call(\n",
      "        Call(Call(Var(\"BFP\"), Var(\"j\")), Lambda(\"x\", Var(\"x\"))), And(Var(\"j\"), Var(\"y\"))\n",
      "    )\n",
      "\n",
      "\n",
      "def test_replace_variable_in_iota():\n",
      "    tree = Iota(\"x\", And(Var(\"x\"), Var(\"y\")))\n",
      "    assert tree.replace_variable(\"x\", Var(\"a\")) == tree\n",
      "    assert tree.replace_variable(\"y\", Var(\"b\")) == Iota(\"x\", And(Var(\"x\"), Var(\"b\")))\n",
      "\n",
      "Output: {'test_ast': [], 'test_ast.test_variable_to_str': ['montague.ast.Var', '<builtin>.str'], 'montague.ast.Var': [], '<builtin>.str': [], 'test_ast.test_and_to_str': ['montague.ast.Var', 'montague.ast.And', '<builtin>.str'], 'montague.ast.And': [], 'test_ast.test_or_to_str': ['montague.ast.Var', 'montague.ast.Or', '<builtin>.str'], 'montague.ast.Or': [], 'test_ast.test_if_then_to_str': ['montague.ast.Var', '<builtin>.str', 'montague.ast.IfThen'], 'montague.ast.IfThen': [], 'test_ast.test_if_and_only_if_to_str': ['montague.ast.Var', 'montague.ast.IfAndOnlyIf', '<builtin>.str'], 'montague.ast.IfAndOnlyIf': [], 'test_ast.test_lambda_to_str': ['montague.ast.Var', 'montague.ast.And', '<builtin>.str', 'montague.ast.Lambda'], 'montague.ast.Lambda': [], 'test_ast.test_call_to_str': ['montague.ast.Var', 'montague.ast.Call', '<builtin>.str', 'montague.ast.Lambda', 'montague.ast.And'], 'montague.ast.Call': [], 'test_ast.test_for_all_to_str': ['montague.ast.Var', '<builtin>.str', 'montague.ast.ForAll', 'montague.ast.Call'], 'montague.ast.ForAll': [], 'test_ast.test_exists_to_str': ['montague.ast.Var', '<builtin>.str', 'montague.ast.Exists', 'montague.ast.Call'], 'montague.ast.Exists': [], 'test_ast.test_not_to_str': ['montague.ast.Not', 'montague.ast.Var', 'montague.ast.Or', '<builtin>.str'], 'montague.ast.Not': [], 'test_ast.test_binary_operators_to_str': ['montague.ast.Var', 'montague.ast.Or', '<builtin>.str', 'montague.ast.And'], 'test_ast.test_nested_exists_and_for_all_to_str': ['montague.ast.Var', 'montague.ast.ForAll', '<builtin>.str', 'montague.ast.Exists', 'montague.ast.And'], 'test_ast.test_iota_to_str': ['montague.ast.Var', 'montague.ast.Iota', '<builtin>.str'], 'montague.ast.Iota': [], 'test_ast.test_entity_to_str': ['<builtin>.str'], 'test_ast.test_event_to_str': ['<builtin>.str'], 'test_ast.test_truth_value_to_str': ['<builtin>.str'], 'test_ast.test_world_to_str': ['<builtin>.str'], 'test_ast.test_recursive_type_to_str': ['montague.ast.ComplexType', '<builtin>.str'], 'montague.ast.ComplexType': [], 'test_ast.test_deeply_recursive_type_to_str': ['montague.ast.ComplexType', '<builtin>.str'], 'test_ast.test_recursive_type_to_concise_str': ['montague.ast.ComplexType'], 'test_ast.test_deeply_recursive_type_to_concise_str': ['montague.ast.ComplexType'], 'test_ast.test_simple_replace_variable': ['montague.ast.Var'], 'test_ast.test_replace_variable_in_and_or': ['montague.ast.Var', 'montague.ast.Or', 'montague.ast.And'], 'test_ast.test_replace_predicate': ['montague.ast.Var', 'montague.ast.Call'], 'test_ast.test_replace_variable_in_quantifiers': ['montague.ast.Var', 'montague.ast.ForAll', 'montague.ast.Exists', 'montague.ast.And', 'montague.ast.Or'], 'test_ast.test_recursive_replace_variable': ['montague.ast.Var', 'montague.ast.Lambda', 'montague.ast.And', 'montague.ast.Call'], 'test_ast.test_replace_variable_in_iota': ['montague.ast.Var', 'montague.ast.And', 'montague.ast.Iota']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\test\\test_ast.py\n",
      "[('test_ast test_variable_to_str', 'montague ast Var'), ('test_ast test_and_to_str', 'montague ast Var'), ('test_ast test_and_to_str', 'montague ast And'), ('test_ast test_or_to_str', 'montague ast Var'), ('test_ast test_or_to_str', 'montague ast Or'), ('test_ast test_if_then_to_str', 'montague ast Var'), ('test_ast test_if_then_to_str', 'montague ast IfThen'), ('test_ast test_if_and_only_if_to_str', 'montague ast Var'), ('test_ast test_if_and_only_if_to_str', 'montague ast IfAndOnlyIf'), ('test_ast test_lambda_to_str', 'montague ast Var'), ('test_ast test_lambda_to_str', 'montague ast And'), ('test_ast test_lambda_to_str', 'montague ast Lambda'), ('test_ast test_call_to_str', 'montague ast Var'), ('test_ast test_call_to_str', 'montague ast Call'), ('test_ast test_call_to_str', 'montague ast Lambda'), ('test_ast test_call_to_str', 'montague ast And'), ('test_ast test_for_all_to_str', 'montague ast Var'), ('test_ast test_for_all_to_str', 'montague ast ForAll'), ('test_ast test_for_all_to_str', 'montague ast Call'), ('test_ast test_exists_to_str', 'montague ast Var'), ('test_ast test_exists_to_str', 'montague ast Exists'), ('test_ast test_exists_to_str', 'montague ast Call'), ('test_ast test_not_to_str', 'montague ast Not'), ('test_ast test_not_to_str', 'montague ast Var'), ('test_ast test_not_to_str', 'montague ast Or'), ('test_ast test_binary_operators_to_str', 'montague ast Var'), ('test_ast test_binary_operators_to_str', 'montague ast Or'), ('test_ast test_binary_operators_to_str', 'montague ast And'), ('test_ast test_nested_exists_and_for_all_to_str', 'montague ast Var'), ('test_ast test_nested_exists_and_for_all_to_str', 'montague ast ForAll')]\n",
      "0\n",
      "found files: []\n",
      "import json\n",
      "import os\n",
      "\n",
      "import pytest\n",
      "\n",
      "from montague.translator import load_lexicon\n",
      "\n",
      "\n",
      "@pytest.fixture(scope=\"session\")\n",
      "def lexicon():\n",
      "    project_dir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\n",
      "    fragment_path = os.path.join(project_dir, \"montague\", \"resources\", \"fragment.json\")\n",
      "    with open(fragment_path) as f:\n",
      "        return load_lexicon(json.load(f))\n",
      "\n",
      "Output: {'conftest': ['pytest.fixture'], 'pytest.fixture': [], 'conftest.lexicon': ['os.path.realpath', 'os.path.dirname', 'json.load', 'os.path.join', 'montague.translator.load_lexicon', '<builtin>.open'], 'os.path.realpath': [], 'os.path.dirname': [], 'os.path.join': [], '<builtin>.open': [], 'json.load': [], 'montague.translator.load_lexicon': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\test\\conftest.py\n",
      "[('conftest', 'pytest fixture'), ('conftest lexicon', 'os path realpath'), ('conftest lexicon', 'os path dirname'), ('conftest lexicon', 'json load'), ('conftest lexicon', 'os path join'), ('conftest lexicon', 'montague translator load_lexicon')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"The command-line interface to the Montague natural language understanding system.\n",
      "\n",
      "Author:  Ian Fisher (iafisher@protonmail.com)\n",
      "Version: November 2018\n",
      "\"\"\"\n",
      "import json\n",
      "import os\n",
      "import readline  # noqa: F401\n",
      "import sys\n",
      "\n",
      "from .translator import load_lexicon, translate_sentence\n",
      "\n",
      "\n",
      "class ShellState:\n",
      "    \"\"\"A box holding all the information the shell needs to run.\"\"\"\n",
      "\n",
      "    def __init__(self, mode=\"translate\", lexicon=None):\n",
      "        self.mode = mode\n",
      "        self.lexicon = lexicon\n",
      "\n",
      "\n",
      "def main():\n",
      "    print(\"The Montague natural language system (v0.1.6).\\n\")\n",
      "    print(HELP_MESSAGE)\n",
      "\n",
      "    try:\n",
      "        with open(FRAGMENT_PATH) as f:\n",
      "            lexicon = load_lexicon(json.load(f))\n",
      "    except (FileNotFoundError, IOError):\n",
      "        sys.stderr.write(\"Error: failed to open {}\\n\".format(FRAGMENT_PATH))\n",
      "        sys.exit(1)\n",
      "\n",
      "    shell_state = ShellState(lexicon=lexicon)\n",
      "    while True:\n",
      "        try:\n",
      "            command = input(\">>> \")\n",
      "        except (EOFError, KeyboardInterrupt):\n",
      "            print()\n",
      "            break\n",
      "\n",
      "        response = execute_command(command, shell_state)\n",
      "        if response is not None:\n",
      "            print(response)\n",
      "\n",
      "\n",
      "def execute_command(command, shell_state):\n",
      "    command = command.strip()\n",
      "    if command.startswith(\"!\"):\n",
      "        command = command[1:]\n",
      "        if command == \"mode\":\n",
      "            return \"You are currently in {} mode.\".format(shell_state.mode)\n",
      "        elif command == \"words\":\n",
      "            return \" \".join(sorted(shell_state.lexicon.keys(), key=str.lower))\n",
      "        elif command.startswith(\"mode \"):\n",
      "            new_mode = command.split(maxsplit=1)[1]\n",
      "            if new_mode in AVAILABLE_MODES:\n",
      "                shell_state.mode = new_mode\n",
      "                return \"Switched to {} mode.\".format(new_mode)\n",
      "            else:\n",
      "                return (\n",
      "                    \"{} is not a recognized mode. Available modes are: {}.\\n\"\n",
      "                    + \"Remaining in {} mode.\"\n",
      "                ).format(new_mode, AVAILABLE_MODES_STR, shell_state.mode)\n",
      "        elif command == \"help\":\n",
      "            return HELP_MESSAGE + \"\\nYou are currently in {} mode.\".format(\n",
      "                shell_state.mode\n",
      "            )\n",
      "        else:\n",
      "            return \"Unrecognized command {}.\".format(command)\n",
      "    elif command:\n",
      "        try:\n",
      "            entries = translate_sentence(command, shell_state.lexicon)\n",
      "        # TODO: Only catch montague errors\n",
      "        except Exception as e:\n",
      "            return \"Error: {}\".format(e)\n",
      "        else:\n",
      "            output = []\n",
      "            for entry in entries:\n",
      "                output.append(\"Denotation: {0.formula}\\nType: {0.type}\".format(entry))\n",
      "            return \"\\n\\n\".join(output)\n",
      "\n",
      "\n",
      "HELP_MESSAGE = \"\"\"\\\n",
      "Available commands:\n",
      "    !mode          Display the current operating mode.\n",
      "    !mode <mode>   Switch the operating mode.\n",
      "    !words         List all words in Montague's lexicon.\n",
      "    !help          Display this help message.\n",
      "    Ctrl+C         Exit the program.\n",
      "\n",
      "Available modes:\n",
      "    translate      Translate English text into logic.\n",
      "\n",
      "\n",
      "Enter a sentence to see its translation!\n",
      "\"\"\"\n",
      "\n",
      "AVAILABLE_MODES = {\"translate\"}\n",
      "AVAILABLE_MODES_STR = \", \".join(AVAILABLE_MODES)\n",
      "\n",
      "PROJECT_DIR = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))\n",
      "FRAGMENT_PATH = os.path.join(PROJECT_DIR, \"montague\", \"resources\", \"fragment.json\")\n",
      "\n",
      "Output: {'main': ['os.path.realpath', 'os.path.join', 'os.path.dirname'], 'main.ShellState.__init__': [], 'main.main': ['sys.exit', '<builtin>.print', 'translator.load_lexicon', 'sys.stderr.write', '<builtin>.open', '<builtin>.input', 'json.load', 'main.execute_command', 'main.ShellState.__init__'], '<builtin>.print': [], '<builtin>.open': [], 'json.load': [], 'translator.load_lexicon': [], 'sys.stderr.write': [], 'sys.exit': [], '<builtin>.input': [], 'main.execute_command': ['translator.translate_sentence', '<builtin>.sorted'], '<builtin>.sorted': [], 'translator.translate_sentence': [], 'os.path.realpath': [], 'os.path.dirname': [], 'os.path.join': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\montague\\main.py\n",
      "[('main', 'os path realpath'), ('main', 'os path join'), ('main', 'os path dirname'), ('main main', 'sys exit'), ('main main', 'translator load_lexicon'), ('main main', 'sys stderr write'), ('main main', 'json load'), ('main main', 'main execute_command'), ('main main', 'main ShellState __init__'), ('main execute_command', 'translator translate_sentence')]\n",
      "0\n",
      "found files: []\n",
      "import pytest\n",
      "\n",
      "from montague.ast import (\n",
      "    And,\n",
      "    Call,\n",
      "    ComplexType,\n",
      "    ForAll,\n",
      "    IfThen,\n",
      "    Iota,\n",
      "    Lambda,\n",
      "    Or,\n",
      "    SentenceNode,\n",
      "    TYPE_ENTITY,\n",
      "    TYPE_TRUTH_VALUE,\n",
      "    Var,\n",
      ")\n",
      "from montague.parser import parse_formula, parse_type\n",
      "from montague.translator import (\n",
      "    LexiconError,\n",
      "    can_combine,\n",
      "    combine,\n",
      "    load_lexicon,\n",
      "    translate_sentence,\n",
      ")\n",
      "\n",
      "\n",
      "TYPE_ET = ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE)\n",
      "\n",
      "\n",
      "def test_translate_is_good(lexicon):\n",
      "    # import pdb; pdb.set_trace()\n",
      "    nodes = translate_sentence(\"is good\", lexicon)\n",
      "\n",
      "    assert len(nodes) == 1\n",
      "\n",
      "    node = nodes[0]\n",
      "    assert node.text == \"is good\"\n",
      "    assert node.formula == Lambda(\"x\", Call(Var(\"Good\"), Var(\"x\")))\n",
      "    assert node.type == TYPE_ET\n",
      "\n",
      "\n",
      "def test_translate_john_is_good(lexicon):\n",
      "    nodes = translate_sentence(\"John is good\", lexicon)\n",
      "\n",
      "    assert len(nodes) == 1\n",
      "\n",
      "    node = nodes[0]\n",
      "    assert node.text == \"John is good\"\n",
      "    assert node.formula == Call(Var(\"Good\"), Var(\"john\"))\n",
      "    assert node.type == TYPE_TRUTH_VALUE\n",
      "\n",
      "\n",
      "def test_translate_john_is_bad(lexicon):\n",
      "    nodes = translate_sentence(\"John is bad\", lexicon)\n",
      "\n",
      "    assert len(nodes) == 1\n",
      "\n",
      "    node = nodes[0]\n",
      "    assert node.text == \"John is bad\"\n",
      "    assert node.formula == Call(Var(\"Bad\"), Var(\"john\"))\n",
      "    assert node.type == TYPE_TRUTH_VALUE\n",
      "\n",
      "\n",
      "def test_translate_every_child_is_good(lexicon):\n",
      "    nodes = translate_sentence(\"every child is good\", lexicon)\n",
      "\n",
      "    assert len(nodes) == 1\n",
      "\n",
      "    node = nodes[0]\n",
      "    assert node.text == \"every child is good\"\n",
      "    assert node.formula == ForAll(\n",
      "        \"x\", IfThen(Call(Var(\"Child\"), Var(\"x\")), Call(Var(\"Good\"), Var(\"x\")))\n",
      "    )\n",
      "    assert node.type == TYPE_TRUTH_VALUE\n",
      "\n",
      "\n",
      "def test_translate_the_child(lexicon):\n",
      "    nodes = translate_sentence(\"the child\", lexicon)\n",
      "\n",
      "    assert len(nodes) == 1\n",
      "\n",
      "    node = nodes[0]\n",
      "    assert node.text == \"the child\"\n",
      "    assert node.formula == Iota(\"x\", Call(Var(\"Child\"), Var(\"x\")))\n",
      "    assert node.type == TYPE_ENTITY\n",
      "\n",
      "\n",
      "def test_translate_unknown_word(lexicon):\n",
      "    nodes = translate_sentence(\"Mikhail\", lexicon)\n",
      "\n",
      "    assert len(nodes) == 3\n",
      "\n",
      "    assert nodes[0].text == \"Mikhail\"\n",
      "    assert nodes[0].formula == Var(\"mikhail\")\n",
      "    assert nodes[0].type == TYPE_ENTITY\n",
      "\n",
      "    assert nodes[1].text == \"Mikhail\"\n",
      "    assert nodes[1].formula == Lambda(\"x\", Call(Var(\"Mikhail\"), Var(\"x\")))\n",
      "    assert nodes[1].type == TYPE_ET\n",
      "\n",
      "    assert nodes[2].text == \"Mikhail\"\n",
      "    assert nodes[2].formula == Lambda(\n",
      "        \"x\", Lambda(\"y\", Call(Call(Var(\"Mikhail\"), Var(\"x\")), Var(\"y\")))\n",
      "    )\n",
      "    assert nodes[2].type == ComplexType(TYPE_ENTITY, TYPE_ET)\n",
      "\n",
      "\n",
      "def test_translate_unknown_word_in_sentence(lexicon):\n",
      "    nodes = translate_sentence(\"John is whorlious\", lexicon)\n",
      "\n",
      "    assert len(nodes) == 2\n",
      "\n",
      "    # TODO [2019-05-20]: For now, this is just wrong (but wrong in the expected way).\n",
      "    assert nodes[0].text == \"John is whorlious\"\n",
      "    assert nodes[0].formula == Call(Var(\"Whorlious\"), Var(\"john\"))\n",
      "    assert nodes[0].type == TYPE_TRUTH_VALUE\n",
      "\n",
      "    assert nodes[1].text == \"John is whorlious\"\n",
      "    assert nodes[1].formula == Call(Var(\"John\"), Var(\"whorlious\"))\n",
      "    assert nodes[1].type == TYPE_TRUTH_VALUE\n",
      "\n",
      "\n",
      "pred = SentenceNode(\"does\", parse_formula(\"Lx.P(x)\"), parse_type(\"<e, t>\"))\n",
      "entity = SentenceNode(\"me\", Var(\"me\"), TYPE_ENTITY)\n",
      "\n",
      "\n",
      "def test_combine_to_saturate_predicate():\n",
      "    assert can_combine(pred, entity)\n",
      "    node = combine(pred, entity)\n",
      "    assert node.text == \"does me\"\n",
      "    assert node.formula == Call(pred.formula, entity.formula)\n",
      "    assert node.type == TYPE_TRUTH_VALUE\n",
      "\n",
      "\n",
      "def test_combine_every_child(lexicon):\n",
      "    every = lexicon[\"every\"][0]\n",
      "    child = lexicon[\"child\"][0]\n",
      "    node = combine(every, child)\n",
      "    assert node.text == \"every child\"\n",
      "    assert node.formula == Call(every.formula, child.formula)\n",
      "    assert node.type == ComplexType(TYPE_ET, TYPE_TRUTH_VALUE)\n",
      "\n",
      "\n",
      "def test_can_combine_is_good(lexicon):\n",
      "    assert can_combine(lexicon[\"is\"][0], lexicon[\"good\"][0])\n",
      "\n",
      "\n",
      "def test_cannot_combine_mismatched_types():\n",
      "    assert not can_combine(pred, pred)\n",
      "    assert not can_combine(entity, pred)\n",
      "    assert not can_combine(entity, entity)\n",
      "\n",
      "\n",
      "def test_simplify_call():\n",
      "    tree = Call(Lambda(\"x\", Var(\"x\")), Var(\"j\"))\n",
      "    assert tree.simplify() == Var(\"j\")\n",
      "\n",
      "\n",
      "def test_simplify_nested_call():\n",
      "    # (Lx.Ly.x & y)(a)(b) -> a & b\n",
      "    tree = Call(\n",
      "        Call(Lambda(\"x\", Lambda(\"y\", And(Var(\"x\"), Var(\"y\")))), Var(\"a\")), Var(\"b\")\n",
      "    )\n",
      "    assert tree.simplify() == And(Var(\"a\"), Var(\"b\"))\n",
      "\n",
      "\n",
      "def test_simplify_call_with_lambda_arg():\n",
      "    # (LP.P(x))(Lx.x | a) -> x | a\n",
      "    tree = Call(\n",
      "        Lambda(\"P\", Call(Var(\"P\"), Var(\"x\"))), Lambda(\"x\", Or(Var(\"x\"), Var(\"a\")))\n",
      "    )\n",
      "    assert tree.simplify() == Or(Var(\"x\"), Var(\"a\"))\n",
      "\n",
      "\n",
      "def test_simplify_super_nested_call():\n",
      "    # (LP.P(a, b))(Lx.Ly.x & y) -> a & b\n",
      "    tree = Call(\n",
      "        Lambda(\"P\", Call(Call(Var(\"P\"), Var(\"a\")), Var(\"b\"))),\n",
      "        Lambda(\"x\", Lambda(\"y\", And(Var(\"x\"), Var(\"y\")))),\n",
      "    )\n",
      "    assert tree.simplify() == And(Var(\"a\"), Var(\"b\"))\n",
      "\n",
      "\n",
      "def test_simplify_every_child(lexicon):\n",
      "    # (LP.LQ.Ax.P(x) -> Q(x))(Lx.Child(x)) -> LQ.Ax.Child(x) -> Q(x)\n",
      "    tree = Call(lexicon[\"every\"][0].formula, lexicon[\"child\"][0].formula)\n",
      "    assert tree.simplify() == Lambda(\n",
      "        \"Q\", ForAll(\"x\", IfThen(Call(Var(\"Child\"), Var(\"x\")), Call(Var(\"Q\"), Var(\"x\"))))\n",
      "    )\n",
      "\n",
      "\n",
      "def test_load_lexicon():\n",
      "    lexicon = load_lexicon(\n",
      "        {\"John\": [{\"d\": \"j\", \"t\": \"e\"}], \"good\": [{\"d\": \"Lx.Good(x)\", \"t\": \"et\"}]}\n",
      "    )\n",
      "    assert lexicon == {\n",
      "        \"John\": [SentenceNode(\"John\", parse_formula(\"j\"), parse_type(\"e\"))],\n",
      "        \"good\": [SentenceNode(\"good\", parse_formula(\"Lx.Good(x)\"), parse_type(\"et\"))],\n",
      "    }\n",
      "\n",
      "\n",
      "def test_load_lexicon_missing_denotation_field():\n",
      "    with pytest.raises(LexiconError) as e:\n",
      "        load_lexicon({\"John\": [{\"t\": \"e\"}]})\n",
      "    assert \"John\" in str(e)\n",
      "\n",
      "\n",
      "def test_load_lexicon_with_missing_type_field():\n",
      "    with pytest.raises(LexiconError) as e:\n",
      "        load_lexicon({\"John\": [{\"d\": \"j\"}]})\n",
      "    assert \"John\" in str(e)\n",
      "\n",
      "\n",
      "def test_load_lexicon_with_invalid_denotation_formula():\n",
      "    with pytest.raises(LexiconError) as e:\n",
      "        load_lexicon({\"John\": [{\"d\": \"???\", \"t\": \"e\"}]})\n",
      "    assert \"John\" in str(e)\n",
      "\n",
      "\n",
      "def test_load_lexicon_with_invalid_type():\n",
      "    with pytest.raises(LexiconError) as e:\n",
      "        load_lexicon({\"John\": [{\"d\": \"j\", \"t\": \"???\"}]})\n",
      "    assert \"John\" in str(e)\n",
      "\n",
      "Output: {'test_translator': ['montague.parser.parse_formula', 'montague.ast.ComplexType', 'montague.ast.SentenceNode', 'montague.parser.parse_type', 'montague.ast.Var'], 'montague.ast.ComplexType': [], 'test_translator.test_translate_is_good': ['montague.translator.translate_sentence', 'montague.ast.Lambda', 'montague.ast.Var', 'montague.ast.Call', '<builtin>.len'], 'montague.translator.translate_sentence': [], '<builtin>.len': [], 'montague.ast.Var': [], 'montague.ast.Call': [], 'montague.ast.Lambda': [], 'test_translator.test_translate_john_is_good': ['montague.translator.translate_sentence', 'montague.ast.Var', 'montague.ast.Call', '<builtin>.len'], 'test_translator.test_translate_john_is_bad': ['montague.translator.translate_sentence', 'montague.ast.Var', 'montague.ast.Call', '<builtin>.len'], 'test_translator.test_translate_every_child_is_good': ['montague.translator.translate_sentence', 'montague.ast.ForAll', 'montague.ast.IfThen', 'montague.ast.Var', 'montague.ast.Call', '<builtin>.len'], 'montague.ast.IfThen': [], 'montague.ast.ForAll': [], 'test_translator.test_translate_the_child': ['montague.translator.translate_sentence', 'montague.ast.Iota', 'montague.ast.Var', 'montague.ast.Call', '<builtin>.len'], 'montague.ast.Iota': [], 'test_translator.test_translate_unknown_word': ['montague.translator.translate_sentence', 'montague.ast.ComplexType', 'montague.ast.Lambda', 'montague.ast.Var', 'montague.ast.Call', '<builtin>.len'], 'test_translator.test_translate_unknown_word_in_sentence': ['montague.translator.translate_sentence', 'montague.ast.Var', 'montague.ast.Call', '<builtin>.len'], 'montague.parser.parse_formula': [], 'montague.parser.parse_type': [], 'montague.ast.SentenceNode': [], 'test_translator.test_combine_to_saturate_predicate': ['montague.translator.can_combine', 'montague.translator.combine', 'montague.ast.Call'], 'montague.translator.can_combine': [], 'montague.translator.combine': [], 'test_translator.test_combine_every_child': ['montague.translator.combine', 'montague.ast.Call', 'montague.ast.ComplexType'], 'test_translator.test_can_combine_is_good': ['montague.translator.can_combine'], 'test_translator.test_cannot_combine_mismatched_types': ['montague.translator.can_combine'], 'test_translator.test_simplify_call': ['montague.ast.Var', 'montague.ast.Call', 'montague.ast.Lambda'], 'test_translator.test_simplify_nested_call': ['montague.ast.And', 'montague.ast.Var', 'montague.ast.Call', 'montague.ast.Lambda'], 'montague.ast.And': [], 'test_translator.test_simplify_call_with_lambda_arg': ['montague.ast.Or', 'montague.ast.Var', 'montague.ast.Call', 'montague.ast.Lambda'], 'montague.ast.Or': [], 'test_translator.test_simplify_super_nested_call': ['montague.ast.And', 'montague.ast.Var', 'montague.ast.Call', 'montague.ast.Lambda'], 'test_translator.test_simplify_every_child': ['montague.ast.Lambda', 'montague.ast.ForAll', 'montague.ast.IfThen', 'montague.ast.Var', 'montague.ast.Call'], 'test_translator.test_load_lexicon': ['montague.parser.parse_type', 'montague.translator.load_lexicon', 'montague.ast.SentenceNode', 'montague.parser.parse_formula'], 'montague.translator.load_lexicon': [], 'test_translator.test_load_lexicon_missing_denotation_field': ['<builtin>.str', 'montague.translator.load_lexicon', 'pytest.raises'], 'pytest.raises': [], '<builtin>.str': [], 'test_translator.test_load_lexicon_with_missing_type_field': ['<builtin>.str', 'montague.translator.load_lexicon', 'pytest.raises'], 'test_translator.test_load_lexicon_with_invalid_denotation_formula': ['<builtin>.str', 'montague.translator.load_lexicon', 'pytest.raises'], 'test_translator.test_load_lexicon_with_invalid_type': ['<builtin>.str', 'montague.translator.load_lexicon', 'pytest.raises']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\test\\test_translator.py\n",
      "[('test_translator', 'montague parser parse_formula'), ('test_translator', 'montague ast ComplexType'), ('test_translator', 'montague ast SentenceNode'), ('test_translator', 'montague parser parse_type'), ('test_translator', 'montague ast Var'), ('test_translator test_translate_is_good', 'montague translator translate_sentence'), ('test_translator test_translate_is_good', 'montague ast Lambda'), ('test_translator test_translate_is_good', 'montague ast Var'), ('test_translator test_translate_is_good', 'montague ast Call'), ('test_translator test_translate_john_is_good', 'montague translator translate_sentence'), ('test_translator test_translate_john_is_good', 'montague ast Var'), ('test_translator test_translate_john_is_good', 'montague ast Call'), ('test_translator test_translate_john_is_bad', 'montague translator translate_sentence'), ('test_translator test_translate_john_is_bad', 'montague ast Var'), ('test_translator test_translate_john_is_bad', 'montague ast Call'), ('test_translator test_translate_every_child_is_good', 'montague translator translate_sentence'), ('test_translator test_translate_every_child_is_good', 'montague ast ForAll'), ('test_translator test_translate_every_child_is_good', 'montague ast IfThen'), ('test_translator test_translate_every_child_is_good', 'montague ast Var'), ('test_translator test_translate_every_child_is_good', 'montague ast Call'), ('test_translator test_translate_the_child', 'montague translator translate_sentence'), ('test_translator test_translate_the_child', 'montague ast Iota'), ('test_translator test_translate_the_child', 'montague ast Var'), ('test_translator test_translate_the_child', 'montague ast Call'), ('test_translator test_translate_unknown_word', 'montague translator translate_sentence'), ('test_translator test_translate_unknown_word', 'montague ast ComplexType'), ('test_translator test_translate_unknown_word', 'montague ast Lambda'), ('test_translator test_translate_unknown_word', 'montague ast Var'), ('test_translator test_translate_unknown_word', 'montague ast Call'), ('test_translator test_translate_unknown_word_in_sentence', 'montague translator translate_sentence')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"The parser for Montague's logical representation language, including type\n",
      "expressions.\n",
      "\n",
      "Author:  Ian Fisher (iafisher@protonmail.com)\n",
      "Version: September 2018\n",
      "\"\"\"\n",
      "from lark import Lark, Transformer\n",
      "from lark.exceptions import LarkError\n",
      "\n",
      "from . import ast\n",
      "from .exceptions import ParseError\n",
      "\n",
      "\n",
      "class TreeToFormula(Transformer):\n",
      "    \"\"\"Transform Lark's parse tree into a formula tree with Formula objects.\"\"\"\n",
      "\n",
      "    def expr(self, matches):\n",
      "        if matches[1] == \"->\":\n",
      "            return ast.IfThen(matches[0], matches[2])\n",
      "        elif matches[1] == \"<->\":\n",
      "            return ast.IfAndOnlyIf(matches[0], matches[2])\n",
      "        else:\n",
      "            raise NotImplementedError\n",
      "\n",
      "    def ifterm(self, matches):\n",
      "        return ast.Or(matches[0], matches[2])\n",
      "\n",
      "    def term(self, matches):\n",
      "        return ast.And(matches[0], matches[2])\n",
      "\n",
      "    def variable(self, matches):\n",
      "        return ast.Var(matches[0])\n",
      "\n",
      "    def lambda_(self, matches):\n",
      "        return ast.Lambda(matches[1], matches[2])\n",
      "\n",
      "    def forall(self, matches):\n",
      "        return ast.ForAll(matches[1], matches[2])\n",
      "\n",
      "    def exists(self, matches):\n",
      "        return ast.Exists(matches[1], matches[2])\n",
      "\n",
      "    def call(self, matches):\n",
      "        # The parse tree allows n-ary functions but the AST only allows unary functions.\n",
      "        # This methods converts the former to the latter, e.g. F(x, y, z) becomes\n",
      "        # F(x)(y)(z), three nested CallNodes.\n",
      "        func = ast.Call(matches[0], matches[1])\n",
      "        for i in range(2, len(matches)):\n",
      "            func = ast.Call(func, matches[i])\n",
      "        return func\n",
      "\n",
      "    def iota(self, matches):\n",
      "        return ast.Iota(matches[1], matches[2])\n",
      "\n",
      "    def not_e(self, matches):\n",
      "        return ast.Not(matches[1])\n",
      "\n",
      "\n",
      "# The grammar of the logical language.\n",
      "formula_parser = Lark(\n",
      "    \"\"\"\n",
      "    ?start: expr\n",
      "\n",
      "    ?expr: ifterm | ifterm IMPLIES expr | ifterm IFF expr\n",
      "\n",
      "    ?ifterm: term | term OR ifterm\n",
      "    ?term: factor | factor AND term\n",
      "    ?factor: variable\n",
      "           | \"[\" expr \"]\"\n",
      "           | call\n",
      "           | lambda_\n",
      "           | forall\n",
      "           | exists\n",
      "           | iota\n",
      "           | NOT factor  -> not_e\n",
      "\n",
      "    call: variable \"(\" _arglist \")\" | \"(\" expr \")\" \"(\" _arglist \")\"\n",
      "    _arglist: ( expr \",\" )* expr\n",
      "\n",
      "    lambda_: LAMBDA SYMBOL \".\" expr\n",
      "    forall: FORALL SYMBOL \".\" expr\n",
      "    exists: EXISTS SYMBOL \".\" expr\n",
      "    iota: IOTA SYMBOL \".\" expr\n",
      "\n",
      "    variable: SYMBOL\n",
      "\n",
      "    SYMBOL: /[B-DF-KM-Za-hj-z][A-Za-z0-9_'-]*/\n",
      "    OR: \"|\"\n",
      "    AND: \"&\"\n",
      "    IMPLIES: \"->\"\n",
      "    IFF: \"<->\"\n",
      "    NOT: \"~\"\n",
      "\n",
      "    LAMBDA: \"L\" | \"\"\n",
      "    FORALL: \"A\" | \"\"\n",
      "    EXISTS: \"E\" | \"\"\n",
      "    IOTA: \"i\" | \"\"\n",
      "\n",
      "    %import common.WS\n",
      "    %ignore WS\n",
      "\"\"\",\n",
      "    parser=\"lalr\",\n",
      "    transformer=TreeToFormula(),\n",
      ")\n",
      "\n",
      "\n",
      "def parse_formula(formula):\n",
      "    \"\"\"Parse `formula`, a string, into a tree of Formula objects.\n",
      "\n",
      "    If the string cannot be parsed, a montague.exceptions.ParseError is raised.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        return formula_parser.parse(formula)\n",
      "    except LarkError as e:\n",
      "        raise ParseError(str(e)) from None\n",
      "\n",
      "\n",
      "class TreeToType(Transformer):\n",
      "    \"\"\"Transform Lark's parse tree into a type tree with ComplexType and AtomicType\n",
      "    objects.\n",
      "    \"\"\"\n",
      "\n",
      "    def type(self, matches):\n",
      "        if len(matches) == 2:\n",
      "            return ast.ComplexType(matches[0], matches[1])\n",
      "        elif len(matches) == 1:\n",
      "            if len(matches[0]) == 2:\n",
      "                return ast.ComplexType(\n",
      "                    ast.AtomicType(matches[0][0]), ast.AtomicType(matches[0][1])\n",
      "                )\n",
      "            else:\n",
      "                return ast.AtomicType(matches[0])\n",
      "        else:\n",
      "            raise NotImplementedError\n",
      "\n",
      "\n",
      "# The grammar of the type mini-language.\n",
      "type_parser = Lark(\n",
      "    \"\"\"\n",
      "    ?start: type\n",
      "\n",
      "    type: \"<\" type \",\" type \">\"\n",
      "        | /[evst]{1,2}/\n",
      "\n",
      "    %import common.WS\n",
      "    %ignore WS\n",
      "\"\"\",\n",
      "    parser=\"lalr\",\n",
      "    transformer=TreeToType(),\n",
      ")\n",
      "\n",
      "\n",
      "def parse_type(typestring):\n",
      "    \"\"\"Parse `typestring` into a tree of ComplexType and AtomicType objects.\n",
      "\n",
      "    If the string cannot be parsed, a montague.exceptions.ParseError is raised.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        return type_parser.parse(typestring)\n",
      "    except LarkError as e:\n",
      "        raise ParseError(str(e)) from None\n",
      "\n",
      "Output: {'parser': ['lark.Lark', 'lark.Transformer.__init__'], 'parser.TreeToFormula.expr': ['ast.IfAndOnlyIf', 'ast.IfThen'], 'ast.IfThen': [], 'ast.IfAndOnlyIf': [], 'parser.TreeToFormula.ifterm': ['ast.Or'], 'ast.Or': [], 'parser.TreeToFormula.term': ['ast.And'], 'ast.And': [], 'parser.TreeToFormula.variable': ['ast.Var'], 'ast.Var': [], 'parser.TreeToFormula.lambda_': ['ast.Lambda'], 'ast.Lambda': [], 'parser.TreeToFormula.forall': ['ast.ForAll'], 'ast.ForAll': [], 'parser.TreeToFormula.exists': ['ast.Exists'], 'ast.Exists': [], 'parser.TreeToFormula.call': ['ast.Call', '<builtin>.range', '<builtin>.len'], 'ast.Call': [], '<builtin>.len': [], '<builtin>.range': [], 'parser.TreeToFormula.iota': ['ast.Iota'], 'ast.Iota': [], 'parser.TreeToFormula.not_e': ['ast.Not'], 'ast.Not': [], 'lark.Transformer.__init__': [], 'lark.Lark': [], 'parser.parse_formula': ['<builtin>.str', 'exceptions.ParseError'], '<builtin>.str': [], 'exceptions.ParseError': [], 'parser.TreeToType.type': ['ast.AtomicType', '<builtin>.len', 'ast.ComplexType'], 'ast.ComplexType': [], 'ast.AtomicType': [], 'parser.parse_type': ['<builtin>.str', 'exceptions.ParseError']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\montague\\parser.py\n",
      "[('parser', 'lark Lark'), ('parser', 'lark Transformer __init__'), ('parser TreeToFormula expr', 'ast IfAndOnlyIf'), ('parser TreeToFormula expr', 'ast IfThen'), ('parser TreeToFormula ifterm', 'ast Or'), ('parser TreeToFormula term', 'ast And'), ('parser TreeToFormula variable', 'ast Var'), ('parser TreeToFormula lambda_', 'ast Lambda'), ('parser TreeToFormula forall', 'ast ForAll'), ('parser TreeToFormula exists', 'ast Exists'), ('parser TreeToFormula call', 'ast Call'), ('parser TreeToFormula iota', 'ast Iota'), ('parser TreeToFormula not_e', 'ast Not'), ('parser parse_formula', 'exceptions ParseError'), ('parser TreeToType type', 'ast AtomicType'), ('parser TreeToType type', 'ast ComplexType'), ('parser parse_type', 'exceptions ParseError')]\n",
      "201\n",
      "found files: []\n",
      "\"\"\"The interpreter that assigns truth values to a logical formula given a model of the\n",
      "world.\n",
      "\n",
      "Author:  Ian Fisher (iafisher@protonmail.com)\n",
      "Version: August 2018\n",
      "\"\"\"\n",
      "from collections import namedtuple\n",
      "\n",
      "from . import ast\n",
      "\n",
      "\n",
      "WorldModel = namedtuple(\"WorldModel\", [\"individuals\", \"assignments\"])\n",
      "\n",
      "\n",
      "def interpret_formula(formula, model):\n",
      "    \"\"\"Given a logical formula and a model of the world, return the formula's denotation\n",
      "    in the model.\n",
      "    \"\"\"\n",
      "    if isinstance(formula, ast.Var):\n",
      "        return model.assignments[formula.value]\n",
      "    elif isinstance(formula, ast.And):\n",
      "        return interpret_formula(formula.left, model) and interpret_formula(\n",
      "            formula.right, model\n",
      "        )\n",
      "    elif isinstance(formula, ast.Or):\n",
      "        return interpret_formula(formula.left, model) or interpret_formula(\n",
      "            formula.right, model\n",
      "        )\n",
      "    elif isinstance(formula, ast.IfThen):\n",
      "        return not interpret_formula(formula.left, model) or interpret_formula(\n",
      "            formula.right, model\n",
      "        )\n",
      "    elif isinstance(formula, ast.Call):\n",
      "        caller = interpret_formula(formula.caller, model)\n",
      "        arg = interpret_formula(formula.arg, model)\n",
      "        return arg in caller\n",
      "    elif isinstance(formula, ast.ForAll):\n",
      "        return len(satisfiers(formula.body, model, formula.symbol)) == len(\n",
      "            model.individuals\n",
      "        )\n",
      "    elif isinstance(formula, ast.Exists):\n",
      "        return len(satisfiers(formula.body, model, formula.symbol)) > 0\n",
      "    elif isinstance(formula, ast.Not):\n",
      "        return not interpret_formula(formula.operand, model)\n",
      "    elif isinstance(formula, ast.Iota):\n",
      "        sset = satisfiers(formula.body, model, formula.symbol)\n",
      "        if len(sset) == 1:\n",
      "            return sset.pop()\n",
      "        else:\n",
      "            return None\n",
      "    else:\n",
      "        # TODO: Handle LambdaNodes differently (they can't be interpreted, but they\n",
      "        # should give a better error message).\n",
      "        raise NotImplementedError(formula.__class__)\n",
      "\n",
      "\n",
      "def satisfiers(formula, model, variable):\n",
      "    individuals = set()\n",
      "    old_value = model.assignments.get(variable)\n",
      "    for individual in model.individuals:\n",
      "        model.assignments[variable] = individual\n",
      "        if interpret_formula(formula, model):\n",
      "            individuals.add(individual)\n",
      "\n",
      "    if old_value is None:\n",
      "        del model.assignments[variable]\n",
      "    else:\n",
      "        model.assignments[variable] = old_value\n",
      "\n",
      "    return individuals\n",
      "\n",
      "Output: {'interpreter': ['collections.namedtuple'], 'collections.namedtuple': [], 'interpreter.interpret_formula': ['<builtin>.NotImplementedError', '<builtin>.len', 'interpreter.satisfiers', '<builtin>.isinstance', 'interpreter.interpret_formula'], '<builtin>.isinstance': [], 'interpreter.satisfiers': ['<builtin>.set', 'interpreter.interpret_formula'], '<builtin>.len': [], '<builtin>.NotImplementedError': [], '<builtin>.set': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\montague\\interpreter.py\n",
      "[('interpreter', 'collections namedtuple'), ('interpreter interpret_formula', 'interpreter satisfiers'), ('interpreter interpret_formula', 'interpreter interpret_formula'), ('interpreter satisfiers', 'interpreter interpret_formula')]\n",
      "95\n",
      "found files: []\n",
      "\"\"\"Pre-commit configuration for git.\n",
      "\n",
      "This file was created by precommit (https://github.com/iafisher/precommit).\n",
      "You are welcome to edit it yourself to customize your pre-commit hook.\n",
      "\"\"\"\n",
      "from precommitlib import checks\n",
      "\n",
      "\n",
      "def init(precommit):\n",
      "    # Generic checks\n",
      "    precommit.check(checks.NoStagedAndUnstagedChanges())\n",
      "    precommit.check(checks.NoWhitespaceInFilePath())\n",
      "    precommit.check(checks.DoNotSubmit())\n",
      "\n",
      "    # Language-specific checks\n",
      "    precommit.check(checks.PythonFormat())\n",
      "    precommit.check(checks.PythonStyle())\n",
      "\n",
      "    precommit.check(\n",
      "        checks.Command([\"mypy\", \"--ignore-missing-imports\"], per_file=True),\n",
      "        pattern=r\".*\\.py\",\n",
      "    )\n",
      "\n",
      "Output: {'precommit': [], 'precommit.init': ['precommitlib.checks.DoNotSubmit', 'precommitlib.checks.Command', 'precommitlib.checks.PythonStyle', 'precommitlib.checks.PythonFormat', 'precommitlib.checks.NoStagedAndUnstagedChanges', 'precommitlib.checks.NoWhitespaceInFilePath'], 'precommitlib.checks.NoStagedAndUnstagedChanges': [], 'precommitlib.checks.NoWhitespaceInFilePath': [], 'precommitlib.checks.DoNotSubmit': [], 'precommitlib.checks.PythonFormat': [], 'precommitlib.checks.PythonStyle': [], 'precommitlib.checks.Command': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\precommit.py\n",
      "[('precommit init', 'precommitlib checks DoNotSubmit'), ('precommit init', 'precommitlib checks Command'), ('precommit init', 'precommitlib checks PythonStyle'), ('precommit init', 'precommitlib checks PythonFormat'), ('precommit init', 'precommitlib checks NoStagedAndUnstagedChanges'), ('precommit init', 'precommitlib checks NoWhitespaceInFilePath')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"\n",
      "Translation from English to the logical representation language.\n",
      "\n",
      "Author:  Ian Fisher (iafisher@protonmail.com)\n",
      "Version: May 2019\n",
      "\"\"\"\n",
      "import itertools\n",
      "from collections import OrderedDict\n",
      "\n",
      "from . import ast\n",
      "from .exceptions import CombinationError, LexiconError, ParseError\n",
      "from .parser import parse_formula, parse_type\n",
      "\n",
      "\n",
      "def translate_sentence(sentence, lexicon):\n",
      "    \"\"\"\n",
      "    Translate `sentence`, a string containing English text, into a logical formula\n",
      "    which represents its truth conditions.\n",
      "    \"\"\"\n",
      "    terms = [lexicon.get(word, default_for_unknown(word)) for word in sentence.split()]\n",
      "    all_possibilities = list(list(t) for t in itertools.product(*terms))\n",
      "    in_progress = []\n",
      "    finished = []\n",
      "    for p in all_possibilities:\n",
      "        if len(p) == 1:\n",
      "            finished.append(p[0])\n",
      "        else:\n",
      "            in_progress.append(p)\n",
      "\n",
      "    while in_progress:\n",
      "        new_in_progress = []\n",
      "        for terms in in_progress:\n",
      "            for new_terms in step(terms):\n",
      "                if len(new_terms) == 1:\n",
      "                    finished.append(new_terms[0])\n",
      "                else:\n",
      "                    new_in_progress.append(new_terms)\n",
      "        in_progress = new_in_progress\n",
      "\n",
      "    for i in range(len(finished)):\n",
      "        finished[i] = finished[i]._replace(formula=finished[i].formula.simplify())\n",
      "\n",
      "    # Weed out duplicate translations by using OrderedDict to simulate an ordered set.\n",
      "    return list(OrderedDict.fromkeys(finished).keys())\n",
      "\n",
      "\n",
      "def step(terms):\n",
      "    stepped_terms = []\n",
      "    for i in range(len(terms) - 1):\n",
      "        try:\n",
      "            combined = combine(terms[i], terms[i + 1])\n",
      "        except CombinationError:\n",
      "            pass\n",
      "        else:\n",
      "            stepped_terms.append(terms[:i] + [combined] + terms[i + 2 :])\n",
      "    return stepped_terms\n",
      "\n",
      "\n",
      "def combine(term1, term2):\n",
      "    \"\"\"Attempt to combine the two terms by function application. If the terms' types are\n",
      "    compatible, then a single term representing the denotation of the two terms combined\n",
      "    is returned. If the types are not compatible, a CombinationError is raised.\n",
      "    \"\"\"\n",
      "    if can_combine(term1, term2):\n",
      "        if term1.type == term2.type:\n",
      "            # Modification\n",
      "            return ast.SentenceNode(\n",
      "                term1.text + \" \" + term2.text,\n",
      "                # TODO [2019-05-20]: Is it safe to introduce a new symbol like this?\n",
      "                ast.Lambda(\n",
      "                    \"x\",\n",
      "                    ast.And(\n",
      "                        ast.Call(term1.formula, ast.Var(\"x\")),\n",
      "                        ast.Call(term2.formula, ast.Var(\"x\")),\n",
      "                    ),\n",
      "                ),\n",
      "                term1.type,\n",
      "            )\n",
      "        else:\n",
      "            # Predication\n",
      "            return ast.SentenceNode(\n",
      "                term1.text + \" \" + term2.text,\n",
      "                ast.Call(term1.formula, term2.formula),\n",
      "                term1.type.right,\n",
      "            )\n",
      "    elif can_combine(term2, term1):\n",
      "        # Don't need to handle the modification case here, because if it applied it\n",
      "        # would have triggered the first if clause.\n",
      "        return ast.SentenceNode(\n",
      "            # `text` should maintain linear order.\n",
      "            term1.text + \" \" + term2.text,\n",
      "            ast.Call(term2.formula, term1.formula),\n",
      "            term2.type.right,\n",
      "        )\n",
      "    else:\n",
      "        raise CombinationError\n",
      "\n",
      "\n",
      "TYPE_ET = ast.ComplexType(ast.TYPE_ENTITY, ast.TYPE_TRUTH_VALUE)\n",
      "\n",
      "\n",
      "def can_combine(term1, term2):\n",
      "    \"\"\"Return True if the terms can be combined.\"\"\"\n",
      "    return (\n",
      "        isinstance(term1.type, ast.ComplexType) and term1.type.left == term2.type\n",
      "    ) or (term1.type == TYPE_ET and term2.type == TYPE_ET and term1.type == term2.type)\n",
      "\n",
      "\n",
      "def load_lexicon(lexicon_json):\n",
      "    \"\"\"Load the lexicon from a dictionary.\n",
      "\n",
      "    If the lexicon is ill-formatted, a LexiconError is raised.\n",
      "    \"\"\"\n",
      "    return {k: load_lexical_entry(k, v) for k, v in lexicon_json.items()}\n",
      "\n",
      "\n",
      "def load_lexical_entry(key, values):\n",
      "    trees = []\n",
      "    for value in values:\n",
      "        try:\n",
      "            denotation = parse_formula(value[\"d\"])\n",
      "        except KeyError:\n",
      "            raise LexiconError('entry for {} has no \"d\" field'.format(key))\n",
      "        except ParseError as e:\n",
      "            raise LexiconError(\"could not parse denotation of {} ({})\".format(key, e))\n",
      "\n",
      "        try:\n",
      "            type_ = parse_type(value[\"t\"])\n",
      "        except KeyError:\n",
      "            raise LexiconError('entry for {} has no \"t\" field'.format(key))\n",
      "        except ParseError as e:\n",
      "            raise LexiconError(\"could not parse type of {} ({})\".format(key, e))\n",
      "\n",
      "        trees.append(ast.SentenceNode(key, denotation, type_))\n",
      "\n",
      "    return trees\n",
      "\n",
      "\n",
      "def default_for_unknown(word):\n",
      "    \"\"\"Provide a default definition for words that are not in the lexicon.\"\"\"\n",
      "    proper_noun = ast.SentenceNode(word, ast.Var(word.lower()), ast.TYPE_ENTITY)\n",
      "    single_place = ast.SentenceNode(\n",
      "        word,\n",
      "        ast.Lambda(\"x\", ast.Call(ast.Var(word.title()), ast.Var(\"x\"))),\n",
      "        ast.ComplexType(ast.TYPE_ENTITY, ast.TYPE_TRUTH_VALUE),\n",
      "    )\n",
      "    double_place = ast.SentenceNode(\n",
      "        word,\n",
      "        ast.Lambda(\n",
      "            \"x\",\n",
      "            ast.Lambda(\n",
      "                \"y\",\n",
      "                ast.Call(ast.Call(ast.Var(word.title()), ast.Var(\"x\")), ast.Var(\"y\")),\n",
      "            ),\n",
      "        ),\n",
      "        ast.ComplexType(\n",
      "            ast.TYPE_ENTITY, ast.ComplexType(ast.TYPE_ENTITY, ast.TYPE_TRUTH_VALUE)\n",
      "        ),\n",
      "    )\n",
      "    return [proper_noun, single_place, double_place]\n",
      "\n",
      "Output: {'translator': ['ast.ComplexType'], 'translator.translate_sentence': ['<builtin>.range', 'translator.step', 'collections.OrderedDict.fromkeys', 'itertools.product', 'translator.default_for_unknown', '<builtin>.len', '<builtin>.list'], 'translator.default_for_unknown': ['ast.Var', 'ast.SentenceNode', 'ast.Lambda', 'ast.Call', 'ast.ComplexType'], '<builtin>.list': [], 'itertools.product': [], '<builtin>.len': [], 'translator.step': ['<builtin>.len', 'translator.combine', '<builtin>.range'], '<builtin>.range': [], 'collections.OrderedDict.fromkeys': [], 'translator.combine': ['translator.can_combine', 'ast.Var', 'ast.SentenceNode', 'exceptions.CombinationError', 'ast.Lambda', 'ast.Call', 'ast.And'], 'translator.can_combine': ['<builtin>.isinstance'], 'ast.Var': [], 'ast.Call': [], 'ast.And': [], 'ast.Lambda': [], 'ast.SentenceNode': [], 'exceptions.CombinationError': [], 'ast.ComplexType': [], '<builtin>.isinstance': [], 'translator.load_lexicon': ['translator.load_lexical_entry'], 'translator.load_lexical_entry': ['exceptions.LexiconError', 'ast.SentenceNode', 'parser.parse_formula', 'parser.parse_type'], 'parser.parse_formula': [], 'exceptions.LexiconError': [], 'parser.parse_type': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\montague\\translator.py\n",
      "[('translator', 'ast ComplexType'), ('translator translate_sentence', 'translator step'), ('translator translate_sentence', 'collections OrderedDict fromkeys'), ('translator translate_sentence', 'itertools product'), ('translator translate_sentence', 'translator default_for_unknown'), ('translator default_for_unknown', 'ast Var'), ('translator default_for_unknown', 'ast SentenceNode'), ('translator default_for_unknown', 'ast Lambda'), ('translator default_for_unknown', 'ast Call'), ('translator default_for_unknown', 'ast ComplexType'), ('translator step', 'translator combine'), ('translator combine', 'translator can_combine'), ('translator combine', 'ast Var'), ('translator combine', 'ast SentenceNode'), ('translator combine', 'exceptions CombinationError'), ('translator combine', 'ast Lambda'), ('translator combine', 'ast Call'), ('translator combine', 'ast And'), ('translator load_lexicon', 'translator load_lexical_entry'), ('translator load_lexical_entry', 'exceptions LexiconError'), ('translator load_lexical_entry', 'ast SentenceNode'), ('translator load_lexical_entry', 'parser parse_formula'), ('translator load_lexical_entry', 'parser parse_type')]\n",
      "407\n",
      "found files: []\n",
      "from montague.ast import And, Call, Exists, ForAll, Iota, Not, Var\n",
      "from montague.interpreter import WorldModel, interpret_formula, satisfiers\n",
      "\n",
      "\n",
      "John = object()\n",
      "Mary = object()\n",
      "\n",
      "\n",
      "test_model = WorldModel(\n",
      "    set([John, Mary]),\n",
      "    {\n",
      "        \"j\": John,\n",
      "        \"m\": Mary,\n",
      "        \"Good\": {John},\n",
      "        \"Bad\": {Mary},\n",
      "        \"Man\": {John},\n",
      "        \"Human\": {Mary, John},\n",
      "        \"Alien\": set(),\n",
      "    },\n",
      ")\n",
      "\n",
      "\n",
      "def test_john_is_good_is_true():\n",
      "    formula = Call(Var(\"Good\"), Var(\"j\"))\n",
      "    assert interpret_formula(formula, test_model)\n",
      "    assert not interpret_formula(Not(formula), test_model)\n",
      "\n",
      "\n",
      "def test_john_is_bad_is_false():\n",
      "    formula = Call(Var(\"Bad\"), Var(\"j\"))\n",
      "    assert not interpret_formula(formula, test_model)\n",
      "    assert interpret_formula(Not(formula), test_model)\n",
      "\n",
      "\n",
      "def test_mary_is_bad_and_john_is_good_is_true():\n",
      "    formula = And(Call(Var(\"Bad\"), Var(\"m\")), Call(Var(\"Good\"), Var(\"j\")))\n",
      "    assert interpret_formula(formula, test_model)\n",
      "\n",
      "\n",
      "def test_everyone_is_bad_is_false():\n",
      "    formula = ForAll(\"x\", Call(Var(\"Bad\"), Var(\"x\")))\n",
      "    assert not interpret_formula(formula, test_model)\n",
      "\n",
      "\n",
      "def test_everyone_is_human_is_true():\n",
      "    formula = ForAll(\"x\", Call(Var(\"Human\"), Var(\"x\")))\n",
      "    assert interpret_formula(formula, test_model)\n",
      "\n",
      "\n",
      "def test_someone_is_bad_is_true():\n",
      "    formula = Exists(\"x\", Call(Var(\"Bad\"), Var(\"x\")))\n",
      "    assert interpret_formula(formula, test_model)\n",
      "\n",
      "\n",
      "def test_someone_is_alien_is_false():\n",
      "    formula = Exists(\"x\", Call(Var(\"Alien\"), Var(\"x\")))\n",
      "    assert not interpret_formula(formula, test_model)\n",
      "\n",
      "\n",
      "def test_the_man_is_john():\n",
      "    formula = Iota(\"x\", Call(Var(\"Man\"), Var(\"x\")))\n",
      "    assert interpret_formula(formula, test_model) == John\n",
      "\n",
      "\n",
      "def test_the_man_is_good_is_true():\n",
      "    formula = Call(Var(\"Good\"), Iota(\"x\", Call(Var(\"Man\"), Var(\"x\"))))\n",
      "    assert interpret_formula(formula, test_model)\n",
      "\n",
      "\n",
      "def test_the_human_is_undefined():\n",
      "    formula = Iota(\"x\", Call(Var(\"Human\"), Var(\"x\")))\n",
      "    assert interpret_formula(formula, test_model) is None\n",
      "\n",
      "\n",
      "def test_satisfiers_good_set():\n",
      "    sset = satisfiers(Call(Var(\"Good\"), Var(\"x\")), test_model, \"x\")\n",
      "    assert sset == {John}\n",
      "\n",
      "\n",
      "def test_satisfiers_bad_set():\n",
      "    sset = satisfiers(Call(Var(\"Bad\"), Var(\"x\")), test_model, \"x\")\n",
      "    assert sset == {Mary}\n",
      "\n",
      "\n",
      "def test_satisfiers_human_set():\n",
      "    sset = satisfiers(Call(Var(\"Human\"), Var(\"x\")), test_model, \"x\")\n",
      "    assert sset == {John, Mary}\n",
      "\n",
      "\n",
      "def test_satisfiers_alien_set():\n",
      "    sset = satisfiers(Call(Var(\"Alien\"), Var(\"x\")), test_model, \"x\")\n",
      "    assert sset == set()\n",
      "\n",
      "\n",
      "def test_satisfiers_does_not_overwrite_assignment():\n",
      "    model = WorldModel({Mary}, {\"j\": John})\n",
      "    satisfiers(Var(\"j\"), model, \"j\")\n",
      "    assert model.assignments[\"j\"] == John\n",
      "\n",
      "\n",
      "def test_satisfiers_does_not_create_assignment():\n",
      "    satisfiers(Var(\"j\"), test_model, \"some_nonexistent_variable\")\n",
      "    assert \"some_nonexistent_variable\" not in test_model.assignments\n",
      "\n",
      "Output: {'test_interpreter': ['<builtin>.set', 'montague.interpreter.WorldModel', '<builtin>.object'], '<builtin>.object': [], '<builtin>.set': [], 'montague.interpreter.WorldModel': [], 'test_interpreter.test_john_is_good_is_true': ['montague.interpreter.interpret_formula', 'montague.ast.Not', 'montague.ast.Call', 'montague.ast.Var'], 'montague.ast.Var': [], 'montague.ast.Call': [], 'montague.interpreter.interpret_formula': [], 'montague.ast.Not': [], 'test_interpreter.test_john_is_bad_is_false': ['montague.interpreter.interpret_formula', 'montague.ast.Not', 'montague.ast.Call', 'montague.ast.Var'], 'test_interpreter.test_mary_is_bad_and_john_is_good_is_true': ['montague.ast.And', 'montague.interpreter.interpret_formula', 'montague.ast.Call', 'montague.ast.Var'], 'montague.ast.And': [], 'test_interpreter.test_everyone_is_bad_is_false': ['montague.interpreter.interpret_formula', 'montague.ast.Call', 'montague.ast.Var', 'montague.ast.ForAll'], 'montague.ast.ForAll': [], 'test_interpreter.test_everyone_is_human_is_true': ['montague.interpreter.interpret_formula', 'montague.ast.Call', 'montague.ast.Var', 'montague.ast.ForAll'], 'test_interpreter.test_someone_is_bad_is_true': ['montague.ast.Exists', 'montague.ast.Call', 'montague.ast.Var', 'montague.interpreter.interpret_formula'], 'montague.ast.Exists': [], 'test_interpreter.test_someone_is_alien_is_false': ['montague.ast.Exists', 'montague.ast.Call', 'montague.ast.Var', 'montague.interpreter.interpret_formula'], 'test_interpreter.test_the_man_is_john': ['montague.ast.Iota', 'montague.ast.Call', 'montague.ast.Var', 'montague.interpreter.interpret_formula'], 'montague.ast.Iota': [], 'test_interpreter.test_the_man_is_good_is_true': ['montague.ast.Iota', 'montague.ast.Call', 'montague.ast.Var', 'montague.interpreter.interpret_formula'], 'test_interpreter.test_the_human_is_undefined': ['montague.ast.Iota', 'montague.ast.Call', 'montague.ast.Var', 'montague.interpreter.interpret_formula'], 'test_interpreter.test_satisfiers_good_set': ['montague.ast.Call', 'montague.ast.Var', 'montague.interpreter.satisfiers'], 'montague.interpreter.satisfiers': [], 'test_interpreter.test_satisfiers_bad_set': ['montague.ast.Call', 'montague.ast.Var', 'montague.interpreter.satisfiers'], 'test_interpreter.test_satisfiers_human_set': ['montague.ast.Call', 'montague.ast.Var', 'montague.interpreter.satisfiers'], 'test_interpreter.test_satisfiers_alien_set': ['<builtin>.set', 'montague.ast.Call', 'montague.ast.Var', 'montague.interpreter.satisfiers'], 'test_interpreter.test_satisfiers_does_not_overwrite_assignment': ['montague.interpreter.WorldModel', 'montague.ast.Var', 'montague.interpreter.satisfiers'], 'test_interpreter.test_satisfiers_does_not_create_assignment': ['montague.ast.Var', 'montague.interpreter.satisfiers']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\test\\test_interpreter.py\n",
      "[('test_interpreter', 'montague interpreter WorldModel'), ('test_interpreter test_john_is_good_is_true', 'montague interpreter interpret_formula'), ('test_interpreter test_john_is_good_is_true', 'montague ast Not'), ('test_interpreter test_john_is_good_is_true', 'montague ast Call'), ('test_interpreter test_john_is_good_is_true', 'montague ast Var'), ('test_interpreter test_john_is_bad_is_false', 'montague interpreter interpret_formula'), ('test_interpreter test_john_is_bad_is_false', 'montague ast Not'), ('test_interpreter test_john_is_bad_is_false', 'montague ast Call'), ('test_interpreter test_john_is_bad_is_false', 'montague ast Var'), ('test_interpreter test_mary_is_bad_and_john_is_good_is_true', 'montague ast And'), ('test_interpreter test_mary_is_bad_and_john_is_good_is_true', 'montague interpreter interpret_formula'), ('test_interpreter test_mary_is_bad_and_john_is_good_is_true', 'montague ast Call'), ('test_interpreter test_mary_is_bad_and_john_is_good_is_true', 'montague ast Var'), ('test_interpreter test_everyone_is_bad_is_false', 'montague interpreter interpret_formula'), ('test_interpreter test_everyone_is_bad_is_false', 'montague ast Call'), ('test_interpreter test_everyone_is_bad_is_false', 'montague ast Var'), ('test_interpreter test_everyone_is_bad_is_false', 'montague ast ForAll'), ('test_interpreter test_everyone_is_human_is_true', 'montague interpreter interpret_formula'), ('test_interpreter test_everyone_is_human_is_true', 'montague ast Call'), ('test_interpreter test_everyone_is_human_is_true', 'montague ast Var'), ('test_interpreter test_everyone_is_human_is_true', 'montague ast ForAll'), ('test_interpreter test_someone_is_bad_is_true', 'montague ast Exists'), ('test_interpreter test_someone_is_bad_is_true', 'montague ast Call'), ('test_interpreter test_someone_is_bad_is_true', 'montague ast Var'), ('test_interpreter test_someone_is_bad_is_true', 'montague interpreter interpret_formula'), ('test_interpreter test_someone_is_alien_is_false', 'montague ast Exists'), ('test_interpreter test_someone_is_alien_is_false', 'montague ast Call'), ('test_interpreter test_someone_is_alien_is_false', 'montague ast Var'), ('test_interpreter test_someone_is_alien_is_false', 'montague interpreter interpret_formula'), ('test_interpreter test_the_man_is_john', 'montague ast Iota')]\n",
      "0\n",
      "found files: []\n",
      "import pytest\n",
      "\n",
      "from montague.ast import (\n",
      "    And,\n",
      "    AtomicType,\n",
      "    Call,\n",
      "    ComplexType,\n",
      "    Exists,\n",
      "    ForAll,\n",
      "    IfAndOnlyIf,\n",
      "    IfThen,\n",
      "    Iota,\n",
      "    Lambda,\n",
      "    Not,\n",
      "    Or,\n",
      "    TYPE_ENTITY,\n",
      "    TYPE_EVENT,\n",
      "    TYPE_TRUTH_VALUE,\n",
      "    TYPE_WORLD,\n",
      "    Var,\n",
      ")\n",
      "from montague.exceptions import ParseError\n",
      "from montague.parser import parse_formula, parse_type\n",
      "\n",
      "\n",
      "def test_parsing_variable():\n",
      "    assert parse_formula(\"a\") == Var(\"a\")\n",
      "    assert parse_formula(\"s8DVY_BUvybJH-VDNS'JhjS\") == Var(\"s8DVY_BUvybJH-VDNS'JhjS\")\n",
      "\n",
      "\n",
      "def test_parsing_conjunction():\n",
      "    assert parse_formula(\"a & a'\") == And(Var(\"a\"), Var(\"a'\"))\n",
      "    assert parse_formula(\"a & b & c\") == And(Var(\"a\"), And(Var(\"b\"), Var(\"c\")))\n",
      "\n",
      "\n",
      "def test_parsing_disjunction():\n",
      "    assert parse_formula(\"b | b0\") == Or(Var(\"b\"), Var(\"b0\"))\n",
      "    assert parse_formula(\"a | b | c\") == Or(Var(\"a\"), Or(Var(\"b\"), Var(\"c\")))\n",
      "\n",
      "\n",
      "def test_parsing_if_then():\n",
      "    assert parse_formula(\"a -> b\") == IfThen(Var(\"a\"), Var(\"b\"))\n",
      "    assert parse_formula(\"a -> b -> c\") == IfThen(Var(\"a\"), IfThen(Var(\"b\"), Var(\"c\")))\n",
      "\n",
      "\n",
      "def test_parsing_if_and_only_if():\n",
      "    assert parse_formula(\"a <-> b\") == IfAndOnlyIf(Var(\"a\"), Var(\"b\"))\n",
      "    assert parse_formula(\"a <-> b <-> c\") == IfAndOnlyIf(\n",
      "        Var(\"a\"), IfAndOnlyIf(Var(\"b\"), Var(\"c\"))\n",
      "    )\n",
      "\n",
      "\n",
      "def test_parsing_negation():\n",
      "    assert parse_formula(\"~a\") == Not(Var(\"a\"))\n",
      "    assert parse_formula(\"~a | b\") == Or(Not(Var(\"a\")), Var(\"b\"))\n",
      "    assert parse_formula(\"~[a | b]\") == Not(Or(Var(\"a\"), Var(\"b\")))\n",
      "\n",
      "\n",
      "def test_parsing_binary_precedence():\n",
      "    assert parse_formula(\"x & y | z -> m\") == IfThen(\n",
      "        Or(And(Var(\"x\"), Var(\"y\")), Var(\"z\")), Var(\"m\")\n",
      "    )\n",
      "    assert parse_formula(\"x | y -> m & z\") == IfThen(\n",
      "        Or(Var(\"x\"), Var(\"y\")), And(Var(\"m\"), Var(\"z\"))\n",
      "    )\n",
      "    assert parse_formula(\"[x | y] & z\") == And(Or(Var(\"x\"), Var(\"y\")), Var(\"z\"))\n",
      "\n",
      "\n",
      "def test_parsing_lambda():\n",
      "    assert parse_formula(\"Lx.Ly.[x & y]\") == Lambda(\n",
      "        \"x\", Lambda(\"y\", And(Var(\"x\"), Var(\"y\")))\n",
      "    )\n",
      "    assert parse_formula(\"L x.L y.[x & y]\") == Lambda(\n",
      "        \"x\", Lambda(\"y\", And(Var(\"x\"), Var(\"y\")))\n",
      "    )\n",
      "    assert parse_formula(\"x.y.[x & y]\") == Lambda(\n",
      "        \"x\", Lambda(\"y\", And(Var(\"x\"), Var(\"y\")))\n",
      "    )\n",
      "\n",
      "\n",
      "def test_parsing_call():\n",
      "    assert parse_formula(\"Happy(x)\") == Call(Var(\"Happy\"), Var(\"x\"))\n",
      "    assert parse_formula(\"Between(x, y & z, [Capital(france)])\") == Call(\n",
      "        Call(Call(Var(\"Between\"), Var(\"x\")), And(Var(\"y\"), Var(\"z\"))),\n",
      "        Call(Var(\"Capital\"), Var(\"france\")),\n",
      "    )\n",
      "    assert parse_formula(\"(Lx.x)(j)\") == Call(Lambda(\"x\", Var(\"x\")), Var(\"j\"))\n",
      "    assert parse_formula(\"((Lx.Ly.x & y) (a)) (b)\") == Call(\n",
      "        Call(Lambda(\"x\", Lambda(\"y\", And(Var(\"x\"), Var(\"y\")))), Var(\"a\")), Var(\"b\")\n",
      "    )\n",
      "\n",
      "\n",
      "def test_parsing_for_all():\n",
      "    assert parse_formula(\"Ax.x & y\") == ForAll(\"x\", And(Var(\"x\"), Var(\"y\")))\n",
      "    assert parse_formula(\"A x.x & y\") == ForAll(\"x\", And(Var(\"x\"), Var(\"y\")))\n",
      "    assert parse_formula(\"x.x & y\") == ForAll(\"x\", And(Var(\"x\"), Var(\"y\")))\n",
      "\n",
      "\n",
      "def test_parsing_exists():\n",
      "    assert parse_formula(\"Ex.x | y\") == Exists(\"x\", Or(Var(\"x\"), Var(\"y\")))\n",
      "    assert parse_formula(\"E x.x | y\") == Exists(\"x\", Or(Var(\"x\"), Var(\"y\")))\n",
      "    assert parse_formula(\"x.x | y\") == Exists(\"x\", Or(Var(\"x\"), Var(\"y\")))\n",
      "\n",
      "\n",
      "def test_parsing_iota():\n",
      "    assert parse_formula(\"ix.Man(x)\") == Iota(\"x\", Call(Var(\"Man\"), Var(\"x\")))\n",
      "    assert parse_formula(\"i x.Man(x)\") == Iota(\"x\", Call(Var(\"Man\"), Var(\"x\")))\n",
      "    # The actual Unicode iota character may be used.\n",
      "    assert parse_formula(\"x.Man(x)\") == Iota(\"x\", Call(Var(\"Man\"), Var(\"x\")))\n",
      "\n",
      "\n",
      "def test_parsing__missing_operand():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_formula(\"a | \")\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_formula(\"b & \")\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_formula(\"| a\")\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_formula(\"& b\")\n",
      "\n",
      "\n",
      "def test_parsing_hanging_bracket():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_formula(\"[x | y\")\n",
      "\n",
      "\n",
      "def test_parsing_lambda_missing_body():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_formula(\"Lx.\")\n",
      "\n",
      "\n",
      "def test_parsing_for_all_missing_body():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_formula(\"Ax.\")\n",
      "\n",
      "\n",
      "def test_parsing_exists_missing_body():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_formula(\"Ex.\")\n",
      "\n",
      "\n",
      "def test_parsing_iota_missing_body():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_formula(\"ix.\")\n",
      "\n",
      "\n",
      "def test_parsing_call_with_no_arg():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_formula(\"Happy()\")\n",
      "\n",
      "\n",
      "def test_parsing_unknown_token():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_formula(\"Lx.x?\")\n",
      "\n",
      "\n",
      "def test_parsing_empty_string():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_formula(\"\")\n",
      "\n",
      "\n",
      "def test_parsing_blank_string():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_formula(\"     \\t    \\n \\r \\f\")\n",
      "\n",
      "\n",
      "def test_parsing_atomic_types():\n",
      "    assert parse_type(\"e\") == TYPE_ENTITY\n",
      "    assert parse_type(\"t\") == TYPE_TRUTH_VALUE\n",
      "    assert parse_type(\"v\") == TYPE_EVENT\n",
      "    assert parse_type(\"s\") == TYPE_WORLD\n",
      "\n",
      "\n",
      "def test_parsing_compound_type():\n",
      "    assert parse_type(\"<e, t>\") == ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE)\n",
      "\n",
      "\n",
      "def test_parsing_abbreviated_compound_types():\n",
      "    assert parse_type(\"et\") == ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE)\n",
      "    assert parse_type(\"vt\") == ComplexType(TYPE_EVENT, TYPE_TRUTH_VALUE)\n",
      "\n",
      "\n",
      "def test_types_are_AtomicType_class():\n",
      "    typ = parse_type(\"<et, et>\")\n",
      "    assert isinstance(typ.left.left, AtomicType)\n",
      "    assert isinstance(typ.left.right, AtomicType)\n",
      "    assert isinstance(typ.right.left, AtomicType)\n",
      "    assert isinstance(typ.right.right, AtomicType)\n",
      "\n",
      "\n",
      "def test_parsing_big_compound_type():\n",
      "    assert parse_type(\"<<e, t>, <e, <s, t>>>\") == ComplexType(\n",
      "        ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE),\n",
      "        ComplexType(TYPE_ENTITY, ComplexType(TYPE_WORLD, TYPE_TRUTH_VALUE)),\n",
      "    )\n",
      "\n",
      "\n",
      "def test_parsing_big_compound_type_with_abbreviations():\n",
      "    assert parse_type(\"<et, <e, st>>\") == ComplexType(\n",
      "        ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE),\n",
      "        ComplexType(TYPE_ENTITY, ComplexType(TYPE_WORLD, TYPE_TRUTH_VALUE)),\n",
      "    )\n",
      "\n",
      "\n",
      "def test_parsing_type_missing_opening_bracket():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_type(\"e, t>\")\n",
      "\n",
      "\n",
      "def test_parsing_type_missing_closing_bracket():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_type(\"<e, t\")\n",
      "\n",
      "\n",
      "def test_parsing_type_trailing_input():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_type(\"<e, t> e\")\n",
      "\n",
      "\n",
      "def test_parsing_type_missing_comma():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_type(\"<e t>\")\n",
      "\n",
      "\n",
      "def test_parsing_type_missing_output_type():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_type(\"<e>\")\n",
      "\n",
      "\n",
      "def test_parsing_type_invalid_abbreviation():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_type(\"evt\")\n",
      "\n",
      "\n",
      "def test_parsing_type_invalid_letter():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_type(\"b\")\n",
      "\n",
      "\n",
      "def test_parsing_type_unknown_token():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_type(\"e?\")\n",
      "\n",
      "\n",
      "def test_parsing_type_empty_string():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_type(\"\")\n",
      "\n",
      "\n",
      "def test_parsing_type_blank():\n",
      "    with pytest.raises(ParseError):\n",
      "        parse_type(\"     \\t    \\n \\r \\f\")\n",
      "\n",
      "Output: {'test_parser': [], 'test_parser.test_parsing_variable': ['montague.ast.Var', 'montague.parser.parse_formula'], 'montague.parser.parse_formula': [], 'montague.ast.Var': [], 'test_parser.test_parsing_conjunction': ['montague.ast.And', 'montague.ast.Var', 'montague.parser.parse_formula'], 'montague.ast.And': [], 'test_parser.test_parsing_disjunction': ['montague.ast.Var', 'montague.parser.parse_formula', 'montague.ast.Or'], 'montague.ast.Or': [], 'test_parser.test_parsing_if_then': ['montague.ast.IfThen', 'montague.ast.Var', 'montague.parser.parse_formula'], 'montague.ast.IfThen': [], 'test_parser.test_parsing_if_and_only_if': ['montague.ast.Var', 'montague.ast.IfAndOnlyIf', 'montague.parser.parse_formula'], 'montague.ast.IfAndOnlyIf': [], 'test_parser.test_parsing_negation': ['montague.ast.Var', 'montague.ast.Not', 'montague.parser.parse_formula', 'montague.ast.Or'], 'montague.ast.Not': [], 'test_parser.test_parsing_binary_precedence': ['montague.ast.IfThen', 'montague.ast.Or', 'montague.ast.And', 'montague.ast.Var', 'montague.parser.parse_formula'], 'test_parser.test_parsing_lambda': ['montague.ast.And', 'montague.ast.Lambda', 'montague.ast.Var', 'montague.parser.parse_formula'], 'montague.ast.Lambda': [], 'test_parser.test_parsing_call': ['montague.ast.Lambda', 'montague.ast.Call', 'montague.ast.And', 'montague.ast.Var', 'montague.parser.parse_formula'], 'montague.ast.Call': [], 'test_parser.test_parsing_for_all': ['montague.ast.ForAll', 'montague.ast.And', 'montague.ast.Var', 'montague.parser.parse_formula'], 'montague.ast.ForAll': [], 'test_parser.test_parsing_exists': ['montague.ast.Exists', 'montague.ast.Var', 'montague.parser.parse_formula', 'montague.ast.Or'], 'montague.ast.Exists': [], 'test_parser.test_parsing_iota': ['montague.ast.Iota', 'montague.ast.Var', 'montague.ast.Call', 'montague.parser.parse_formula'], 'montague.ast.Iota': [], 'test_parser.test_parsing__missing_operand': ['montague.parser.parse_formula', 'pytest.raises'], 'pytest.raises': [], 'test_parser.test_parsing_hanging_bracket': ['montague.parser.parse_formula', 'pytest.raises'], 'test_parser.test_parsing_lambda_missing_body': ['montague.parser.parse_formula', 'pytest.raises'], 'test_parser.test_parsing_for_all_missing_body': ['montague.parser.parse_formula', 'pytest.raises'], 'test_parser.test_parsing_exists_missing_body': ['montague.parser.parse_formula', 'pytest.raises'], 'test_parser.test_parsing_iota_missing_body': ['montague.parser.parse_formula', 'pytest.raises'], 'test_parser.test_parsing_call_with_no_arg': ['montague.parser.parse_formula', 'pytest.raises'], 'test_parser.test_parsing_unknown_token': ['montague.parser.parse_formula', 'pytest.raises'], 'test_parser.test_parsing_empty_string': ['montague.parser.parse_formula', 'pytest.raises'], 'test_parser.test_parsing_blank_string': ['montague.parser.parse_formula', 'pytest.raises'], 'test_parser.test_parsing_atomic_types': ['montague.parser.parse_type'], 'montague.parser.parse_type': [], 'test_parser.test_parsing_compound_type': ['montague.ast.ComplexType', 'montague.parser.parse_type'], 'montague.ast.ComplexType': [], 'test_parser.test_parsing_abbreviated_compound_types': ['montague.ast.ComplexType', 'montague.parser.parse_type'], 'test_parser.test_types_are_AtomicType_class': ['<builtin>.isinstance', 'montague.parser.parse_type'], '<builtin>.isinstance': [], 'test_parser.test_parsing_big_compound_type': ['montague.ast.ComplexType', 'montague.parser.parse_type'], 'test_parser.test_parsing_big_compound_type_with_abbreviations': ['montague.ast.ComplexType', 'montague.parser.parse_type'], 'test_parser.test_parsing_type_missing_opening_bracket': ['montague.parser.parse_type', 'pytest.raises'], 'test_parser.test_parsing_type_missing_closing_bracket': ['montague.parser.parse_type', 'pytest.raises'], 'test_parser.test_parsing_type_trailing_input': ['montague.parser.parse_type', 'pytest.raises'], 'test_parser.test_parsing_type_missing_comma': ['montague.parser.parse_type', 'pytest.raises'], 'test_parser.test_parsing_type_missing_output_type': ['montague.parser.parse_type', 'pytest.raises'], 'test_parser.test_parsing_type_invalid_abbreviation': ['montague.parser.parse_type', 'pytest.raises'], 'test_parser.test_parsing_type_invalid_letter': ['montague.parser.parse_type', 'pytest.raises'], 'test_parser.test_parsing_type_unknown_token': ['montague.parser.parse_type', 'pytest.raises'], 'test_parser.test_parsing_type_empty_string': ['montague.parser.parse_type', 'pytest.raises'], 'test_parser.test_parsing_type_blank': ['montague.parser.parse_type', 'pytest.raises']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\test\\test_parser.py\n",
      "[('test_parser test_parsing_variable', 'montague ast Var'), ('test_parser test_parsing_variable', 'montague parser parse_formula'), ('test_parser test_parsing_conjunction', 'montague ast And'), ('test_parser test_parsing_conjunction', 'montague ast Var'), ('test_parser test_parsing_conjunction', 'montague parser parse_formula'), ('test_parser test_parsing_disjunction', 'montague ast Var'), ('test_parser test_parsing_disjunction', 'montague parser parse_formula'), ('test_parser test_parsing_disjunction', 'montague ast Or'), ('test_parser test_parsing_if_then', 'montague ast IfThen'), ('test_parser test_parsing_if_then', 'montague ast Var'), ('test_parser test_parsing_if_then', 'montague parser parse_formula'), ('test_parser test_parsing_if_and_only_if', 'montague ast Var'), ('test_parser test_parsing_if_and_only_if', 'montague ast IfAndOnlyIf'), ('test_parser test_parsing_if_and_only_if', 'montague parser parse_formula'), ('test_parser test_parsing_negation', 'montague ast Var'), ('test_parser test_parsing_negation', 'montague ast Not'), ('test_parser test_parsing_negation', 'montague parser parse_formula'), ('test_parser test_parsing_negation', 'montague ast Or'), ('test_parser test_parsing_binary_precedence', 'montague ast IfThen'), ('test_parser test_parsing_binary_precedence', 'montague ast Or'), ('test_parser test_parsing_binary_precedence', 'montague ast And'), ('test_parser test_parsing_binary_precedence', 'montague ast Var'), ('test_parser test_parsing_binary_precedence', 'montague parser parse_formula'), ('test_parser test_parsing_lambda', 'montague ast And'), ('test_parser test_parsing_lambda', 'montague ast Lambda'), ('test_parser test_parsing_lambda', 'montague ast Var'), ('test_parser test_parsing_lambda', 'montague parser parse_formula'), ('test_parser test_parsing_call', 'montague ast Lambda'), ('test_parser test_parsing_call', 'montague ast Call'), ('test_parser test_parsing_call', 'montague ast And')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"Exception classes for the Montague package.\n",
      "\n",
      "Author:  Ian Fisher (iafisher@protonmail.com)\n",
      "Version: May 2019\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class CombinationError(Exception):\n",
      "    \"\"\"When two expressions cannot be combined.\"\"\"\n",
      "\n",
      "\n",
      "class LexiconError(Exception):\n",
      "    \"\"\"When the lexicon is ill-formatted.\"\"\"\n",
      "\n",
      "\n",
      "class ParseError(Exception):\n",
      "    \"\"\"When a formula or type could not be parsed.\"\"\"\n",
      "\n",
      "Output: {'exceptions': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\montague\\exceptions.py\n",
      "[]\n",
      "found files: []\n",
      "from setuptools import find_packages, setup\n",
      "\n",
      "\n",
      "with open(\"README.md\", \"r\") as f:\n",
      "    long_description = f.read()\n",
      "\n",
      "\n",
      "setup(\n",
      "    name=\"montague-nlu\",\n",
      "    version=\"0.1.6\",\n",
      "    description=\"Natural language understanding system\",\n",
      "    long_description=long_description,\n",
      "    long_description_content_type=\"text/markdown\",\n",
      "    license=\"MIT\",\n",
      "    author=\"Ian Fisher\",\n",
      "    author_email=\"iafisher@protonmail.com\",\n",
      "    entry_points={\"console_scripts\": [\"montague = montague.main:main\"]},\n",
      "    packages=find_packages(exclude=[\"tests\"]),\n",
      "    package_data={\"montague\": [\"resources/*json\"]},\n",
      "    install_requires=[\"lark-parser==0.6.4\"],\n",
      "    project_urls={\"Source\": \"https://github.com/iafisher/montague\"},\n",
      "    classifiers=[\n",
      "        \"Programming Language :: Python :: 3\",\n",
      "        \"License :: OSI Approved :: MIT License\",\n",
      "        \"Natural Language :: English\",\n",
      "        \"Topic :: Text Processing :: Linguistic\",\n",
      "        \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n",
      "    ],\n",
      ")\n",
      "\n",
      "Output: {'setup': ['setuptools.find_packages', 'setuptools.setup', '<builtin>.open'], '<builtin>.open': [], 'setuptools.find_packages': [], 'setuptools.setup': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\setup.py\n",
      "[('setup', 'setuptools find_packages'), ('setup', 'setuptools setup')]\n",
      "0\n",
      "found files: []\n",
      "import pytest\n",
      "from unittest.mock import patch\n",
      "\n",
      "from montague.ast import (\n",
      "    Call,\n",
      "    ComplexType,\n",
      "    Lambda,\n",
      "    SentenceNode,\n",
      "    TYPE_ENTITY,\n",
      "    TYPE_TRUTH_VALUE,\n",
      "    Var,\n",
      ")\n",
      "from montague.main import ShellState, execute_command, HELP_MESSAGE\n",
      "\n",
      "\n",
      "TEST_LEXICON = {\n",
      "    \"good\": SentenceNode(\n",
      "        \"good\",\n",
      "        Lambda(\"x\", Call(Var(\"Good\"), Var(\"x\"))),\n",
      "        ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE),\n",
      "    ),\n",
      "    \"bad\": SentenceNode(\n",
      "        \"bad\",\n",
      "        Lambda(\"x\", Call(Var(\"Bad\"), Var(\"x\"))),\n",
      "        ComplexType(TYPE_ENTITY, TYPE_TRUTH_VALUE),\n",
      "    ),\n",
      "}\n",
      "\n",
      "\n",
      "@pytest.fixture\n",
      "def shell_state():\n",
      "    return ShellState(lexicon=TEST_LEXICON)\n",
      "\n",
      "\n",
      "def test_shell_command_help(shell_state):\n",
      "    response = execute_command(\"!help\", shell_state)\n",
      "    assert HELP_MESSAGE in response\n",
      "    assert \"currently in \" + shell_state.mode in response\n",
      "\n",
      "\n",
      "def test_shell_command_mode(shell_state):\n",
      "    response = execute_command(\"!mode\", shell_state)\n",
      "    assert shell_state.mode in response\n",
      "\n",
      "\n",
      "def test_shell_command_switch_mode(shell_state):\n",
      "    response = execute_command(\"!mode translate\", shell_state)\n",
      "    assert \"translate\" in response\n",
      "    assert shell_state.mode == \"translate\"\n",
      "\n",
      "\n",
      "def test_shell_command_words(shell_state):\n",
      "    response = execute_command(\"!words\", shell_state)\n",
      "    assert response == \"bad good\"\n",
      "\n",
      "\n",
      "def test_shell_switch_to_unrecognized_mode(shell_state):\n",
      "    old_mode = shell_state.mode\n",
      "    response = execute_command(\"!mode bolivia\", shell_state)\n",
      "    assert \"bolivia is not a recognized mode\" in response\n",
      "    assert shell_state.mode == old_mode\n",
      "\n",
      "\n",
      "def test_shell_display_formula(shell_state):\n",
      "    with patch(\"montague.main.translate_sentence\") as mock_translate_sentence:\n",
      "        mock_translate_sentence.return_value = [\n",
      "            SentenceNode(\"good\", Call(Var(\"Good\"), Var(\"j\")), TYPE_TRUTH_VALUE)\n",
      "        ]\n",
      "        response = execute_command(\"John is good\", shell_state)\n",
      "        assert \"Denotation: Good(j)\" in response\n",
      "        assert \"Type: t\" in response\n",
      "\n",
      "\n",
      "def test_shell_unrecognized_command(shell_state):\n",
      "    response = execute_command(\"!paraguay\", shell_state)\n",
      "    assert \"Unrecognized command paraguay.\" == response\n",
      "\n",
      "Output: {'test_main': ['montague.ast.SentenceNode', 'montague.ast.Lambda', 'pytest.fixture', 'montague.ast.ComplexType', 'montague.ast.Var', 'montague.ast.Call'], 'montague.ast.Var': [], 'montague.ast.Call': [], 'montague.ast.Lambda': [], 'montague.ast.ComplexType': [], 'montague.ast.SentenceNode': [], 'pytest.fixture': [], 'test_main.shell_state': ['montague.main.ShellState'], 'montague.main.ShellState': [], 'test_main.test_shell_command_help': ['montague.main.execute_command'], 'montague.main.execute_command': [], 'test_main.test_shell_command_mode': ['montague.main.execute_command'], 'test_main.test_shell_command_switch_mode': ['montague.main.execute_command'], 'test_main.test_shell_command_words': ['montague.main.execute_command'], 'test_main.test_shell_switch_to_unrecognized_mode': ['montague.main.execute_command'], 'test_main.test_shell_display_formula': ['montague.ast.SentenceNode', 'montague.main.execute_command', 'unittest.mock.patch', 'montague.ast.Var', 'montague.ast.Call'], 'unittest.mock.patch': [], 'test_main.test_shell_unrecognized_command': ['montague.main.execute_command']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\iafisher_montague\\test\\test_main.py\n",
      "[('test_main', 'montague ast SentenceNode'), ('test_main', 'montague ast Lambda'), ('test_main', 'pytest fixture'), ('test_main', 'montague ast ComplexType'), ('test_main', 'montague ast Var'), ('test_main', 'montague ast Call'), ('test_main shell_state', 'montague main ShellState'), ('test_main test_shell_command_help', 'montague main execute_command'), ('test_main test_shell_command_mode', 'montague main execute_command'), ('test_main test_shell_command_switch_mode', 'montague main execute_command'), ('test_main test_shell_command_words', 'montague main execute_command'), ('test_main test_shell_switch_to_unrecognized_mode', 'montague main execute_command'), ('test_main test_shell_display_formula', 'montague ast SentenceNode'), ('test_main test_shell_display_formula', 'montague main execute_command'), ('test_main test_shell_display_formula', 'unittest mock patch'), ('test_main test_shell_display_formula', 'montague ast Var'), ('test_main test_shell_display_formula', 'montague ast Call'), ('test_main test_shell_unrecognized_command', 'montague main execute_command')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('ast And __str__', 'ast wrapb'), ('ast Or __str__', 'ast wrapb'), ('ast IfThen __str__', 'ast wrapb'), ('ast IfAndOnlyIf __str__', 'ast wrapb'), ('ast Not __str__', 'ast wrapb')], [('test_integration', 'montague interpreter WorldModel'), ('test_integration test_john_is_good_is_true', 'montague translator translate_sentence'), ('test_integration test_john_is_good_is_true', 'montague interpreter interpret_formula'), ('test_integration test_john_is_bad_is_false', 'montague translator translate_sentence'), ('test_integration test_john_is_bad_is_false', 'montague interpreter interpret_formula')], [('test_ast test_variable_to_str', 'montague ast Var'), ('test_ast test_and_to_str', 'montague ast Var'), ('test_ast test_and_to_str', 'montague ast And'), ('test_ast test_or_to_str', 'montague ast Var'), ('test_ast test_or_to_str', 'montague ast Or'), ('test_ast test_if_then_to_str', 'montague ast Var'), ('test_ast test_if_then_to_str', 'montague ast IfThen'), ('test_ast test_if_and_only_if_to_str', 'montague ast Var'), ('test_ast test_if_and_only_if_to_str', 'montague ast IfAndOnlyIf'), ('test_ast test_lambda_to_str', 'montague ast Var'), ('test_ast test_lambda_to_str', 'montague ast And'), ('test_ast test_lambda_to_str', 'montague ast Lambda'), ('test_ast test_call_to_str', 'montague ast Var'), ('test_ast test_call_to_str', 'montague ast Call'), ('test_ast test_call_to_str', 'montague ast Lambda'), ('test_ast test_call_to_str', 'montague ast And'), ('test_ast test_for_all_to_str', 'montague ast Var'), ('test_ast test_for_all_to_str', 'montague ast ForAll'), ('test_ast test_for_all_to_str', 'montague ast Call'), ('test_ast test_exists_to_str', 'montague ast Var'), ('test_ast test_exists_to_str', 'montague ast Exists'), ('test_ast test_exists_to_str', 'montague ast Call'), ('test_ast test_not_to_str', 'montague ast Not'), ('test_ast test_not_to_str', 'montague ast Var'), ('test_ast test_not_to_str', 'montague ast Or'), ('test_ast test_binary_operators_to_str', 'montague ast Var'), ('test_ast test_binary_operators_to_str', 'montague ast Or'), ('test_ast test_binary_operators_to_str', 'montague ast And'), ('test_ast test_nested_exists_and_for_all_to_str', 'montague ast Var'), ('test_ast test_nested_exists_and_for_all_to_str', 'montague ast ForAll')], [('conftest', 'pytest fixture'), ('conftest lexicon', 'os path realpath'), ('conftest lexicon', 'os path dirname'), ('conftest lexicon', 'json load'), ('conftest lexicon', 'os path join'), ('conftest lexicon', 'montague translator load_lexicon')], [('main', 'os path realpath'), ('main', 'os path join'), ('main', 'os path dirname'), ('main main', 'sys exit'), ('main main', 'translator load_lexicon'), ('main main', 'sys stderr write'), ('main main', 'json load'), ('main main', 'main execute_command'), ('main main', 'main ShellState __init__'), ('main execute_command', 'translator translate_sentence')], [('test_translator', 'montague parser parse_formula'), ('test_translator', 'montague ast ComplexType'), ('test_translator', 'montague ast SentenceNode'), ('test_translator', 'montague parser parse_type'), ('test_translator', 'montague ast Var'), ('test_translator test_translate_is_good', 'montague translator translate_sentence'), ('test_translator test_translate_is_good', 'montague ast Lambda'), ('test_translator test_translate_is_good', 'montague ast Var'), ('test_translator test_translate_is_good', 'montague ast Call'), ('test_translator test_translate_john_is_good', 'montague translator translate_sentence'), ('test_translator test_translate_john_is_good', 'montague ast Var'), ('test_translator test_translate_john_is_good', 'montague ast Call'), ('test_translator test_translate_john_is_bad', 'montague translator translate_sentence'), ('test_translator test_translate_john_is_bad', 'montague ast Var'), ('test_translator test_translate_john_is_bad', 'montague ast Call'), ('test_translator test_translate_every_child_is_good', 'montague translator translate_sentence'), ('test_translator test_translate_every_child_is_good', 'montague ast ForAll'), ('test_translator test_translate_every_child_is_good', 'montague ast IfThen'), ('test_translator test_translate_every_child_is_good', 'montague ast Var'), ('test_translator test_translate_every_child_is_good', 'montague ast Call'), ('test_translator test_translate_the_child', 'montague translator translate_sentence'), ('test_translator test_translate_the_child', 'montague ast Iota'), ('test_translator test_translate_the_child', 'montague ast Var'), ('test_translator test_translate_the_child', 'montague ast Call'), ('test_translator test_translate_unknown_word', 'montague translator translate_sentence'), ('test_translator test_translate_unknown_word', 'montague ast ComplexType'), ('test_translator test_translate_unknown_word', 'montague ast Lambda'), ('test_translator test_translate_unknown_word', 'montague ast Var'), ('test_translator test_translate_unknown_word', 'montague ast Call'), ('test_translator test_translate_unknown_word_in_sentence', 'montague translator translate_sentence')], [('parser', 'lark Lark'), ('parser', 'lark Transformer __init__'), ('parser TreeToFormula expr', 'ast IfAndOnlyIf'), ('parser TreeToFormula expr', 'ast IfThen'), ('parser TreeToFormula ifterm', 'ast Or'), ('parser TreeToFormula term', 'ast And'), ('parser TreeToFormula variable', 'ast Var'), ('parser TreeToFormula lambda_', 'ast Lambda'), ('parser TreeToFormula forall', 'ast ForAll'), ('parser TreeToFormula exists', 'ast Exists'), ('parser TreeToFormula call', 'ast Call'), ('parser TreeToFormula iota', 'ast Iota'), ('parser TreeToFormula not_e', 'ast Not'), ('parser parse_formula', 'exceptions ParseError'), ('parser TreeToType type', 'ast AtomicType'), ('parser TreeToType type', 'ast ComplexType'), ('parser parse_type', 'exceptions ParseError')], [('interpreter', 'collections namedtuple'), ('interpreter interpret_formula', 'interpreter satisfiers'), ('interpreter interpret_formula', 'interpreter interpret_formula'), ('interpreter satisfiers', 'interpreter interpret_formula')], [('precommit init', 'precommitlib checks DoNotSubmit'), ('precommit init', 'precommitlib checks Command'), ('precommit init', 'precommitlib checks PythonStyle'), ('precommit init', 'precommitlib checks PythonFormat'), ('precommit init', 'precommitlib checks NoStagedAndUnstagedChanges'), ('precommit init', 'precommitlib checks NoWhitespaceInFilePath')], [('translator', 'ast ComplexType'), ('translator translate_sentence', 'translator step'), ('translator translate_sentence', 'collections OrderedDict fromkeys'), ('translator translate_sentence', 'itertools product'), ('translator translate_sentence', 'translator default_for_unknown'), ('translator default_for_unknown', 'ast Var'), ('translator default_for_unknown', 'ast SentenceNode'), ('translator default_for_unknown', 'ast Lambda'), ('translator default_for_unknown', 'ast Call'), ('translator default_for_unknown', 'ast ComplexType'), ('translator step', 'translator combine'), ('translator combine', 'translator can_combine'), ('translator combine', 'ast Var'), ('translator combine', 'ast SentenceNode'), ('translator combine', 'exceptions CombinationError'), ('translator combine', 'ast Lambda'), ('translator combine', 'ast Call'), ('translator combine', 'ast And'), ('translator load_lexicon', 'translator load_lexical_entry'), ('translator load_lexical_entry', 'exceptions LexiconError'), ('translator load_lexical_entry', 'ast SentenceNode'), ('translator load_lexical_entry', 'parser parse_formula'), ('translator load_lexical_entry', 'parser parse_type')], [('test_interpreter', 'montague interpreter WorldModel'), ('test_interpreter test_john_is_good_is_true', 'montague interpreter interpret_formula'), ('test_interpreter test_john_is_good_is_true', 'montague ast Not'), ('test_interpreter test_john_is_good_is_true', 'montague ast Call'), ('test_interpreter test_john_is_good_is_true', 'montague ast Var'), ('test_interpreter test_john_is_bad_is_false', 'montague interpreter interpret_formula'), ('test_interpreter test_john_is_bad_is_false', 'montague ast Not'), ('test_interpreter test_john_is_bad_is_false', 'montague ast Call'), ('test_interpreter test_john_is_bad_is_false', 'montague ast Var'), ('test_interpreter test_mary_is_bad_and_john_is_good_is_true', 'montague ast And'), ('test_interpreter test_mary_is_bad_and_john_is_good_is_true', 'montague interpreter interpret_formula'), ('test_interpreter test_mary_is_bad_and_john_is_good_is_true', 'montague ast Call'), ('test_interpreter test_mary_is_bad_and_john_is_good_is_true', 'montague ast Var'), ('test_interpreter test_everyone_is_bad_is_false', 'montague interpreter interpret_formula'), ('test_interpreter test_everyone_is_bad_is_false', 'montague ast Call'), ('test_interpreter test_everyone_is_bad_is_false', 'montague ast Var'), ('test_interpreter test_everyone_is_bad_is_false', 'montague ast ForAll'), ('test_interpreter test_everyone_is_human_is_true', 'montague interpreter interpret_formula'), ('test_interpreter test_everyone_is_human_is_true', 'montague ast Call'), ('test_interpreter test_everyone_is_human_is_true', 'montague ast Var'), ('test_interpreter test_everyone_is_human_is_true', 'montague ast ForAll'), ('test_interpreter test_someone_is_bad_is_true', 'montague ast Exists'), ('test_interpreter test_someone_is_bad_is_true', 'montague ast Call'), ('test_interpreter test_someone_is_bad_is_true', 'montague ast Var'), ('test_interpreter test_someone_is_bad_is_true', 'montague interpreter interpret_formula'), ('test_interpreter test_someone_is_alien_is_false', 'montague ast Exists'), ('test_interpreter test_someone_is_alien_is_false', 'montague ast Call'), ('test_interpreter test_someone_is_alien_is_false', 'montague ast Var'), ('test_interpreter test_someone_is_alien_is_false', 'montague interpreter interpret_formula'), ('test_interpreter test_the_man_is_john', 'montague ast Iota')], [('test_parser test_parsing_variable', 'montague ast Var'), ('test_parser test_parsing_variable', 'montague parser parse_formula'), ('test_parser test_parsing_conjunction', 'montague ast And'), ('test_parser test_parsing_conjunction', 'montague ast Var'), ('test_parser test_parsing_conjunction', 'montague parser parse_formula'), ('test_parser test_parsing_disjunction', 'montague ast Var'), ('test_parser test_parsing_disjunction', 'montague parser parse_formula'), ('test_parser test_parsing_disjunction', 'montague ast Or'), ('test_parser test_parsing_if_then', 'montague ast IfThen'), ('test_parser test_parsing_if_then', 'montague ast Var'), ('test_parser test_parsing_if_then', 'montague parser parse_formula'), ('test_parser test_parsing_if_and_only_if', 'montague ast Var'), ('test_parser test_parsing_if_and_only_if', 'montague ast IfAndOnlyIf'), ('test_parser test_parsing_if_and_only_if', 'montague parser parse_formula'), ('test_parser test_parsing_negation', 'montague ast Var'), ('test_parser test_parsing_negation', 'montague ast Not'), ('test_parser test_parsing_negation', 'montague parser parse_formula'), ('test_parser test_parsing_negation', 'montague ast Or'), ('test_parser test_parsing_binary_precedence', 'montague ast IfThen'), ('test_parser test_parsing_binary_precedence', 'montague ast Or'), ('test_parser test_parsing_binary_precedence', 'montague ast And'), ('test_parser test_parsing_binary_precedence', 'montague ast Var'), ('test_parser test_parsing_binary_precedence', 'montague parser parse_formula'), ('test_parser test_parsing_lambda', 'montague ast And'), ('test_parser test_parsing_lambda', 'montague ast Lambda'), ('test_parser test_parsing_lambda', 'montague ast Var'), ('test_parser test_parsing_lambda', 'montague parser parse_formula'), ('test_parser test_parsing_call', 'montague ast Lambda'), ('test_parser test_parsing_call', 'montague ast Call'), ('test_parser test_parsing_call', 'montague ast And')], [('setup', 'setuptools find_packages'), ('setup', 'setuptools setup')], [('test_main', 'montague ast SentenceNode'), ('test_main', 'montague ast Lambda'), ('test_main', 'pytest fixture'), ('test_main', 'montague ast ComplexType'), ('test_main', 'montague ast Var'), ('test_main', 'montague ast Call'), ('test_main shell_state', 'montague main ShellState'), ('test_main test_shell_command_help', 'montague main execute_command'), ('test_main test_shell_command_mode', 'montague main execute_command'), ('test_main test_shell_command_switch_mode', 'montague main execute_command'), ('test_main test_shell_command_words', 'montague main execute_command'), ('test_main test_shell_switch_to_unrecognized_mode', 'montague main execute_command'), ('test_main test_shell_display_formula', 'montague ast SentenceNode'), ('test_main test_shell_display_formula', 'montague main execute_command'), ('test_main test_shell_display_formula', 'unittest mock patch'), ('test_main test_shell_display_formula', 'montague ast Var'), ('test_main test_shell_display_formula', 'montague ast Call'), ('test_main test_shell_unrecognized_command', 'montague main execute_command')]]\n",
      "********************doctrings*************************\n",
      "['wrapb [SEP] Return the child node as a string, wrapped in brackets if its precedence is higher than the parent n', 'test john is good is true test john is bad is false', 'test variable to str test and to str test or to str test if then to str test if and only if to str test lambda to str test call to str test for all to str test exists to str test not to str test binary operators to str test nested exists and for all to str test iota to str test entity to str test event to str test truth value to str test world to str test recursive type to str test deeply recursive type to str test recursive type to concise str test deeply recursive type to concise str test simple replace variable test replace variable in and or test replace predicate test replace variable in quantifiers test recursive replace variable test replace variable in iota', 'lexicon', 'main execute command', 'test translate is good test translate john is good test translate john is bad test translate every child is good test translate the child test translate unknown word test translate unknown word in sentence test combine to saturate predicate test combine every child test can combine is good test cannot combine mismatched types test simplify call test simplify nested call test simplify call with lambda arg test simplify super nested call test simplify every child test load lexicon test load lexicon missing denotation field test load lexicon with missing type field test load lexicon with invalid denotation formula test load lexicon with invalid type', 'parse formula parse type [SEP] Parse `formula`, a string, into a tree of Formula objects. If the string cannot be parsed, a montag Parse `typestring` into a tree of ComplexType and AtomicType objects. If the string cannot be parse', \"interpret formula satisfiers [SEP] Given a logical formula and a model of the world, return the formula's denotation in the model.\", 'init', \"translate sentence step combine can combine load lexicon load lexical entry default for unknown [SEP] Translate `sentence`, a string containing English text, into a logical formula which represents its Attempt to combine the two terms by function application. If the terms' types are compatible, then a Return True if the terms can be combined. Load t\", 'test john is good is true test john is bad is false test mary is bad and john is good is true test everyone is bad is false test everyone is human is true test someone is bad is true test someone is alien is false test the man is john test the man is good is true test the human is undefined test satisfiers good set test satisfiers bad set test satisfiers human set test satisfiers alien set test satisfiers does not overwrite assignment test satisfiers does not create assignment', 'test parsing variable test parsing conjunction test parsing disjunction test parsing if then test parsing if and only if test parsing negation test parsing binary precedence test parsing lambda test parsing call test parsing for all test parsing exists test parsing iota test parsing missing operand test parsing hanging bracket test parsing lambda missing body test parsing for all missing body test parsing exists missing body test parsing iota missing body test parsing call with no arg test parsing unknown token test parsing empty string test parsing blank string test parsing atomic types test parsing compound type test parsing abbreviated compound types test types are  tomic ype class test parsing big compound type test parsing big compound type with abbreviations test parsing type missing opening bracket test parsing type missing closing bracket', '', 'shell state test shell command help test shell command mode test shell command switch mode test shell command words test shell switch to unrecognized mode test shell display formula test shell unrecognized command']\n",
      "embed index dataset: 26\n",
      "all relevant repo files: ['C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\helper\\\\accs.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\rst2xml.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\rst2html5.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\rst2html.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\rst2latex.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\checker\\\\test.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\src\\\\checker\\\\stemmer\\\\bangla_stemmer.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\checker\\\\spell_check.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\rstpep2html.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\word2vec\\\\train.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\checker\\\\checker.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\rst2html4.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\checker\\\\suggestion_generation.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\checker\\\\spell_check_ngram.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\rst2pseudoxml.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\src\\\\main\\\\wsgi.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\checker\\\\phonetic_encoder.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\helper\\\\create_sentence.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\django-admin.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\word2vec\\\\sample_train.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\rst2man.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\src\\\\checker\\\\helper.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\rst2xetex.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\src\\\\main\\\\urls.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\checker\\\\stemmer\\\\bangla_stemmer.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\src\\\\checker\\\\views.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\src\\\\checker\\\\urls.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\rst2s5.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\src\\\\main\\\\settings.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\rst2odt_prepstyles.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\src\\\\checker\\\\apps.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\helper\\\\web_crawl.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\checker\\\\spell_check_word2vec.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\jp.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\src\\\\manage.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\word2vec\\\\create_stemmed_corpus.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\activate_this.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\bin\\\\rst2odt.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Bangla-spell_checker\\\\src\\\\checker\\\\phonetic_encoder.py', 'C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\pritomsaha_Context-sensitive-Bangla-spell-checker\\\\Others\\\\helper\\\\phonetic_encoder.py']\n",
      "import re, os\n",
      "from phonetic_encoder import soundex_encode, doublemetaphone_encode\n",
      "bn_char_pattern = re.compile(r'[^\\u0980-\\u0983\\u0985-\\u098C\\u098F-\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BC-\\u09C4\\u09C7-\\u09C8\\u09CB-\\u09CE\\u09D7\\u09DC-\\u09DD\\u09DF-\\u09E3\\u09F0-\\u09FD]+', re.UNICODE)\n",
      "bn_al_pattern = re.compile(r'[\\u0980-\\u0983\\u0985-\\u098C\\u098F-\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BC-\\u09C4\\u09C7-\\u09C8\\u09CB-\\u09CE\\u09D7\\u09DC-\\u09DD\\u09DF-\\u09E3\\u09F0-\\u09FD]+', re.UNICODE)\n",
      "\n",
      "\n",
      "word_freq = {}\n",
      "bnwordlist_path = \"bnwordlist2.txt\"\n",
      "bnwordfreq_path = \"bnwordfreq.txt\"\n",
      "encwordlist_path = \"sd_encwordlist.txt\"\n",
      "corpus_path = \"../corpus/initial_corp\"\n",
      "doublemetaphone = False\n",
      "if doublemetaphone:\n",
      "\tencwordlist_path = \"dm_encwordlist.txt\"\n",
      "\n",
      "def get_wordlist(text):\n",
      "\ttext = re.sub(bn_char_pattern, ' ', text)\n",
      "\twords = text.strip().split(\" \")\n",
      "\treturn (words)\n",
      "\n",
      "\n",
      "def count_word(folder_name):\n",
      "\tfor file_name in os.listdir(folder_name):\n",
      "\t\twith open(folder_name+'/'+file_name, 'r', encoding = \"utf-8\") as infile:\n",
      "\t\t\tfor line in infile:\n",
      "\t\t\t\twords = get_wordlist(line)\n",
      "\t\t\t\tfor word in words:\n",
      "\t\t\t\t\tcount = word_freq.get(word, 0)\n",
      "\t\t\t\t\tword_freq[word] = count + 1\n",
      "\n",
      "\n",
      "def get_word_freq():\n",
      "\tcount_word(corpus_path)\n",
      "\tword_count = {}\n",
      "\twith open(bnwordlist_path, 'r', encoding = \"utf-8\") as infile:\n",
      "\t\tfor line in infile:\n",
      "\t\t\tword = line.strip()\n",
      "\t\t\tcount = word_freq.get(word, 1)\n",
      "\t\t\tword_count[word] = count\n",
      "#\t\t\tyield word, count\n",
      "\treturn word_count\n",
      "\t\t\t\n",
      "# def add_test_word():\n",
      "# \twords = set()\n",
      "# \twith open(bnwordlist_path, 'r', encoding = 'utf-8') as infile:\n",
      "# \t\tfor line in infile:\n",
      "# \t\t\twords.add(line.strip())\n",
      "\n",
      "# \twith open('test.txt', 'r', encoding = 'utf-8') as infile:\n",
      "# \t\tfor line in infile:\n",
      "# \t\t\tword = line.split(\"-\")[1].strip()\n",
      "# \t\t\twords.add(word)\n",
      "\n",
      "# \twords = sorted(list(words))\n",
      "\n",
      "# \twith open(bnwordlist_path, 'w', encoding = 'utf-8') as infile:\n",
      "# \t\tfor word in words:\n",
      "# \t\t\tinfile.write(word+\"\\n\")\n",
      "\n",
      "def create_encoded_freq_lexicon():\n",
      "\t\n",
      "\tdef get_encoded_word(word):\n",
      "\t\treturn doublemetaphone_encode(word) if doublemetaphone else soundex_encode(word)\n",
      "\n",
      "\twith open(encwordlist_path, \"w\", encoding = \"utf-8\") as file:\n",
      "\t\tdic_word_freq = get_word_freq()\n",
      "\t\tmax_count = max(dic_word_freq.values())\n",
      "\t\tprint(max_count)\n",
      "\t\tfor word in dic_word_freq:\n",
      "\t\t\tcount = dic_word_freq[word]/max_count\n",
      "\t\t\tencoded_word = get_encoded_word(word)\n",
      "\t\t\tfile.write(encoded_word+\" \"+word+\" \"+str(count)+\"\\n\")\n",
      "\n",
      "def chunks(data, rows = 10000):\n",
      "\tl = len(data)\n",
      "\tfor i in range(0, l, rows):\n",
      "\t\tyield data[i:i+rows]\n",
      "\n",
      "def save_dic_to_db():\n",
      "\timport sqlite3\n",
      "\tconn = sqlite3.connect(\"../Spell-Checker/spell_checker.db\")\n",
      "\tcur = conn.cursor()\n",
      "\tcur.execute(\"create table if not exists dictionary (word varchar(30) NOT NULL, encoded_word varchar(30) NOT NULL);\")\n",
      "\tcounter = 1\n",
      "\tsql_create_row = \"insert into dictionary (word, encoded_word) values(?, ?);\"\n",
      "\twith open('../dm_encwordlist.txt', 'r') as file:\n",
      "\t\tdata = file.readlines()\n",
      "\t\tchunks_data = chunks(data)\n",
      "\t\tfor chunk in chunks_data:\n",
      "\t\t\trows = []\n",
      "\t\t\tfor line in chunk:\n",
      "\t\t\t\tdata = line.strip().split()\n",
      "\t\t\t\tif len(data) == 3:\n",
      "\t\t\t\t\trows.append((data[1], data[0]))\n",
      "\t\t\t\t\n",
      "\t\t\tcur.executemany(sql_create_row, rows)\n",
      "\t\t\tprint(counter)\n",
      "\t\t\tcounter += 1\n",
      "\n",
      "\tconn.commit()\n",
      "\tconn.close()\n",
      "\t\n",
      "#def sample(text):\n",
      "#\twords = []\n",
      "#\tseparators = []\n",
      "#\tword = \"\"\n",
      "#\t\n",
      "#\twords = re.split(bn_char_pattern,  text)\n",
      "#\tseparators = re.split(bn_al_pattern, text)\n",
      "#\tseparators = list(filter(None, separators))\n",
      "#\ti = 0\n",
      "#\tnew_txt = []\n",
      "#\tfor w in words:\n",
      "#\t\tnew_txt.append(w)\n",
      "#\t\tif i < len(separators):saq78\n",
      "#\t\t\tnew_txt.append(separators[i])\n",
      "#\t\t\ti += 1\n",
      "#\t\t\n",
      "#\tprint(words,\"\\n\", separators)\n",
      "#\tprint(new_txt)\n",
      "\n",
      "\n",
      "def clean_list():\n",
      "\tf = open(\"bangla_words2.txt\", \"w\", encoding =\"utf-8\")\n",
      "\twith open(\"bangla_words.txt\", \"r\") as infile:\n",
      "\t\tfor line in infile:\n",
      "\t\t\twords = line.strip().split()\n",
      "\t\t\tl = \"\"\n",
      "\t\t\tfor w in words:\n",
      "\t\t\t\tif \"\" not in w:\n",
      "\t\t\t\t\tprint(w)\n",
      "\t\t\t\t\tl += w+\" \"\n",
      "\t\t\tf.write(l.strip()+\"\\n\")\n",
      "\t\t\t\n",
      "\tf.close()\n",
      "\t\t\n",
      "\t\n",
      "def create_sentences():\n",
      "\twith open(\"others_.txt\", \"r\") as lines:\n",
      "\t\twith open(\"others.txt\", \"a\") as file:\n",
      "\t\t\tfor line in lines:\n",
      "\t\t\t\tsentences = re.split(r\"\\|\\?\", line)\n",
      "\t\t\t\tsentences = \"\\n\".join(sentence.strip() for sentence in sentences[:-1])\t\t\t\t\n",
      "\t\t\t\tfile.write(sentences)\n",
      "\t\t\t\n",
      "if __name__ == '__main__':\n",
      "#\tclean_list()\n",
      "#\tsample(\",,, ,,           \")\n",
      "\tcreate_encoded_freq_lexicon()\n",
      "#\tcreate_sentences()\n",
      "#\tsave_dic_to_db()\n",
      "\n",
      "\n",
      "\n",
      "                                          ,                      \n",
      "\n",
      "\n",
      "            (   ,        )                       \n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Others\\helper\\accs.py\n",
      "[]\n",
      "found files: []\n",
      "#!/mnt/2ADAADCBDAAD941B/SPL3/Spell-Checker/project/bin/python3\n",
      "\n",
      "# $Id: rst2xml.py 4564 2006-05-21 20:44:42Z wiemann $\n",
      "# Author: David Goodger <goodger@python.org>\n",
      "# Copyright: This module has been placed in the public domain.\n",
      "\n",
      "\"\"\"\n",
      "A minimal front end to the Docutils Publisher, producing Docutils XML.\n",
      "\"\"\"\n",
      "\n",
      "try:\n",
      "    import locale\n",
      "    locale.setlocale(locale.LC_ALL, '')\n",
      "except:\n",
      "    pass\n",
      "\n",
      "from docutils.core import publish_cmdline, default_description\n",
      "\n",
      "\n",
      "description = ('Generates Docutils-native XML from standalone '\n",
      "               'reStructuredText sources.  ' + default_description)\n",
      "\n",
      "publish_cmdline(writer_name='xml', description=description)\n",
      "\n",
      "Output: {'rst2xml': ['locale.setlocale', 'docutils.core.publish_cmdline'], 'locale.setlocale': [], 'docutils.core.publish_cmdline': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Bangla-spell_checker\\bin\\rst2xml.py\n",
      "[('rst2xml', 'locale setlocale'), ('rst2xml', 'docutils core publish_cmdline')]\n",
      "0\n",
      "found files: []\n",
      "#!/mnt/2ADAADCBDAAD941B/SPL3/Spell-Checker/project/bin/python3\n",
      "# -*- coding: utf8 -*-\n",
      "# :Copyright:  2015 Gnter Milde.\n",
      "# :License: Released under the terms of the `2-Clause BSD license`_, in short:\n",
      "#\n",
      "#    Copying and distribution of this file, with or without modification,\n",
      "#    are permitted in any medium without royalty provided the copyright\n",
      "#    notice and this notice are preserved.\n",
      "#    This file is offered as-is, without any warranty.\n",
      "#\n",
      "# .. _2-Clause BSD license: http://www.spdx.org/licenses/BSD-2-Clause\n",
      "#\n",
      "# Revision: $Revision: 7847 $\n",
      "# Date: $Date: 2015-03-17 18:30:47 +0100 (Di, 17 Mr 2015) $\n",
      "\n",
      "\"\"\"\n",
      "A minimal front end to the Docutils Publisher, producing HTML5 documents.\n",
      "\n",
      "The output also conforms to XHTML 1.0 transitional\n",
      "(except for the doctype declaration).\n",
      "\"\"\"\n",
      "\n",
      "try:\n",
      "    import locale # module missing in Jython\n",
      "    locale.setlocale(locale.LC_ALL, '')\n",
      "except locale.Error:\n",
      "    pass\n",
      "\n",
      "from docutils.core import publish_cmdline, default_description\n",
      "\n",
      "description = (u'Generates HTML5 documents from standalone '\n",
      "               u'reStructuredText sources '\n",
      "               + default_description)\n",
      "\n",
      "publish_cmdline(writer_name='html5', description=description)\n",
      "\n",
      "Output: {'rst2html5': ['locale.setlocale', 'docutils.core.publish_cmdline'], 'locale.setlocale': [], 'docutils.core.publish_cmdline': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Bangla-spell_checker\\bin\\rst2html5.py\n",
      "[('rst2html5', 'locale setlocale'), ('rst2html5', 'docutils core publish_cmdline')]\n",
      "0\n",
      "found files: []\n",
      "#!/mnt/2ADAADCBDAAD941B/SPL3/Spell-Checker/project/bin/python3\n",
      "\n",
      "# $Id: rst2html.py 4564 2006-05-21 20:44:42Z wiemann $\n",
      "# Author: David Goodger <goodger@python.org>\n",
      "# Copyright: This module has been placed in the public domain.\n",
      "\n",
      "\"\"\"\n",
      "A minimal front end to the Docutils Publisher, producing HTML.\n",
      "\"\"\"\n",
      "\n",
      "try:\n",
      "    import locale\n",
      "    locale.setlocale(locale.LC_ALL, '')\n",
      "except:\n",
      "    pass\n",
      "\n",
      "from docutils.core import publish_cmdline, default_description\n",
      "\n",
      "\n",
      "description = ('Generates (X)HTML documents from standalone reStructuredText '\n",
      "               'sources.  ' + default_description)\n",
      "\n",
      "publish_cmdline(writer_name='html', description=description)\n",
      "\n",
      "Output: {'rst2html': ['docutils.core.publish_cmdline', 'locale.setlocale'], 'locale.setlocale': [], 'docutils.core.publish_cmdline': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Bangla-spell_checker\\bin\\rst2html.py\n",
      "[('rst2html', 'docutils core publish_cmdline'), ('rst2html', 'locale setlocale')]\n",
      "0\n",
      "found files: []\n",
      "#!/mnt/2ADAADCBDAAD941B/SPL3/Spell-Checker/project/bin/python3\n",
      "\n",
      "# $Id: rst2latex.py 5905 2009-04-16 12:04:49Z milde $\n",
      "# Author: David Goodger <goodger@python.org>\n",
      "# Copyright: This module has been placed in the public domain.\n",
      "\n",
      "\"\"\"\n",
      "A minimal front end to the Docutils Publisher, producing LaTeX.\n",
      "\"\"\"\n",
      "\n",
      "try:\n",
      "    import locale\n",
      "    locale.setlocale(locale.LC_ALL, '')\n",
      "except:\n",
      "    pass\n",
      "\n",
      "from docutils.core import publish_cmdline\n",
      "\n",
      "description = ('Generates LaTeX documents from standalone reStructuredText '\n",
      "               'sources. '\n",
      "               'Reads from <source> (default is stdin) and writes to '\n",
      "               '<destination> (default is stdout).  See '\n",
      "               '<http://docutils.sourceforge.net/docs/user/latex.html> for '\n",
      "               'the full reference.')\n",
      "\n",
      "publish_cmdline(writer_name='latex', description=description)\n",
      "\n",
      "Output: {'rst2latex': ['docutils.core.publish_cmdline', 'locale.setlocale'], 'locale.setlocale': [], 'docutils.core.publish_cmdline': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Bangla-spell_checker\\bin\\rst2latex.py\n",
      "[('rst2latex', 'docutils core publish_cmdline'), ('rst2latex', 'locale setlocale')]\n",
      "0\n",
      "found files: []\n",
      "from spell_check import *\n",
      "\n",
      "def test_nonword(file_name = \"wrong_words.txt\"):\n",
      "\tcount = {\"in_first\": 0, \"in_third\": 0, \"in_tenth\": 0, \"in_all\": 0}\n",
      "\ttotal_words = 0\n",
      "\twith open(file_name, 'r', encoding = \"utf-8\") as infile:\n",
      "\t\tlines = infile.readlines()\n",
      "\t\ttotal_words = len(lines)\n",
      "\t\tfor line in lines:\n",
      "\t\t\twrong, correct = line.split('-')\n",
      "\t\t\tcorrect = correct.strip()\n",
      "\t\t\tsuggestion_dic = get_confusion_set(wrong.strip())\n",
      "\t\t\tsuggestions = sorted(suggestion_dic, key = lambda x: (suggestion_dic[x][0], ))\n",
      "\n",
      "\t\t\tif correct in suggestions:\n",
      "\t\t\t\tcount[\"in_all\"]+=1\n",
      "\t\t\t\tif correct in suggestions[:10]:\n",
      "\t\t\t\t\tcount[\"in_tenth\"]+=1\n",
      "\t\t\t\t\tif correct in suggestions[:3]:\n",
      "\t\t\t\t\t\tcount[\"in_third\"]+=1\n",
      "\t\t\t\t\t\tif correct in suggestions[:1]:\n",
      "\t\t\t\t\t\t\tcount[\"in_first\"]+=1\n",
      "\n",
      "\tfor c in count:\n",
      "\t\tcount[c] = (count[c]/total_words)*100.0\n",
      "\tprint(count)\n",
      "\n",
      "def clean_test_corp():\n",
      "\tfrom random import randint\n",
      "\n",
      "\twith open(\"test_corpus.txt\", \"r\") as infile:\n",
      "\t\tcounter = 0\n",
      "\t\tclean_file = open(\"clean_testcorp.txt\", \"w\")\n",
      "\t\tresult_file = open(\"result.txt\", \"w\")\n",
      "\t\tline_num = 0\n",
      "\t\tfor line in infile:\n",
      "\t\t\twords = get_bn_wordlist(line)\n",
      "\t\t\twords_str = \"\"\n",
      "\t\t\tfor i in range(len(words)):\n",
      "\t\t\t\tword = words[i]\n",
      "\t\t\t\tif counter == 20:\n",
      "\t\t\t\t\tcandidates = get_confusion_set(word)\n",
      "\t\t\t\t\tcandidates = list(candidates.keys())\n",
      "\t\t\t\t\tln = len(candidates)\n",
      "\t\t\t\t\tif ln == 0:\n",
      "\t\t\t\t\t\twords_str += word+\" \"\n",
      "\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\tcounter = 0\n",
      "\t\t\t\t\twhile True:\n",
      "\t\t\t\t\t\tr = randint(0,ln-1)\n",
      "\t\t\t\t\t\tif candidates[r] != word and candidates[r] not in stopwords:\n",
      "\t\t\t\t\t\t\tt = word==candidates[r]\n",
      "\t\t\t\t\t\t\tif t:\n",
      "\t\t\t\t\t\t\t\tprint(t)\n",
      "\t\t\t\t\t\t\t\treturn\n",
      "\n",
      "\t\t\t\t\t\t\tresult_file.write(candidates[r]+\" \"+word+\" \"+str(line_num)+\" \"+str(i)+\"\\n\")\n",
      "\t\t\t\t\t\t\tword = candidates[r]\n",
      "\t\t\t\t\t\t\tbreak\n",
      "\t\t\t\t\t\tif ln == 1:\n",
      "\t\t\t\t\t\t\tbreak\n",
      "\n",
      "\n",
      "\t\t\t\tcounter += 1\n",
      "\t\t\t\twords_str += word+\" \"\n",
      "\t\t\t\n",
      "\t\t\tclean_file.write(words_str.strip()+\"\\n\")\n",
      "\t\t\tline_num += 1\n",
      "\t\tclean_file.close()\n",
      "\t\tresult_file.close()\n",
      "\t\t\n",
      "def save_test_result():\n",
      "\twith open(\"clean_testcorp.txt\", \"r\") as infile:\n",
      "\t\tline_num = 0\n",
      "\t\ttest_result_f = open('test_result.txt', 'w')\n",
      "\t\tfor line in infile:\n",
      "\t\t\tword_list = line.strip().split()\n",
      "\t\t\tfor i, suggestions in check(word_list):\n",
      "\t\t\t\tif suggestions:\n",
      "\t\t\t\t\tsuggestions_str = \",\".join(s for s in suggestions)\n",
      "\t\t\t\t\ttest_result_f.write(word_list[i]+\" \"+\" \"+str(line_num)+\" \"+str(i)+\" \"+suggestions_str+\"\\n\")\n",
      "\t\t\tline_num += 1\n",
      "\t\ttest_result_f.close()\n",
      "\t\t\n",
      "\t\n",
      "\t\t\n",
      "def get_final_result():\n",
      "\tresults = []\n",
      "\treal_words = []\n",
      "\tnum_error = 0\n",
      "\terror_detected = 0\n",
      "\ttrue_positive = 0\n",
      "\twith open(\"result.txt\", 'r') as infile:\n",
      "\t\t\n",
      "\t\tfor line in infile:\n",
      "\t\t\trs = line.split()\n",
      "\t\t\treal_words.append(rs[1])\n",
      "\t\t\trs = rs[:1]+rs[2:]\n",
      "\t\t\trs_str = ''.join(r for r in rs)\n",
      "\t\t\tresults.append(rs_str)\n",
      "\t\t\tnum_error += 1\n",
      "\t\n",
      "#\tprint(real_words)\n",
      "#\treturn\n",
      "\tsuggest_acc = {}\t\n",
      "\twith open(\"test_result.txt\", 'r') as infile:\n",
      "\t\t\n",
      "\t\tfor line in infile:\n",
      "\t\t\tsplit = line.split()\n",
      "\t\t\ttrs = split[:3]\n",
      "\t\t\tsuggestions = split[3].split(\",\")\n",
      "\t\t\ttrs_str = ''.join(t for t in trs)\n",
      "\t\t\tif trs_str in results:\n",
      "\t\t\t\ttrue_positive += 1\n",
      "\t\t\t\tindex = results.index(trs_str)\n",
      "\t\t\t\tif real_words[index] in suggestions[:1]:\n",
      "\t\t\t\t\tsuggest_acc[1] = suggest_acc.get(1, 0) + 1\n",
      "\t\t\t\tif real_words[index] in suggestions[:3]:\n",
      "\t\t\t\t\tsuggest_acc[3] = suggest_acc.get(3, 0) + 1\n",
      "\t\t\t\tif real_words[index] in suggestions[:5]:\t\t\t\t\n",
      "\t\t\t\t\tsuggest_acc[5] = suggest_acc.get(5, 0) + 1\n",
      "\t\t\terror_detected += 1\n",
      "\t\t\t\n",
      "\tprecision = true_positive/error_detected\n",
      "\trecall = true_positive/num_error\n",
      "\t\t\t\n",
      "\tprint(\"true_positive:\",true_positive, \"error_detected:\", error_detected, \"num_error:\", num_error)\n",
      "\tprint(\"precision : \",precision)\n",
      "\tprint(\"recall :\", recall)\n",
      "#\tprint(suggest_acc)\n",
      "\t\n",
      "clean_test_corp()\n",
      "save_test_result()\n",
      "get_final_result()\t\n",
      "#test_nonword()\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Others\\checker\\test.py\n",
      "[]\n",
      "found files: []\n",
      "import re, os\n",
      "\n",
      "class RuleFileParser(object):\n",
      "\t\n",
      "\tCURLY_OPEN = \"{\"\n",
      "\tCURLY_CLOSE = \"}\"\n",
      "\t\n",
      "\tdef __init__(self, rule_file_path = \"common.rules\"):\n",
      "\t\tcurrent_abs_path = os.path.dirname(os.path.abspath(__file__))\n",
      "\t\trule_file_path = current_abs_path+'/'+rule_file_path\n",
      "\t\tself.lines = []\n",
      "\t\tself.passes = []\n",
      "\t\tself.replaceRule = {}\n",
      "\t\tself.dependant_vowels_unicode = re.compile(r'[\\u09BE-\\u09C4\\u09C7-\\u09C8\\u09CB-\\u09CD]', re.UNICODE)\n",
      "\n",
      "\t\twith open(rule_file_path, 'r', encoding = \"utf-8\") as infile:\n",
      "\t\t\tfor line in infile:\n",
      "\t\t\t\tline = self.commentTrim(line)\n",
      "\t\t\t\tline = line.strip()\n",
      "\t\t\t\tif len(line) == 0:\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\tline, replace = self.extractReplaceRule(line)\n",
      "\t\t\t\tself.replaceRule[line] = replace\n",
      "\t\t\t\tself.lines.append(line)\n",
      "\n",
      "\t\t\tl, cnt = len(self.lines), 0\n",
      "\t\t\tfor i in range(l):\n",
      "\t\t\t\tif self.lines[i] == self.CURLY_OPEN:\n",
      "\t\t\t\t\tself.passes.append([])\n",
      "\t\t\t\t\ti += 1\n",
      "\t\t\t\t\twhile i<l and self.lines[i]!=self.CURLY_CLOSE:\n",
      "\t\t\t\t\t\tself.passes[cnt].append(self.lines[i])\n",
      "\t\t\t\t\t\ti += 1\n",
      "\t\t\t\t\tcnt += 1\n",
      "\n",
      "\n",
      "\tdef extractReplaceRule(self, string):\n",
      "\t\tif \"->\" in string:\n",
      "\t\t\tsplit = string.split(\"->\")\n",
      "\t\t\treturn split[0].strip(), split[1].strip()\n",
      "\t\treturn string, \"\"\n",
      "\n",
      "\tdef commentTrim(self, string):\n",
      "\t\treturn re.sub(\"#.*\", \"\", string)\n",
      "\n",
      "\tdef check(self, word):\n",
      "\t\tl = len(re.sub(self.dependant_vowels_unicode, \"\", word))\n",
      "\t\tl -= word.count(\"\\u09CD\")\n",
      "\t\treturn l >=2\n",
      "\n",
      "\tdef stemOfWord(self, word):\n",
      "\t\tfor _pass in self.passes:\n",
      "\t\t\tfor replace_prefix in _pass:\n",
      "\t\t\t\tpattern = re.compile(\".*\"+replace_prefix+\"$\")\n",
      "\t\t\t\tif pattern.match(word):\n",
      "\t\t\t\t\treplace_suffix = self.replaceRule[replace_prefix]\n",
      "\t\t\t\t\tnew_word = word[:(len(word) - len(replace_prefix))]\n",
      "\t\t\t\t\tif len(replace_suffix):\n",
      "\t\t\t\t\t\trest_word = word[(len(word) - len(replace_prefix)):]\n",
      "\t\t\t\t\t\tfor i in range(len(replace_suffix)):\n",
      "\t\t\t\t\t\t\tif replace_suffix[i] == \".\":\n",
      "\t\t\t\t\t\t\t\tnew_word += rest_word[i]\n",
      "\t\t\t\t\t\t\telse:\n",
      "\t\t\t\t\t\t\t\tnew_word += replace_suffix[i]\n",
      "\t\t\t\t\t\tword = new_word\n",
      "\t\t\t\t\telif self.check(new_word):\n",
      "\t\t\t\t\t\tword = new_word\n",
      "\t\t\t\t\tbreak\n",
      "\n",
      "\t\treturn word\n",
      "\n",
      "\tdef stemOfWords(self, words):\n",
      "\t\twords = [self.stemOfWord(w) for w in words]\n",
      "\t\treturn words\n",
      "\n",
      "\n",
      "bangla_stemmer = RuleFileParser()\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\tprint(\"hi\")\n",
      "\trule_file_parser = RuleFileParser()\n",
      "\twith open(\"input.txt\", \"r\") as lines:\n",
      "\t\twith open(\"output.txt\", \"w\") as file:\n",
      "\t\t\tfor line in lines:\n",
      "\t\t\t\tstem_word = rule_file_parser.stemOfWord(line.strip())\n",
      "\t\t\t\tprint(stem_word)\n",
      "\t\t\t\tfile.write(stem_word+\"\\n\")\n",
      "\n",
      "Output: {'bangla_stemmer': ['bangla_stemmer.RuleFileParser.stemOfWord', '<builtin>.print', 'bangla_stemmer.RuleFileParser.__init__', '<builtin>.open'], 'bangla_stemmer.RuleFileParser.__init__': ['os.path.abspath', 'bangla_stemmer.RuleFileParser.commentTrim', '<builtin>.range', '<builtin>.len', 'bangla_stemmer.RuleFileParser.extractReplaceRule', 'os.path.dirname', 're.compile', '<builtin>.open'], 'os.path.abspath': [], 'os.path.dirname': [], 're.compile': [], '<builtin>.open': [], 'bangla_stemmer.RuleFileParser.commentTrim': ['re.sub'], '<builtin>.len': [], 'bangla_stemmer.RuleFileParser.extractReplaceRule': [], '<builtin>.range': [], 're.sub': [], 'bangla_stemmer.RuleFileParser.check': ['<builtin>.len', 're.sub'], 'bangla_stemmer.RuleFileParser.stemOfWord': ['<builtin>.len', '<builtin>.range', 're.compile', 'bangla_stemmer.RuleFileParser.check'], 'bangla_stemmer.RuleFileParser.stemOfWords': ['bangla_stemmer.RuleFileParser.stemOfWord'], '<builtin>.print': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Bangla-spell_checker\\src\\checker\\stemmer\\bangla_stemmer.py\n",
      "[('bangla_stemmer', 'bangla_stemmer RuleFileParser stemOfWord'), ('bangla_stemmer', 'bangla_stemmer RuleFileParser __init__'), ('bangla_stemmer RuleFileParser __init__', 'os path abspath'), ('bangla_stemmer RuleFileParser __init__', 'bangla_stemmer RuleFileParser commentTrim'), ('bangla_stemmer RuleFileParser __init__', 'bangla_stemmer RuleFileParser extractReplaceRule'), ('bangla_stemmer RuleFileParser __init__', 'os path dirname'), ('bangla_stemmer RuleFileParser __init__', 're compile'), ('bangla_stemmer RuleFileParser commentTrim', 're sub'), ('bangla_stemmer RuleFileParser check', 're sub'), ('bangla_stemmer RuleFileParser stemOfWord', 're compile'), ('bangla_stemmer RuleFileParser stemOfWord', 'bangla_stemmer RuleFileParser check'), ('bangla_stemmer RuleFileParser stemOfWords', 'bangla_stemmer RuleFileParser stemOfWord')]\n",
      "0\n",
      "found files: []\n",
      "import time\n",
      "from phonetic_encoder import doublemetaphone_encode, soundex_encode\n",
      "from stemmer.bangla_stemmer import bangla_stemmer\n",
      "from gensim.models import Word2Vec, KeyedVectors\n",
      "from gensim.matutils import unitvec\n",
      "import numpy as np\n",
      "import re\n",
      "\n",
      "doublemetaphone = True\n",
      "dict_path = \"sd_encwordlist.txt\"\n",
      "if doublemetaphone:\n",
      "\tdict_path = \"dm_encwordlist.txt\"\n",
      "\t\n",
      "model_path = \"../word2vec/bn_model_sg1_win5_hs1_negative10\"\n",
      "bn_char_pattern = re.compile(r'[^\\u0980-\\u0983\\u0985-\\u098C\\u098F-\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BC-\\u09C4\\u09C7-\\u09C8\\u09CB-\\u09CE\\u09D7\\u09DC-\\u09DD\\u09DF-\\u09E3\\u09F0-\\u09FD]', re.UNICODE)\n",
      "stopwords_path = \"../stop-words.txt\"\n",
      "stopwords = open(stopwords_path, 'r').read().rstrip('\\n').split(',')\n",
      "max_edit_distance = 1\n",
      "\n",
      "wordlist, delete_word_dic, encode_to_word_dic =set(), {}, {}\n",
      "\n",
      "def get_bn_wordlist(text, remove_stopwords = True):\n",
      "\ttext = re.sub(bn_char_pattern, ' ', text)\n",
      "\twords = text.strip().split()\n",
      "\tif remove_stopwords:\n",
      "\t\twords = [w for w in words if w not in stopwords]\n",
      "\n",
      "\treturn words\n",
      "\n",
      "def get_edit_distance(s1, s2):\n",
      "    if len(s1) > len(s2):\n",
      "        s1, s2 = s2, s1\n",
      "    distances = range(len(s1) + 1)\n",
      "    for i2, c2 in enumerate(s2):\n",
      "        distances_ = [i2+1]\n",
      "        for i1, c1 in enumerate(s1):\n",
      "            if c1 == c2:\n",
      "                distances_.append(distances[i1])\n",
      "            else:\n",
      "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
      "        distances = distances_\n",
      "    return distances[-1]\n",
      "\n",
      "\n",
      "def get_encoded_word(word):\n",
      "\tif doublemetaphone:\n",
      "\t\treturn doublemetaphone_encode(word)\n",
      "\treturn soundex_encode(word)\n",
      "\t\n",
      "def weighted_distance(phonetic_edit_dist, edit_dist):\n",
      "\treturn phonetic_edit_dist*0.6 + edit_dist*0.4\n",
      "\n",
      "def create_delete_list(word, delete_words, edit_distance = 1):\n",
      "\tl = len(word)\n",
      "\tif edit_distance > max_edit_distance or l <3 : return\n",
      "\t\n",
      "\tfor c in range(l):\n",
      "\t\tnew_word = word[:c] + word[c+1:]\n",
      "\t\tif new_word not in delete_words:\n",
      "\t\t\tdelete_words.append(new_word)\n",
      "\t\t\tif len(new_word) > 2:\n",
      "\t\t\t\tcreate_delete_list(new_word, delete_words, edit_distance + 1)\n",
      "\n",
      "def generate_dictionary():\n",
      "\twith open(dict_path, 'r', encoding = \"utf-8\") as lines:\n",
      "\t\tfor line in lines:\n",
      "\t\t\tencoded_word, real_word,  count = line.strip().split()\n",
      "\t\t\twordlist.add(real_word)\n",
      "\t\t\tif encoded_word in encode_to_word_dic:\n",
      "\t\t\t\tencode_to_word_dic[encoded_word].append(real_word)\n",
      "\t\t\telse: \n",
      "\t\t\t\tencode_to_word_dic[encoded_word] = [real_word]\n",
      "\n",
      "\t\t\tif encoded_word not in delete_word_dic:\n",
      "\t\t\t\tdelete_word_dic[encoded_word] = []\n",
      "\t\t\t\n",
      "\t\t\tdelete_words = []\n",
      "\t\t\tcreate_delete_list(encoded_word, delete_words)\n",
      "\n",
      "\t\t\tfor item in delete_words:\n",
      "\t\t\t\tif item in delete_word_dic:\n",
      "\t\t\t\t\tdelete_word_dic[item].append(encoded_word)\n",
      "\t\t\t\telse: delete_word_dic[item] = [encoded_word]\n",
      "\treturn delete_word_dic, encode_to_word_dic\n",
      "\t\n",
      "def get_confusion_set(input_word):\n",
      "\tsuggestion_dic = {}\n",
      "\tencoded_input_word = get_encoded_word(input_word)\n",
      "\tencoded_input_word_len = len(encoded_input_word)\n",
      "\tlisted_encoded_words = []\n",
      "\tif encoded_input_word in delete_word_dic:\n",
      "\t\tif encoded_input_word in encode_to_word_dic:\n",
      "\t\t\tlisted_encoded_words.append(encoded_input_word)\n",
      "\t\t\tphonetic_edit_dist = 0\n",
      "\t\t\tfor word in encode_to_word_dic[encoded_input_word]:\n",
      "\t\t\t\tif word == input_word:\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\tweighted_edit_distance = weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word))\n",
      "#\t\t\t\tif weighted_edit_distance > max_edit_distance:\n",
      "#\t\t\t\t\tcontinue\n",
      "\t\t\t\tsuggestion_dic[word] = (weighted_edit_distance, )\n",
      "\n",
      "\t\tfor encoded_word in delete_word_dic[encoded_input_word]:\n",
      "\t\t\tif encoded_word not in listed_encoded_words:\n",
      "\t\t\t\tlisted_encoded_words.append(encoded_word)\n",
      "\t\t\t\tphonetic_edit_dist = len(encoded_word) - encoded_input_word_len\n",
      "\t\t\t\tfor word in encode_to_word_dic[encoded_word]:\n",
      "\t\t\t\t\tweighted_edit_distance = weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word))\n",
      "#\t\t\t\t\tif weighted_edit_distance > max_edit_distance:\n",
      "#\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\tsuggestion_dic[word] = (weighted_edit_distance, )\n",
      "\n",
      "\tencoded_delete_words = []\n",
      "\tcreate_delete_list(encoded_input_word, encoded_delete_words)\n",
      "\tfor encoded_delete_word in encoded_delete_words:\n",
      "\t\tif encoded_delete_word in delete_word_dic:\n",
      "\t\t\tif encoded_delete_word in encode_to_word_dic:\n",
      "\t\t\t\tif encoded_delete_word not in listed_encoded_words:\n",
      "\t\t\t\t\tlisted_encoded_words.append(encoded_delete_word)\n",
      "\t\t\t\t\tphonetic_edit_dist = encoded_input_word_len - len(encoded_delete_word)\n",
      "\t\t\t\t\tfor word in encode_to_word_dic[encoded_delete_word]:\n",
      "\t\t\t\t\t\tweighted_edit_distance = weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word))\n",
      "#\t\t\t\t\t\tif weighted_edit_distance > max_edit_distance:\n",
      "#\t\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\t\tsuggestion_dic[word] = (weighted_edit_distance, )\n",
      "\n",
      "\t\t\tfor encoded_word in delete_word_dic[encoded_delete_word]:\n",
      "\t\t\t\tif encoded_word not in listed_encoded_words:\n",
      "\t\t\t\t\tlisted_encoded_words.append(encoded_word)\n",
      "\t\t\t\t\tphonetic_edit_dist = get_edit_distance(encoded_word, encoded_input_word)\n",
      "\t\t\t\t\tfor word in encode_to_word_dic[encoded_word]:\n",
      "\t\t\t\t\t\tweighted_edit_distance = weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word))\n",
      "#\t\t\t\t\t\tif weighted_edit_distance > max_edit_distance:\n",
      "#\t\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\t\tsuggestion_dic[word] = (weighted_edit_distance, )\n",
      "\treturn suggestion_dic\n",
      "\n",
      "\n",
      "def cosine_similarity_score(word, context_words):\n",
      "\tif word not in wv: return 0.0\n",
      "\tif len(context_words) == 0: return 0.0\n",
      "\tcontext_vectors = [wv[w] for w in context_words]\n",
      "\tvector_mean = np.mean(np.array(context_vectors), axis=0, dtype=np.float64)\n",
      "\tdot_product = unitvec(wv[word]).dot(unitvec(np.array(vector_mean)))\n",
      "\treturn dot_product if dot_product>0 else 0.0\n",
      "\n",
      "\n",
      "def detect_NonwordError(word, context_words):\n",
      "\t\n",
      "\tif word in wordlist or bangla_stemmer.stemOfWord(word) in wordlist:\n",
      "\t\treturn None\n",
      "\n",
      "\tif word in wv:\n",
      "\t\tif wv.vocab[word].count > 99:\n",
      "\t\t\treturn None\n",
      "\n",
      "\t\tstemmed_word = bangla_stemmer.stemOfWord(word)\n",
      "\t\tif stemmed_word in wv:\n",
      "\t\t\tif wv.vocab[stemmed_word].count > 99: \n",
      "\t\t\t\treturn None\n",
      "\t\n",
      "\tcandidates = get_confusion_set(word)\n",
      "\tfor candidate in candidates:\n",
      "\t\tcandidates[candidate] +=(cosine_similarity_score(candidate, context_words),)\n",
      "\t\n",
      "\treturn sorted(candidates, key = lambda x: (candidates[x][0]-candidates[x][1],))[:10]\n",
      "\t\n",
      "\t\n",
      "def detect_RealwordError(word, context_words):\n",
      "\tif len(context_words) == 0:\n",
      "\t\treturn None\n",
      "\tcandidates = get_confusion_set(word)\n",
      "\tword_similarity = 0\n",
      "\tif word not in wv:\n",
      "\t\tstemmed_word = bangla_stemmer.stemOfWord(word)\n",
      "\t\tif stemmed_word in wv:\n",
      "\t\t\tword_similarity = cosine_similarity_score(stemmed_word, context_words)\n",
      "\telse:\n",
      "\t\tword_similarity = cosine_similarity_score(word, context_words)\n",
      "\t\n",
      "\tmax_cosine_sim = 0\n",
      "\tfor candidate in candidates:\n",
      "\t\tif candidate not in wv:\n",
      "\t\t\tsimilarity = cosine_similarity_score(bangla_stemmer.stemOfWord(candidate), \tcontext_words)\t\n",
      "\t\telse: similarity = cosine_similarity_score(candidate, context_words)\n",
      "\t\tmax_cosine_sim = max(max_cosine_sim, similarity)\n",
      "\t\tcandidates[candidate] +=(similarity,)\n",
      "\t\t\n",
      "\tif word_similarity >= 0.1*max_cosine_sim:\n",
      "\t\treturn None\n",
      "\t\t\n",
      "\tcandidates = {k: v for k, v in candidates.items() if v[1] >= 0.1*max_cosine_sim }\n",
      "\treturn sorted(candidates, key = lambda x: (candidates[x][0], ))[:10]\n",
      "\t\n",
      "\t\n",
      "def check(word_list):\n",
      "\tln = len(word_list)\n",
      "\tfor i in range(ln):\n",
      "\t\tword = word_list[i]\n",
      "\t\tsuggestions = None\n",
      "\t\tif word and word not in stopwords:\n",
      "\t\t\tleft_context = word_list[0:i]\n",
      "\t\t\tright_context = word_list[i+1:]\n",
      "\t\t\tcontext_words = []\n",
      "\t\t\tcount = 0\n",
      "\t\t\tfor w in reversed(left_context):\n",
      "\t\t\t\tif w not in wv:\n",
      "\t\t\t\t\tstemmed_word = bangla_stemmer.stemOfWord(w)\n",
      "\t\t\t\t\tif stemmed_word in wv:\n",
      "\t\t\t\t\t\tcontext_words.append(stemmed_word)\n",
      "\t\t\t\t\t\tcount += 1\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tcontext_words.append(w)\n",
      "\t\t\t\t\tcount += 1\n",
      "\t\t\t\tif count == 2:\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\tcount = 0\t\t\n",
      "\t\t\tfor w in right_context:\n",
      "\t\t\t\tif w not in wv:\n",
      "\t\t\t\t\tstemmed_word = bangla_stemmer.stemOfWord(w)\n",
      "\t\t\t\t\tif stemmed_word in wv:\n",
      "\t\t\t\t\t\tcontext_words.append(stemmed_word)\n",
      "\t\t\t\t\t\tcount += 1\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tcontext_words.append(w)\n",
      "\t\t\t\t\tcount += 1\n",
      "\t\t\t\tif count == 2:\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\n",
      "\t\t\tsuggestions = detect_RealwordError(word, context_words)\n",
      "\t\t\n",
      "\t\tyield i, suggestions\n",
      "\n",
      "\n",
      "model = KeyedVectors.load(model_path, mmap='r')\n",
      "wv = model.wv\n",
      "del model\n",
      "generate_dictionary()\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\tstart = time.time()\n",
      "\tprint(time.time()-start)\n",
      "\t\n",
      "\t\n",
      "# nonword test\n",
      "#{'in_third': 93.80952380952381, 'in_tenth': 94.76190476190476, 'in_first': 86.82539682539682, 'in_all': 95.55555555555556}\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Others\\checker\\spell_check.py\n",
      "[]\n",
      "found files: []\n",
      "#!/mnt/2ADAADCBDAAD941B/SPL3/Spell-Checker/project/bin/python3\n",
      "\n",
      "# $Id: rstpep2html.py 4564 2006-05-21 20:44:42Z wiemann $\n",
      "# Author: David Goodger <goodger@python.org>\n",
      "# Copyright: This module has been placed in the public domain.\n",
      "\n",
      "\"\"\"\n",
      "A minimal front end to the Docutils Publisher, producing HTML from PEP\n",
      "(Python Enhancement Proposal) documents.\n",
      "\"\"\"\n",
      "\n",
      "try:\n",
      "    import locale\n",
      "    locale.setlocale(locale.LC_ALL, '')\n",
      "except:\n",
      "    pass\n",
      "\n",
      "from docutils.core import publish_cmdline, default_description\n",
      "\n",
      "\n",
      "description = ('Generates (X)HTML from reStructuredText-format PEP files.  '\n",
      "               + default_description)\n",
      "\n",
      "publish_cmdline(reader_name='pep', writer_name='pep_html',\n",
      "                description=description)\n",
      "\n",
      "Output: {'rstpep2html': ['docutils.core.publish_cmdline', 'locale.setlocale'], 'locale.setlocale': [], 'docutils.core.publish_cmdline': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Bangla-spell_checker\\bin\\rstpep2html.py\n",
      "[('rstpep2html', 'docutils core publish_cmdline'), ('rstpep2html', 'locale setlocale')]\n",
      "0\n",
      "found files: []\n",
      "import re, os\n",
      "from stemmer.bangla_stemmer import bangla_stemmer\n",
      "import logging\n",
      "import multiprocessing\n",
      "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)\n",
      "init_corpus_path = \"../corpus\"\n",
      "retrain_corpus_path = \"../corpus\"\n",
      "stopwords_path = \"../stop-words.txt\"\n",
      "bn_char_pattern = re.compile(r'[^\\u0980-\\u0983\\u0985-\\u098C\\u098F-\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BC-\\u09C4\\u09C7-\\u09C8\\u09CB-\\u09CE\\u09D7\\u09DC-\\u09DD\\u09DF-\\u09E3\\u09F0-\\u09FD]', re.UNICODE)\n",
      "\n",
      "stopwords = open(stopwords_path, 'r').read().rstrip('\\n').split(',')\n",
      "\n",
      "def  get_bn_wordlist(text, remove_stopwords = True):\n",
      "\ttext = re.sub(bn_char_pattern, ' ', text)\n",
      "\twords = text.strip().split()\n",
      "\tif remove_stopwords:\n",
      "\t\twords = [w for w in words if w not in stopwords]\n",
      "\n",
      "\treturn (words)\n",
      "\n",
      "class Sentences(object):\n",
      "\tdef __init__(self, dirname):\n",
      "\t\tself.dirname = dirname\n",
      "\n",
      "\tdef __iter__(self):\n",
      "\t\tfor file_name in os.listdir(self.dirname):\n",
      "\t\t\tif os.path.isdir(file_name):\n",
      "\t\t\t\tcontinue\n",
      "\t\t\twith open(os.path.join(self.dirname, file_name), 'r', encoding = \"utf-8\") as infile:\n",
      "\t\t\t\tfor line in infile:\n",
      "\t\t\t\t\twordlist = get_bn_wordlist(line)\n",
      "\t\t\t\t\tif len(wordlist) >= 2:\n",
      "\t\t\t\t\t\tyield wordlist\n",
      "\n",
      "\n",
      "def  train(corpus_path):\n",
      "\tfrom gensim.models import word2vec\n",
      "\tsentences = Sentences(corpus_path)\n",
      "\tsize = 300   # Word vector dimensionality                      \n",
      "\tmin_count = 5   # Minimum word count                        \n",
      "\tworkers = multiprocessing.cpu_count()       # Number of threads to run in parallel\n",
      "\twindow = 5       # Context window size                                        \n",
      "\tsg = 0\n",
      "\ths = 1\n",
      "\tnegative = 10                                            \n",
      "#\tsample = 1e-3   # Downsample setting for frequent words\n",
      "\n",
      "\tprint(\"Training model.......\")\n",
      "\tmodel = word2vec.Word2Vec(sentences, workers=workers, \\\n",
      "            size=size, min_count=min_count, \\\n",
      "            window=window, sg=sg, hs = hs, negative=negative)\n",
      "\n",
      "\tmodel.save(\"bn_model_sg\"+str(sg)+\"_win\"+str(window)+\"_hs\"+str(hs)+\"_negative\"+str(negative))\n",
      "\n",
      "# you can retrain model with more sentences\n",
      "def retrain(corpus_path, model_path):\n",
      "\tfrom gensim.models import Word2Vec\n",
      "\tnew_sentences = Sentences(corpus_path)\n",
      "\tmodel = Word2Vec.load(model_path)\n",
      "\tmodel.build_vocab(new_sentences, update=True)\n",
      "\tmodel.train(new_sentences, total_examples = model.corpus_count, epochs = model.iter)\n",
      "\tmodel.save(model_path)\n",
      "\n",
      "def main():\n",
      "\t\n",
      "\ttrain(init_corpus_path)\n",
      "#\tretrain(retrain_corpus_path, \"bn_model_sg0_win2_size300\")\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\tmain()\n",
      "\t\n",
      "\n",
      "Output: {'train': ['logging.basicConfig', 're.compile', '<builtin>.open', 'train.main'], 'logging.basicConfig': [], 're.compile': [], '<builtin>.open': [], 'train.get_bn_wordlist': ['re.sub'], 're.sub': [], 'train.Sentences.__init__': [], 'train.Sentences.__iter__': ['os.listdir', '<builtin>.open', 'os.path.join', 'train.get_bn_wordlist', 'os.path.isdir', '<builtin>.len'], 'os.listdir': [], 'os.path.isdir': [], 'os.path.join': [], '<builtin>.len': [], 'train.train': ['gensim.models.word2vec.Word2Vec', '<builtin>.str', 'multiprocessing.cpu_count', '<builtin>.print', 'train.Sentences.__init__'], 'multiprocessing.cpu_count': [], '<builtin>.print': [], 'gensim.models.word2vec.Word2Vec': [], '<builtin>.str': [], 'train.retrain': ['train.Sentences.__init__', 'gensim.models.Word2Vec.load'], 'gensim.models.Word2Vec.load': [], 'train.main': ['train.train']}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Others\\word2vec\\train.py\n",
      "[('train', 'logging basicConfig'), ('train', 're compile'), ('train', 'train main'), ('train get_bn_wordlist', 're sub'), ('train Sentences __iter__', 'os listdir'), ('train Sentences __iter__', 'os path join'), ('train Sentences __iter__', 'train get_bn_wordlist'), ('train Sentences __iter__', 'os path isdir'), ('train train', 'gensim models word2vec Word2Vec'), ('train train', 'multiprocessing cpu_count'), ('train train', 'train Sentences __init__'), ('train retrain', 'train Sentences __init__'), ('train retrain', 'gensim models Word2Vec load'), ('train main', 'train train')]\n",
      "0\n",
      "found files: []\n",
      "import time\n",
      "from phonetic_encoder import soundex_encode, doublemetaphone_encode\n",
      "max_edit_distance = 1\n",
      "dict_path = \"../sd_encwordlist.txt\"\n",
      "doublemetaphone = False\n",
      "if doublemetaphone:\n",
      "\tdict_path = \"dm_encwordlist.txt\"\n",
      "def get_edit_distance(s1, s2):\n",
      "    if len(s1) > len(s2):\n",
      "        s1, s2 = s2, s1\n",
      "\n",
      "    distances = range(len(s1) + 1)\n",
      "    for i2, c2 in enumerate(s2):\n",
      "        distances_ = [i2+1]\n",
      "        for i1, c1 in enumerate(s1):\n",
      "            if c1 == c2:\n",
      "                distances_.append(distances[i1])\n",
      "            else:\n",
      "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
      "        distances = distances_\n",
      "    return distances[-1]\n",
      "\n",
      "def get_encoded_word(word):\n",
      "\treturn doublemetaphone_encode(word) if doublemetaphone else soundex_encode(word)\n",
      "\n",
      "def create_delete_list(word, delete_words, edit_distance = 1):\n",
      "\tl = len(word)\n",
      "\tif edit_distance > max_edit_distance or l <3 : return\n",
      "\t\n",
      "\tfor c in range(l):\n",
      "\t\tnew_word = word[:c] + word[c+1:]\n",
      "\t\tif new_word not in delete_words:\n",
      "\t\t\tdelete_words.append(new_word)\n",
      "\t\t\tif len(new_word) > 2:\n",
      "\t\t\t\tcreate_delete_list(new_word, delete_words, edit_distance + 1)\n",
      "\n",
      "def weighted_distance(phonetic_edit_dist, edit_dist):\n",
      "\treturn phonetic_edit_dist*0.6 + edit_dist*0.4\n",
      "\n",
      "def generate_dictionary():\n",
      "\tdictionary, encode_to_word_map = {}, {}\n",
      "\twith open(dict_path, 'r', encoding = \"utf-8\") as lines:\n",
      "\t\tfor line in lines:\n",
      "\t\t\tencoded_word, real_word,  count = line.strip().split()\n",
      "\t\t\tif encoded_word in encode_to_word_map:\n",
      "\t\t\t\tencode_to_word_map[encoded_word].append((real_word, int(count)))\n",
      "\t\t\telse: \n",
      "\t\t\t\tencode_to_word_map[encoded_word] = [(real_word, int(count))]\n",
      "\n",
      "\t\t\tif encoded_word not in dictionary:\n",
      "\t\t\t\tdictionary[encoded_word] = []\n",
      "\t\t\t\n",
      "\t\t\tdelete_words = []\n",
      "\t\t\tcreate_delete_list(encoded_word, delete_words)\n",
      "\n",
      "\t\t\tfor item in delete_words:\n",
      "\t\t\t\tif item in dictionary:\n",
      "\t\t\t\t\tdictionary[item].append(encoded_word)\n",
      "\t\t\t\telse: dictionary[item] = [encoded_word]\n",
      "\treturn dictionary, encode_to_word_map\n",
      "\n",
      "def get_suggestion(dictionary, encode_to_word_map, input_word):\n",
      "\tsuggestion_dic = {}\n",
      "\tencoded_input_word = get_encoded_word(input_word)\n",
      "\tencoded_input_word_len = len(encoded_input_word)\n",
      "\tlisted_encoded_words = []\n",
      "\tif encoded_input_word in dictionary:\n",
      "\t\tif encoded_input_word in encode_to_word_map:\n",
      "\t\t\tlisted_encoded_words.append(encoded_input_word)\n",
      "\t\t\tfor word_tuple in encode_to_word_map[encoded_input_word]:\n",
      "\t\t\t\tsuggestion_dic[word_tuple[0]] = (word_tuple[1], weighted_distance(0, get_edit_distance(input_word, word_tuple[0])))\n",
      "\n",
      "\t\tfor encoded_word in dictionary[encoded_input_word]:\n",
      "\t\t\tif encoded_word not in listed_encoded_words:\n",
      "\t\t\t\tlisted_encoded_words.append(encoded_word)\n",
      "\t\t\t\tphonetic_edit_dist = len(encoded_word) - encoded_input_word_len\n",
      "\t\t\t\tfor word_tuple in encode_to_word_map[encoded_word]:\n",
      "\t\t\t\t\tsuggestion_dic[word_tuple[0]] = (word_tuple[1], weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word_tuple[0])))\n",
      "\t\n",
      "\tencoded_delete_words = []\n",
      "\tcreate_delete_list(encoded_input_word, encoded_delete_words)\n",
      "\tfor encoded_delete_word in encoded_delete_words:\n",
      "\t\tif encoded_delete_word in dictionary:\n",
      "\t\t\tif encoded_delete_word in encode_to_word_map:\n",
      "\t\t\t\tif encoded_delete_word not in listed_encoded_words:\n",
      "\t\t\t\t\tlisted_encoded_words.append(encoded_delete_word)\n",
      "\t\t\t\t\tphonetic_edit_dist = encoded_input_word_len - len(encoded_delete_word)\n",
      "\t\t\t\t\tfor word_tuple in encode_to_word_map[encoded_delete_word]:\n",
      "\t\t\t\t\t\tsuggestion_dic[word_tuple[0]] = (word_tuple[1], weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word_tuple[0])))\n",
      "\n",
      "\t\t\tfor encoded_word in dictionary[encoded_delete_word]:\n",
      "\t\t\t\tif encoded_word not in listed_encoded_words:\n",
      "\t\t\t\t\tlisted_encoded_words.append(encoded_word)\n",
      "\t\t\t\t\tphonetic_edit_dist = get_edit_distance(encoded_word, encoded_input_word)\n",
      "\t\t\t\t\tfor word_tuple in encode_to_word_map[encoded_word]:\n",
      "\t\t\t\t\t\tsuggestion_dic[word_tuple[0]] = (word_tuple[1], weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word_tuple[0])))\n",
      "\n",
      "\treturn sorted(suggestion_dic, key = lambda x: (suggestion_dic[x][1],))\n",
      "\n",
      "\n",
      "def test(file_name, dictionary, encode_to_word_map):\n",
      "\tcount = {\"in_first\": 0, \"in_third\": 0, \"in_tenth\": 0, \"in_all\": 0}\n",
      "\ttotal_words = 0\n",
      "\twith open(file_name, 'r', encoding = \"utf-8\") as infile:\n",
      "\t\tlines = infile.readlines()\n",
      "\t\ttotal_words = len(lines)\n",
      "\t\tfor line in lines:\n",
      "\t\t\twrong, correct = line.split('-')\n",
      "\t\t\tcorrect = correct.strip()\n",
      "\t\t\tsuggestions = get_suggestion(dictionary, encode_to_word_map, wrong.strip())\n",
      "\n",
      "\t\t\tif correct in suggestions:\n",
      "\t\t\t\tcount[\"in_all\"]+=1\n",
      "\t\t\t\tif correct in suggestions[:10]:\n",
      "\t\t\t\t\tcount[\"in_tenth\"]+=1\n",
      "\t\t\t\t\tif correct in suggestions[:3]:\n",
      "\t\t\t\t\t\tcount[\"in_third\"]+=1\n",
      "\t\t\t\t\t\tif correct in suggestions[:1]:\n",
      "\t\t\t\t\t\t\tcount[\"in_first\"]+=1\n",
      "\n",
      "\tfor c in count:\n",
      "\t\tcount[c] = (count[c]/total_words)*100.0\n",
      "\tprint(count)\n",
      "\n",
      "\n",
      "def main():\n",
      "\t\n",
      "\tdictionary, encode_to_word_map = generate_dictionary()\n",
      "\t\n",
      "#\tprint(dictionary[\"asa\"], encode_to_word_map[\"asar\"])\n",
      "\tstart_time = time.time()\n",
      "\ttest(\"test.txt\", dictionary, encode_to_word_map)\n",
      "\t\n",
      "\tprint((time.time() - start_time))\n",
      "\t\n",
      "\t\n",
      "if __name__ == '__main__':\n",
      "\tmain()\n",
      "\t# start_time = time.time()\n",
      "\t# print(levenshteinDistance(\"edit\", \"edt\"))\n",
      "\t# print(get_edit_distance(\"edit\", \"edt\"))\n",
      "\n",
      "\t# print(time.time()-start_time)\n",
      "#\tprint(soundex_encode(\"\"), doublemetaphone_encode(\"\"))\n",
      "\n",
      "# accuracy using wiki data\n",
      "\n",
      "# max_phonetic edit distance = 2\n",
      "\t# soundex\n",
      "\t# {'in_third': 94.12698412698413, 'in_all': 98.09523809523809, 'in_first': 77.77777777777779, 'in_tenth': 96.82539682539682}\n",
      "\t\n",
      "\t# doublemetaphone\n",
      "\t# {'in_all': 98.09523809523809, 'in_tenth': 97.46031746031746, 'in_third': 95.55555555555556, 'in_first': 79.84126984126985}\n",
      "\t\n",
      "# max_phonetic edit distance = 1\n",
      "\t# soundex\n",
      "\t# {'in_all': 94.76190476190476, 'in_third': 93.33333333333333, 'in_first': 77.61904761904762, 'in_tenth': 94.6031746031746}\n",
      "\t# doublemetaphone\n",
      "\t# {'in_third': 94.12698412698413, 'in_first': 79.36507936507937, 'in_tenth': 95.23809523809523, 'in_all': 95.3968253968254}\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Others\\checker\\checker.py\n",
      "[]\n",
      "found files: []\n",
      "#!/mnt/2ADAADCBDAAD941B/SPL3/Spell-Checker/project/bin/python3\n",
      "\n",
      "# $Id: rst2html4.py 7994 2016-12-10 17:41:45Z milde $\n",
      "# Author: David Goodger <goodger@python.org>\n",
      "# Copyright: This module has been placed in the public domain.\n",
      "\n",
      "\"\"\"\n",
      "A minimal front end to the Docutils Publisher, producing (X)HTML.\n",
      "\n",
      "The output conforms to XHTML 1.0 transitional\n",
      "and almost to HTML 4.01 transitional (except for closing empty tags).\n",
      "\"\"\"\n",
      "\n",
      "try:\n",
      "    import locale\n",
      "    locale.setlocale(locale.LC_ALL, '')\n",
      "except:\n",
      "    pass\n",
      "\n",
      "from docutils.core import publish_cmdline, default_description\n",
      "\n",
      "\n",
      "description = ('Generates (X)HTML documents from standalone reStructuredText '\n",
      "               'sources.  ' + default_description)\n",
      "\n",
      "publish_cmdline(writer_name='html4', description=description)\n",
      "\n",
      "Output: {'rst2html4': ['docutils.core.publish_cmdline', 'locale.setlocale'], 'locale.setlocale': [], 'docutils.core.publish_cmdline': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Bangla-spell_checker\\bin\\rst2html4.py\n",
      "[('rst2html4', 'docutils core publish_cmdline'), ('rst2html4', 'locale setlocale')]\n",
      "0\n",
      "found files: []\n",
      "import time\n",
      "from phonetic_encoder import soundex_encode, doublemetaphone_encode\n",
      "max_edit_distance = 1\n",
      "dict_path = \"../sd_encwordlist.txt\"\n",
      "doublemetaphone = True\n",
      "if doublemetaphone:\n",
      "\tdict_path = \"dm_encwordlist.txt\"\n",
      "\n",
      "def get_edit_distance(s1, s2):\n",
      "    if len(s1) > len(s2):\n",
      "        s1, s2 = s2, s1\n",
      "    distances = range(len(s1) + 1)\n",
      "    for i2, c2 in enumerate(s2):\n",
      "        distances_ = [i2+1]\n",
      "        for i1, c1 in enumerate(s1):\n",
      "            if c1 == c2:\n",
      "                distances_.append(distances[i1])\n",
      "            else:\n",
      "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
      "        distances = distances_\n",
      "    return distances[-1]\n",
      "\n",
      "\n",
      "def get_encoded_word(word):\n",
      "\treturn doublemetaphone_encode(word) if doublemetaphone else soundex_encode(word)\n",
      "\n",
      "def weighted_distance(phonetic_edit_dist, edit_dist):\n",
      "\treturn phonetic_edit_dist*0.6 + edit_dist*0.4\n",
      "\n",
      "def create_delete_list(word, delete_words, edit_distance = 1):\n",
      "\tl = len(word)\n",
      "\tif edit_distance > max_edit_distance or l <3 : return\n",
      "\t\n",
      "\tfor c in range(l):\n",
      "\t\tnew_word = word[:c] + word[c+1:]\n",
      "\t\tif new_word not in delete_words:\n",
      "\t\t\tdelete_words.append(new_word)\n",
      "\t\t\tif len(new_word) > 2:\n",
      "\t\t\t\tcreate_delete_list(new_word, delete_words, edit_distance + 1)\n",
      "\n",
      "def read_from_file():\n",
      "\tencode_to_word_list, delete_enc_dic = {}, {}\n",
      "\twith open(\"encode_to_word_list.txt\", \"r\", encoding = \"utf-8\") as lines:\n",
      "\t\tfor line in lines:\n",
      "\t\t\twords = line.strip().split()\n",
      "\t\t\tencoded_word = words[0]\n",
      "\t\t\tencode_to_word_list[encoded_word] = words[1:]\n",
      "\t\t\tdelete_words = []\n",
      "\t\t\tcreate_delete_list(encoded_word, delete_words)\n",
      "\t\t\tfor item in delete_words:\n",
      "\t\t\t\tif item in delete_enc_dic:\n",
      "\t\t\t\t\tdelete_enc_dic[item].append(encoded_word)\n",
      "\t\t\t\telse: delete_enc_dic[item] = [encoded_word]\n",
      "\treturn delete_enc_dic, encode_to_word_list\n",
      "\n",
      "def generate_dictionary():\n",
      "\tdictionary, encode_to_word_map = {}, {}\n",
      "\twith open(dict_path, 'r', encoding = \"utf-8\") as lines:\n",
      "\t\tfor line in lines:\n",
      "\t\t\tencoded_word, real_word,  count = line.strip().split()\n",
      "\t\t\tif encoded_word in encode_to_word_map:\n",
      "\t\t\t\tencode_to_word_map[encoded_word].append(real_word)\n",
      "\t\t\telse: \n",
      "\t\t\t\tencode_to_word_map[encoded_word] = [real_word]\n",
      "\n",
      "\t\t\tif encoded_word not in dictionary:\n",
      "\t\t\t\tdictionary[encoded_word] = []\n",
      "\t\t\t\n",
      "\t\t\tdelete_words = []\n",
      "\t\t\tcreate_delete_list(encoded_word, delete_words)\n",
      "\n",
      "\t\t\tfor item in delete_words:\n",
      "\t\t\t\tif item in dictionary:\n",
      "\t\t\t\t\tdictionary[item].append(encoded_word)\n",
      "\t\t\t\telse: dictionary[item] = [encoded_word]\n",
      "\treturn dictionary, encode_to_word_map\n",
      "\t\n",
      "def get_suggestions(input_word):\n",
      "\tsuggestion_dic = {}\n",
      "\tencoded_input_word = get_encoded_word(input_word)\n",
      "\tencoded_input_word_len = len(encoded_input_word)\n",
      "\tlisted_encoded_words = []\n",
      "\tif encoded_input_word in dictionary:\n",
      "\t\tif encoded_input_word in encode_to_word_map:\n",
      "\t\t\tlisted_encoded_words.append(encoded_input_word)\n",
      "\t\t\tphonetic_edit_dist = 0\n",
      "\t\t\tfor word in encode_to_word_map[encoded_input_word]:\n",
      "\t\t\t\tweighted_edit_distance = weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word))\n",
      "#\t\t\t\tif weighted_edit_distance > max_edit_distance:\n",
      "#\t\t\t\t\tcontinue\n",
      "\t\t\t\tsuggestion_dic[word] = (weighted_edit_distance, )\n",
      "\n",
      "\t\tfor encoded_word in dictionary[encoded_input_word]:\n",
      "\t\t\tif encoded_word not in listed_encoded_words:\n",
      "\t\t\t\tlisted_encoded_words.append(encoded_word)\n",
      "\t\t\t\tphonetic_edit_dist = len(encoded_word) - encoded_input_word_len\n",
      "\t\t\t\tfor word in encode_to_word_map[encoded_word]:\n",
      "\t\t\t\t\tweighted_edit_distance = weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word))\n",
      "#\t\t\t\t\tif weighted_edit_distance > max_edit_distance:\n",
      "#\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\tsuggestion_dic[word] = (weighted_edit_distance, )\n",
      "\n",
      "\tencoded_delete_words = []\n",
      "\tcreate_delete_list(encoded_input_word, encoded_delete_words)\n",
      "\tfor encoded_delete_word in encoded_delete_words:\n",
      "\t\tif encoded_delete_word in dictionary:\n",
      "\t\t\tif encoded_delete_word in encode_to_word_map:\n",
      "\t\t\t\tif encoded_delete_word not in listed_encoded_words:\n",
      "\t\t\t\t\tlisted_encoded_words.append(encoded_delete_word)\n",
      "\t\t\t\t\tphonetic_edit_dist = encoded_input_word_len - len(encoded_delete_word)\n",
      "\t\t\t\t\tfor word in encode_to_word_map[encoded_delete_word]:\n",
      "\t\t\t\t\t\tweighted_edit_distance = weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word))\n",
      "#\t\t\t\t\t\tif weighted_edit_distance > max_edit_distance:\n",
      "#\t\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\t\tsuggestion_dic[word] = (weighted_edit_distance, )\n",
      "\n",
      "\t\t\tfor encoded_word in dictionary[encoded_delete_word]:\n",
      "\t\t\t\tif encoded_word not in listed_encoded_words:\n",
      "\t\t\t\t\tlisted_encoded_words.append(encoded_word)\n",
      "\t\t\t\t\tphonetic_edit_dist = get_edit_distance(encoded_word, encoded_input_word)\n",
      "\t\t\t\t\tfor word in encode_to_word_map[encoded_word]:\n",
      "\t\t\t\t\t\tweighted_edit_distance = weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word))\n",
      "#\t\t\t\t\t\tif weighted_edit_distance > max_edit_distance:\n",
      "#\t\t\t\t\t\t\tcontinue\n",
      "\t\t\t\t\t\tsuggestion_dic[word] = (weighted_edit_distance, )\n",
      "\treturn suggestion_dic\n",
      "\n",
      "def test(file_name, dictionary, encode_to_word_map):\n",
      "\tcount = {\"in_first\": 0, \"in_third\": 0, \"in_tenth\": 0, \"in_all\": 0}\n",
      "\ttotal_words = 0\n",
      "\twith open(file_name, 'r', encoding = \"utf-8\") as infile:\n",
      "\t\tlines = infile.readlines()\n",
      "\t\ttotal_words = len(lines)\n",
      "\t\tfor line in lines:\n",
      "\t\t\twrong, correct = line.split('-')\n",
      "\t\t\tcorrect = correct.strip()\n",
      "\t\t\tsuggestion_dic = get_suggestions(wrong.strip())\n",
      "\t\t\tsuggestions = sorted(suggestion_dic, key = lambda x: (suggestion_dic[x][0], ))\n",
      "\n",
      "\t\t\tif correct in suggestions:\n",
      "\t\t\t\tcount[\"in_all\"]+=1\n",
      "\t\t\t\tif correct in suggestions[:10]:\n",
      "\t\t\t\t\tcount[\"in_tenth\"]+=1\n",
      "\t\t\t\t\tif correct in suggestions[:3]:\n",
      "\t\t\t\t\t\tcount[\"in_third\"]+=1\n",
      "\t\t\t\t\t\tif correct in suggestions[:1]:\n",
      "\t\t\t\t\t\t\tcount[\"in_first\"]+=1\n",
      "\n",
      "\tfor c in count:\n",
      "\t\tcount[c] = (count[c]/total_words)*100.0\n",
      "\tprint(count)\n",
      "\n",
      "import time\n",
      "start_time = time.time()\n",
      "dictionary, encode_to_word_map = generate_dictionary()\n",
      "#dictionary, encode_to_word_map = read_from_file()\n",
      "test(\"test.txt\", dictionary, encode_to_word_map)\n",
      "\t\n",
      "print((time.time() - start_time))\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Others\\checker\\suggestion_generation.py\n",
      "[]\n",
      "found files: []\n",
      "import sqlite3\n",
      "import re, time\n",
      "from suggestion_generation import get_suggestions\n",
      "db_name = \"spell_checker.db\"\n",
      "conn = sqlite3.connect(db_name)\n",
      "cur = conn.cursor()\n",
      "\n",
      "\n",
      "bn_char_pattern = re.compile(r'[^\\u0980-\\u0983\\u0985-\\u098C\\u098F-\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BC-\\u09C4\\u09C7-\\u09C8\\u09CB-\\u09CE\\u09D7\\u09DC-\\u09DD\\u09DF-\\u09E3\\u09F0-\\u09FD]', re.UNICODE)\n",
      "stopwords_path = \"../stop-words.txt\"\n",
      "stopwords = open(stopwords_path, 'r').read().rstrip('\\n').split(',')\n",
      "\n",
      "def  get_bn_wordlist(text, remove_stopwords = False):\n",
      "\ttext = re.sub(bn_char_pattern, ' ', text)\n",
      "\twords = text.strip().split()\n",
      "\tif remove_stopwords:\n",
      "\t\twords = [w for w in words if w not in stopwords]\n",
      "\n",
      "\treturn words\n",
      "\n",
      "def get_ngram_count(text_grams):\n",
      "\t# table_name = \"bigrams\" if n==2 else \"trigrams\" \n",
      "\tcounts = [0, 0, 0]\n",
      "\tif text_grams[0]:\n",
      "\t\tresult = cur.execute(\"select count from bigrams where grams ='\"+text_grams[0]+\"_\"+text_grams[1]+\"';\").fetchone()\n",
      "\t\tif result:\n",
      "\t\t\tcounts[0] = result[0]\n",
      "\tif text_grams[2]:\n",
      "\t\tresult = cur.execute(\"select count from bigrams where grams ='\"+text_grams[1]+\"_\"+text_grams[2]+\"';\").fetchone()\n",
      "\t\tif result:\n",
      "\t\t\tcounts[1] = result[0]\n",
      "\tif not None in text_grams:\n",
      "\t\tresult = cur.execute(\"select count from trigrams where grams ='\"+text_grams[0]+\"_\"+text_grams[1]+\"_\"+text_grams[2]+\"';\").fetchone()\n",
      "\t\tif result:\n",
      "\t\t\tcounts[2] = result[0]\n",
      "\n",
      "\treturn counts\n",
      "\n",
      "def weighted_score(count, total):\n",
      "\treturn 0.25*(count[0]/total[0]+count[1]/total[1]) + 0.5*count[2]/total[2]\n",
      "\n",
      "def get_total(counts):\n",
      "\tvalues = list(counts.values())\n",
      "\ttotal = [0,0,0]\n",
      "\tfor v in values:\n",
      "\t\ttotal[0] += v[0]\n",
      "\t\ttotal[1] += v[1]\n",
      "\t\ttotal[2] += v[2]\n",
      "\tfor i in range(3):\n",
      "\t\tif total[i] == 0:\n",
      "\t\t\t total[i] = 1\n",
      "\treturn total\n",
      "\n",
      "def detect(sentence):\n",
      "\twords = get_bn_wordlist(sentence)\n",
      "\tl = len(words)\n",
      "\n",
      "\tfor i in range(l):\n",
      "\t\tcounts = {}\n",
      "\t\ttext_grams = [None, words[i], None]\n",
      "\t\tif i-1 > 0:\n",
      "\t\t\ttext_grams[0] = words[i-1]\n",
      "\t\tif i+1 < l:\n",
      "\t\t\ttext_grams[2] = words[i+1]\n",
      "\t\t\n",
      "\t\tcounts[words[i]] = get_ngram_count(text_grams)\n",
      "\t\tconfusion_set = get_suggestions(words[i])\n",
      "\t\tconfusion_set[words[i]] = (0.0,)\n",
      "\t\tfor word in confusion_set:\n",
      "\t\t\ttext_grams[1] = word\n",
      "\t\t\tcounts[word] = get_ngram_count(text_grams)\n",
      "\t\t\n",
      "\t\ttotal = get_total(counts)\n",
      "\t\tfor word in confusion_set:\n",
      "\t\t\tconfusion_set[word] +=(weighted_score(counts[word], total),)\n",
      "\t\t\n",
      "\t\tsuggestions = sorted(confusion_set, key = lambda x: (-confusion_set[x][1], confusion_set[x][0]))\n",
      "\t\t\n",
      "#\t\tprint(suggestions)\n",
      "\t\t\n",
      "\t\tif confusion_set[words[i]][1] == 0:\n",
      "\t\t\tindex = suggestions.index(words[i])\n",
      "\t\t\tsuggestions = suggestions[:index]\n",
      "\t\telif confusion_set[suggestions[0]][1]*0.01 > confusion_set[words[i]][1]:\n",
      "\t\t\tindex = suggestions.index(words[i])\n",
      "\t\t\tsuggestions = suggestions[:index]\n",
      "\t\telse:\n",
      "\t\t\tsuggestions = None\n",
      "\t\t\n",
      "\t\tprint(suggestions)\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\t\n",
      "\twhile True:\n",
      "\t\tsentence = input()\n",
      "\t\tstart_time = time.time()\n",
      "\t\tdetect(sentence)\n",
      "\t\tprint(time.time() - start_time)\n",
      "\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Others\\checker\\spell_check_ngram.py\n",
      "[]\n",
      "found files: []\n",
      "#!/mnt/2ADAADCBDAAD941B/SPL3/Spell-Checker/project/bin/python3\n",
      "\n",
      "# $Id: rst2pseudoxml.py 4564 2006-05-21 20:44:42Z wiemann $\n",
      "# Author: David Goodger <goodger@python.org>\n",
      "# Copyright: This module has been placed in the public domain.\n",
      "\n",
      "\"\"\"\n",
      "A minimal front end to the Docutils Publisher, producing pseudo-XML.\n",
      "\"\"\"\n",
      "\n",
      "try:\n",
      "    import locale\n",
      "    locale.setlocale(locale.LC_ALL, '')\n",
      "except:\n",
      "    pass\n",
      "\n",
      "from docutils.core import publish_cmdline, default_description\n",
      "\n",
      "\n",
      "description = ('Generates pseudo-XML from standalone reStructuredText '\n",
      "               'sources (for testing purposes).  ' + default_description)\n",
      "\n",
      "publish_cmdline(description=description)\n",
      "\n",
      "Output: {'rst2pseudoxml': ['locale.setlocale', 'docutils.core.publish_cmdline'], 'locale.setlocale': [], 'docutils.core.publish_cmdline': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Bangla-spell_checker\\bin\\rst2pseudoxml.py\n",
      "[('rst2pseudoxml', 'locale setlocale'), ('rst2pseudoxml', 'docutils core publish_cmdline')]\n",
      "0\n",
      "found files: []\n",
      "\"\"\"\n",
      "WSGI config for main project.\n",
      "\n",
      "It exposes the WSGI callable as a module-level variable named ``application``.\n",
      "\n",
      "For more information on this file, see\n",
      "https://docs.djangoproject.com/en/2.0/howto/deployment/wsgi/\n",
      "\"\"\"\n",
      "\n",
      "import os\n",
      "\n",
      "from django.core.wsgi import get_wsgi_application\n",
      "\n",
      "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"main.settings\")\n",
      "\n",
      "application = get_wsgi_application()\n",
      "\n",
      "Output: {'wsgi': ['django.core.wsgi.get_wsgi_application', 'os.environ.setdefault'], 'os.environ.setdefault': [], 'django.core.wsgi.get_wsgi_application': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Bangla-spell_checker\\src\\main\\wsgi.py\n",
      "[('wsgi', 'django core wsgi get_wsgi_application'), ('wsgi', 'os environ setdefault')]\n",
      "0\n",
      "found files: []\n",
      "encodes = {\"\" :\"o\",  \"\": \"a\", \"\": \"a\",  \"\": \"i\", \"\": \"i\", \"\":\"i\", \"\" : \"i\", \"\" : \"u\", \"\": \"u\", \"\": \"u\", \"\": \"u\", \"\": \"e\", \"\": \"e\", \"\": \"oi\", \"\": \"oi\", \"\": \"o\", \"\": \"ou\",\"\": \"ou\", \"\": \"k\", \"\": \"k\", \"\": \"g\", \"\": \"g\", \"\": \"ng\", \"\": \"ng\", \"\": \"c\", \"\": \"c\", \"\": \"j\", \"\": \"j\", \"\": \"j\", \"\": \"n\", \"\": \"T\", \"\": \"T\", \"\": \"D\", \"\": \"D\", \"\": \"ri\", \"\": \"r\", \"\": \"r\", \"\": \"r\", \"\": \"n\", \"\": \"n\", \"\": \"t\", \"\": \"t\", \"\": \"d\", \"\": \"d\", \"\": \"p\", \"\": \"p\", \"\": \"b\", \"\": \"b\", \"\": \"m\", \"\": \"y\", \"\": \"l\", \"\": \"s\", \"\": \"s\", \"\": \"s\", \"\": \"h\", \"\" : \"h\", \"\": \"t\", '': 'ri'}\n",
      "\n",
      "\n",
      "letters_tobe_checked = {'', '', '', '', '', '',''}\n",
      "\n",
      "def soundex_encode(word):\n",
      "\tencoded_word = \"\"\n",
      "\tfor w in word:\n",
      "\t\tencoded_word += encodes.get(w, \"\")\n",
      "\treturn encoded_word\n",
      "    \n",
      "def doublemetaphone_encode(word):\n",
      "\tencoded_word = \"\"\n",
      "\ti, l = 0, len(word)\n",
      "\twhile i<l:\n",
      "\t\tif word[i] not in letters_tobe_checked:\n",
      "\t\t\tencoded_word += encodes.get(word[i], \"\")\n",
      "\t\telif word[i] == \"\":\n",
      "\t\t\tif word[i:i+3] == \"\":\n",
      "\t\t\t\tif i == 0:\n",
      "\t\t\t\t\tencoded_word += \"k\"\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tencoded_word += \"kk\"\n",
      "\t\t\t\ti += 2\n",
      "\t\t\telse:\n",
      "\t\t\t\tencoded_word += \"k\"\n",
      "\t\telif word[i] == \"\":\n",
      "\t\t\tif word[i:i+2] == '':\n",
      "\t\t\t\tencoded_word += \"y\"\n",
      "\t\t\telif i != 0 and word[i-1:i+1] == '':\n",
      "\t\t\t\tif i == 2:\n",
      "\t\t\t\t\tencoded_word += \"e\"\n",
      "\t\t\t\telif i-3>-1 and word[i-3] == '\\u09CD':\n",
      "\t\t\t\t\tpass\n",
      "\t\t\t\telif word[i-2] == '':\n",
      "\t\t\t\t\tencoded_word += \"j\"\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tif encoded_word:\n",
      "\t\t\t\t\t\tencoded_word += encoded_word[-1]\n",
      "\t\t\telse:\n",
      "\t\t\t\tencoded_word += \"j\"\n",
      "\t\telif word[i] == \"\":\n",
      "\t\t\tif i != 0 and word[i-1] == '\\u09CD':\n",
      "\t\t\t\tif word[i-2] == \"\":\n",
      "\t\t\t\t\tif i == 2 and i+1 != l and word[i+1] == \"\":\n",
      "\t\t\t\t\t\tencoded_word = encoded_word[:-1] + \"ge\"\n",
      "\t\t\t\t\t\ti += 1\n",
      "\t\t\t\t\telse:\n",
      "\t\t\t\t\t\tencoded_word = encoded_word[:-1] + \"gg\"\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tencoded_word += \"n\"\n",
      "\t\t\telif i+1 != l and word[i+1] in {\"\",\"\", \"\",\"\",\"\",\"\"}:\n",
      "\t\t\t\tpass\n",
      "\t\t\telse:\n",
      "\t\t\t\tencoded_word += \"n\"\n",
      "\t\t\t\t\n",
      "\t\telif word[i] == \"\":\n",
      "\t\t\tif i != 0 and word[i-1] == '\\u09CD':\n",
      "\t\t\t\tif i == 2 or (i-3>-1 and word[i-3] == '\\u09CD'):\n",
      "\t\t\t\t\tpass\n",
      "\t\t\t\telif word[i-2] in {'',''} or word[i-3:i+1] == '':\n",
      "\t\t\t\t\tencoded_word += \"b\"\n",
      "\t\t\t\t\t\n",
      "\t\t\t\telse: \n",
      "\t\t\t\t\tif encoded_word:\n",
      "\t\t\t\t\t\tencoded_word += encoded_word[-1]\n",
      "\t\t\t\n",
      "\t\t\telse: encoded_word += \"b\"\n",
      "\t\t\n",
      "\t\telif word[i] == \"\":\n",
      "\t\t\tif i != 0 and word[i-1] == '\\u09CD':\n",
      "\t\t\t\tif i == 2 or (i-3>-1 and word[i-3] == '\\u09CD'):\n",
      "\t\t\t\t\tpass\n",
      "\t\t\t\telif word[i-2] in {'', '', '', '', '', '', '', '', '', ''}:\n",
      "\t\t\t\t\tencoded_word += \"m\"\n",
      "#\t\t\t\telif word[i-2] == '' and (i == l-1 or (i+1 == l-1 and word[i+1] in {\"\",\"\", \"\",\"\",\"\",\"\"} ) ):\n",
      "#\t\t\t\t\tpass\n",
      "\t\t\t\telse: \n",
      "\t\t\t\t\tif encoded_word:\n",
      "\t\t\t\t\t\tencoded_word += encoded_word[-1]\n",
      "\t\t\telse: \n",
      "\t\t\t\tencoded_word += \"m\"\n",
      "\t\t\t\t\n",
      "\t\telif word[i] == \"\":\n",
      "\t\t\tif word[i+1:i+2] == '' or word[i+1:i+3] == '':\n",
      "\t\t\t\tpass\n",
      "\t\t\telif word[i+1:i+3] == '' or word[i+1:i+3] == '':\n",
      "\t\t\t\tencoded_word += \"n\"\n",
      "\t\t\telif word[i+1:i+3] == '':\n",
      "\t\t\t\tencoded_word += \"m\"\n",
      "\t\t\telif word[i+1:i+3] == '':\n",
      "\t\t\t\tencoded_word += \"j\"\n",
      "\t\t\telif word[i+1:i+3] == '':\n",
      "\t\t\t\tencoded_word += \"l\"\n",
      "\t\t\telse:\n",
      "\t\t\t\tencoded_word += \"h\"\n",
      "\t\t\n",
      "\t\telif word[i] == '':\n",
      "\t\t\tif l<4 and i == l-1:\n",
      "\t\t\t\tencoded_word += \"h\"\n",
      "\t\t\telse:\n",
      "\t\t\t\tpass\n",
      "\t\t\n",
      "\t\tif i-1 > -1 and word[i-1] == '':\n",
      "\t\t\tif i-1 != 0 and i-1 != l-1:\n",
      "\t\t\t\tif encoded_word:\n",
      "\t\t\t\t\tencoded_word += encoded_word[-1]\t\t \n",
      "\t\t\n",
      "\t\ti += 1\n",
      "\treturn encoded_word\n",
      "\n",
      "[Errno 2] No such file or directory: 'temporary_output.json'\n",
      "Output: None\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Others\\checker\\phonetic_encoder.py\n",
      "[]\n",
      "found files: []\n",
      "import re, os\n",
      "def create_sentences(text):\n",
      "\ttext = re.sub(\"\\n\", \"\", text)\n",
      "\tif len(text) == 0:\n",
      "\t\treturn \"\"\n",
      "\tpattern = r\"[\\|\\?|;]+\"\n",
      "\tsentences = re.split(pattern, text.rstrip(pattern))\n",
      "\tsentences = \"\\n\".join(sentence.strip() for sentence in sentences)\n",
      "\tsentences += \"\\n\"\n",
      "\treturn sentences\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\tfor file_name in os.listdir():\n",
      "\t\tif os.path.isdir(file_name):\n",
      "\t\t\tcontinue\n",
      "\t\twith open(file_name, \"r\") as infile:\n",
      "\t\t\twith open(\"New/\"+file_name, \"a\") as outfile:\n",
      "\t\t\t\tfor line in infile:\n",
      "\t\t\t\t\tsentences = create_sentences(line)\n",
      "\t\t\t\t\toutfile.write(sentences)\n",
      "\n",
      "Output: {'create_sentence': ['os.listdir', 'os.path.isdir', '<builtin>.open', 'create_sentence.create_sentences'], 'create_sentence.create_sentences': ['<builtin>.len', 're.sub', 're.split'], 're.sub': [], '<builtin>.len': [], 're.split': [], 'os.listdir': [], 'os.path.isdir': [], '<builtin>.open': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Others\\helper\\create_sentence.py\n",
      "[('create_sentence', 'os listdir'), ('create_sentence', 'os path isdir'), ('create_sentence', 'create_sentence create_sentences'), ('create_sentence create_sentences', 're sub'), ('create_sentence create_sentences', 're split')]\n",
      "0\n",
      "found files: []\n",
      "#!/mnt/2ADAADCBDAAD941B/SPL3/Spell-Checker/project/bin/python3\n",
      "from django.core import management\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    management.execute_from_command_line()\n",
      "\n",
      "Output: {'django-admin': ['django.core.management.execute_from_command_line'], 'django.core.management.execute_from_command_line': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Bangla-spell_checker\\bin\\django-admin.py\n",
      "[('django-admin', 'django core management execute_from_command_line')]\n",
      "0\n",
      "found files: []\n",
      "from stemmer.bangla_stemmer import bangla_stemmer\n",
      "import re\n",
      "import logging\n",
      "import multiprocessing\n",
      "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)\n",
      "\n",
      "stopwords_path = \"../stop-words.txt\"\n",
      "bn_char_pattern = re.compile(r'[^\\u0980-\\u0983\\u0985-\\u098C\\u098F-\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BC-\\u09C4\\u09C7-\\u09C8\\u09CB-\\u09CE\\u09D7\\u09DC-\\u09DD\\u09DF-\\u09E3\\u09F0-\\u09FD]', re.UNICODE)\n",
      "\n",
      "stopwords = open(stopwords_path, 'r').read().rstrip('\\n').split(',')\n",
      "\n",
      "def get_bn_wordlist(text, remove_stopwords = True):\n",
      "\ttext = re.sub(bn_char_pattern, ' ', text)\n",
      "\twords = text.strip().split()\n",
      "\tif remove_stopwords:\n",
      "\t\twords = [w for w in words if w not in stopwords]\n",
      "\t\t\n",
      "\treturn words\n",
      "\t\t\n",
      "class Sentences(object):\n",
      "\tdef __init__(self, file_name):\n",
      "\t\tself.file_name = file_name\n",
      "\n",
      "\tdef __iter__(self):\n",
      "\t\twith open(self.file_name, 'r', encoding = \"utf-8\") as infile:\n",
      "\t\t\tfor line in infile:\n",
      "\t\t\t\twordlist = get_bn_wordlist(line)\n",
      "\t\t\t\tif len(wordlist) >= 2:\n",
      "\t\t\t\t\tyield wordlist\n",
      "\t\t\t\t\t\t\t\t\n",
      "def  train(corpus_path):\n",
      "\tfrom gensim.models import word2vec\n",
      "\tsentences = Sentences(corpus_path)\n",
      "\tsize = 100   # Word vector dimensionality                      \n",
      "\tmin_count = 2   # Minimum word count                        \n",
      "\tworkers = multiprocessing.cpu_count()       # Number of threads to run in parallel\n",
      "\twindow = 5       # Context window size                                        \n",
      "\tsg = 0                                            \n",
      "#\tsample = 1e-3   # Downsample setting for frequent words\n",
      "\n",
      "\tprint(\"Training model.......\")\n",
      "\tmodel = word2vec.Word2Vec(sentences, workers=workers, \\\n",
      "            size=size, min_count = min_count, \\\n",
      "            window = window, sg = sg, hs=0, negative = 0)\n",
      "\n",
      "\tmodel.save(\"sample_model\")\n",
      "\t\n",
      "train(\"sample.txt\")\n",
      "\n",
      "Output: {'sample_train': ['sample_train.train', 'logging.basicConfig', 're.compile', '<builtin>.open'], 'logging.basicConfig': [], 're.compile': [], '<builtin>.open': [], 'sample_train.get_bn_wordlist': ['re.sub'], 're.sub': [], 'sample_train.Sentences.__init__': [], 'sample_train.Sentences.__iter__': ['sample_train.get_bn_wordlist', '<builtin>.len', '<builtin>.open'], '<builtin>.len': [], 'sample_train.train': ['multiprocessing.cpu_count', 'gensim.models.word2vec.Word2Vec', 'sample_train.Sentences.__init__', '<builtin>.print'], 'multiprocessing.cpu_count': [], '<builtin>.print': [], 'gensim.models.word2vec.Word2Vec': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Others\\word2vec\\sample_train.py\n",
      "[('sample_train', 'sample_train train'), ('sample_train', 'logging basicConfig'), ('sample_train', 're compile'), ('sample_train get_bn_wordlist', 're sub'), ('sample_train Sentences __iter__', 'sample_train get_bn_wordlist'), ('sample_train train', 'multiprocessing cpu_count'), ('sample_train train', 'gensim models word2vec Word2Vec'), ('sample_train train', 'sample_train Sentences __init__')]\n",
      "0\n",
      "found files: []\n",
      "#!/mnt/2ADAADCBDAAD941B/SPL3/Spell-Checker/project/bin/python3\n",
      "\n",
      "# Author: \n",
      "# Contact: grubert@users.sf.net\n",
      "# Copyright: This module has been placed in the public domain.\n",
      "\n",
      "\"\"\"\n",
      "man.py\n",
      "======\n",
      "\n",
      "This module provides a simple command line interface that uses the\n",
      "man page writer to output from ReStructuredText source.\n",
      "\"\"\"\n",
      "\n",
      "import locale\n",
      "try:\n",
      "    locale.setlocale(locale.LC_ALL, '')\n",
      "except:\n",
      "    pass\n",
      "\n",
      "from docutils.core import publish_cmdline, default_description\n",
      "from docutils.writers import manpage\n",
      "\n",
      "description = (\"Generates plain unix manual documents.  \" + default_description)\n",
      "\n",
      "publish_cmdline(writer=manpage.Writer(), description=description)\n",
      "\n",
      "Output: {'rst2man': ['docutils.core.publish_cmdline', 'locale.setlocale', 'docutils.writers.manpage.Writer'], 'locale.setlocale': [], 'docutils.writers.manpage.Writer': [], 'docutils.core.publish_cmdline': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Bangla-spell_checker\\bin\\rst2man.py\n",
      "[('rst2man', 'docutils core publish_cmdline'), ('rst2man', 'locale setlocale'), ('rst2man', 'docutils writers manpage Writer')]\n",
      "0\n",
      "found files: []\n",
      "import re, os\n",
      "from django.conf import settings\n",
      "from .phonetic_encoder import doublemetaphone_encode\n",
      "from gensim.models import Word2Vec, KeyedVectors\n",
      "from gensim.matutils import unitvec\n",
      "import numpy as np\n",
      "from django.conf import settings\n",
      "from .stemmer.bangla_stemmer import bangla_stemmer\n",
      "bn_char_pattern = re.compile(r'[^\\u0980-\\u0983\\u0985-\\u098C\\u098F-\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BC-\\u09C4\\u09C7-\\u09C8\\u09CB-\\u09CE\\u09D7\\u09DC-\\u09DD\\u09DF-\\u09E3\\u09F0-\\u09FD]+', re.UNICODE)\n",
      "bn_al_pattern = re.compile(r'[\\u0980-\\u0983\\u0985-\\u098C\\u098F-\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BC-\\u09C4\\u09C7-\\u09C8\\u09CB-\\u09CE\\u09D7\\u09DC-\\u09DD\\u09DF-\\u09E3\\u09F0-\\u09FD]+', re.UNICODE)\n",
      "\n",
      "def get_edit_distance(s1, s2):\n",
      "    if len(s1) > len(s2):\n",
      "        s1, s2 = s2, s1\n",
      "    distances = range(len(s1) + 1)\n",
      "    for i2, c2 in enumerate(s2):\n",
      "        distances_ = [i2+1]\n",
      "        for i1, c1 in enumerate(s1):\n",
      "            if c1 == c2:\n",
      "                distances_.append(distances[i1])\n",
      "            else:\n",
      "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
      "        distances = distances_\n",
      "    return distances[-1]\n",
      "\n",
      "\n",
      "def get_encoded_word(word):\n",
      "\treturn doublemetaphone_encode(word)\n",
      "\n",
      "def weighted_distance(phonetic_edit_dist, edit_dist):\n",
      "\treturn phonetic_edit_dist*0.6 + edit_dist*0.4\n",
      "\n",
      "max_edit_distance = 1\n",
      "def create_delete_list(word, delete_words, edit_distance = 1):\n",
      "\tl = len(word)\n",
      "\tif edit_distance > max_edit_distance or l <3 : return\n",
      "\t\n",
      "\tfor c in range(l):\n",
      "\t\tnew_word = word[:c] + word[c+1:]\n",
      "\t\tif new_word not in delete_words:\n",
      "\t\t\tdelete_words.append(new_word)\n",
      "\t\t\tif len(new_word) > 2:\n",
      "\t\t\t\tcreate_delete_list(new_word, delete_words, edit_distance + 1)\n",
      "\n",
      "def startup():\n",
      "\tdict_path = os.path.join(settings.BASE_DIR, \"checker/dm_encwordlist.txt\")\n",
      "\tmodel_path = os.path.join(settings.BASE_DIR, \"checker/word2vec_model/bn_model_sg0_win5_hs1_negative0\")\n",
      "\tstopwords_path = os.path.join(settings.BASE_DIR, \"checker/stop-words.txt\")\n",
      "\tmodel = KeyedVectors.load(model_path, mmap='r')\n",
      "\twv = model.wv\n",
      "\twordlist, delete_word_dic, encode_to_word_dic = set(), {}, {}\n",
      "\twith open(dict_path, 'r', encoding = \"utf-8\") as lines:\n",
      "\t\tfor line in lines:\n",
      "\t\t\tencoded_word, real_word,  count = line.strip().split()\n",
      "\t\t\twordlist.add(real_word)\n",
      "\t\t\tif encoded_word in encode_to_word_dic:\n",
      "\t\t\t\tencode_to_word_dic[encoded_word].append(real_word)\n",
      "\t\t\telse: \n",
      "\t\t\t\tencode_to_word_dic[encoded_word] = [real_word]\n",
      "\n",
      "\t\t\tif encoded_word not in delete_word_dic:\n",
      "\t\t\t\tdelete_word_dic[encoded_word] = []\n",
      "\t\t\t\n",
      "\t\t\tdelete_words = []\n",
      "\t\t\tcreate_delete_list(encoded_word, delete_words)\n",
      "\n",
      "\t\t\tfor item in delete_words:\n",
      "\t\t\t\tif item in delete_word_dic:\n",
      "\t\t\t\t\tdelete_word_dic[item].append(encoded_word)\n",
      "\t\t\t\telse: delete_word_dic[item] = [encoded_word]\n",
      "\t\n",
      "\tstopwords = open(stopwords_path, 'r').read().rstrip('\\n').split(',')\n",
      "\tsettings.wv = wv\n",
      "\tsettings.wordlist = wordlist\n",
      "\tsettings.delete_word_dic = delete_word_dic\n",
      "\tsettings.encode_to_word_dic = encode_to_word_dic\n",
      "\tsettings.stopwords = set(stopwords)\n",
      "\n",
      "\n",
      "def get_confusion_set(input_word):\n",
      "\tsuggestion_dic = {}\n",
      "\tencoded_input_word = get_encoded_word(input_word)\n",
      "\tencoded_input_word_len = len(encoded_input_word)\n",
      "\tlisted_encoded_words = []\n",
      "\tif encoded_input_word in settings.delete_word_dic:\n",
      "\t\tif encoded_input_word in settings.encode_to_word_dic:\n",
      "\t\t\tlisted_encoded_words.append(encoded_input_word)\n",
      "\t\t\tphonetic_edit_dist = 0\n",
      "\t\t\tfor word in settings.encode_to_word_dic[encoded_input_word]:\n",
      "\t\t\t\tif word == input_word:\n",
      "\t\t\t\t\tcontinue\n",
      "\t\t\t\tweighted_edit_distance = weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word))\n",
      "\t\t\t\tsuggestion_dic[word] = (weighted_edit_distance, )\n",
      "\n",
      "\t\tfor encoded_word in settings.delete_word_dic[encoded_input_word]:\n",
      "\t\t\tif encoded_word not in listed_encoded_words:\n",
      "\t\t\t\tlisted_encoded_words.append(encoded_word)\n",
      "\t\t\t\tphonetic_edit_dist = len(encoded_word) - encoded_input_word_len\n",
      "\t\t\t\tfor word in settings.encode_to_word_dic[encoded_word]:\n",
      "\t\t\t\t\tweighted_edit_distance = weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word))\n",
      "\t\t\t\t\tsuggestion_dic[word] = (weighted_edit_distance, )\n",
      "\n",
      "\tencoded_delete_words = []\n",
      "\tcreate_delete_list(encoded_input_word, encoded_delete_words)\n",
      "\tfor encoded_delete_word in encoded_delete_words:\n",
      "\t\tif encoded_delete_word in settings.delete_word_dic:\n",
      "\t\t\tif encoded_delete_word in settings.encode_to_word_dic:\n",
      "\t\t\t\tif encoded_delete_word not in listed_encoded_words:\n",
      "\t\t\t\t\tlisted_encoded_words.append(encoded_delete_word)\n",
      "\t\t\t\t\tphonetic_edit_dist = encoded_input_word_len - len(encoded_delete_word)\n",
      "\t\t\t\t\tfor word in settings.encode_to_word_dic[encoded_delete_word]:\n",
      "\t\t\t\t\t\tweighted_edit_distance = weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word))\n",
      "\t\t\t\t\t\tsuggestion_dic[word] = (weighted_edit_distance, )\n",
      "\n",
      "\t\t\tfor encoded_word in settings.delete_word_dic[encoded_delete_word]:\n",
      "\t\t\t\tif encoded_word not in listed_encoded_words:\n",
      "\t\t\t\t\tlisted_encoded_words.append(encoded_word)\n",
      "\t\t\t\t\tphonetic_edit_dist = get_edit_distance(encoded_word, encoded_input_word)\n",
      "\t\t\t\t\tfor word in settings.encode_to_word_dic[encoded_word]:\n",
      "\t\t\t\t\t\tweighted_edit_distance = weighted_distance(phonetic_edit_dist, get_edit_distance(input_word, word))\n",
      "\t\t\t\t\t\tsuggestion_dic[word] = (weighted_edit_distance, )\n",
      "\treturn suggestion_dic\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def cosine_similarity_score(word, context_words):\n",
      "\tif word not in settings.wv: return 0.0\n",
      "\tif len(context_words) == 0: return 0.0\n",
      "\tcontext_vectors = [settings.wv[w] for w in context_words]\n",
      "\tvector_mean = np.mean(np.array(context_vectors), axis=0, dtype=np.float64)\n",
      "\tdot_product = unitvec(settings.wv[word]).dot(unitvec(np.array(vector_mean)))\n",
      "\treturn dot_product if dot_product>0 else 0.0\n",
      "\t\n",
      "def detect_NonwordError(word, context_words):\n",
      "\t\n",
      "\tif word in settings.wordlist or bangla_stemmer.stemOfWord(word) in settings.wordlist:\n",
      "\t\treturn None\n",
      "\n",
      "\tif word in settings.wv:\n",
      "\t\tif settings.wv.vocab[word].count > 99:\n",
      "\t\t\treturn None\n",
      "\n",
      "\t\tstemmed_word = bangla_stemmer.stemOfWord(word)\n",
      "\t\tif stemmed_word in settings.wv:\n",
      "\t\t\tif settings.wv.vocab[stemmed_word].count > 99: \n",
      "\t\t\t\treturn None\n",
      "\n",
      "\tcandidates = get_confusion_set(word)\n",
      "\tif not candidates:\n",
      "\t\treturn None\n",
      "\tfor candidate in candidates:\n",
      "\t\tcandidates[candidate] +=(cosine_similarity_score(candidate, context_words),)\n",
      "\t\n",
      "\treturn sorted(candidates, key = lambda x: (candidates[x][0]-candidates[x][1],))[:10]\n",
      "\t\n",
      "def detect_RealwordError(word, context_words):\n",
      "\tif len(context_words) == 0:\n",
      "\t\treturn None\n",
      "\tcandidates = get_confusion_set(word)\n",
      "\tword_similarity = 0\n",
      "\tif word not in settings.wv:\n",
      "\t\tstemmed_word = bangla_stemmer.stemOfWord(word)\n",
      "\t\tif stemmed_word in settings.wv:\n",
      "\t\t\tword_similarity = cosine_similarity_score(stemmed_word, context_words)\n",
      "\telse:\n",
      "\t\tword_similarity = cosine_similarity_score(word, context_words)\n",
      "\t\n",
      "\tmax_cosine_sim = 0\n",
      "\tfor candidate in candidates:\n",
      "\t\tif candidate not in settings.wv:\n",
      "\t\t\tsimilarity = cosine_similarity_score(bangla_stemmer.stemOfWord(candidate), \tcontext_words)\t\n",
      "\t\telse: similarity = cosine_similarity_score(candidate, context_words)\n",
      "\t\tmax_cosine_sim = max(max_cosine_sim, similarity)\n",
      "\t\tcandidates[candidate] +=(similarity,)\n",
      "\t\t\n",
      "\tif word_similarity >= 0.1*max_cosine_sim:\n",
      "\t\treturn None\n",
      "\tcandidates = {k: v for k, v in candidates.items() if v[1] >= 0.1*max_cosine_sim }\n",
      "\tif not candidates:\n",
      "\t\treturn None\n",
      "\treturn sorted(candidates, key = lambda x: (candidates[x][0], ))[:10]\n",
      "\n",
      "\n",
      "\n",
      "def check(word_list):\n",
      "\tln = len(word_list)\n",
      "\tfor i in range(ln):\n",
      "\t\tword = word_list[i]\n",
      "\t\tisNonWord = True\n",
      "\t\tsuggestions = None\n",
      "\t\tif word and word not in settings.stopwords:\n",
      "\t\t\tleft_context = word_list[0:i]\n",
      "\t\t\tright_context = word_list[i+1:]\n",
      "\t\t\tcontext_words = []\n",
      "\t\t\tcount = 0\n",
      "\t\t\tfor w in reversed(left_context):\n",
      "\t\t\t\tif w not in settings.wv:\n",
      "\t\t\t\t\tstemmed_word = bangla_stemmer.stemOfWord(w)\n",
      "\t\t\t\t\tif stemmed_word in settings.wv:\n",
      "\t\t\t\t\t\tcontext_words.append(stemmed_word)\n",
      "\t\t\t\t\t\tcount += 1\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tcontext_words.append(w)\n",
      "\t\t\t\t\tcount += 1\n",
      "\t\t\t\tif count == 2:\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\tcount = 0\t\t\n",
      "\t\t\tfor w in right_context:\n",
      "\t\t\t\tif w not in settings.wv:\n",
      "\t\t\t\t\tstemmed_word = bangla_stemmer.stemOfWord(w)\n",
      "\t\t\t\t\tif stemmed_word in settings.wv:\n",
      "\t\t\t\t\t\tcontext_words.append(stemmed_word)\n",
      "\t\t\t\t\t\tcount += 1\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tcontext_words.append(w)\n",
      "\t\t\t\t\tcount += 1\n",
      "\t\t\t\tif count == 2:\n",
      "\t\t\t\t\tbreak\n",
      "\t\t\t\n",
      "\t\t\tsuggestions = detect_NonwordError(word, context_words)\n",
      "\t\t\tif suggestions is None:\n",
      "\t\t\t\tisNonWord = False\n",
      "\t\t\t\tsuggestions = detect_RealwordError(word, context_words)\n",
      "\t\t\n",
      "\t\tyield isNonWord, suggestions\n",
      "Output: {'helper': ['re.compile'], 're.compile': [], 'helper.get_edit_distance': ['<builtin>.range', '<builtin>.enumerate', '<builtin>.len', '<builtin>.min'], '<builtin>.len': [], '<builtin>.range': [], '<builtin>.enumerate': [], '<builtin>.min': [], 'helper.get_encoded_word': ['phonetic_encoder.doublemetaphone_encode'], 'phonetic_encoder.doublemetaphone_encode': [], 'helper.weighted_distance': [], 'helper.create_delete_list': ['<builtin>.range', '<builtin>.len', 'helper.create_delete_list'], 'helper.startup': ['helper.create_delete_list', 'os.path.join', '<builtin>.open', '<builtin>.set', 'gensim.models.KeyedVectors.load'], 'os.path.join': [], 'gensim.models.KeyedVectors.load': [], '<builtin>.set': [], '<builtin>.open': [], 'helper.get_confusion_set': ['helper.get_encoded_word', 'helper.create_delete_list', 'helper.get_edit_distance', 'helper.weighted_distance', '<builtin>.len'], 'helper.cosine_similarity_score': ['numpy.array', 'gensim.matutils.unitvec', 'numpy.mean', '<builtin>.len'], 'numpy.array': [], 'numpy.mean': [], 'gensim.matutils.unitvec': [], 'helper.detect_NonwordError': ['helper.get_confusion_set', 'stemmer.bangla_stemmer.bangla_stemmer.stemOfWord', 'helper.cosine_similarity_score', '<builtin>.sorted'], 'stemmer.bangla_stemmer.bangla_stemmer.stemOfWord': [], 'helper.detect_NonwordError.<lambda1>': [], '<builtin>.sorted': [], 'helper.detect_RealwordError': ['helper.cosine_similarity_score', 'stemmer.bangla_stemmer.bangla_stemmer.stemOfWord', '<builtin>.sorted', 'helper.get_confusion_set', '<builtin>.max', '<builtin>.len'], '<builtin>.max': [], 'helper.detect_RealwordError.<lambda1>': [], 'helper.check': ['<builtin>.reversed', '<builtin>.range', 'stemmer.bangla_stemmer.bangla_stemmer.stemOfWord', 'helper.detect_RealwordError', 'helper.detect_NonwordError', '<builtin>.len'], '<builtin>.reversed': []}\n",
      "C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\pritomsaha_Context-sensitive-Bangla-spell-checker\\Bangla-spell_checker\\src\\checker\\helper.py\n",
      "[('helper', 're compile'), ('helper get_encoded_word', 'phonetic_encoder doublemetaphone_encode'), ('helper create_delete_list', 'helper create_delete_list'), ('helper startup', 'helper create_delete_list'), ('helper startup', 'os path join'), ('helper startup', 'gensim models KeyedVectors load'), ('helper get_confusion_set', 'helper get_encoded_word'), ('helper get_confusion_set', 'helper create_delete_list'), ('helper get_confusion_set', 'helper get_edit_distance'), ('helper get_confusion_set', 'helper weighted_distance'), ('helper cosine_similarity_score', 'numpy array'), ('helper cosine_similarity_score', 'gensim matutils unitvec'), ('helper cosine_similarity_score', 'numpy mean'), ('helper detect_NonwordError', 'helper get_confusion_set'), ('helper detect_NonwordError', 'stemmer bangla_stemmer bangla_stemmer stemOfWord'), ('helper detect_NonwordError', 'helper cosine_similarity_score'), ('helper detect_RealwordError', 'helper cosine_similarity_score'), ('helper detect_RealwordError', 'stemmer bangla_stemmer bangla_stemmer stemOfWord'), ('helper detect_RealwordError', 'helper get_confusion_set'), ('helper check', 'stemmer bangla_stemmer bangla_stemmer stemOfWord'), ('helper check', 'helper detect_RealwordError'), ('helper check', 'helper detect_NonwordError')]\n",
      "0\n",
      "********************pycgContent*************************\n",
      "[[('rst2xml', 'locale setlocale'), ('rst2xml', 'docutils core publish_cmdline')], [('rst2html5', 'locale setlocale'), ('rst2html5', 'docutils core publish_cmdline')], [('rst2html', 'docutils core publish_cmdline'), ('rst2html', 'locale setlocale')], [('rst2latex', 'docutils core publish_cmdline'), ('rst2latex', 'locale setlocale')], [('bangla_stemmer', 'bangla_stemmer RuleFileParser stemOfWord'), ('bangla_stemmer', 'bangla_stemmer RuleFileParser __init__'), ('bangla_stemmer RuleFileParser __init__', 'os path abspath'), ('bangla_stemmer RuleFileParser __init__', 'bangla_stemmer RuleFileParser commentTrim'), ('bangla_stemmer RuleFileParser __init__', 'bangla_stemmer RuleFileParser extractReplaceRule'), ('bangla_stemmer RuleFileParser __init__', 'os path dirname'), ('bangla_stemmer RuleFileParser __init__', 're compile'), ('bangla_stemmer RuleFileParser commentTrim', 're sub'), ('bangla_stemmer RuleFileParser check', 're sub'), ('bangla_stemmer RuleFileParser stemOfWord', 're compile'), ('bangla_stemmer RuleFileParser stemOfWord', 'bangla_stemmer RuleFileParser check'), ('bangla_stemmer RuleFileParser stemOfWords', 'bangla_stemmer RuleFileParser stemOfWord')], [('rstpep2html', 'docutils core publish_cmdline'), ('rstpep2html', 'locale setlocale')], [('train', 'logging basicConfig'), ('train', 're compile'), ('train', 'train main'), ('train get_bn_wordlist', 're sub'), ('train Sentences __iter__', 'os listdir'), ('train Sentences __iter__', 'os path join'), ('train Sentences __iter__', 'train get_bn_wordlist'), ('train Sentences __iter__', 'os path isdir'), ('train train', 'gensim models word2vec Word2Vec'), ('train train', 'multiprocessing cpu_count'), ('train train', 'train Sentences __init__'), ('train retrain', 'train Sentences __init__'), ('train retrain', 'gensim models Word2Vec load'), ('train main', 'train train')], [('rst2html4', 'docutils core publish_cmdline'), ('rst2html4', 'locale setlocale')], [('rst2pseudoxml', 'locale setlocale'), ('rst2pseudoxml', 'docutils core publish_cmdline')], [('wsgi', 'django core wsgi get_wsgi_application'), ('wsgi', 'os environ setdefault')], [('create_sentence', 'os listdir'), ('create_sentence', 'os path isdir'), ('create_sentence', 'create_sentence create_sentences'), ('create_sentence create_sentences', 're sub'), ('create_sentence create_sentences', 're split')], [('django-admin', 'django core management execute_from_command_line')], [('sample_train', 'sample_train train'), ('sample_train', 'logging basicConfig'), ('sample_train', 're compile'), ('sample_train get_bn_wordlist', 're sub'), ('sample_train Sentences __iter__', 'sample_train get_bn_wordlist'), ('sample_train train', 'multiprocessing cpu_count'), ('sample_train train', 'gensim models word2vec Word2Vec'), ('sample_train train', 'sample_train Sentences __init__')], [('rst2man', 'docutils core publish_cmdline'), ('rst2man', 'locale setlocale'), ('rst2man', 'docutils writers manpage Writer')], [('helper', 're compile'), ('helper get_encoded_word', 'phonetic_encoder doublemetaphone_encode'), ('helper create_delete_list', 'helper create_delete_list'), ('helper startup', 'helper create_delete_list'), ('helper startup', 'os path join'), ('helper startup', 'gensim models KeyedVectors load'), ('helper get_confusion_set', 'helper get_encoded_word'), ('helper get_confusion_set', 'helper create_delete_list'), ('helper get_confusion_set', 'helper get_edit_distance'), ('helper get_confusion_set', 'helper weighted_distance'), ('helper cosine_similarity_score', 'numpy array'), ('helper cosine_similarity_score', 'gensim matutils unitvec'), ('helper cosine_similarity_score', 'numpy mean'), ('helper detect_NonwordError', 'helper get_confusion_set'), ('helper detect_NonwordError', 'stemmer bangla_stemmer bangla_stemmer stemOfWord'), ('helper detect_NonwordError', 'helper cosine_similarity_score'), ('helper detect_RealwordError', 'helper cosine_similarity_score'), ('helper detect_RealwordError', 'stemmer bangla_stemmer bangla_stemmer stemOfWord'), ('helper detect_RealwordError', 'helper get_confusion_set'), ('helper check', 'stemmer bangla_stemmer bangla_stemmer stemOfWord'), ('helper check', 'helper detect_RealwordError'), ('helper check', 'helper detect_NonwordError')]]\n",
      "********************doctrings*************************\n",
      "['', '', '', '', '', '', 'get bn wordlist train retrain main', '', '', '', 'create sentences', '', 'get bn wordlist train', '', 'get edit distance get encoded word weighted distance create delete list startup get confusion set cosine similarity score detect  onword rror detect  ealword rror check']\n"
     ]
    }
   ],
   "source": [
    "!python ../Topical/compute_embeddings.py --path \"C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "flexible-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python \"C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\Topical\\compute_embeddings.py\" --path \"C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99600f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Computervision' 'Naturallanguageprocessing' 'Reinforcementlearning']\n",
      "13    [[-0.4109915, -0.016310826, -0.017920159, -0.1...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "16    [[-0.33786047, 0.050598882, -0.019305259, -0.1...\n",
      "0     [[-0.31261173, -0.009432742, 0.023866095, -0.0...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "8     [[-0.39955235, 0.016104745, -0.07130942, -0.12...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "1     [[-0.30176756, -0.006085719, 0.025267933, -0.0...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "11    [[-0.4027931, 0.05899366, 0.03296145, -0.06252...\n",
      "Name: dep_emb, dtype: object\n",
      "0     [[-0.31261173, -0.009432742, 0.023866095, -0.0...\n",
      "1     [[-0.30176756, -0.006085719, 0.025267933, -0.0...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "8     [[-0.39955235, 0.016104745, -0.07130942, -0.12...\n",
      "9     [[-0.37348747, 0.04451768, 0.06526425, -0.0601...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "11    [[-0.4027931, 0.05899366, 0.03296145, -0.06252...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "13    [[-0.4109915, -0.016310826, -0.017920159, -0.1...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "16    [[-0.33786047, 0.050598882, -0.019305259, -0.1...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "18    [[-0.45196813, 0.024296911, 0.0024789274, -0.1...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "Name: dep_emb, dtype: object\n",
      "Total param size: 334659\n",
      "{'train_runtime': 0.8716, 'train_samples_per_second': 55.071, 'train_steps_per_second': 27.535, 'train_loss': 0.6749252478281657, 'epoch': 3.0}\n",
      "['Computervision' 'Naturallanguageprocessing' 'Reinforcementlearning']\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "Name: dep_emb, dtype: object\n",
      "0     [[-0.31261173, -0.009432742, 0.023866095, -0.0...\n",
      "1     [[-0.30176756, -0.006085719, 0.025267933, -0.0...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "8     [[-0.39955235, 0.016104745, -0.07130942, -0.12...\n",
      "9     [[-0.37348747, 0.04451768, 0.06526425, -0.0601...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "11    [[-0.4027931, 0.05899366, 0.03296145, -0.06252...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "13    [[-0.4109915, -0.016310826, -0.017920159, -0.1...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "16    [[-0.33786047, 0.050598882, -0.019305259, -0.1...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "18    [[-0.45196813, 0.024296911, 0.0024789274, -0.1...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "Name: dep_emb, dtype: object\n",
      "Total param size: 334659\n",
      "{'train_runtime': 0.851, 'train_samples_per_second': 56.401, 'train_steps_per_second': 28.201, 'train_loss': 0.677680492401123, 'epoch': 3.0}\n",
      "['Computervision' 'Naturallanguageprocessing' 'Reinforcementlearning']\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "Name: dep_emb, dtype: object\n",
      "0     [[-0.31261173, -0.009432742, 0.023866095, -0.0...\n",
      "1     [[-0.30176756, -0.006085719, 0.025267933, -0.0...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "8     [[-0.39955235, 0.016104745, -0.07130942, -0.12...\n",
      "9     [[-0.37348747, 0.04451768, 0.06526425, -0.0601...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "11    [[-0.4027931, 0.05899366, 0.03296145, -0.06252...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "13    [[-0.4109915, -0.016310826, -0.017920159, -0.1...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "16    [[-0.33786047, 0.050598882, -0.019305259, -0.1...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "18    [[-0.45196813, 0.024296911, 0.0024789274, -0.1...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "Name: dep_emb, dtype: object\n",
      "Total param size: 334659\n",
      "{'train_runtime': 0.681, 'train_samples_per_second': 70.484, 'train_steps_per_second': 35.242, 'train_loss': 0.677680492401123, 'epoch': 3.0}\n",
      "['Computervision' 'Naturallanguageprocessing' 'Reinforcementlearning']\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "Name: dep_emb, dtype: object\n",
      "0     [[-0.31261173, -0.009432742, 0.023866095, -0.0...\n",
      "1     [[-0.30176756, -0.006085719, 0.025267933, -0.0...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "8     [[-0.39955235, 0.016104745, -0.07130942, -0.12...\n",
      "9     [[-0.37348747, 0.04451768, 0.06526425, -0.0601...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "11    [[-0.4027931, 0.05899366, 0.03296145, -0.06252...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "13    [[-0.4109915, -0.016310826, -0.017920159, -0.1...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "16    [[-0.33786047, 0.050598882, -0.019305259, -0.1...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "18    [[-0.45196813, 0.024296911, 0.0024789274, -0.1...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "Name: dep_emb, dtype: object\n",
      "Total param size: 334659\n",
      "{'train_runtime': 0.7437, 'train_samples_per_second': 64.543, 'train_steps_per_second': 32.272, 'train_loss': 0.677680492401123, 'epoch': 3.0}\n",
      "['Computervision' 'Naturallanguageprocessing' 'Reinforcementlearning']\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "Name: dep_emb, dtype: object\n",
      "0     [[-0.31261173, -0.009432742, 0.023866095, -0.0...\n",
      "1     [[-0.30176756, -0.006085719, 0.025267933, -0.0...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "8     [[-0.39955235, 0.016104745, -0.07130942, -0.12...\n",
      "9     [[-0.37348747, 0.04451768, 0.06526425, -0.0601...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "11    [[-0.4027931, 0.05899366, 0.03296145, -0.06252...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "13    [[-0.4109915, -0.016310826, -0.017920159, -0.1...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "16    [[-0.33786047, 0.050598882, -0.019305259, -0.1...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "18    [[-0.45196813, 0.024296911, 0.0024789274, -0.1...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "Name: dep_emb, dtype: object\n",
      "Total param size: 334659\n",
      "{'train_runtime': 0.6645, 'train_samples_per_second': 72.239, 'train_steps_per_second': 36.119, 'train_loss': 0.677680492401123, 'epoch': 3.0}\n",
      "['Computervision' 'Naturallanguageprocessing' 'Reinforcementlearning']\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "Name: dep_emb, dtype: object\n",
      "0     [[-0.31261173, -0.009432742, 0.023866095, -0.0...\n",
      "1     [[-0.30176756, -0.006085719, 0.025267933, -0.0...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "8     [[-0.39955235, 0.016104745, -0.07130942, -0.12...\n",
      "9     [[-0.37348747, 0.04451768, 0.06526425, -0.0601...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "11    [[-0.4027931, 0.05899366, 0.03296145, -0.06252...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "13    [[-0.4109915, -0.016310826, -0.017920159, -0.1...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "16    [[-0.33786047, 0.050598882, -0.019305259, -0.1...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "18    [[-0.45196813, 0.024296911, 0.0024789274, -0.1...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "Name: dep_emb, dtype: object\n",
      "Total param size: 334659\n",
      "{'train_runtime': 0.68, 'train_samples_per_second': 70.587, 'train_steps_per_second': 35.293, 'train_loss': 0.677680492401123, 'epoch': 3.0}\n",
      "['Computervision' 'Naturallanguageprocessing' 'Reinforcementlearning']\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "Name: dep_emb, dtype: object\n",
      "0     [[-0.31261173, -0.009432742, 0.023866095, -0.0...\n",
      "1     [[-0.30176756, -0.006085719, 0.025267933, -0.0...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "8     [[-0.39955235, 0.016104745, -0.07130942, -0.12...\n",
      "9     [[-0.37348747, 0.04451768, 0.06526425, -0.0601...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "11    [[-0.4027931, 0.05899366, 0.03296145, -0.06252...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "13    [[-0.4109915, -0.016310826, -0.017920159, -0.1...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "16    [[-0.33786047, 0.050598882, -0.019305259, -0.1...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "18    [[-0.45196813, 0.024296911, 0.0024789274, -0.1...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "Name: dep_emb, dtype: object\n",
      "Total param size: 334659\n",
      "{'train_runtime': 0.6544, 'train_samples_per_second': 73.35, 'train_steps_per_second': 36.675, 'train_loss': 0.677680492401123, 'epoch': 3.0}\n",
      "['Computervision' 'Naturallanguageprocessing' 'Reinforcementlearning']\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "Name: dep_emb, dtype: object\n",
      "0     [[-0.31261173, -0.009432742, 0.023866095, -0.0...\n",
      "1     [[-0.30176756, -0.006085719, 0.025267933, -0.0...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "8     [[-0.39955235, 0.016104745, -0.07130942, -0.12...\n",
      "9     [[-0.37348747, 0.04451768, 0.06526425, -0.0601...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "11    [[-0.4027931, 0.05899366, 0.03296145, -0.06252...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "13    [[-0.4109915, -0.016310826, -0.017920159, -0.1...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "16    [[-0.33786047, 0.050598882, -0.019305259, -0.1...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "18    [[-0.45196813, 0.024296911, 0.0024789274, -0.1...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "Name: dep_emb, dtype: object\n",
      "Total param size: 334659\n",
      "{'train_runtime': 0.6559, 'train_samples_per_second': 73.181, 'train_steps_per_second': 36.59, 'train_loss': 0.677680492401123, 'epoch': 3.0}\n",
      "['Computervision' 'Naturallanguageprocessing' 'Reinforcementlearning']\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "Name: dep_emb, dtype: object\n",
      "0     [[-0.31261173, -0.009432742, 0.023866095, -0.0...\n",
      "1     [[-0.30176756, -0.006085719, 0.025267933, -0.0...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "8     [[-0.39955235, 0.016104745, -0.07130942, -0.12...\n",
      "9     [[-0.37348747, 0.04451768, 0.06526425, -0.0601...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "11    [[-0.4027931, 0.05899366, 0.03296145, -0.06252...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "13    [[-0.4109915, -0.016310826, -0.017920159, -0.1...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "16    [[-0.33786047, 0.050598882, -0.019305259, -0.1...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "18    [[-0.45196813, 0.024296911, 0.0024789274, -0.1...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "Name: dep_emb, dtype: object\n",
      "Total param size: 334659\n",
      "{'train_runtime': 0.6679, 'train_samples_per_second': 71.863, 'train_steps_per_second': 35.931, 'train_loss': 0.677680492401123, 'epoch': 3.0}\n",
      "['Computervision' 'Naturallanguageprocessing' 'Reinforcementlearning']\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "Name: dep_emb, dtype: object\n",
      "0     [[-0.31261173, -0.009432742, 0.023866095, -0.0...\n",
      "1     [[-0.30176756, -0.006085719, 0.025267933, -0.0...\n",
      "2     [[-0.34484053, 0.07757525, 0.099213414, -0.133...\n",
      "3     [[-0.3224294, -0.06069673, 0.031981442, -0.034...\n",
      "4     [[-0.28782058, 0.022182493, 0.04987477, -0.077...\n",
      "5     [[-0.36026767, 0.004909549, 0.03169379, -0.091...\n",
      "6     [[-0.3464192, -0.03966223, 0.017525703, -0.072...\n",
      "7     [[-0.27429277, -0.019385416, 0.07479653, -0.01...\n",
      "8     [[-0.39955235, 0.016104745, -0.07130942, -0.12...\n",
      "9     [[-0.37348747, 0.04451768, 0.06526425, -0.0601...\n",
      "10    [[-0.34837472, 0.06516314, 0.058723573, -0.123...\n",
      "11    [[-0.4027931, 0.05899366, 0.03296145, -0.06252...\n",
      "12    [[-0.42427683, 0.037113145, 0.04993995, -0.092...\n",
      "13    [[-0.4109915, -0.016310826, -0.017920159, -0.1...\n",
      "14    [[-0.4231194, 0.043938413, -0.014690474, -0.07...\n",
      "15    [[-0.2853701, -0.0722348, 0.057012536, -0.0788...\n",
      "16    [[-0.33786047, 0.050598882, -0.019305259, -0.1...\n",
      "17    [[-0.40412623, 0.0369958, 0.069391035, -0.0750...\n",
      "18    [[-0.45196813, 0.024296911, 0.0024789274, -0.1...\n",
      "19    [[-0.4150287, 0.06596557, 0.013919979, -0.1113...\n",
      "20    [[-0.26347768, -0.053023428, -0.026331984, -0....\n",
      "21    [[-0.3799924, 0.045927793, 0.058055434, -0.064...\n",
      "22    [[-0.29694808, 0.044561177, 0.1119708, -0.1226...\n",
      "23    [[-0.3208446, -0.043916352, 0.035990763, -0.09...\n",
      "Name: dep_emb, dtype: object\n",
      "Total param size: 334659\n",
      "{'train_runtime': 0.6564, 'train_samples_per_second': 73.125, 'train_steps_per_second': 36.563, 'train_loss': 0.677680492401123, 'epoch': 3.0}\n",
      "results saved to:  C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[Model hyperparams]: Namespace(batch_size=2, bi=True, clip=5, cuda=True, dataset='C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\\\\\resources.pkl', drop=0, emsize=192, epochs=3, fine=False, hidden=96, k=10, lr=0.002, model='GRU', n_pca_comp=192, nlayers=2, repo_size=15, topics=['Computervision', 'Reinforcementlearning', 'Naturallanguageprocessing'])\n",
      "INFO:root:run 0\n",
      "INFO:root:Fitting PCA with 64 each\n",
      "INFO:root:Number of labels: 3\n",
      "INFO:root:Model 0 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 16 training samples\n",
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\n",
      " 12%|        | 3/24 [00:00<00:00, 27.57it/s]\n",
      " 29%|       | 7/24 [00:00<00:00, 29.44it/s]\n",
      " 42%|     | 10/24 [00:00<00:00, 28.52it/s]\n",
      " 58%|    | 14/24 [00:00<00:00, 29.01it/s]\n",
      " 71%|   | 17/24 [00:00<00:00, 26.69it/s]\n",
      " 88%| | 21/24 [00:00<00:00, 27.89it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 24/24 [00:00<00:00, 27.89it/s]\n",
      "100%|| 24/24 [00:00<00:00, 27.89it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n",
      "INFO:root:run 1\n",
      "INFO:root:Fitting PCA with 64 each\n",
      "INFO:root:Number of labels: 3\n",
      "INFO:root:Model 1 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 16 training samples\n",
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\n",
      " 12%|        | 3/24 [00:00<00:00, 28.35it/s]\n",
      " 29%|       | 7/24 [00:00<00:00, 29.40it/s]\n",
      " 42%|     | 10/24 [00:00<00:00, 28.05it/s]\n",
      " 54%|    | 13/24 [00:00<00:00, 28.50it/s]\n",
      " 71%|   | 17/24 [00:00<00:00, 28.11it/s]\n",
      " 88%| | 21/24 [00:00<00:00, 29.08it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 24/24 [00:00<00:00, 29.08it/s]\n",
      "100%|| 24/24 [00:00<00:00, 28.59it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n",
      "INFO:root:run 2\n",
      "INFO:root:Fitting PCA with 64 each\n",
      "INFO:root:Number of labels: 3\n",
      "INFO:root:Model 2 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 16 training samples\n",
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\n",
      " 21%|        | 5/24 [00:00<00:00, 41.37it/s]\n",
      " 38%|      | 9/24 [00:00<00:00, 38.60it/s]\n",
      " 58%|    | 14/24 [00:00<00:00, 39.07it/s]\n",
      " 71%|   | 17/24 [00:00<00:00, 35.72it/s]\n",
      " 92%|| 22/24 [00:00<00:00, 37.08it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 24/24 [00:00<00:00, 37.08it/s]\n",
      "100%|| 24/24 [00:00<00:00, 35.82it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n",
      "INFO:root:run 3\n",
      "INFO:root:Fitting PCA with 64 each\n",
      "INFO:root:Number of labels: 3\n",
      "INFO:root:Model 3 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 16 training samples\n",
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\n",
      " 17%|        | 4/24 [00:00<00:00, 38.35it/s]\n",
      " 33%|      | 8/24 [00:00<00:00, 37.91it/s]\n",
      " 42%|     | 10/24 [00:00<00:00, 26.14it/s]\n",
      " 62%|   | 15/24 [00:00<00:00, 29.60it/s]\n",
      " 79%|  | 19/24 [00:00<00:00, 30.60it/s]\n",
      "100%|| 24/24 [00:00<00:00, 33.33it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 24/24 [00:00<00:00, 33.33it/s]\n",
      "100%|| 24/24 [00:00<00:00, 32.76it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n",
      "INFO:root:run 4\n",
      "INFO:root:Fitting PCA with 64 each\n",
      "INFO:root:Number of labels: 3\n",
      "INFO:root:Model 4 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 16 training samples\n",
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\n",
      " 21%|        | 5/24 [00:00<00:00, 42.61it/s]\n",
      " 38%|      | 9/24 [00:00<00:00, 39.52it/s]\n",
      " 58%|    | 14/24 [00:00<00:00, 40.74it/s]\n",
      " 75%|  | 18/24 [00:00<00:00, 37.83it/s]\n",
      " 96%|| 23/24 [00:00<00:00, 39.06it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 24/24 [00:00<00:00, 39.06it/s]\n",
      "100%|| 24/24 [00:00<00:00, 36.73it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n",
      "INFO:root:run 5\n",
      "INFO:root:Fitting PCA with 64 each\n",
      "INFO:root:Number of labels: 3\n",
      "INFO:root:Model 5 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 16 training samples\n",
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\n",
      " 21%|        | 5/24 [00:00<00:00, 41.89it/s]\n",
      " 38%|      | 9/24 [00:00<00:00, 38.24it/s]\n",
      " 58%|    | 14/24 [00:00<00:00, 39.50it/s]\n",
      " 71%|   | 17/24 [00:00<00:00, 35.39it/s]\n",
      " 92%|| 22/24 [00:00<00:00, 37.37it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 24/24 [00:00<00:00, 37.37it/s]\n",
      "100%|| 24/24 [00:00<00:00, 35.90it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n",
      "INFO:root:run 6\n",
      "INFO:root:Fitting PCA with 64 each\n",
      "INFO:root:Number of labels: 3\n",
      "INFO:root:Model 6 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 16 training samples\n",
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\n",
      " 21%|        | 5/24 [00:00<00:00, 43.35it/s]\n",
      " 38%|      | 9/24 [00:00<00:00, 39.43it/s]\n",
      " 58%|    | 14/24 [00:00<00:00, 40.43it/s]\n",
      " 71%|   | 17/24 [00:00<00:00, 36.51it/s]\n",
      " 92%|| 22/24 [00:00<00:00, 38.77it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 24/24 [00:00<00:00, 38.77it/s]\n",
      "100%|| 24/24 [00:00<00:00, 37.36it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n",
      "INFO:root:run 7\n",
      "INFO:root:Fitting PCA with 64 each\n",
      "INFO:root:Number of labels: 3\n",
      "INFO:root:Model 7 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 16 training samples\n",
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\n",
      " 21%|        | 5/24 [00:00<00:00, 43.35it/s]\n",
      " 38%|      | 9/24 [00:00<00:00, 39.78it/s]\n",
      " 58%|    | 14/24 [00:00<00:00, 40.35it/s]\n",
      " 75%|  | 18/24 [00:00<00:00, 38.02it/s]\n",
      " 96%|| 23/24 [00:00<00:00, 39.38it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 24/24 [00:00<00:00, 39.38it/s]\n",
      "100%|| 24/24 [00:00<00:00, 37.25it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n",
      "INFO:root:run 8\n",
      "INFO:root:Fitting PCA with 64 each\n",
      "INFO:root:Number of labels: 3\n",
      "INFO:root:Model 8 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 16 training samples\n",
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\n",
      " 21%|        | 5/24 [00:00<00:00, 42.79it/s]\n",
      " 38%|      | 9/24 [00:00<00:00, 39.11it/s]\n",
      " 58%|    | 14/24 [00:00<00:00, 40.44it/s]\n",
      " 71%|   | 17/24 [00:00<00:00, 36.38it/s]\n",
      " 92%|| 22/24 [00:00<00:00, 37.83it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 24/24 [00:00<00:00, 37.83it/s]\n",
      "100%|| 24/24 [00:00<00:00, 36.62it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n",
      "INFO:root:run 9\n",
      "INFO:root:Fitting PCA with 64 each\n",
      "INFO:root:Number of labels: 3\n",
      "INFO:root:Model 9 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 16 training samples\n",
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]\n",
      " 21%|        | 5/24 [00:00<00:00, 41.37it/s]\n",
      " 38%|      | 9/24 [00:00<00:00, 38.71it/s]\n",
      " 58%|    | 14/24 [00:00<00:00, 39.85it/s]\n",
      " 75%|  | 18/24 [00:00<00:00, 38.04it/s]\n",
      " 96%|| 23/24 [00:00<00:00, 39.35it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 24/24 [00:00<00:00, 39.35it/s]\n",
      "100%|| 24/24 [00:00<00:00, 37.25it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n"
     ]
    }
   ],
   "source": [
    "!python \"C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\Topical\\\\run.py\" --dataset \"C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\\\resources.pkl\" --topics \"Computervision\" \"Reinforcementlearning\" \"Naturallanguageprocessing\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "colored-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LRAP: 0.546 (0.075)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recall: 0.983 (0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision: 0.386 (0.008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1-score: 0.543 (0.014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>threshold: 0.045 (0.136)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>support: 6.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>------------------------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LRAP: 0.54 (0.056)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>recall: 1.0 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>precision: 0.389 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f1-score: 0.548 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>threshold: 0.0 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>support: 6.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>------------------------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LRAP: 0.55 (0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recall: 1.0 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>precision: 0.414 (0.075)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>f1-score: 0.564 (0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>threshold: 0.044 (0.133)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>support: 6.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>------------------------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LRAP: 0.479 (0.063)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>recall: 1.0 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>precision: 0.389 (0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>f1-score: 0.548 (0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>threshold: 0.042 (0.127)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>support: 6.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>------------------------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LRAP: 0.608 (0.013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>recall: 1.0 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>precision: 0.389 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>f1-score: 0.548 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>threshold: 0.0 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>support: 6.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>------------------------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LRAP: 0.508 (0.087)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>recall: 1.0 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>precision: 0.389 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>f1-score: 0.548 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>threshold: 0.0 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>support: 6.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>------------------------</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LRAP: 0.546 (0.075)\n",
       "0       recall: 0.983 (0.05)\n",
       "1   precision: 0.386 (0.008)\n",
       "2    f1-score: 0.543 (0.014)\n",
       "3   threshold: 0.045 (0.136)\n",
       "4              support: 6.0)\n",
       "5   ------------------------\n",
       "6         LRAP: 0.54 (0.056)\n",
       "7          recall: 1.0 (0.0)\n",
       "8     precision: 0.389 (0.0)\n",
       "9      f1-score: 0.548 (0.0)\n",
       "10      threshold: 0.0 (0.0)\n",
       "11             support: 6.0)\n",
       "12  ------------------------\n",
       "13        LRAP: 0.55 (0.025)\n",
       "14         recall: 1.0 (0.0)\n",
       "15  precision: 0.414 (0.075)\n",
       "16    f1-score: 0.564 (0.05)\n",
       "17  threshold: 0.044 (0.133)\n",
       "18             support: 6.0)\n",
       "19  ------------------------\n",
       "20       LRAP: 0.479 (0.063)\n",
       "21         recall: 1.0 (0.0)\n",
       "22  precision: 0.389 (0.002)\n",
       "23   f1-score: 0.548 (0.002)\n",
       "24  threshold: 0.042 (0.127)\n",
       "25             support: 6.0)\n",
       "26  ------------------------\n",
       "27       LRAP: 0.608 (0.013)\n",
       "28         recall: 1.0 (0.0)\n",
       "29    precision: 0.389 (0.0)\n",
       "30     f1-score: 0.548 (0.0)\n",
       "31      threshold: 0.0 (0.0)\n",
       "32             support: 6.0)\n",
       "33  ------------------------\n",
       "34       LRAP: 0.508 (0.087)\n",
       "35         recall: 1.0 (0.0)\n",
       "36    precision: 0.389 (0.0)\n",
       "37     f1-score: 0.548 (0.0)\n",
       "38      threshold: 0.0 (0.0)\n",
       "39             support: 6.0)\n",
       "40  ------------------------"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\\\results_datasize.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c689a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['repo', 'labels', 'dep_emb', 'docstring_emb', 'code_emb'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "df = pkl.load(open(\"C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\\\resources.pkl\",'rb'))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a01c58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "Index(['repo', 'labels', 'dep_emb', 'docstring_emb', 'code_emb'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "path = \"C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\\\resources.pkl\"\n",
    "dataset = pd.read_pickle(path)\n",
    "print(len(dataset))\n",
    "topics = [\"'Computervision'\", \"'Reinforcementlearning'\", \"'Naturallanguageprocessing'\"]\n",
    "\n",
    "def topics_dataset(topics: str, dataset: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for i, row in dataset.iterrows():\n",
    "        if isinstance(row[\"labels\"], str):\n",
    "            row[\"labels\"] = ast.literal_eval(row[\"labels\"])\n",
    "        else:\n",
    "            pass\n",
    "        intersection = set(topics).intersection(set(row[\"labels\"]))\n",
    "        if len(intersection) > 0:\n",
    "            row[\"labels\"] = list(intersection)\n",
    "            rows.append(row)\n",
    "        filtered_dataset = pd.DataFrame(rows)\n",
    "    return filtered_dataset\n",
    "\n",
    "dataset2 = topics_dataset(topics, dataset)\n",
    "print(dataset.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae4af676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 24\n",
      "Total param size: 94185\n",
      "{'train_runtime': 0.854, 'train_samples_per_second': 73.77, 'train_steps_per_second': 38.642, 'train_loss': 0.6925727381850734, 'epoch': 3.0}\n",
      "{'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '1': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '4': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '6': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1}, '7': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1}, '8': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2}, 'micro avg': {'precision': 0.3333333333333333, 'recall': 1.0, 'f1-score': 0.5, 'support': 6}, 'macro avg': {'precision': 0.3333333333333333, 'recall': 0.5555555555555556, 'f1-score': 0.4074074074074074, 'support': 6}, 'weighted avg': {'precision': 0.6666666666666666, 'recall': 1.0, 'f1-score': 0.7777777777777777, 'support': 6}, 'samples avg': {'precision': 0.3333333333333333, 'recall': 1.0, 'f1-score': 0.4895104895104895, 'support': 6}, 'lrap': 0.5357142857142857, 'optimized_threshold': 0.0}\n",
      "21 24\n",
      "Total param size: 94282\n",
      "{'train_runtime': 0.8395, 'train_samples_per_second': 75.048, 'train_steps_per_second': 39.311, 'train_loss': 0.6803299296985973, 'epoch': 3.0}\n",
      "{'0': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '8': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'micro avg': {'precision': 0.1, 'recall': 1.0, 'f1-score': 0.18181818181818182, 'support': 2}, 'macro avg': {'precision': 0.1, 'recall': 0.2, 'f1-score': 0.13333333333333333, 'support': 2}, 'weighted avg': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 2}, 'samples avg': {'precision': 0.1, 'recall': 1.0, 'f1-score': 0.18181818181818182, 'support': 2}, 'lrap': 0.6166666666666667, 'optimized_threshold': 0.0}\n",
      "21 24\n",
      "Total param size: 94282\n",
      "{'train_runtime': 0.8691, 'train_samples_per_second': 72.492, 'train_steps_per_second': 37.972, 'train_loss': 0.6803299296985973, 'epoch': 3.0}\n",
      "{'0': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '8': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'micro avg': {'precision': 0.1, 'recall': 1.0, 'f1-score': 0.18181818181818182, 'support': 2}, 'macro avg': {'precision': 0.1, 'recall': 0.2, 'f1-score': 0.13333333333333333, 'support': 2}, 'weighted avg': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 2}, 'samples avg': {'precision': 0.1, 'recall': 1.0, 'f1-score': 0.18181818181818182, 'support': 2}, 'lrap': 0.6166666666666667, 'optimized_threshold': 0.0}\n",
      "21 24\n",
      "Total param size: 94282\n",
      "{'train_runtime': 0.7116, 'train_samples_per_second': 88.535, 'train_steps_per_second': 46.375, 'train_loss': 0.6803299296985973, 'epoch': 3.0}\n",
      "{'0': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, '8': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'micro avg': {'precision': 0.1, 'recall': 1.0, 'f1-score': 0.18181818181818182, 'support': 2}, 'macro avg': {'precision': 0.1, 'recall': 0.2, 'f1-score': 0.13333333333333333, 'support': 2}, 'weighted avg': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 2}, 'samples avg': {'precision': 0.1, 'recall': 1.0, 'f1-score': 0.18181818181818182, 'support': 2}, 'lrap': 0.6166666666666667, 'optimized_threshold': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[Model hyperparams]: Namespace(batch_size=2, bi=True, clip=5, cuda=True, dataset='C:\\\\JPMC\\\\DEV\\\\TMP\\\\ds\\\\Topical\\\\senatus-code-s4\\\\examples\\\\dataset\\\\\\\\resources.pkl', drop=0, emsize=192, epochs=4, fine=False, hidden=48, k=4, lr=0.001, model='GRU', n_cca_comp=128, n_pca_comp=128, nlayers=2, repo_size=15)\n",
      "INFO:root:run 0\n",
      "INFO:root:Fitting PCA with 128 each\n",
      "INFO:root:Number of labels: 9\n",
      "INFO:root:Model 0 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 21 training samples\n",
      "\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]\n",
      " 12%|        | 4/33 [00:00<00:00, 39.88it/s]\n",
      " 27%|       | 9/33 [00:00<00:00, 40.76it/s]\n",
      " 39%|      | 13/33 [00:00<00:00, 38.50it/s]\n",
      " 55%|    | 18/33 [00:00<00:00, 39.18it/s]\n",
      " 70%|   | 23/33 [00:00<00:00, 39.67it/s]\n",
      " 85%| | 28/33 [00:00<00:00, 41.31it/s]\n",
      "100%|| 33/33 [00:00<00:00, 41.23it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 33/33 [00:00<00:00, 41.23it/s]\n",
      "100%|| 33/33 [00:00<00:00, 39.36it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n",
      "INFO:root:run 1\n",
      "INFO:root:Fitting PCA with 128 each\n",
      "INFO:root:Number of labels: 10\n",
      "INFO:root:Model 1 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 21 training samples\n",
      "\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]\n",
      " 18%|        | 6/33 [00:00<00:00, 50.06it/s]\n",
      " 33%|      | 11/33 [00:00<00:00, 48.12it/s]\n",
      " 45%|     | 15/33 [00:00<00:00, 42.55it/s]\n",
      " 61%|    | 20/33 [00:00<00:00, 42.35it/s]\n",
      " 73%|  | 24/33 [00:00<00:00, 39.84it/s]\n",
      " 88%| | 29/33 [00:00<00:00, 40.24it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 33/33 [00:00<00:00, 40.24it/s]\n",
      "100%|| 33/33 [00:00<00:00, 40.15it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n",
      "INFO:root:run 2\n",
      "INFO:root:Fitting PCA with 128 each\n",
      "INFO:root:Number of labels: 10\n",
      "INFO:root:Model 2 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 21 training samples\n",
      "\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]\n",
      " 15%|        | 5/33 [00:00<00:00, 46.59it/s]\n",
      " 30%|       | 10/33 [00:00<00:00, 45.14it/s]\n",
      " 42%|     | 14/33 [00:00<00:00, 41.01it/s]\n",
      " 58%|    | 19/33 [00:00<00:00, 39.79it/s]\n",
      " 70%|   | 23/33 [00:00<00:00, 37.35it/s]\n",
      " 85%| | 28/33 [00:00<00:00, 38.88it/s]\n",
      "100%|| 33/33 [00:00<00:00, 40.07it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 33/33 [00:00<00:00, 40.07it/s]\n",
      "100%|| 33/33 [00:00<00:00, 38.51it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n",
      "INFO:root:run 3\n",
      "INFO:root:Fitting PCA with 128 each\n",
      "INFO:root:Number of labels: 10\n",
      "INFO:root:Model 3 initiated\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "INFO:root:Beginning training phase on: 21 training samples\n",
      "\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]\n",
      " 18%|        | 6/33 [00:00<00:00, 54.14it/s]\n",
      " 36%|      | 12/33 [00:00<00:00, 50.51it/s]\n",
      " 55%|    | 18/33 [00:00<00:00, 51.41it/s]\n",
      " 70%|   | 23/33 [00:00<00:00, 47.92it/s]\n",
      " 88%| | 29/33 [00:00<00:00, 49.45it/s]\n",
      "                                               \n",
      "\n",
      "100%|| 33/33 [00:00<00:00, 49.45it/s]\n",
      "100%|| 33/33 [00:00<00:00, 47.17it/s]\n",
      "INFO:root:Beginning testing\n",
      "INFO:root:Selected threshold: 0.0\n"
     ]
    }
   ],
   "source": [
    "!python \"C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\Topical\\\\tagging_task.py\" --dataset \"C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\examples\\dataset\\\\resources.pkl\" --n_pca_comp 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e978a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\jpmc\\dev\\tmp\\ds\\tools\\python3.7\\3.7.9.ds2\\python.exe: can't open file 'api/github_crawler.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python \"C:\\JPMC\\DEV\\TMP\\ds\\Topical\\senatus-code-s4\\crawlerapi/github_crawler.py\" --topics \"topics.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3edad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rules based stuff for compliance\n",
    "# OAS file generated without any OAuth2 -> -> run through deterministic rule set -> fails -> Ask ChatGPT to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a43acd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eef2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23c0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32cc51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('Topical': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4fe31c9dcacfa8262380ac7c2dd9e8b600b61555afdc601d885f595e3d3fe410"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
